% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={My R Codes for Data Analysis},
  pdfauthor={Serdar Balcƒ±},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{My R Codes for Data Analysis}
\author{Serdar Balcƒ±}
\date{\texttt{\{r\ Sys.Date()}}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

\texttt{\textbackslash{}n\{r\ echo=TRUE\}\ \#\ install.packages(\ bookdown\ )\ \#\ or\ the\ development\ version\ \#\ devtools::install\_github(\ rstudio/bookdown\ )}

\texttt{\textbackslash{}n\{r\ echo=TRUE\}\ \#\ automatically\ create\ a\ bib\ database\ for\ R\ packages\ knitr::write\_bib(c(\ \ \ .packages(),\ \textquotesingle{}bookdown\textquotesingle{},\ \textquotesingle{}knitr\textquotesingle{},\ \textquotesingle{}rmarkdown\textquotesingle{}\ ),\ \textquotesingle{}bib/packages.bib\textquotesingle{})}

UNDER CONSTRUCTION üõ†‚õîÔ∏è‚ö†Ô∏èüî©

This repository is a draft version of many different codes. Organizing
them will take some time. That is why I have started a template
repository on GitHub.

\url{https://github.com/sbalci/histopathology-template/}\\
\url{https://sbalci.github.io/histopathology-template/}

These templates will allow me to make histopathology research data
analysis easier and more standard.

--

Bir sonraki R-project sunumuna ≈üu linkten belirtilen g√ºn ve saatte
eri≈üebilirsiniz.

Bir sonraki sunum:\\
R, RStudio ve RMarkdown ile Tekrarlanabilir Rapor\\
Join Zoom Meeting\\
\url{https://us04web.zoom.us/j/808337924}~\\
Meeting ID: 808 337 924

Sunum linkleri:\\
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.nb.html}~\\
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.html}

25 Eyl√ºl 2019\\
\url{https://youtu.be/GZ85WE9f2R0}~\\
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.html}~\\
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.nb.html}

Anonim Geri Bildirim:\\
\url{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}

\hypertarget{lecture-notes}{%
\chapter{Lecture Notes}\label{lecture-notes}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\href{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.nb.html}{R-Giris}
\href{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.html}{R-Giris
Sunum}

\href{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Arayuzler.nb.html}{R-Arayuzler}

\href{https://sbalci.github.io/MyRCodesForDataAnalysis/WhereToLearnR.nb.html}{Where To Learn
R}

\hypertarget{use-r-markdown}{%
\section{Use R Markdown}\label{use-r-markdown}}

\href{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.nb.html}{R-Markdown}

\href{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.html}{R-Markdown
Sunum}

--

\hypertarget{my-r-codes-for-data-analysis}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis}}

In this repository I am going to collect \texttt{R\ codes} for data analysis.

The title says ``My R Codes'' but I am only the collector. I will try to
refer the original sources as far as I can. \href{https://www.serdarbalci.com/}{Serdar Balci, MD,
Pathologist}

\textbf{My aim} is to collect all the codes one needs, where one starts with
an excel or spss file and then end with the most common analysis used in
histopathology papers : \emph{\href{https://media.nature.com/original/nature-assets/modpathol/journal/v31/n1/extref/modpathol2017106x4.docx}{example
table}}

There are plenty of ways to do an analysis in \texttt{R}, which is great but
also confusing for the newbies. I will collect the codes here so that I
can refer later and then update them as I learn more.

\textbf{See the links for the Codes below:}

--

WorldBankCountryAnalysis.R 1 cards.R 2 .R 3 GABAHip.R 4
googleCite.R 5 makenames.R 6 R-Program-Env-1-2.R 8 SurvivalAnalysis.R 9
SurvivalAnalysisR.R 10 tangram.R 11 TurkPathScholar.R deneme.R
geom\_bartext.R gilbert-dahl.R GitHubUpdateV2.R
join-animations-with-gganimate.R plumber.R plumberRun.R
power\_multiplot.R quRan-data-raw-clean\_data.R
Retrieve\_pubmed\_citation\_data.R sf\_transitions.R silge.R

--

12 ArticlesPerJournalsPerCountry.Rmd 13 CountryBasedComparison.Rmd 14
JournalWatchPBPath.Rmd 15
MeSH\_Terms\_Pathology\_Articles\_From\_Turkey.Rmd 16 6-tables.Rmd
arsenal.Rmd AutomatedDashboardDeviation.Rmd Autoreport.Rmd bbplot.Rmd
Bibliography.Rmd bioconductor.Rmd Biyoinformatik.Rmd CancerInSilico.Rmd
CancerPackages.Rmd CloudForResearch.Rmd codes.Rmd CompareMeans.Rmd
CompareProportions.Rmd ContingencyTables.Rmd Correlations.Rmd
DataList.Rmd DataScienceLiveBook.Rmd datatable.Rmd DataTools.Rmd
DecisionTreeKararAgaci.Rmd DescriptiveStatistics.Rmd drive.Rmd
edirect-addin.Rmd eurostat.Rmd EvidenceSynthesisProjects.Rmd
ExplatoryDataAnalysisSummaryStatistics.Rmd FileOrganization.Rmd
finalfit.Rmd finalfit2.Rmd FlippingCoin.Rmd formattable.Rmd Formulas.Rmd
GeneralLinearModels.Rmd GeneralResources.Rmd GettingDataVeriYukleme.Rmd
GitHub.Rmd githubdocument.Rmd googledrive-trial.Rmd GoogleScholar.Rmd
Graphs.Rmd h2o.Rmd HierarchicalClustering.Rmd
HistopathologyResearchTemplate.Rmd How-To-Use-R-With-Excel.Rmd
htmlclean.Rmd htmldocco.Rmd huxtable.Rmd HypothesisTesting.Rmd keras.Rmd
KMeansClustering.Rmd lessR.Rmd LinearRegression.Rmd MachineLearning.Rmd
material.Rmd MultiplePages.Rmd mxnet.Rmd news.Rmd Ninja.Rmd OpenCPU.Rmd
papeR.Rmd papeR2.Rmd Power\_Analysis.Rmd power.Rmd PowerAnalysis.Rmd
PrepareData.Rmd PythonPandas.Rmd R-Arayuzler.Rmd R-Giris.Rmd R-Tipps.Rmd
radix.Rmd rchess.Rmd readthedown.Rmd Regression.Rmd reprex.Rmd
ReproducibleResearch.Rmd RISmed.Rmd RinPathologyResearch.Rmd
rmarkdown\_websites\_tutorial.Rmd rmarkdown\_websites\_tutorial2.Rmd
ROC.Rmd rorcid.Rmd RPackagesUsed.Rmd SankeyDiagrams.Rmd
SensitivitySpecificity.Rmd shiny.Rmd ShinyCodes.Rmd snahelper.Rmd
summarytools\_introduction.Rmd summarytools\_markdown.Rmd
survival\_analysis\_in\_r\_tutorial.Rmd
survival\_analysis\_in\_r\_tutorial2.Rmd SurvivalAnalysis.Rmd
SyncingGitHubFork.Rmd Table.Rmd tensorflow.Rmd TextMining.Rmd
the-lesser-known-stars-of-the-tidyverse.Rmd tuftedoc.Rmd Tutorials.Rmd
tweetbook1.Rmd Twitter.Rmd TwitterDashboard.Rmd Untitled1.Rmd
Untitled22.Rmd VisualisationGraphsPlots.Rmd WebScrapping.Rmd
WhereToLearnR.Rmd

--

\hypertarget{getting-data-into-r-veriyi-ra-yuxfckleme}{%
\chapter{Getting Data into R / Veriyi R'a y√ºkleme}\label{getting-data-into-r-veriyi-ra-yuxfckleme}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/GettingDataVeriYukleme.nb.html}

\begin{itemize}
\tightlist
\item
  Import Data

  \begin{itemize}
  \tightlist
  \item
    Import using RStudio
  \item
    Import CSV File
  \item
    Import TXT File
  \item
    Import Excel File

    \begin{itemize}
    \tightlist
    \item
      Import Sheets
    \end{itemize}
  \item
    Import SPSS File
  \end{itemize}
\item
  Export Data

  \begin{itemize}
  \tightlist
  \item
    Export to SPSS, while keeping labels
  \end{itemize}
\end{itemize}

\hypertarget{prepare-data-for-analysis-veriyi-analiz-iuxe7in-hazux131rlamak}{%
\chapter{Prepare Data for Analysis / Veriyi Analiz i√ßin hazƒ±rlamak}\label{prepare-data-for-analysis-veriyi-analiz-iuxe7in-hazux131rlamak}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/PrepareData.nb.html}

\hypertarget{data.table}{%
\section{data.table}\label{data.table}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/datatable.nb.html}

\hypertarget{file-organization-best-practices}{%
\chapter{File organization best practices}\label{file-organization-best-practices}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/FileOrganization.nb.html}

\hypertarget{analysis}{%
\chapter{Analysis}\label{analysis}}

\hypertarget{descriptive-statistics-exploratory-data-analysis-summary-statistics}{%
\section{Descriptive Statistics, Exploratory Data Analysis, Summary Statistics}\label{descriptive-statistics-exploratory-data-analysis-summary-statistics}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/DescriptiveStatistics.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/ExplatoryDataAnalysisSummaryStatistics.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/freq-tables.html}

the-lesser-known-stars-of-the-tidyverse.nb.html

\hypertarget{hypothesis-testing}{%
\section{Hypothesis Testing}\label{hypothesis-testing}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/HypothesisTesting.nb.html}

\hypertarget{compare-means}{%
\subsection{Compare Means}\label{compare-means}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/CompareMeans.nb.html}

\hypertarget{compare-proportions}{%
\subsection{Compare Proportions}\label{compare-proportions}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/CompareProportions.nb.html}

\hypertarget{survival-analysis-in-r}{%
\section{Survival Analysis in R}\label{survival-analysis-in-r}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/SurvivalAnalysis.nb.html}

\url{https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html}

\hypertarget{contingency-tables}{%
\section{Contingency Tables}\label{contingency-tables}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/ContingencyTables.nb.html}

\hypertarget{other-analysis}{%
\section{Other Analysis}\label{other-analysis}}

\hypertarget{regression}{%
\subsection{Regression}\label{regression}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Regression.nb.html}

\hypertarget{linearregression.nb.html}{%
\subsection{LinearRegression.nb.html}\label{linearregression.nb.html}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/LinearRegression.nb.html}

\hypertarget{general-linear-models}{%
\subsection{General Linear Models}\label{general-linear-models}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/GeneralLinearModels.nb.html}

\hypertarget{decision-trees}{%
\subsection{Decision Trees}\label{decision-trees}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/DecisionTreeKararAgaci.nb.html}

\hypertarget{clustering}{%
\subsection{Clustering}\label{clustering}}

\hypertarget{k-means-clustering}{%
\subsection{K Means Clustering}\label{k-means-clustering}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/KMeansClustering.nb.html}

\hypertarget{hierarchical-clustering}{%
\subsection{Hierarchical Clustering}\label{hierarchical-clustering}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/HierarchicalClustering.nb.html}

\hypertarget{graphs-plots}{%
\chapter{Graphs Plots}\label{graphs-plots}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/VisualisationGraphsPlots.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Graphs.nb.html}

\hypertarget{sankey-diagrams}{%
\section{Sankey Diagrams}\label{sankey-diagrams}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/SankeyDiagrams.nb.html}

\hypertarget{reporting}{%
\chapter{Reporting}\label{reporting}}

\hypertarget{reproducible-research}{%
\section{Reproducible Research}\label{reproducible-research}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/ReproducibleResearch.nb.html}

\hypertarget{tables}{%
\section{Tables}\label{tables}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Table.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/finalfit.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/formattable.nb.html}

\hypertarget{autoreport}{%
\section{Autoreport}\label{autoreport}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Autoreport.nb.html}

\hypertarget{shiny}{%
\section{shiny}\label{shiny}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/shiny.nb.html}

\hypertarget{creating-websites-in-r}{%
\section{Creating websites in R}\label{creating-websites-in-r}}

\url{https://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html}

\hypertarget{bioinformatics}{%
\chapter{Bioinformatics}\label{bioinformatics}}

\hypertarget{bioconductor}{%
\section{bioconductor}\label{bioconductor}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/bioconductor.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/CancerInSilico.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/CancerPackages.nb.html}

\hypertarget{backup-analysis-and-data}{%
\chapter{Backup Analysis and Data}\label{backup-analysis-and-data}}

\hypertarget{github}{%
\section{GitHub}\label{github}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/GitHub.nb.html}

SyncingGitHubFork.nb.html

\hypertarget{text-analysis-sentiment-analysis}{%
\chapter{Text Analysis Sentiment Analysis}\label{text-analysis-sentiment-analysis}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/TextMining.nb.html}

\hypertarget{twitter-analysis-with-r}{%
\section{Twitter Analysis With R}\label{twitter-analysis-with-r}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Twitter.nb.html}

\hypertarget{news}{%
\section{News}\label{news}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/news.nb.html}

\hypertarget{web-scrapping}{%
\section{web scrapping}\label{web-scrapping}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/WebScrapping.nb.html}

\hypertarget{bibliography}{%
\chapter{Bibliography}\label{bibliography}}

Other Bibliographic Studies:
\url{https://sbalci.github.io/ResearchOnBibliography/}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Bibliography.nb.html}

\hypertarget{pubmed}{%
\section{PubMed}\label{pubmed}}

\hypertarget{rismed}{%
\subsection{RISmed}\label{rismed}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/RISmed.nb.html}

\hypertarget{orcid}{%
\section{ORCID}\label{orcid}}

\hypertarget{rorcid}{%
\subsection{rorcid}\label{rorcid}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/rorcid.nb.html}

\hypertarget{google-scholar}{%
\section{Google Scholar}\label{google-scholar}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/GoogleScholar.nb.html}

\hypertarget{scholar}{%
\subsection{Scholar}\label{scholar}}

\hypertarget{coauthor}{%
\subsection{Coauthor}\label{coauthor}}

\hypertarget{power-analysis}{%
\section{Power Analysis}\label{power-analysis}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/PowerAnalysis.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Power_Analysis.nb.html}
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/PowerAnalysis.nb.html}

\hypertarget{formulas}{%
\section{Formulas}\label{formulas}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Formulas.nb.html}

\hypertarget{flipping-coin}{%
\section{Flipping Coin}\label{flipping-coin}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/FlippingCoin.nb.html}

\hypertarget{general-resources}{%
\chapter{General Resources}\label{general-resources}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/GeneralResources.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/DataScienceLiveBook.nb.html}

\hypertarget{package-list}{%
\chapter{Package List}\label{package-list}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/RPackagesUsed.nb.html}

\hypertarget{data-list}{%
\chapter{Data List}\label{data-list}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/DataList.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/eurostat.nb.html}

\hypertarget{data-tools}{%
\chapter{Data Tools}\label{data-tools}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/DataTools.nb.html}

\hypertarget{miscellaneous}{%
\chapter{Miscellaneous}\label{miscellaneous}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/codes.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/OpenCPU.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/papeR.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Tutorials.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/PythonPandas.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/lessR.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/arsenal.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/rchess.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/EvidenceSynthesisProjects.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/MachineLearning.nb.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/Correlations.nb.html}

\url{https://xgboost.readthedocs.io/en/latest/index.html}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Tipps.nb.html}

\hypertarget{feedback}{%
\chapter{Feedback}\label{feedback}}

\begin{itemize}
\item
  \href{https://github.com/sbalci}{Yours truly} would like to hear your
  feedback: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{feedback form}}
\item
  See \url{https://sbalci.github.io/} for other analysis.
\end{itemize}

You may also contact with me with the comment field below.

--

\{\% if page.comments \%\}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the
comments powered by
Disqus.

\{\% endif \%\}

--

\hypertarget{getting-data-into-r}{%
\chapter{Getting Data into R}\label{getting-data-into-r}}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

You can label chapter and section titles using \texttt{\{\#label\}} after them, e.g., we can reference Chapter \ref{intro}. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \ref{methods}.

Figures and tables with captions will be placed in \texttt{figure} and \texttt{table} environments, respectively.

\begin{verbatim}
{r , fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
\end{verbatim}

Reference a figure by its code chunk label with the \texttt{fig:} prefix, e.g., see Figure \ref{fig:}. Similarly, you can reference tables generated from \texttt{knitr::kable()}, e.g., see Table \ref{tab:}.

\begin{verbatim}
{r , tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
\end{verbatim}

You can write citations, too. For example, we are using the \textbf{bookdown} package \citep{R-bookdown} in this sample book, which was built on top of R Markdown and \textbf{knitr} \citep{xie2015}.

\hypertarget{bibliographic-studies}{%
\chapter{Bibliographic Studies}\label{bibliographic-studies}}

\hypertarget{articles-per-journals-per-country}{%
\section{Articles per journals per country}\label{articles-per-journals-per-country}}

If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page.

\hypertarget{analysis-1}{%
\subsection{Analysis}\label{analysis-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(
    eval = FALSE,
    message = FALSE,
    warning = FALSE,
    include = FALSE,
    tidy = TRUE
)
\end{verbatim}

\hypertarget{articles-per-journals-per-country-1}{%
\subsubsection{Articles per journals per country}\label{articles-per-journals-per-country-1}}

\textbf{Aim:}

In the \href{https://sbalci.github.io/pubmed/CountryBasedComparison.html}{previous analysis} we have observed that Japanese researchers have much more articles than German and Turkish researchers.

Here we will look at the distribution of articles per journals per country.

\textbf{Methods:}

\begin{verbatim}
{r , eval=FALSE, include=FALSE, echo=TRUE}
# load required packages
library(tidyverse)
library(RISmed)
\end{verbatim}

Pathology Journal ISSN List was retrieved from \href{https://jcr.incites.thomsonreuters.com/}{In Cites Clarivate}, and Journal Data Filtered as follows: \texttt{JCR\ Year:\ 2016\ Selected\ Editions:\ SCIE,SSCI\ Selected\ Categories:\ \textquotesingle{}PATHOLOGY\textquotesingle{}\ Selected\ Category\ Scheme:\ WoS}

\begin{verbatim}
{r Get ISSN List from data downloaded from WoS, eval=FALSE, include=FALSE, echo=TRUE}
# Get ISSN List from data downloaded from WoS
ISSNList <- JournalHomeGrid <- read_csv( data/JournalHomeGrid.csv , 
                                        skip = 1) %>% 
    select(ISSN) %>% 
    filter(!is.na(ISSN)) %>% 
    t() %>% 
    paste( OR  , collapse =   ) # add OR between ISSN List

ISSNList <- gsub(  OR $ ,   ,ISSNList) # to remove last OR
\end{verbatim}

Data is retrieved from PubMed via RISmed package.
PubMed collection from National Library of Medicine (\url{https://www.ncbi.nlm.nih.gov/pubmed/}), has the most comprehensive information about peer reviewed articles in medicine.
The API (\url{https://dataguide.nlm.nih.gov/}), and R packages are available for getting and fetching data from the server.

The search formula for PubMed is generated as ISSN List AND Country{[}Affiliation{]} like done in \href{https://www.ncbi.nlm.nih.gov/pubmed/advanced}{advanced search of PubMed}.

\begin{verbatim}
{r Generate Search Formula For Pathology Journals AND Countries, eval=FALSE, include=FALSE, echo=TRUE}
# Generate Search Formula For Pathology Journals AND Countries
searchformulaTR <- paste( ' ,ISSNList, ' ,   AND  ,  Turkey[Affiliation] )
searchformulaDE <- paste( ' ,ISSNList, ' ,   AND  ,  Germany[Affiliation] )
searchformulaJP <- paste( ' ,ISSNList, ' ,   AND  ,  Japan[Affiliation] )
\end{verbatim}

Articles from Japan, German and Turkey are retrieved limiting the search with pathology journals, affiliation and last 10 years.

\begin{verbatim}
{r Search PubMed, eval=FALSE, include=FALSE, echo=TRUE}
# Search PubMed, Get and Fetch
TurkeyArticles <- EUtilsSummary(searchformulaTR, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchTurkey <- EUtilsGet(TurkeyArticles)

GermanyArticles <- EUtilsSummary(searchformulaDE, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchGermany <- EUtilsGet(GermanyArticles)

JapanArticles <- EUtilsSummary(searchformulaJP, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchJapan <- EUtilsGet(JapanArticles)
\end{verbatim}

The retrieved information was compiled in a table.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

ISSNTR <- table(ISSN(fetchTurkey)) %>% 
    as_tibble() %>% 
    rename(Turkey = n, Journal = Var1)

ISSNDE <- table(ISSN(fetchGermany)) %>% 
    as_tibble() %>% 
    rename(Germany = n, Journal = Var1)

ISSNJP <- table(ISSN(fetchJapan)) %>% 
    as_tibble() %>% 
    rename(Japan = n, Journal = Var1)

articles_per_journal <- list(
    ISSNTR,
    ISSNDE,
    ISSNJP
) %>%
    reduce(left_join, by =  Journal , .id =  id ) %>% 
    gather(Country, n, 2:4)

articles_per_journal$Country <- factor(articles_per_journal$Country,
                                       levels =c( Japan ,  Germany ,  Turkey ))
\end{verbatim}

\textbf{Result:}

In this graph x-axis is the list of journals with decreasing impact factor, and y-axis is the number of articles published in that journal. The colors and shapes are showing the country of affiliation. We see that in one journal articles from Japan is more than 800.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(data = articles_per_journal, aes(x = Journal, y = n, group = Country,
                                     colour = Country, shape = Country,
                                     levels = Country
)) +
    geom_point() +
    labs(x =  Journals with decreasing impact factor , y =  Number of Articles ) +
    ggtitle( Pathology Articles Per Journal ) + 
    theme(plot.title = element_text(hjust = 0.5),
          axis.text.x=element_blank())
\end{verbatim}

\textbf{Comment:}

It is seen that one of the journals \href{https://onlinelibrary.wiley.com/page/journal/14401827/homepage/productinformation.html}{ISSN: 1440-1827} has more than 800 articles from Japan. This journal is also from Japan. Here we wonder if there is an editorial preference for articles from their home country.

We sometimes observe this situation if there is a conference in that country, and the conference abstracts are indexed.

This may also be a clue that if a country has a journal listed in indexes, than it is more easy for the researchers in that country to publish their results.

\textbf{Future Work:}

Whether this observation is a unique situation, or there is a tendency in the journals to publish article from their country of origin, merits further investigation.

\hypertarget{country-based-comparison}{%
\chapter{Country Based Comparison}\label{country-based-comparison}}

\hypertarget{analysis-2}{%
\section{Analysis}\label{analysis-2}}

\hypertarget{pubmed-indexed-peer-reviewed-articles-in-pathology-journals-a-country-based-comparison}{%
\subsection{PubMed Indexed Peer Reviewed Articles in Pathology Journals: A country based comparison}\label{pubmed-indexed-peer-reviewed-articles-in-pathology-journals-a-country-based-comparison}}

\textbf{Aim:}

Here, we are going to compare 3 countries (German, Japan and Turkey), in terms of number of articles in pathology journals during the last decade.

\textbf{Methods:}

If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page.

\begin{verbatim}
{r , eval=FALSE, include=FALSE, echo=TRUE}
# load required packages
library(tidyverse)
library(RISmed)
\end{verbatim}

Pathology Journal ISSN List was retrieved from \href{https://jcr.incites.thomsonreuters.com/}{In Cites Clarivate}, and Journal Data Filtered as follows: \texttt{JCR\ Year:\ 2016\ Selected\ Editions:\ SCIE,SSCI\ Selected\ Categories:\ \textquotesingle{}PATHOLOGY\textquotesingle{}\ Selected\ Category\ Scheme:\ WoS}

\begin{verbatim}
{r Get ISSN List from data downloaded from WoS 2, eval=FALSE, include=FALSE, echo=TRUE}
# Get ISSN List from data downloaded from WoS
ISSNList <- JournalHomeGrid <- read_csv( data/JournalHomeGrid.csv , 
                                        skip = 1) %>% 
    select(ISSN) %>% 
    filter(!is.na(ISSN)) %>% 
    t() %>% 
    paste( OR  , collapse =   ) # add OR between ISSN List

ISSNList <- gsub(  OR $ ,   ,ISSNList) # to remove last OR
\end{verbatim}

Data is retrieved from PubMed via RISmed package.
PubMed collection from National Library of Medicine (\url{https://www.ncbi.nlm.nih.gov/pubmed/}), has the most comprehensive information about peer reviewed articles in medicine.
The API (\url{https://dataguide.nlm.nih.gov/}), and R packages are available for getting and fetching data from the server.

The search formula for PubMed is generated as ISSN List AND Country{[}Affiliation{]} like done in \href{https://www.ncbi.nlm.nih.gov/pubmed/advanced}{advanced search of PubMed}.

\begin{verbatim}
{r Generate Search Formula For Pathology Journals AND Countries 2, eval=FALSE, include=FALSE, echo=TRUE}
# Generate Search Formula For Pathology Journals AND Countries
searchformulaTR <- paste( ' ,ISSNList, ' ,   AND  ,  Turkey[Affiliation] )
searchformulaDE <- paste( ' ,ISSNList, ' ,   AND  ,  Germany[Affiliation] )
searchformulaJP <- paste( ' ,ISSNList, ' ,   AND  ,  Japan[Affiliation] )
\end{verbatim}

\begin{verbatim}
{r Search PubMed 2, eval=FALSE, include=FALSE, echo=TRUE}
# Search PubMed, Get and Fetch
TurkeyArticles <- EUtilsSummary(searchformulaTR, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchTurkey <- EUtilsGet(TurkeyArticles)

GermanyArticles <- EUtilsSummary(searchformulaDE, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchGermany <- EUtilsGet(GermanyArticles)

JapanArticles <- EUtilsSummary(searchformulaJP, type = 'esearch', db = 'pubmed', mindate = 2007, maxdate = 2017, retmax = 10000)
fetchJapan <- EUtilsGet(JapanArticles)
\end{verbatim}

From the fetched data the year of articles are grouped and counted by country.

\begin{verbatim}
{r Articles per countries per year 2, eval=FALSE, include=FALSE, echo=TRUE}
# Articles per countries per year
tableTR <- table(YearPubmed(fetchTurkey)) %>% 
    as_tibble() %>% 
    rename(Turkey = n, Year = Var1)

tableDE <- table(YearPubmed(fetchGermany)) %>% 
    as_tibble() %>% 
    rename(Germany = n, Year = Var1)

tableJP <- table(YearPubmed(fetchJapan)) %>% 
    as_tibble() %>% 
    rename(Japan = n, Year = Var1)

# Join Tables
articles_per_year_table <- list(
    tableTR,
    tableDE,
    tableJP
    ) %>%
    reduce(left_join, by =  Year , .id =  id )
\end{verbatim}

\begin{verbatim}
{r Prepare table for output 2, eval=FALSE, include=FALSE, echo=TRUE}
# Prepare table for output
articles_per_year <- articles_per_year_table %>% 
    gather(Country, n, 2:4)

articles_per_year$Country <- factor(articles_per_year$Country,
                                       levels =c( Japan ,  Germany ,  Turkey ))
\end{verbatim}

\textbf{Result:}

In the below table we see the number of articles per country in the last decade.

\begin{verbatim}
{r Print the Table of Articles per year per country 2, eval=FALSE, include=FALSE, echo=TRUE}
# Print the Table of Articles per year, per country
knitr::kable(articles_per_year_table, caption =  Table of Articles per year, per country )
\end{verbatim}

And the figure below shows this data in a line graph.

\begin{verbatim}
{r Graph of Table of Articles per year per country 2, eval=FALSE, fig.align= center , include=FALSE}
ggplot(data = articles_per_year, aes(x = Year, y = n, group = Country,
                                     colour = Country, shape = Country,
                                     levels = Country
                                     )) +
    geom_line() +
    geom_point() +
    labs(x =  Year , y =  Number of Articles ) +
    ggtitle( Pathology Articles Per Year ) +
    theme(plot.title = element_text(hjust = 0.4), 
          text = element_text(size = 9))
\end{verbatim}

\textbf{Comment:}

We see that Japan has much more articles than German and Turkey.
Turkey has a small increase in number of articles.

\textbf{Future Work:}

\begin{itemize}
\tightlist
\item
  Indentify why Japan has too much articles.
\item
  Compare Japan with other countries.
\item
  Compare Turkey with neighbours, EU, OECD \& Middle East countries.
\item
  Analyse multinational studies.
\item
  Analyse adding journal impact as a factor.
\end{itemize}

\hypertarget{pbpath-journal-watch}{%
\chapter{PBPath Journal Watch}\label{pbpath-journal-watch}}

\hypertarget{recent-articles-from-pubmed}{%
\section{Recent Articles from PubMed}\label{recent-articles-from-pubmed}}

\hypertarget{analysis-of-recent-pancreas-related-articles}{%
\subsection{Analysis of Recent Pancreas Related Articles}\label{analysis-of-recent-pancreas-related-articles}}

Pancreas Journals
\url{https://www.ncbi.nlm.nih.gov/nlmcatalog/?term=pancreas}

Pathology Journals

Member List

DOI Link
PubMed Link
Journal Link
Altmetric API
Dimensions API

USCAP abstracts vs publication

Member list vs worldmap

\begin{verbatim}
{r , eval=FALSE, include=FALSE, echo=TRUE}
# load required packages
library(tidyverse)
library(knitr)
library(rstudioapi)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(
    eval = FALSE,
    message = FALSE,
    warning = FALSE,
    include = FALSE,
    tidy = TRUE
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(myTerm,  esearch -db pubmed -query 'pancreas[Title/Abstract]) AND pathology' -datetype EDAT -min 2018/05/01 -max 3000 | \
efetch -format xml | \
xtract -pattern PubmedArticle -element MedlineCitation/PMID \
-block ArticleId -if ArticleId@IdType -equals doi -element ArticleId &> myquery.txt )
Sys.sleep(1)
repeat{
    Sys.sleep(0.1)
    if(rstudioapi::terminalBusy(myTerm) == FALSE){
        print( Code Executed )
        break
    }
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
readLines( myquery.txt )
\end{verbatim}

Pathology Journal ISSN List was retrieved from \href{https://jcr.incites.thomsonreuters.com/}{In Cites Clarivate}, and Journal Data Filtered as follows: \texttt{JCR\ Year:\ 2016\ Selected\ Editions:\ SCIE,SSCI\ Selected\ Categories:\ \textquotesingle{}PATHOLOGY\textquotesingle{}\ Selected\ Category\ Scheme:\ WoS}

\begin{verbatim}
{r Get ISSN List from data downloaded from WoS 1, eval=FALSE, include=FALSE, echo=TRUE}
# Get ISSN List from data downloaded from WoS
ISSNList <- JournalHomeGrid <- read_csv( data/JournalHomeGrid.csv ,
                                        skip = 1) %>%
    select(ISSN) %>%
    filter(!is.na(ISSN)) %>%
    t() %>%
    paste( OR  , collapse =   ) # add OR between ISSN List

ISSNList <- gsub(  OR $ ,   ,ISSNList) # to remove last OR
\end{verbatim}

Data is retrieved from PubMed via E-direct.

PubMed collection from National Library of Medicine (\url{https://www.ncbi.nlm.nih.gov/pubmed/}), has the most comprehensive information about peer reviewed articles in medicine.
The API (\url{https://dataguide.nlm.nih.gov/}) is available for getting and fetching data from the server.

The query for PubMed is generated as ISSN List AND keywords like done in \href{https://www.ncbi.nlm.nih.gov/pubmed/advanced}{advanced search of PubMed}.

\begin{verbatim}
{r Generate Search Formula For Pathology Journals AND Countries 1, eval=FALSE, include=FALSE, echo=TRUE}
# Generate Search Formula For Pathology Journals AND Countries
searchformulaTR <- paste( ' ,ISSNList, ' ,   AND  ,  Turkey[Affiliation] )
searchformulaDE <- paste( ' ,ISSNList, ' ,   AND  ,  Germany[Affiliation] )
searchformulaJP <- paste( ' ,ISSNList, ' ,   AND  ,  Japan[Affiliation] )
\end{verbatim}

From the fetched data articles are grouped by country and keywords.

\begin{verbatim}
{r Articles per countries per year 1, eval=FALSE, include=FALSE, echo=TRUE}
# Articles per countries per year
tableTR <- table(YearPubmed(fetchTurkey)) %>%
    as_tibble() %>%
    rename(Turkey = n, Year = Var1)

tableDE <- table(YearPubmed(fetchGermany)) %>%
    as_tibble() %>%
    rename(Germany = n, Year = Var1)

tableJP <- table(YearPubmed(fetchJapan)) %>%
    as_tibble() %>%
    rename(Japan = n, Year = Var1)

# Join Tables
articles_per_year_table <- list(
    tableTR,
    tableDE,
    tableJP
) %>%
    reduce(left_join, by =  Year , .id =  id )
\end{verbatim}

\begin{verbatim}
{r Prepare table for output 1, eval=FALSE, include=FALSE, echo=TRUE}
# Prepare table for output
articles_per_year <- articles_per_year_table %>%
    gather(Country, n, 2:4)

articles_per_year$Country <- factor(articles_per_year$Country,
                                    levels =c( Japan ,  Germany ,  Turkey ))
\end{verbatim}

\textbf{Result:}

\begin{verbatim}
{r Print the Table of Articles per year per country 1, eval=FALSE, include=FALSE, echo=TRUE}
# Print the Table of Articles per year, per country
knitr::kable(articles_per_year_table, caption =  Table of Articles per year, per country )
\end{verbatim}

mapgraph

And the figure below shows this data in a line graph.

\hypertarget{bibliographic-studies-1}{%
\chapter{Bibliographic Studies}\label{bibliographic-studies-1}}

\begin{verbatim}
output: 
  html_notebook: 
    code_folding: hide
    fig_caption: yes
    highlight: kate
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
  html_document: 
    code_folding: hide
    df_print: kable
    keep_md: yes
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
    highlight: kate
\end{verbatim}

If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page.

\hypertarget{analysis-3}{%
\chapter{Analysis}\label{analysis-3}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(
    eval = FALSE,
    message = FALSE,
    warning = FALSE,
    include = FALSE,
    tidy = TRUE
)
\end{verbatim}

\hypertarget{mesh-terms-in-pathology-articles-from-turkey}{%
\section{MeSH Terms In Pathology Articles From Turkey}\label{mesh-terms-in-pathology-articles-from-turkey}}

\textbf{Background}

PubMed collection from \href{https://www.ncbi.nlm.nih.gov/pubmed/}{National Library of Medicine}, has the most comprehensive information about peer reviewed articles in medicine.

\href{https://www.nlm.nih.gov/pubs/factsheets/mesh.html}{MeSH Terms} is a controlled vocabulary that is used to label PubMed articles according to their content. It is done by experts in National Library of Medicine. Keywords are lables that are given by authors of the article. Both are included in a PubMed record of an article.

\textbf{Aim:}

In this analysis we aimed to identify the common research topics Turkish pathologists are interested. We extracted most common MeSH terms and keywords from PubMed articles using \href{https://dataguide.nlm.nih.gov/edirect/overview.html}{EDirect}:
\href{https://sbalci.github.io/pubmed/MeSH_Terms_Pathology_Articles_From_Turkey.html}{MeSH Terms Pathology Articles From Turkey}

\textbf{Methods:}

Packages used for analysis. Tidyverse is used for data manipulation, and \href{https://github.com/rstudio/rstudio/issues/2193}{rstudioapi to run e-utilities commands from RStudio}.

\begin{verbatim}
{r load -if not present install- required packages 3, eval=FALSE, include=FALSE, echo=TRUE}
usePackage <- function(p) 
{
    if (!is.element(p, installed.packages()[,1]))
        install.packages(p, dep = TRUE)
    require(p, character.only = TRUE)
}

usePackage( tidyverse )
usePackage( rstudioapi )
\end{verbatim}

Pathology Journal ISSN List was retrieved from \href{https://jcr.incites.thomsonreuters.com/}{In Cites Clarivate}, and Journal Data Filtered as follows:

\begin{verbatim}
JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'PATHOLOGY' Selected Category Scheme: WoS
\end{verbatim}

\begin{verbatim}
{r Get ISSN List from data downloaded from WoS 3, eval=FALSE, include=FALSE, echo=TRUE}
# Get ISSN List from data downloaded from WoS
ISSNList <- JournalHomeGrid <- read_csv( data/JournalHomeGrid.csv , 
                                        skip = 1) %>% 
    select(ISSN) %>% 
    filter(!is.na(ISSN)) %>% 
    t() %>% 
    paste( OR  , collapse =   ) # add OR between ISSN List

ISSNList <- gsub(  OR $ ,   ,ISSNList) # to remove last OR
\end{verbatim}

Data is retrieved from PubMed via \href{https://dataguide.nlm.nih.gov/}{e-Utilities}.

The search formula for PubMed is generated as ISSN List AND Country{[}Affiliation{]} like done in \href{https://www.ncbi.nlm.nih.gov/pubmed/advanced}{advanced search of PubMed}.

\begin{verbatim}
{r Generate Search Formula For Pathology Journals AND Countries 3, eval=FALSE, include=FALSE, echo=TRUE}
# Generate Search Formula For Pathology Journals AND Countries
searchformula <- paste( ' ,ISSNList, ' ,   AND  ,  Turkey[Affiliation] )
write(searchformula,  data/searchformula.txt )
\end{verbatim}

Articles are downloaded as xml.

\begin{verbatim}
{r Search PubMed 3, eval=FALSE, include=FALSE, echo=TRUE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(myTerm,  esearch -db pubmed -query \ $(cat data/searchformula.txt)\  -datetype PDAT -mindate 1900 -maxdate 3000 | efetch -format xml > data/PathologyTurkey.xml \n )
Sys.sleep(1)
repeat{
    Sys.sleep(0.1)
    if(rstudioapi::terminalBusy(myTerm) == FALSE){
        print( Code Executed )
        break
    }
}
\end{verbatim}

MeSH terms are extracted from xml. \href{https://www.nlm.nih.gov/bsd/indexing/training/CHK_010.html}{Common terms} are excluded and \href{https://www.nlm.nih.gov/bsd/disted/meshtutorial/principlesofmedlinesubjectindexing/majortopics/}{major topics} are selected.

\begin{verbatim}
{r extract major MeSH topics -excluding common tags- from xml 3, eval=FALSE, include=FALSE, echo=TRUE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(myTerm,  xtract -input data/PathologyTurkey.xml
-pattern MeshHeading -if DescriptorName@MajorTopicYN -equals Y
-or QualifierName@MajorTopicYN -equals Y -element DescriptorName| 
grep -vxf data/checktags.txt | sort-uniq-count-rank > data/PathologyTurkeyMeSH.txt \n )
Sys.sleep(1)
repeat{
    Sys.sleep(0.1)
    if(rstudioapi::terminalBusy(myTerm) == FALSE){
        print( Code Executed )
        break
    }
}
\end{verbatim}

Keywords are extracted from xml.

\begin{verbatim}
{r extract author keywords from xml 3, eval=FALSE, include=FALSE, echo=TRUE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(myTerm,  xtract -input data/PathologyTurkey.xml -pattern Keyword -element Keyword | sort-uniq-count-rank > authorkeywords.txt \n )
Sys.sleep(1)
repeat{
    Sys.sleep(0.1)
    if(rstudioapi::terminalBusy(myTerm) == FALSE){
        print( Code Executed )
        break
    }
}
\end{verbatim}

\textbf{Result:}

The retrieved information was compiled in a table.

\begin{verbatim}
{r display results as table 3, eval=FALSE, include=FALSE, echo=TRUE}

my_tbl <- tibble::tribble(
  ~Col_1, ~Col_2, ~Col_3,
      NA,     NA,     NA,
      NA,     NA,     NA,
      NA,     NA,     NA,
      NA,     NA,     NA
  )

require(rhandsontable)
rhandsontable(my_tbl, rowHeaders = NULL,
               digits = 3, useTypes = FALSE, search = FALSE,
               width = NULL, height = NULL)


\end{verbatim}

\textbf{Comment:}

\textbf{Future Work:}

\hypertarget{feedback-1}{%
\chapter{Feedback}\label{feedback-1}}

\href{https://github.com/sbalci}{Serdar Balcƒ±, MD, Pathologist} would like to hear your feedback: \url{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}

This document will be continiously updated and the last update was on .

\hypertarget{back-to-main-menu}{%
\chapter{Back to Main Menu}\label{back-to-main-menu}}

\href{https://sbalci.github.io/pubmed/BibliographicStudies.html}{Main Page for Bibliographic Analysis}

\hypertarget{table-options}{%
\chapter{Table options}\label{table-options}}

Several packages support making beautiful tables with R, such as

\begin{itemize}
\tightlist
\item
  \href{https://cran.r-project.org/web/packages/xtable/}{xtable}
\item
  \href{https://cran.r-project.org/web/packages/stargazer/}{stargazer}
\item
  \href{http://rapporter.github.io/pander/}{pander}
\item
  \href{https://cran.r-project.org/web/packages/tables/}{tables}
\item
  \href{http://eusebe.github.io/ascii/}{ascii}
\item
  etc.
\end{itemize}

It is also very easy to make tables with knitr's \texttt{kable} function:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(head(iris), caption =  Title of the table )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pander::pander(mtcars)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
stargazer::stargazer(mtcars)
\end{verbatim}

\begin{verbatim}
{r echo = TRUE, results = 'asis'}
library(knitr)
kable(mtcars[1:5, ], caption =  A knitr kable. )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rhandsontable)
rhandsontable(mtcars)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
xtable::xtable(mtcars)
\end{verbatim}

\hypertarget{analysing-the-hiv-pandemic}{%
\chapter{Analysing the HIV pandemic}\label{analysing-the-hiv-pandemic}}

\url{https://rviews.rstudio.com/2019/04/30/analysing-hiv-pandemic-part-1/}

\hypertarget{arsenal}{%
\chapter{arsenal}\label{arsenal}}

\hypertarget{the-compare-function}{%
\section{The compare function}\label{the-compare-function}}

\url{https://cran.r-project.org/web/packages/arsenal/vignettes/compare.html}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
library(arsenal)
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
df1 <- data.frame(id = paste0( person , 1:3),
                  a = c( a ,  b ,  c ),
                  b = c(1, 3, 4),
                  c = c( f ,  e ,  d ),
                  row.names = paste0( rn , 1:3),
                  stringsAsFactors = FALSE)
df2 <- data.frame(id = paste0( person , 3:1),
                  a = c( c ,  b ,  a ),
                  b = c(1, 3, 4),
                  d = paste0( rn , 1:3),
                  row.names = paste0( rn , c(1,3,2)),
                  stringsAsFactors = FALSE)
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
compare(df1, df2)
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
summary(compare(df1, df2))
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
summary(compare(df1, df2, by =  id ))
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
data(mockstudy)
mockstudy2 <- muck_up_mockstudy()
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
summary(compare(mockstudy, mockstudy2, by =  case ))
\end{verbatim}

\begin{verbatim}
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
x   arm 3   character
x   fu.time 6   integer
x   fu.stat 7   integer
y   fu_time 11  integer
y   fu stat 12  integer
y   Arm 13  character
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
ast 12  integer ast 8   numeric
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
sex sex 1495    0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1741 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
sex sex 76170   Male    Male    26  20
sex sex 76240   Male    Male    27  21
sex sex 76431   Female  Female  28  22
sex sex 76712   Male    Male    29  23
sex sex 76780   Female  Female  30  24
sex sex 77066   Female  Female  31  25
sex sex 77316   Male    Male    32  26
sex sex 77355   Male    Male    33  27
sex sex 77591   Male    Male    34  28
sex sex 77851   Male    Male    35  29
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
Non-identical attributes
var.x   var.y   name
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Column name comparison options
It is possible to change which column names are considered ‚Äúthe same variable‚Äù.

Ignoring case
For example, to ignore case in variable names (so that Arm and arm are considered the same), pass tol.vars =  case .

You can do this using comparison.control()

summary(compare(mockstudy, mockstudy2, by =  case , control = comparison.control(tol.vars =  case )))
or pass it through the ... arguments.

summary(compare(mockstudy, mockstudy2, by =  case , tol.vars =  case ))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
x   fu.time 6   integer
x   fu.stat 7   integer
y   fu_time 11  integer
y   fu stat 12  integer
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
ast 12  integer ast 8   numeric
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 1495    0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1741 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
sex sex 76170   Male    Male    26  20
sex sex 76240   Male    Male    27  21
sex sex 76431   Female  Female  28  22
sex sex 76712   Male    Male    29  23
sex sex 76780   Female  Female  30  24
sex sex 77066   Female  Female  31  25
sex sex 77316   Male    Male    32  26
sex sex 77355   Male    Male    33  27
sex sex 77591   Male    Male    34  28
sex sex 77851   Male    Male    35  29
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Treating dots and underscores the same (equivalence classes)
It is possible to treat certain characters or sets of characters as the same by passing a character vector of equivalence classes to the tol.vars= argument.

In short, each string in the vector is split into single characters, and the resulting set of characters is replaced by the first character in the string. For example, passing c( ._ ) would replace all underscores with dots in the column names of both datasets. Similarly, passing c( aA ,  BbCc ) would replace all instances of  A  with  a  and all instances of  b ,  C , or  c  with  B . This is one way to ignore case for certain letters. Otherwise, it‚Äôs possible to combine the equivalence classes with ignoring case, by passing (e.g.) c( ._ ,  case ).

Passing a single character as an element this vector will replace that character with the empty string. For example, passing c(  ‚Äú,‚Äù.‚Äú) would remove all spaces and dots from the column names.

For mockstudy, let‚Äôs treat dots, underscores, and spaces as the same, and ignore case:

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ) # dots=underscores=spaces, ignore case
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
ast 12  integer ast 8   numeric
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 1495    0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1741 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
sex sex 76170   Male    Male    26  20
sex sex 76240   Male    Male    27  21
sex sex 76431   Female  Female  28  22
sex sex 76712   Male    Male    29  23
sex sex 76780   Female  Female  30  24
sex sex 77066   Female  Female  31  25
sex sex 77316   Male    Male    32  26
sex sex 77355   Male    Male    33  27
sex sex 77591   Male    Male    34  28
sex sex 77851   Male    Male    35  29
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Column comparison options
Logical tolerance
Use the tol.logical= argument to change how logicals are compared. By default, they‚Äôre expected to be equal to each other.

Numeric tolerance
To allow numeric differences of a certain tolerance, use the tol.num= and tol.num.val= options. tol.num.val= determines the maximum (unsigned) difference tolerated if tol.num= absolute  (default), and determines the maximum (unsigned) percent difference tolerated if tol.num= percent .

Also note the option int.as.num=, which determines whether integers and numerics should be compared despite their class difference. If TRUE, the integers are coerced to numeric. Note that mockstudy$ast is integer, while mockstudy2$ast is numeric:

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE            # compare integers and numerics
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 1495    0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 3   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1741 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
sex sex 76170   Male    Male    26  20
sex sex 76240   Male    Male    27  21
sex sex 76431   Female  Female  28  22
sex sex 76712   Male    Male    29  23
sex sex 76780   Female  Female  30  24
sex sex 77066   Female  Female  31  25
sex sex 77316   Male    Male    32  26
sex sex 77355   Male    Male    33  27
sex sex 77591   Male    Male    34  28
sex sex 77851   Male    Male    35  29
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
ast ast 86205   27  36  6   3
ast ast 105271  100 36  3   2
ast ast 110754  35  36  1   1
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Suppose a tolerance of up to 10 is allowed for ast:

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE,           # compare integers and numerics
                tol.num.val = 10             # allow absolute differences <= 10
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 1495    0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 1   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1741 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
sex sex 76170   Male    Male    26  20
sex sex 76240   Male    Male    27  21
sex sex 76431   Female  Female  28  22
sex sex 76712   Male    Male    29  23
sex sex 76780   Female  Female  30  24
sex sex 77066   Female  Female  31  25
sex sex 77316   Male    Male    32  26
sex sex 77355   Male    Male    33  27
sex sex 77591   Male    Male    34  28
sex sex 77851   Male    Male    35  29
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
ast ast 105271  100 36  3   2
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Factor tolerance
By default, factors are compared to each other based on both the labels and the underlying numeric levels. Set tol.factor= levels  to match only the numeric levels, or set tol.factor= labels  to match only the labels.

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE,           # compare integers and numerics
                tol.num.val = 10,            # allow absolute differences <= 10
                tol.factor =  labels         # match only factor labels
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
var.x   pos.x   class.x var.y   pos.y   class.y
race    5   character   race    3   factor
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 0   0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 1   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (256 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
ast ast 105271  100 36  3   2
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Also note the option factor.as.char=, which determines whether factors and characters should be compared despite their class difference. If TRUE, the factors are coerced to characters. Note that mockstudy$race is a character, while mockstudy2$race is a factor:

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE,           # compare integers and numerics
                tol.num.val = 10,            # allow absolute differences <= 10
                tol.factor =  labels ,       # match only factor labels
                factor.as.char = TRUE        # compare factors and characters
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
No other variables not compared
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 0   0
race    race    1285    0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 1   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (1531 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
race    race    76170   Caucasian   caucasian   26  20
race    race    76240   Caucasian   caucasian   27  21
race    race    76431   Caucasian   caucasian   28  22
race    race    76712   Caucasian   caucasian   29  23
race    race    76780   Caucasian   caucasian   30  24
race    race    77066   Caucasian   caucasian   31  25
race    race    77316   Caucasian   caucasian   32  26
race    race    77591   Caucasian   caucasian   34  28
race    race    77851   Caucasian   caucasian   35  29
race    race    77956   Caucasian   caucasian   36  30
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
ast ast 105271  100 36  3   2
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Character tolerance
Use the tol.char= argument to change how character variables are compared. By default, they are compared as-is, but they can be compared after ignoring case or trimming whitespace or both.

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE,           # compare integers and numerics
                tol.num.val = 10,            # allow absolute differences <= 10
                tol.factor =  labels ,       # match only factor labels
                factor.as.char = TRUE,       # compare factors and characters
                tol.char =  case             # ignore case in character vectors
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
No other variables not compared
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 0   0
race    race    0   0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 266 266
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 1   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable (256 differences not shown)
var.x   var.y   case    values.x    values.y    row.x   row.y
ps  ps  86205   0   NA  6   3
hgb hgb 88714   NA  -9  192 186
hgb hgb 88955   NA  -9  204 198
hgb hgb 89549   NA  -9  229 223
hgb hgb 89563   NA  -9  231 225
hgb hgb 89584   NA  -9  237 231
hgb hgb 89591   NA  -9  238 232
hgb hgb 89595   NA  -9  239 233
hgb hgb 89647   NA  -9  243 237
hgb hgb 89665   NA  -9  244 238
hgb hgb 89827   NA  -9  255 249
ast ast 105271  100 36  3   2
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Date tolerance
Use the tol.date= argument to change how dates are compared. By default, they‚Äôre expected to be equal to each other.

Other data type tolerances
Use the tol.other= argument to change how other objects are compared. By default, they‚Äôre expected to be identical().

User-defined tolerance functions
Details
The comparison.control() function accepts functions for any of the tolerance arguments in addition to the short-hand character strings. This allows the user to create custom tolerance functions to suit his/her needs.

Any custom tolerance function must accept two vectors as arguments and return a logical vector of the same length. The TRUEs in the results should correspond to elements which are deemed ‚Äúdifferent‚Äù. Note that the numeric and date tolerance functions should also include a third argument for tolerance size (even if it‚Äôs not used).

CAUTION: the results should not include NAs, since the logical vector is used to subset the input data.frames. The tol.NA() function is useful for considering any NAs in the two vectors (but not both) as differences, in addition to other criteria.

tol.NA
function (x, y, idx) 
{
    (is.na(x) & !is.na(y)) | (is.na(y) & !is.na(x)) | (!is.na(x) & 
        !is.na(y) & idx)
}
<environment: namespace:arsenal>
The tol.NA() function is used in all default tolerance functions to help handle NAs.

Example 1
Suppose we want to ignore any dates which are later in the second dataset than the first. We define a custom tolerance function.

my.tol <- function(x, y, tol)
{
  tol.NA(x, y, x > y)
}

date.df1 <- data.frame(dt = as.Date(c( 2017-09-07 ,  2017-08-08 ,  2017-07-09 , NA)))
date.df2 <- data.frame(dt = as.Date(c( 2017-10-01 ,  2017-08-08 ,  2017-07-10 ,  2017-01-01 )))
n.diffs(compare(date.df1, date.df2)) # default finds any differences
[1] 3
n.diffs(compare(date.df1, date.df2, tol.date = my.tol)) # our function identifies only the NA as different...
[1] 1
n.diffs(compare(date.df2, date.df1, tol.date = my.tol)) # ... until we change the argument order
[1] 3
Example 2
(Continuing our mockstudy example)

Suppose we‚Äôre okay with NAs getting replaced by -9.

tol.minus9 <- function(x, y, tol)
{
  idx1 <- is.na(x) & !is.na(y) & y == -9
  idx2 <- tol.num.absolute(x, y, tol) # find other absolute differences
  return(!idx1 & idx2)
}

summary(compare(mockstudy, mockstudy2, by =  case ,
                tol.vars = c( ._  ,  case ), # dots=underscores=spaces, ignore case
                int.as.num = TRUE,           # compare integers and numerics
                tol.num.val = 10,            # allow absolute differences <= 10
                tol.factor =  labels ,       # match only factor labels
                factor.as.char = TRUE,       # compare factors and characters
                tol.char =  case ,           # ignore case in character vectors
                tol.num = tol.minus9         # ignore NA -> -9 changes
))
Summary of data.frames
version arg ncol    nrow
x   mockstudy   14  1499
y   mockstudy2  13  1495
Variables not shared
version variable    position    class
x   age 2   integer
Other variables not compared
No other variables not compared
Observations not shared
version case    observation
x   88989   9
x   90158   8
x   99508   7
x   112263  5
Differences detected by variable
var.x   var.y   n   NAs
arm Arm 0   0
sex sex 0   0
race    race    0   0
fu.time fu_time 0   0
fu.stat fu stat 0   0
ps  ps  1   1
hgb hgb 0   0
bmi bmi 0   0
alk.phos    alk.phos    0   0
ast ast 1   0
mdquality.s mdquality.s 0   0
age.ord age.ord 0   0
First 10 differences detected per variable
var.x   var.y   case    values.x    values.y    row.x   row.y
ps  ps  86205   0   NA  6   3
ast ast 105271  100 36  3   2
Non-identical attributes
var.x   var.y   name
arm Arm label
sex sex label
sex sex levels
race    race    class
race    race    label
race    race    levels
bmi bmi label
Extract Differences
Differences can be easily extracted using the diffs() function. If you only want to determine how many differences were found, use the n.diffs() function.

cmp <- compare(mockstudy, mockstudy2, by =  case , tol.vars = c( ._  ,  case ), int.as.num = TRUE)
n.diffs(cmp)
[1] 1765
head(diffs(cmp))
  var.x var.y  case values.x values.y row.x row.y
1   sex   sex 76170     Male     Male    26    20
2   sex   sex 76240     Male     Male    27    21
3   sex   sex 76431   Female   Female    28    22
4   sex   sex 76712     Male     Male    29    23
5   sex   sex 76780   Female   Female    30    24
6   sex   sex 77066   Female   Female    31    25
Differences can also be summarized by variable.

diffs(cmp, by.var = TRUE)
         var.x       var.y    n NAs
1          arm         Arm    0   0
2          sex         sex 1495   0
3      fu.time     fu_time    0   0
4      fu.stat     fu stat    0   0
5           ps          ps    1   1
6          hgb         hgb  266 266
7          bmi         bmi    0   0
8     alk.phos    alk.phos    0   0
9          ast         ast    3   0
10 mdquality.s mdquality.s    0   0
11     age.ord     age.ord    0   0
To report differences from only a few variables, one can pass a list of variable names to diffs().

diffs(cmp, vars = c( ps ,  ast ), by.var = TRUE)
  var.x var.y n NAs
5    ps    ps 1   1
9   ast   ast 3   0
diffs(cmp, vars = c( ps ,  ast ))
     var.x var.y   case values.x values.y row.x row.y
1496    ps    ps  86205        0       NA     6     3
1763   ast   ast  86205       27       36     6     3
1764   ast   ast 105271      100       36     3     2
1765   ast   ast 110754       35       36     1     1
Appendix
Stucture of the Object
(This section is just as much for my use as for yours!)

obj <- compare(mockstudy, mockstudy2, by =  case )
There are two main objects in the  compare.data.frame  object, each with its own print method.

The frame.summary contains:

the substituted-deparsed arguments

information about the number of columns and rows in each dataset

the by-variables for each dataset (which may not be the same)

the attributes for each dataset (which get counted in the print method)

a data.frame of by-variables and row numbers of observations not shared between datasets

the number of shared observations

print(obj$frame.summary)
  version        arg ncol nrow   by        attrs       unique n.shared
1       x  mockstudy   14 1499 case 3 attributes 4 unique obs     1495
2       y mockstudy2   13 1495 case 3 attributes 0 unique obs     1495
The vars.summary contains:

variable name, column number, and class vector (with possibly more than one element) for each x and y. These are all NA if there isn‚Äôt a match in both datasets.

values, a list-column of the text string  by-variable  for the by-variables, NULL for columns that aren‚Äôt compared, or a data.frame containing:

The by-variables for differences found

The values which are different for x and y

The row numbers for differences found

attrs, a list-column of NULL if there are no attributes, or a data.frame containing:

The name of the attributes

The attributes for x and y, set to NA if non-existant

The actual attributes (if show.attr=TRUE).

print(obj$vars.summary)
         var.x pos.x         class.x       var.y pos.y         class.y           values        attrs
8         case     1         integer        case     1         integer      by-variable 0 attributes
17         sex     4          factor         sex     2          factor 1495 differences 2 attributes
16        race     5       character        race     3          factor     Not compared 3 attributes
15          ps     8         integer          ps     4         integer    1 differences 0 attributes
13         hgb     9         numeric         hgb     5         numeric  266 differences 0 attributes
7          bmi    10         numeric         bmi     6         numeric    0 differences 1 attributes
4     alk.phos    11         integer    alk.phos     7         integer    0 differences 0 attributes
6          ast    12         integer         ast     8         numeric     Not compared 0 attributes
14 mdquality.s    13         integer mdquality.s     9         integer    0 differences 0 attributes
3      age.ord    14 ordered, factor     age.ord    10 ordered, factor    0 differences 0 attributes
2          age     2         integer        <NA>    NA              NA     Not compared 0 attributes
5          arm     3       character        <NA>    NA              NA     Not compared 0 attributes
11     fu.time     6         integer        <NA>    NA              NA     Not compared 0 attributes
10     fu.stat     7         integer        <NA>    NA              NA     Not compared 0 attributes
12        <NA>    NA              NA     fu_time    11         integer     Not compared 0 attributes
9         <NA>    NA              NA     fu stat    12         integer     Not compared 0 attributes
1         <NA>    NA              NA         Arm    13       character     Not compared 0 attributes




## The freqlist function


https://cran.r-project.org/web/packages/arsenal/vignettes/freqlist.html

The freqlist function
Tina Gunderson and Ethan Heinzen
09 November, 2018
Overview
Sample dataset
The freqlist object
Basic output using summary()
Using a formula with freqlist
Rounding percentage digits or changing variable names for printing
Additional examples
Including combinations with frequencies of zero
Options for NA handling
Frequency counts and percentages subset by factor levels
Change labels on the fly
Using xtable() to format and print freqlist() results
Use freqlist in bookdown
Appendix: Notes regarding table options in R
NAs
Table dimname names (dnn)
Overview
freqlist() is a function meant to produce output similar to SAS‚Äôs PROC FREQ procedure when using the /list option of the TABLE statement. freqlist() provides options for handling missing or sparse data and can provide cumulative counts and percentages based on subgroups. It depends on the knitr package for printing.

require(arsenal)
Sample dataset
For our examples, we‚Äôll load the mockstudy data included with this package and use it to create a basic table. Because they have fewer levels, for brevity, we‚Äôll use the variables arm, sex, and mdquality.s to create the example table. We‚Äôll retain NAs in the table creation. See the appendix for notes regarding default NA handling and other useful information regarding tables in R.

# load the data
data(mockstudy)

# retain NAs when creating the table using the useNA argument
tab.ex <- table(mockstudy[, c( arm ,  sex ,  mdquality.s )], useNA =  ifany )
The freqlist object
The freqlist() function returns an object of class  freqlist , which has three parts: freqlist, byVar, and labels.

freqlist is a single data frame containing all contingency tables with calculated frequencies, cumulative frequencies, percentages, and cumulative percentages.

byVar and labels are used in the summary method for subgroups and variable names, which will be covered in later examples.

Note that freqlist() is an S3 generic, with methods for tables and formulas.

noby <- freqlist(tab.ex)

str(noby)
List of 3
 $ freqlist:'data.frame':   18 obs. of  7 variables:
  ..$ arm        : Factor w/ 3 levels  A: IFL , F: FOLFOX ,..: 1 1 1 1 1 1 2 2 2 2 ...
  ..$ sex        : Factor w/ 2 levels  Male , Female : 1 1 1 2 2 2 1 1 1 2 ...
  ..$ mdquality.s: Factor w/ 2 levels  0 , 1 : 1 2 NA 1 2 NA 1 2 NA 1 ...
  ..$ Freq       : int [1:18] 29 214 34 12 118 21 31 285 95 21 ...
  ..$ cumFreq    : int [1:18] 29 243 277 289 407 428 459 744 839 860 ...
  ..$ freqPercent: num [1:18] 1.93 14.28 2.27 0.8 7.87 ...
  ..$ cumPercent : num [1:18] 1.93 16.21 18.48 19.28 27.15 ...
 $ byVar   : NULL
 $ labels  : NULL
 - attr(*,  class )= chr  freqlist 
# view the data frame portion of freqlist output
head(noby[[ freqlist ]])  ## or use as.data.frame(noby)
     arm    sex mdquality.s Freq cumFreq freqPercent cumPercent
1 A: IFL   Male           0   29      29        1.93       1.93
2 A: IFL   Male           1  214     243       14.28      16.21
3 A: IFL   Male        <NA>   34     277        2.27      18.48
4 A: IFL Female           0   12     289        0.80      19.28
5 A: IFL Female           1  118     407        7.87      27.15
6 A: IFL Female        <NA>   21     428        1.40      28.55
Basic output using summary()
The summary method for freqlist() relies on the kable() function (in the knitr package) for printing. knitr::kable() converts the output to markdown which can be printed in the console or easily rendered in Word, PDF, or HTML documents.

Note that you must supply results= asis  to properly format the markdown output.

summary(noby)
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
You can print a title for the table using the title= argument.

summary(noby, title =  Basic freqlist output )
Basic freqlist output
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
You can also easily pull out the freqlist data frame for more complicated formatting or manipulation (e.g. with another function such as xtable() or pander()) using as.data.frame():

head(as.data.frame(noby))
     arm    sex mdquality.s Freq cumFreq freqPercent cumPercent
1 A: IFL   Male           0   29      29        1.93       1.93
2 A: IFL   Male           1  214     243       14.28      16.21
3 A: IFL   Male        <NA>   34     277        2.27      18.48
4 A: IFL Female           0   12     289        0.80      19.28
5 A: IFL Female           1  118     407        7.87      27.15
6 A: IFL Female        <NA>   21     428        1.40      28.55
Using a formula with freqlist
Instead of passing a pre-computed table to freqlist(), you can instead pass a formula, which will be in turn passed to the xtabs() function. Additional freqlist() arguments are passed through the ... to the freqlist() table method.

Note that the addNA= argument was added to xtabs() in R 3.4.0. In previous versions, NAs have to be added to relevant columns using addNA().

### this works in R >= 3.4.0 summary(freqlist(~ arm + sex + mdquality.s, data =
### mockstudy, addNA = TRUE))

### This one is backwards-compatible
summary(freqlist(~arm + sex + addNA(mdquality.s), data = mockstudy))


|arm       |sex    |addNA.mdquality.s. | Freq| cumFreq| freqPercent| cumPercent|
|:|:|:|-:|-:|--:|-:|
|A: IFL    |Male   |0                  |   29|      29|        1.93|       1.93|
|          |       |1                  |  214|     243|       14.28|      16.21|
|          |       |NA                 |   34|     277|        2.27|      18.48|
|          |Female |0                  |   12|     289|        0.80|      19.28|
|          |       |1                  |  118|     407|        7.87|      27.15|
|          |       |NA                 |   21|     428|        1.40|      28.55|
|F: FOLFOX |Male   |0                  |   31|     459|        2.07|      30.62|
|          |       |1                  |  285|     744|       19.01|      49.63|
|          |       |NA                 |   95|     839|        6.34|      55.97|
|          |Female |0                  |   21|     860|        1.40|      57.37|
|          |       |1                  |  198|    1058|       13.21|      70.58|
|          |       |NA                 |   61|    1119|        4.07|      74.65|
|G: IROX   |Male   |0                  |   17|    1136|        1.13|      75.78|
|          |       |1                  |  187|    1323|       12.47|      88.26|
|          |       |NA                 |   24|    1347|        1.60|      89.86|
|          |Female |0                  |   14|    1361|        0.93|      90.79|
|          |       |1                  |  121|    1482|        8.07|      98.87|
|          |       |NA                 |   17|    1499|        1.13|     100.00|
One can also set NAs to an explicit value using includeNA().

summary(freqlist(~arm + sex + includeNA(mdquality.s,  Missing ), data = mockstudy))


|arm       |sex    |includeNA.mdquality.s...Missing.. | Freq| cumFreq| freqPercent| cumPercent|
|:|:|:|-:|-:|--:|-:|
|A: IFL    |Male   |0                                 |   29|      29|        1.93|       1.93|
|          |       |1                                 |  214|     243|       14.28|      16.21|
|          |       |Missing                           |   34|     277|        2.27|      18.48|
|          |Female |0                                 |   12|     289|        0.80|      19.28|
|          |       |1                                 |  118|     407|        7.87|      27.15|
|          |       |Missing                           |   21|     428|        1.40|      28.55|
|F: FOLFOX |Male   |0                                 |   31|     459|        2.07|      30.62|
|          |       |1                                 |  285|     744|       19.01|      49.63|
|          |       |Missing                           |   95|     839|        6.34|      55.97|
|          |Female |0                                 |   21|     860|        1.40|      57.37|
|          |       |1                                 |  198|    1058|       13.21|      70.58|
|          |       |Missing                           |   61|    1119|        4.07|      74.65|
|G: IROX   |Male   |0                                 |   17|    1136|        1.13|      75.78|
|          |       |1                                 |  187|    1323|       12.47|      88.26|
|          |       |Missing                           |   24|    1347|        1.60|      89.86|
|          |Female |0                                 |   14|    1361|        0.93|      90.79|
|          |       |1                                 |  121|    1482|        8.07|      98.87|
|          |       |Missing                           |   17|    1499|        1.13|     100.00|
Rounding percentage digits or changing variable names for printing
The digits= argument takes a single numeric value and controls the rounding of percentages in the output. The  labelTranslations= argument is a character vector or list whose length must be equal to the number of factors used in the table. Note: this does not change the names of the data frame in the freqlist object, only those used in printing. Both options are applied in the following example.

withnames <- freqlist(tab.ex, labelTranslations = c( Treatment Arm ,  Gender ,  LASA QOL ), 
    digits = 0)
summary(withnames)
Treatment Arm   Gender  LASA QOL    Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  2   2
1   214 243 14  16
NA  34  277 2   18
Female  0   12  289 1   19
1   118 407 8   27
NA  21  428 1   29
F: FOLFOX   Male    0   31  459 2   31
1   285 744 19  50
NA  95  839 6   56
Female  0   21  860 1   57
1   198 1058    13  71
NA  61  1119    4   75
G: IROX Male    0   17  1136    1   76
1   187 1323    12  88
NA  24  1347    2   90
Female  0   14  1361    1   91
1   121 1482    8   99
NA  17  1499    1   100
Additional examples
Including combinations with frequencies of zero
The sparse= argument takes a single logical value as input. The default option is FALSE. If set to TRUE, the sparse option will include combinations with frequencies of zero in the list of results. As our initial table did not have any such levels, we create a second table to use in our example.

summary(freqlist(~race + sex + arm, data = mockstudy, sparse = TRUE, digits = 1))
race    sex arm Freq    cumFreq freqPercent cumPercent
African-Am  Male    A: IFL  25  25  1.7 1.7
F: FOLFOX   24  49  1.6 3.3
G: IROX 16  65  1.1 4.4
Female  A: IFL  14  79  0.9 5.3
F: FOLFOX   25  104 1.7 7.0
G: IROX 11  115 0.7 7.7
Asian   Male    A: IFL  0   115 0.0 7.7
F: FOLFOX   10  125 0.7 8.4
G: IROX 1   126 0.1 8.4
Female  A: IFL  1   127 0.1 8.5
F: FOLFOX   4   131 0.3 8.8
G: IROX 2   133 0.1 8.9
Caucasian   Male    A: IFL  240 373 16.1    25.0
F: FOLFOX   352 725 23.6    48.6
G: IROX 195 920 13.1    61.7
Female  A: IFL  131 1051    8.8 70.4
F: FOLFOX   234 1285    15.7    86.1
G: IROX 136 1421    9.1 95.2
Hawaii/Pacific  Male    A: IFL  1   1422    0.1 95.3
F: FOLFOX   1   1423    0.1 95.4
G: IROX 0   1423    0.0 95.4
Female  A: IFL  0   1423    0.0 95.4
F: FOLFOX   2   1425    0.1 95.5
G: IROX 1   1426    0.1 95.6
Hispanic    Male    A: IFL  8   1434    0.5 96.1
F: FOLFOX   17  1451    1.1 97.3
G: IROX 12  1463    0.8 98.1
Female  A: IFL  4   1467    0.3 98.3
F: FOLFOX   11  1478    0.7 99.1
G: IROX 2   1480    0.1 99.2
Native-Am/Alaska    Male    A: IFL  1   1481    0.1 99.3
F: FOLFOX   0   1481    0.0 99.3
G: IROX 2   1483    0.1 99.4
Female  A: IFL  1   1484    0.1 99.5
F: FOLFOX   1   1485    0.1 99.5
G: IROX 0   1485    0.0 99.5
Other   Male    A: IFL  2   1487    0.1 99.7
F: FOLFOX   2   1489    0.1 99.8
G: IROX 1   1490    0.1 99.9
Female  A: IFL  0   1490    0.0 99.9
F: FOLFOX   2   1492    0.1 100.0
G: IROX 0   1492    0.0 100.0
Options for NA handling
The various na.options= allow you to include or exclude data with missing values for one or more factor levels in the counts and percentages, as well as show the missing data but exclude it from the cumulative counts and percentages. The default option is to include all combinations with missing values.

summary(freqlist(tab.ex, na.options =  include ))
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
summary(freqlist(tab.ex, na.options =  showexclude ))
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  2.33    2.33
1   214 243 17.16   19.49
NA  34  NA  NA  NA
Female  0   12  255 0.96    20.45
1   118 373 9.46    29.91
NA  21  NA  NA  NA
F: FOLFOX   Male    0   31  404 2.49    32.40
1   285 689 22.85   55.25
NA  95  NA  NA  NA
Female  0   21  710 1.68    56.94
1   198 908 15.88   72.81
NA  61  NA  NA  NA
G: IROX Male    0   17  925 1.36    74.18
1   187 1112    15.00   89.17
NA  24  NA  NA  NA
Female  0   14  1126    1.12    90.30
1   121 1247    9.70    100.00
NA  17  NA  NA  NA
summary(freqlist(tab.ex, na.options =  remove ))
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  2.33    2.33
1   214 243 17.16   19.49
Female  0   12  255 0.96    20.45
1   118 373 9.46    29.91
F: FOLFOX   Male    0   31  404 2.49    32.40
1   285 689 22.85   55.25
Female  0   21  710 1.68    56.94
1   198 908 15.88   72.81
G: IROX Male    0   17  925 1.36    74.18
1   187 1112    15.00   89.17
Female  0   14  1126    1.12    90.30
1   121 1247    9.70    100.00
Frequency counts and percentages subset by factor levels
The groupBy= argument internally subsets the data by the specified factor prior to calculating cumulative counts and percentages. By default, when used each subset will print in a separate table. Using the single = TRUE option when printing will collapse the subsetted result into a single table.

withby <- freqlist(tab.ex, groupBy = c( arm ,  sex ))
summary(withby)
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  10.47   10.47
1   214 243 77.26   87.73
NA  34  277 12.27   100.00
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Female  0   12  12  7.95    7.95
1   118 130 78.15   86.09
NA  21  151 13.91   100.00
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
F: FOLFOX   Male    0   31  31  7.54    7.54
1   285 316 69.34   76.89
NA  95  411 23.11   100.00
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
F: FOLFOX   Female  0   21  21  7.50    7.50
1   198 219 70.71   78.21
NA  61  280 21.79   100.00
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
G: IROX Male    0   17  17  7.46    7.46
1   187 204 82.02   89.47
NA  24  228 10.53   100.00
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
G: IROX Female  0   14  14  9.21    9.21
1   121 135 79.61   88.82
NA  17  152 11.18   100.00
# using the single = TRUE argument will collapse results into a single table for
# printing
summary(withby, single = TRUE)
arm sex mdquality.s Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  10.47   10.47
1   214 243 77.26   87.73
NA  34  277 12.27   100.00
Female  0   12  12  7.95    7.95
1   118 130 78.15   86.09
NA  21  151 13.91   100.00
F: FOLFOX   Male    0   31  31  7.54    7.54
1   285 316 69.34   76.89
NA  95  411 23.11   100.00
Female  0   21  21  7.50    7.50
1   198 219 70.71   78.21
NA  61  280 21.79   100.00
G: IROX Male    0   17  17  7.46    7.46
1   187 204 82.02   89.47
NA  24  228 10.53   100.00
Female  0   14  14  9.21    9.21
1   121 135 79.61   88.82
NA  17  152 11.18   100.00
Change labels on the fly
At this time, the labels can be changed just for the variables (e.g. not the frequency columns).

labels(noby) <- c( Arm ,  Sex ,  QOL )
summary(noby)
Arm Sex QOL Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
You can also supply labelTranslations= to summary().

summary(noby, labelTranslations = c( Arm ,  Sex ,  QOL ))
Arm Sex QOL Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
Using xtable() to format and print freqlist() results
Fair warning: xtable() has kind of a steep learning curve. These examples are given without explanation, for more advanced users.

require(xtable)
Loading required package: xtable
# set up custom function for xtable text
italic <- function(x) {
    paste0( <i> , x,  </i> )
}
xftbl <- xtable(noby[[ freqlist ]], caption =  xtable formatted output of freqlist data frame , 
    align =  |r|r|r|r|c|c|c|r| )

# change the column names
names(xftbl)[1:3] <- c( Arm ,  Gender ,  LASA QOL )

print(xftbl, sanitize.colnames.function = italic, include.rownames = FALSE, type =  html , 
    comment = FALSE)
xtable formatted output of freqlist data frame
Arm Gender  LASA QOL    Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
A: IFL  Male    1   214 243 14.28   16.21
A: IFL  Male        34  277 2.27    18.48
A: IFL  Female  0   12  289 0.80    19.28
A: IFL  Female  1   118 407 7.87    27.15
A: IFL  Female      21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
F: FOLFOX   Male    1   285 744 19.01   49.63
F: FOLFOX   Male        95  839 6.34    55.97
F: FOLFOX   Female  0   21  860 1.40    57.37
F: FOLFOX   Female  1   198 1058    13.21   70.58
F: FOLFOX   Female      61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
G: IROX Male    1   187 1323    12.47   88.26
G: IROX Male        24  1347    1.60    89.86
G: IROX Female  0   14  1361    0.93    90.79
G: IROX Female  1   121 1482    8.07    98.87
G: IROX Female      17  1499    1.13    100.00
Use freqlist in bookdown
Since the backbone of freqlist() is knitr::kable(), tables still render well in bookdown. However, print.summary.freqlist() doesn‚Äôt use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID.

summary(freqlist(~sex + age, data = mockstudy), title =  (\\#tab:mytableby) Caption here )
Appendix: Notes regarding table options in R
NAs
There are several widely used options for basic tables in R. The table() function in base R is probably the most common; by default it excludes NA values. You can change NA handling in base::table() using the useNA= or exclude= arguments.

# base table default removes NAs
tab.d1 <- base::table(mockstudy[, c( arm ,  sex ,  mdquality.s )], useNA =  ifany )
tab.d1
, , mdquality.s = 0

           sex
arm         Male Female
  A: IFL      29     12
  F: FOLFOX   31     21
  G: IROX     17     14

, , mdquality.s = 1

           sex
arm         Male Female
  A: IFL     214    118
  F: FOLFOX  285    198
  G: IROX    187    121

, , mdquality.s = NA

           sex
arm         Male Female
  A: IFL      34     21
  F: FOLFOX   95     61
  G: IROX     24     17
xtabs() is similar to table(), but uses a formula-based syntax. However, there is not an option for retaining NAs in the xtabs() function; instead, NAs must be added to each level of the factor where present using the addNA() function, or (in R >= 3.4.0) using the argument addNA = TRUE.

# without specifying addNA
tab.d2 <- xtabs(formula = ~arm + sex + mdquality.s, data = mockstudy)
tab.d2
, , mdquality.s = 0

           sex
arm         Male Female
  A: IFL      29     12
  F: FOLFOX   31     21
  G: IROX     17     14

, , mdquality.s = 1

           sex
arm         Male Female
  A: IFL     214    118
  F: FOLFOX  285    198
  G: IROX    187    121
# now with addNA
tab.d3 <- xtabs(~arm + sex + addNA(mdquality.s), data = mockstudy)
tab.d3
, , addNA(mdquality.s) = 0

           sex
arm         Male Female
  A: IFL      29     12
  F: FOLFOX   31     21
  G: IROX     17     14

, , addNA(mdquality.s) = 1

           sex
arm         Male Female
  A: IFL     214    118
  F: FOLFOX  285    198
  G: IROX    187    121

, , addNA(mdquality.s) = NA

           sex
arm         Male Female
  A: IFL      34     21
  F: FOLFOX   95     61
  G: IROX     24     17
Since the formula method of freqlist() uses xtabs(), NAs should be treated in the same way. includeNA() can also be helpful here for setting explicit NA values.

Table dimname names (dnn)
Supplying a data.frame to the table() function without giving columns individually will create a contingency table using all variables in the data.frame.

However, if the columns of a data.frame or matrix are supplied separately (i.e., as vectors), column names will not be preserved.

# providing variables separately (as vectors) drops column names
tab.d4 <- base::table(mockstudy$arm, mockstudy$sex, mockstudy$mdquality.s)
tab.d4
, ,  = 0

           
            Male Female
  A: IFL      29     12
  F: FOLFOX   31     21
  G: IROX     17     14

, ,  = 1

           
            Male Female
  A: IFL     214    118
  F: FOLFOX  285    198
  G: IROX    187    121
If desired, you can use the dnn= argument to pass variable names.

# add the column name labels back using dnn option in base::table
tab.dnn <- base::table(mockstudy$arm, mockstudy$sex, mockstudy$mdquality.s, dnn = c( Arm , 
     Sex ,  QOL ))
tab.dnn
, , QOL = 0

           Sex
Arm         Male Female
  A: IFL      29     12
  F: FOLFOX   31     21
  G: IROX     17     14

, , QOL = 1

           Sex
Arm         Male Female
  A: IFL     214    118
  F: FOLFOX  285    198
  G: IROX    187    121
If using freqlist(), you can provide the labels directly to freqlist() or to summary() using labelTranslations=.





## A Few Notes on Labels


https://cran.r-project.org/web/packages/arsenal/vignettes/labels.html

A Few Notes on Labels
Ethan Heinzen
09 November, 2018
Introduction
Examples
Set labels in the function call
Modify labels after the fact
Add labels to a data.frame
Introduction
The arsenal package relies somewhat heavily on variable labels to make output more ‚Äúpretty‚Äù. A label here is understood to be a single character string with ‚Äúpretty‚Äù text (i.e., not an ‚Äúugly‚Äù variable name). Three of the main  arsenal function use labels in their summary() output. There are several ways to set these labels.

We‚Äôll use the mockstudy dataset for all examples here:

library(arsenal)
data(mockstudy)
library(magrittr)

# for 'freqlist' examples
tab.ex <- table(mockstudy[, c( arm ,  sex ,  mdquality.s )], useNA= ifany )
Examples
Set labels in the function call
The summary() method for tableby(), modelsum(), and freqlist() objects contains a labelTranslations = argument to specify labels in the function call. Note that the freqlist() function matches labels in order, whereas the other two match labels by name. The labels can be input as a list or a character vector.

summary(freqlist(tab.ex),
        labelTranslations = c( Treatment Arm ,  Gender ,  LASA QOL ))
Treatment Arm   Gender  LASA QOL    Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
summary(tableby(arm ~ sex + age, data = mockstudy),
        labelTranslations = c(sex =  SEX , age =  Age, yrs ))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
SEX                 0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
summary(modelsum(bmi ~ age, adjust = ~sex, data = mockstudy),
        labelTranslations = list(sexFemale =  Female , age =  Age, yrs ))
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
Female  -0.718  0.291   0.014   
Modify labels after the fact
Another option is to add labels after you have created the object. To do this, you can use the form labels(x) <- value or use the pipe-able version, set_labels().

# the non-pipe version; somewhat clunky
tmp <- freqlist(tab.ex)
labels(tmp) <- c( Treatment Arm ,  Gender ,  LASA QOL )
summary(tmp)
Treatment Arm   Gender  LASA QOL    Freq    cumFreq freqPercent cumPercent
A: IFL  Male    0   29  29  1.93    1.93
1   214 243 14.28   16.21
NA  34  277 2.27    18.48
Female  0   12  289 0.80    19.28
1   118 407 7.87    27.15
NA  21  428 1.40    28.55
F: FOLFOX   Male    0   31  459 2.07    30.62
1   285 744 19.01   49.63
NA  95  839 6.34    55.97
Female  0   21  860 1.40    57.37
1   198 1058    13.21   70.58
NA  61  1119    4.07    74.65
G: IROX Male    0   17  1136    1.13    75.78
1   187 1323    12.47   88.26
NA  24  1347    1.60    89.86
Female  0   14  1361    0.93    90.79
1   121 1482    8.07    98.87
NA  17  1499    1.13    100.00
# piped--much cleaner
mockstudy %>% 
  tableby(arm ~ sex + age, data = .) %>% 
  set_labels(c(sex =  SEX , age =  Age, yrs )) %>% 
  summary()
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
SEX                 0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
mockstudy %>% 
  modelsum(bmi ~ age, adjust = ~ sex, data = .) %>% 
  set_labels(list(sexFemale =  Female , age =  Age, yrs )) %>% 
  summary()
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
Female  -0.718  0.291   0.014   
Add labels to a data.frame
tableby() and modelsum() also allow you to have label attributes on the data. Note that by default these attributes usually get dropped upon subsetting, but tableby() and modelsum() use the keep.labels() function to retain them.

mockstudy.lab <- keep.labels(mockstudy)
You can set attributes one at a time in two ways:

attr(mockstudy.lab$sex,  label ) <-  Sex 
labels(mockstudy.lab$age) <-  Age, yrs 
‚Ä¶or all at once:

labels(mockstudy.lab) <- list(sex =  Sex , age =  Age, yrs )
summary(tableby(arm ~ sex + age, data = mockstudy.lab))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Sex                 0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
You can pipe this, too.

mockstudy %>% 
  set_labels(list(sex =  SEX , age =  Age, yrs )) %>% 
  modelsum(bmi ~ age, adjust = ~ sex, data = .) %>% 
  summary()
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
SEX Female  -0.718  0.291   0.014   
To extract labels from a data.frame, simply use the labels() function:

labels(mockstudy.lab)
## $case
## NULL
## 
## $age
## [1]  Age, yrs 
## 
## $arm
## [1]  Treatment Arm 
## 
## $sex
## [1]  Sex 
## 
## $race
## [1]  Race 
## 
## $fu.time
## NULL
## 
## $fu.stat
## NULL
## 
## $ps
## NULL
## 
## $hgb
## NULL
## 
## $bmi
## [1]  Body Mass Index (kg/m^2) 
## 
## $alk.phos
## NULL
## 
## $ast
## NULL
## 
## $mdquality.s
## NULL
## 
## $age.ord
## NULL




## The modelsum function

https://cran.r-project.org/web/packages/arsenal/vignettes/modelsum.html

The modelsum function
Beth Atkinson, Ethan Heinzen, Pat Votruba, Jason Sinnwell, Shannon McDonnell and Greg Dougherty
09 November, 2018
Introduction
Simple Example
Pretty text version of table
Pretty Rmarkdown version of table
Data frame version of table
Add an adjustor to the model
Models for each endpoint type
Gaussian
Fit and summarize linear regression model
Extract data using the broom package
Create a summary table using modelsum
Binomial
Fit and summarize logistic regression model
Extract data using broom package
Create a summary table using modelsum
Survival
Fit and summarize a Cox regression model
Extract data using broom package
Create a summary table using modelsum
Poisson
Example 1: fit and summarize a Poisson regression model
Extract data using broom package
Create a summary table using modelsum
Example 2: fit and summarize a Poisson regression model
Extract data using broom package
Create a summary table using modelsum
Additional Examples
1. Change summary statistics globally
2. Add labels to independent variables
3. Don‚Äôt show intercept values
4. Don‚Äôt show results for adjustment variables
5. Summarize multiple variables without typing them out
6. Subset the dataset used in the analysis
7. Create combinations of variables on the fly
8. Transform variables on the fly
9. Change the ordering of the variables or delete a variable
10. Merge two modelsum objects together
11. Add a title to the table
12. Modify how missing values are treated
13. Modify the number of digits used
14. Use case-weights in the models
15. Use modelsum within an Sweave document
16. Export modelsum results to a .CSV file
17. Write modelsum object to a separate Word or HTML file
18. Use modelsum in R Shiny
23. Use modelsum in bookdown
Available Function Options
Summary statistics
modelsum.control settings
summary.modelsum settings
Introduction
Very often we are asked to summarize model results from multiple fits into a nice table. The endpoint might be of different types (e.g., survival, case/control, continuous) and there may be several independent variables that we want to examine univariately or adjusted for certain variables such as age and sex. Locally at Mayo, the SAS macros %modelsum, %glmuniv, and %logisuni were written to create such summary tables. With the increasing interest in R, we have developed the function modelsum to create similar tables within the R environment.

In developing the modelsum function, the goal was to bring the best features of these macros into an R function. However, the task was not simply to duplicate all the functionality, but rather to make use of R‚Äôs strengths (modeling, method dispersion, flexibility in function definition and output format) and make a tool that fits the needs of R users. Additionally, the results needed to fit within the general reproducible research framework so the tables could be displayed within an R markdown report.

This report provides step-by-step directions for using the functions associated with modelsum. All functions presented here are available within the arsenal package. An assumption is made that users are somewhat familiar with R markdown documents. For those who are new to the topic, a good initial resource is available at rmarkdown.rstudio.com.

Simple Example
The first step when using the modelsum function is to load the arsenal package. All the examples in this report use a dataset called mockstudy made available by Paul Novotny which includes a variety of types of variables (character, numeric, factor, ordered factor, survival) to use as examples.

> require(arsenal)
> data(mockstudy) # load data
> dim(mockstudy)  # look at how many subjects and variables are in the dataset 
[1] 1499   14
> # help(mockstudy) # learn more about the dataset and variables
> str(mockstudy) # quick look at the data
'data.frame':   1499 obs. of  14 variables:
 $ case       : int  110754 99706 105271 105001 112263 86205 99508 90158 88989 90515 ...
 $ age        : atomic  67 74 50 71 69 56 50 57 51 63 ...
  ..- attr(*,  label )= chr  Age in Years 
 $ arm        : atomic  F: FOLFOX A: IFL A: IFL G: IROX ...
  ..- attr(*,  label )= chr  Treatment Arm 
 $ sex        : Factor w/ 2 levels  Male , Female : 1 2 2 2 2 1 1 1 2 1 ...
 $ race       : atomic  Caucasian Caucasian Caucasian Caucasian ...
  ..- attr(*,  label )= chr  Race 
 $ fu.time    : int  922 270 175 128 233 120 369 421 387 363 ...
 $ fu.stat    : int  2 2 2 2 2 2 2 2 2 2 ...
 $ ps         : int  0 1 1 1 0 0 0 0 1 1 ...
 $ hgb        : num  11.5 10.7 11.1 12.6 13 10.2 13.3 12.1 13.8 12.1 ...
 $ bmi        : atomic  25.1 19.5 NA 29.4 26.4 ...
  ..- attr(*,  label )= chr  Body Mass Index (kg/m^2) 
 $ alk.phos   : int  160 290 700 771 350 569 162 152 231 492 ...
 $ ast        : int  35 52 100 68 35 27 16 12 25 18 ...
 $ mdquality.s: int  NA 1 1 1 NA 1 1 1 1 1 ...
 $ age.ord    : Ord.factor w/ 8 levels  10-19 < 20-29 <..: 6 7 4 7 6 5 4 5 5 6 ...
To create a simple linear regression table (the default), use a formula statement to specify the variables that you want summarized. The example below predicts BMI with the variables sex and age.

> tab1 <- modelsum(bmi ~ sex + age, data=mockstudy)
If you want to take a quick look at the table, you can use summary on your modelsum object and the table will print out as text in your R console window. If you use summary without any options you will see a number of &nbsp; statements which translates to ‚Äúspace‚Äù in HTML.

Pretty text version of table
If you want a nicer version in your console window then adding the text=TRUE option.

> summary(tab1, text=TRUE)


|             |estimate |std.error |p.value |adj.r.squared |
|:|:--|:|:-|:-|
|(Intercept)  |27.491   |0.181     |< 0.001 |0.004         |
|sex Female   |-0.731   |0.290     |0.012   |              |
|(Intercept)  |26.424   |0.752     |< 0.001 |0.000         |
|Age in Years |0.013    |0.012     |0.290   |              |
Pretty Rmarkdown version of table
In order for the report to look nice within an R markdown (knitr) report, you just need to specify results= asis  when creating the r chunk. This changes the layout slightly (compresses it) and bolds the variable names.

> summary(tab1)
estimate    std.error   p.value adj.r.squared
(Intercept) 27.491  0.181   < 0.001 0.004
sex Female  -0.731  0.290   0.012   
(Intercept) 26.424  0.752   < 0.001 0.000
Age in Years    0.013   0.012   0.290   
Data frame version of table
If you want a data.frame version, simply use as.data.frame.

> as.data.frame(tab1)
  model        term        label term.type    estimate  std.error
1     1 (Intercept)  (Intercept) Intercept 27.49147713 0.18134740
2     1   sexFemale   sex Female      Term -0.73105055 0.29032223
3     2 (Intercept)  (Intercept) Intercept 26.42372272 0.75211474
4     2         age Age in Years      Term  0.01304859 0.01231653
        p.value adj.r.squared
1  0.000000e+00  3.632258e-03
2  1.190605e-02  3.632258e-03
3 1.279109e-196  8.354809e-05
4  2.895753e-01  8.354809e-05
Add an adjustor to the model
The argument adjust allows the user to indicate that all the variables should be adjusted for these terms.

> tab2 <- modelsum(alk.phos ~ arm + ps + hgb, adjust= ~age + sex, data=mockstudy)
> summary(tab2)
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 175.548 20.587  < 0.001 -0.001  0
Treatment Arm F: FOLFOX -13.701 8.730   0.117       
Treatment Arm G: IROX   -2.245  9.860   0.820       
Age in Years    -0.017  0.319   0.956       
sex Female  3.016   7.521   0.688       
(Intercept) 148.391 19.585  < 0.001 0.045   266
ps  46.721  5.987   < 0.001     
Age in Years    -0.084  0.311   0.787       
sex Female  1.169   7.343   0.874       
(Intercept) 336.554 32.239  < 0.001 0.031   266
hgb -13.845 2.137   < 0.001     
Age in Years    0.095   0.314   0.763       
sex Female  -5.980  7.516   0.426       
Models for each endpoint type
To make sure the correct model is run you need to specify ‚Äúfamily‚Äù. The options available right now are : gaussian, binomial, survival, and poisson. If there is enough interest, additional models can be added.

Gaussian
Fit and summarize linear regression model
Look at whether there is any evidence that AlkPhos values vary by study arm after adjusting for sex and age (assuming a linear age relationship).

> fit <- lm(alk.phos ~ arm + age + sex, data=mockstudy)
> summary(fit)

Call:
lm(formula = alk.phos ~ arm + age + sex, data = mockstudy)

Residuals:
    Min      1Q  Median      3Q     Max 
-168.80  -81.45  -47.17   37.39  853.56 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  175.54808   20.58665   8.527   <2e-16 ***
armF: FOLFOX -13.70062    8.72963  -1.569    0.117    
armG: IROX    -2.24498    9.86004  -0.228    0.820    
age           -0.01741    0.31878  -0.055    0.956    
sexFemale      3.01598    7.52097   0.401    0.688    

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 128.5 on 1228 degrees of freedom
  (266 observations deleted due to missingness)
Multiple R-squared:  0.002552,  Adjusted R-squared:  -0.0006969 
F-statistic: 0.7855 on 4 and 1228 DF,  p-value: 0.5346
> plot(fit)

The results suggest that the endpoint may need to be transformed. Calculating the Box-Cox transformation suggests a log transformation.

> require(MASS)
> boxcox(fit)

> fit2 <- lm(log(alk.phos) ~ arm + age + sex, data=mockstudy)
> summary(fit2)

Call:
lm(formula = log(alk.phos) ~ arm + age + sex, data = mockstudy)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0098 -0.4470 -0.1065  0.4205  2.0620 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)   4.9692474  0.1025239  48.469   <2e-16 ***
armF: FOLFOX -0.0766798  0.0434746  -1.764    0.078 .  
armG: IROX   -0.0192828  0.0491041  -0.393    0.695    
age          -0.0004058  0.0015876  -0.256    0.798    
sexFemale     0.0179253  0.0374553   0.479    0.632    

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.6401 on 1228 degrees of freedom
  (266 observations deleted due to missingness)
Multiple R-squared:  0.003121,  Adjusted R-squared:  -0.0001258 
F-statistic: 0.9613 on 4 and 1228 DF,  p-value: 0.4278
> plot(fit2)

Finally, look to see whether there there is a non-linear relationship with age.

> require(gam)
> fit3 <- lm(log(alk.phos) ~ arm + ns(age, df=2) + sex, data=mockstudy)
> 
> # test whether there is a difference between models 
> stats::anova(fit2,fit3)
Analysis of Variance Table

Model 1: log(alk.phos) ~ arm + age + sex
Model 2: log(alk.phos) ~ arm + ns(age, df = 2) + sex
  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  
1   1228 503.19                              
2   1227 502.07  1    1.1137 2.7218 0.09924 .

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> # look at functional form of age
> termplot(fit3, term=2, se=T, rug=T)

In this instance it looks like there isn‚Äôt enough evidence to say that the relationship is non-linear.

Extract data using the broom package
The broom package makes it easy to extract information from the fit.

> tmp <- tidy(fit3) # coefficients, p-values
> class(tmp)
[1]  tbl_df       tbl          data.frame 
> tmp
# A tibble: 6 x 5
  term             estimate std.error statistic   p.value
  <chr>               <dbl>     <dbl>     <dbl>     <dbl>
1 (Intercept)        4.76      0.141     33.8   1.93e-177
2 armF: FOLFOX      -0.0767    0.0434    -1.77  7.78e-  2
3 armG: IROX        -0.0195    0.0491    -0.396 6.92e-  1
4 ns(age, df = 2)1   0.330     0.260      1.27  2.04e-  1
5 ns(age, df = 2)2  -0.101     0.0935    -1.08  2.82e-  1
6 sexFemale          0.0183    0.0374     0.489 6.25e-  1
> 
> glance(fit3)
# A tibble: 1 x 11
  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
*     <dbl>         <dbl> <dbl>     <dbl>   <dbl> <int>  <dbl> <dbl> <dbl>
1   0.00533       0.00127 0.640      1.31   0.255     6 -1196. 2405. 2441.
# ... with 2 more variables: deviance <dbl>, df.residual <int>
Create a summary table using modelsum
> ms.logy <- modelsum(log(alk.phos) ~ arm + ps + hgb, data=mockstudy, adjust= ~age + sex, 
+                     family=gaussian,  
+                     gaussian.stats=c( estimate , CI.lower.estimate , CI.upper.estimate , p.value ))
> summary(ms.logy)
estimate    CI.lower.estimate   CI.upper.estimate   p.value
(Intercept) 4.969   4.768   5.170   < 0.001
Treatment Arm F: FOLFOX -0.077  -0.162  0.009   0.078
Treatment Arm G: IROX   -0.019  -0.116  0.077   0.695
Age in Years    -0.000  -0.004  0.003   0.798
sex Female  0.018   -0.056  0.091   0.632
(Intercept) 4.832   4.640   5.023   < 0.001
ps  0.226   0.167   0.284   < 0.001
Age in Years    -0.001  -0.004  0.002   0.636
sex Female  0.009   -0.063  0.081   0.814
(Intercept) 5.765   5.450   6.080   < 0.001
hgb -0.069  -0.090  -0.048  < 0.001
Age in Years    0.000   -0.003  0.003   0.925
sex Female  -0.027  -0.101  0.046   0.468
Binomial
Fit and summarize logistic regression model
> boxplot(age ~ mdquality.s, data=mockstudy, ylab=attr(mockstudy$age,'label'), xlab='mdquality.s')

> 
> fit <- glm(mdquality.s ~ age + sex, data=mockstudy, family=binomial)
> summary(fit)

Call:
glm(formula = mdquality.s ~ age + sex, family = binomial, data = mockstudy)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.1832   0.4500   0.4569   0.4626   0.4756  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)  2.329442   0.514684   4.526 6.01e-06 ***
age         -0.002353   0.008256  -0.285    0.776    
sexFemale    0.039227   0.195330   0.201    0.841    

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 807.68  on 1246  degrees of freedom
Residual deviance: 807.55  on 1244  degrees of freedom
  (252 observations deleted due to missingness)
AIC: 813.55

Number of Fisher Scoring iterations: 4
> 
> # create Odd's ratio w/ confidence intervals
> tmp <- data.frame(summary(fit)$coef)
> tmp
                Estimate  Std..Error    z.value     Pr...z..
(Intercept)  2.329441734 0.514683688  4.5259677 6.011977e-06
age         -0.002353404 0.008255814 -0.2850602 7.755980e-01
sexFemale    0.039227292 0.195330166  0.2008256 8.408350e-01
> 
> tmp$OR <- round(exp(tmp[,1]),2)
> tmp$lower.CI <- round(exp(tmp[,1] - 1.96* tmp[,2]),2)
> tmp$upper.CI <- round(exp(tmp[,1] + 1.96* tmp[,2]),2)
> names(tmp)[4] <- 'P-value'
> 
> kable(tmp[,c('OR','lower.CI','upper.CI','P-value')])
OR  lower.CI    upper.CI    P-value
(Intercept) 10.27   3.75    28.17   0.000006
age 1.00    0.98    1.01    0.775598
sexFemale   1.04    0.71    1.53    0.840835
> 
> # Assess the predictive ability of the model
> 
> # code using the pROC package
> require(pROC)
> pred <- predict(fit, type='response')
> tmp <- pROC::roc(mockstudy$mdquality.s[!is.na(mockstudy$mdquality.s)]~ pred, plot=TRUE, percent=TRUE)

> tmp$auc
Area under the curve: 50.69%
Extract data using broom package
The broom package makes it easy to extract information from the fit.

> tidy(fit, exp=T, conf.int=T) # coefficients, p-values, conf.intervals
# A tibble: 3 x 7
  term        estimate std.error statistic    p.value conf.low conf.high
  <chr>          <dbl>     <dbl>     <dbl>      <dbl>    <dbl>     <dbl>
1 (Intercept)   10.3     0.515       4.53  0.00000601    3.83      28.9 
2 age            0.998   0.00826    -0.285 0.776         0.981      1.01
3 sexFemale      1.04    0.195       0.201 0.841         0.712      1.53
> 
> glance(fit) # model summary statistics
# A tibble: 1 x 7
  null.deviance df.null logLik   AIC   BIC deviance df.residual
          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int>
1          808.    1246  -404.  814.  829.     808.        1244
Create a summary table using modelsum
> summary(modelsum(mdquality.s ~ age + bmi, data=mockstudy, adjust=~sex, family=binomial))
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 10.272  3.831   28.876  < 0.001 0.507   0
Age in Years    0.998   0.981   1.014   0.776       
sex Female  1.040   0.712   1.534   0.841       
(Intercept) 4.814   1.709   13.221  0.003   0.550   33
Body Mass Index (kg/m^2)    1.023   0.987   1.063   0.220       
sex Female  1.053   0.717   1.561   0.794       
> 
> fitall <- modelsum(mdquality.s ~ age, data=mockstudy, family=binomial,
+                    binomial.stats=c( Nmiss2 , OR , p.value ))
> summary(fitall)
OR  p.value Nmiss2
(Intercept) 10.493  < 0.001 0
Age in Years    0.998   0.766   
Survival
Fit and summarize a Cox regression model
> require(survival)
Loading required package: survival

Attaching package: 'survival'
The following object is masked from 'package:rpart':

    solder
> 
> # multivariable model with all 3 terms
> fit  <- coxph(Surv(fu.time, fu.stat) ~ age + sex + arm, data=mockstudy)
> summary(fit)
Call:
coxph(formula = Surv(fu.time, fu.stat) ~ age + sex + arm, data = mockstudy)

  n= 1499, number of events= 1356 

                  coef exp(coef)  se(coef)      z Pr(>|z|)    
age           0.004600  1.004611  0.002501  1.839   0.0659 .  
sexFemale     0.039893  1.040699  0.056039  0.712   0.4765    
armF: FOLFOX -0.454650  0.634670  0.064878 -7.008 2.42e-12 ***
armG: IROX   -0.140785  0.868676  0.072760 -1.935   0.0530 .  

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

             exp(coef) exp(-coef) lower .95 upper .95
age             1.0046     0.9954    0.9997    1.0095
sexFemale       1.0407     0.9609    0.9324    1.1615
armF: FOLFOX    0.6347     1.5756    0.5589    0.7207
armG: IROX      0.8687     1.1512    0.7532    1.0018

Concordance= 0.563  (se = 0.009 )
Rsquare= 0.037   (max possible= 1 )
Likelihood ratio test= 56.21  on 4 df,   p=2e-11
Wald test            = 56.26  on 4 df,   p=2e-11
Score (logrank) test = 56.96  on 4 df,   p=1e-11
> 
> # check proportional hazards assumption
> fit.z <- cox.zph(fit)
> fit.z
                 rho chisq     p
age          -0.0311  1.46 0.226
sexFemale    -0.0325  1.44 0.230
armF: FOLFOX  0.0343  1.61 0.205
armG: IROX    0.0337  1.54 0.214
GLOBAL            NA  4.59 0.332
> plot(fit.z[1], resid=FALSE) # makes for a cleaner picture in this case
> abline(h=coef(fit)[1], col='red')

> 
> # check functional form for age using pspline (penalized spline)
> # results are returned for the linear and non-linear components
> fit2 <- coxph(Surv(fu.time, fu.stat) ~ pspline(age) + sex + arm, data=mockstudy)
> fit2
Call:
coxph(formula = Surv(fu.time, fu.stat) ~ pspline(age) + sex + 
    arm, data = mockstudy)

                         coef se(coef)      se2    Chisq   DF       p
pspline(age), linear  0.00443  0.00237  0.00237  3.48989 1.00  0.0617
pspline(age), nonlin                            13.11270 3.08  0.0047
sexFemale             0.03993  0.05610  0.05607  0.50663 1.00  0.4766
armF: FOLFOX         -0.46240  0.06494  0.06493 50.69608 1.00 1.1e-12
armG: IROX           -0.15243  0.07301  0.07299  4.35876 1.00  0.0368

Iterations: 6 outer, 16 Newton-Raphson
     Theta= 0.954 
Degrees of freedom for terms= 4.1 1.0 2.0 
Likelihood ratio test=70.1  on 7.08 df, p=2e-12
n= 1499, number of events= 1356 
> 
> # plot smoothed age to visualize why significant
> termplot(fit2, se=T, terms=1)
> abline(h=0)

> 
> # The c-statistic comes out in the summary of the fit
> summary(fit2)$concordance
        C     se(C) 
0.5684325 0.5684325 
> 
> # It can also be calculated using the survConcordance function
> survConcordance(Surv(fu.time, fu.stat) ~ predict(fit2), data=mockstudy)
Call:
survConcordance(formula = Surv(fu.time, fu.stat) ~ predict(fit2), 
    data = mockstudy)

  n= 1499 
Concordance= 0.5684325 se= 0.008779125
concordant discordant  tied.risk  tied.time   std(c-d) 
 620221.00  470282.00    5021.00     766.00   19235.49 
Extract data using broom package
The broom package makes it easy to extract information from the fit.

> tidy(fit) # coefficients, p-values
# A tibble: 4 x 7
  term         estimate std.error statistic  p.value  conf.low conf.high
  <chr>           <dbl>     <dbl>     <dbl>    <dbl>     <dbl>     <dbl>
1 age           0.00460   0.00250     1.84  6.59e- 2 -0.000302   0.00950
2 sexFemale     0.0399    0.0560      0.712 4.77e- 1 -0.0699     0.150  
3 armF: FOLFOX -0.455     0.0649     -7.01  2.42e-12 -0.582     -0.327  
4 armG: IROX   -0.141     0.0728     -1.93  5.30e- 2 -0.283      0.00182
> 
> glance(fit) # model summary statistics
# A tibble: 1 x 15
      n nevent statistic.log p.value.log statistic.sc p.value.sc
  <int>  <dbl>         <dbl>       <dbl>        <dbl>      <dbl>
1  1499   1356          56.2    1.81e-11         57.0   1.26e-11
# ... with 9 more variables: statistic.wald <dbl>, p.value.wald <dbl>,
#   r.squared <dbl>, r.squared.max <dbl>, concordance <dbl>,
#   std.error.concordance <dbl>, logLik <dbl>, AIC <dbl>, BIC <dbl>
Create a summary table using modelsum
> ##Note: You must use quotes when specifying family= survival  
> ##      family=survival will not work
> summary(modelsum(Surv(fu.time, fu.stat) ~ arm, 
+                  adjust=~age + sex, data=mockstudy, family= survival ))
HR  CI.lower.HR CI.upper.HR p.value concordance
Treatment Arm F: FOLFOX 0.635   0.559   0.721   < 0.001 0.563
Treatment Arm G: IROX   0.869   0.753   1.002   0.053   
Age in Years    1.005   1.000   1.010   0.066   
sex Female  1.041   0.932   1.162   0.477   
> 
> ##Note: the pspline term is not working yet
> #summary(modelsum(Surv(fu.time, fu.stat) ~ arm, 
> #                adjust=~pspline(age) + sex, data=mockstudy, family='survival'))
Poisson
Poisson regression is useful when predicting an outcome variable representing counts. It can also be useful when looking at survival data. Cox models and Poisson models are very closely related and survival data can be summarized using Poisson regression. If you have overdispersion (see if the residual deviance is much larger than degrees of freedom), you may want to use quasipoisson() instead of poisson(). Some of these diagnostics need to be done outside of modelsum.

Example 1: fit and summarize a Poisson regression model
For the first example, use the solder dataset available in the rpart package. The endpoint skips has a definite Poisson look.

> require(rpart) ##just to get access to solder dataset
> data(solder)
> hist(solder$skips)

> 
> fit <- glm(skips ~ Opening + Solder + Mask , data=solder, family=poisson)
> stats::anova(fit, test='Chi')
Analysis of Deviance Table

Model: poisson, link: log

Response: skips

Terms added sequentially (first to last)

        Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    
NULL                      899     8788.2              
Opening  2   2920.5       897     5867.7 < 2.2e-16 ***
Solder   1   1168.4       896     4699.3 < 2.2e-16 ***
Mask     4   2015.7       892     2683.7 < 2.2e-16 ***

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> summary(fit)

Call:
glm(formula = skips ~ Opening + Solder + Mask, family = poisson, 
    data = solder)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-6.1251  -1.4720  -0.7826   0.5986   6.6031  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -1.12220    0.07742  -14.50  < 2e-16 ***
OpeningM     0.57161    0.05707   10.02  < 2e-16 ***
OpeningS     1.81475    0.05044   35.98  < 2e-16 ***
SolderThin   0.84682    0.03327   25.45  < 2e-16 ***
MaskA3       0.51315    0.07098    7.23 4.83e-13 ***
MaskA6       1.81103    0.06609   27.40  < 2e-16 ***
MaskB3       1.20225    0.06697   17.95  < 2e-16 ***
MaskB6       1.86648    0.06310   29.58  < 2e-16 ***

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 8788.2  on 899  degrees of freedom
Residual deviance: 2683.7  on 892  degrees of freedom
AIC: 4802.2

Number of Fisher Scoring iterations: 5
Overdispersion is when the Residual deviance is larger than the degrees of freedom. This can be tested, approximately using the following code. The goal is to have a p-value that is >0.05.

> 1-pchisq(fit$deviance, fit$df.residual)
[1] 0
One possible solution is to use the quasipoisson family instead of the poisson family. This adjusts for the overdispersion.

> fit2 <- glm(skips ~ Opening + Solder + Mask, data=solder, family=quasipoisson)
> summary(fit2)

Call:
glm(formula = skips ~ Opening + Solder + Mask, family = quasipoisson, 
    data = solder)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-6.1251  -1.4720  -0.7826   0.5986   6.6031  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.12220    0.13483  -8.323 3.19e-16 ***
OpeningM     0.57161    0.09939   5.751 1.22e-08 ***
OpeningS     1.81475    0.08784  20.660  < 2e-16 ***
SolderThin   0.84682    0.05794  14.615  < 2e-16 ***
MaskA3       0.51315    0.12361   4.151 3.62e-05 ***
MaskA6       1.81103    0.11510  15.735  < 2e-16 ***
MaskB3       1.20225    0.11663  10.308  < 2e-16 ***
MaskB6       1.86648    0.10989  16.984  < 2e-16 ***

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for quasipoisson family taken to be 3.033198)

    Null deviance: 8788.2  on 899  degrees of freedom
Residual deviance: 2683.7  on 892  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5
Extract data using broom package
The broom package makes it easy to extract information from the fit.

> tidy(fit) # coefficients, p-values
# A tibble: 8 x 5
  term        estimate std.error statistic   p.value
  <chr>          <dbl>     <dbl>     <dbl>     <dbl>
1 (Intercept)   -1.12     0.0774    -14.5  1.29e- 47
2 OpeningM       0.572    0.0571     10.0  1.29e- 23
3 OpeningS       1.81     0.0504     36.0  1.66e-283
4 SolderThin     0.847    0.0333     25.5  6.47e-143
5 MaskA3         0.513    0.0710      7.23 4.83e- 13
6 MaskA6         1.81     0.0661     27.4  2.45e-165
7 MaskB3         1.20     0.0670     18.0  4.55e- 72
8 MaskB6         1.87     0.0631     29.6  2.71e-192
> 
> glance(fit) # model summary statistics
# A tibble: 1 x 7
  null.deviance df.null logLik   AIC   BIC deviance df.residual
          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int>
1         8788.     899 -2393. 4802. 4841.    2684.         892
Create a summary table using modelsum
> summary(modelsum(skips~Opening + Solder + Mask, data=solder, family= quasipoisson ))
RR  CI.lower.RR CI.upper.RR p.value
(Intercept) 1.533   1.179   1.952   < 0.001
Opening M   2.328   1.733   3.167   < 0.001
Opening S   7.491   5.780   9.888   < 0.001
(Intercept) 2.904   2.423   3.446   < 0.001
Solder Thin 2.808   2.295   3.458   < 0.001
(Intercept) 1.611   1.135   2.204   0.005
Mask A3 1.469   0.995   2.214   0.059
Mask A6 8.331   5.839   12.222  < 0.001
Mask B3 3.328   2.309   4.920   < 0.001
Mask B6 6.466   4.598   9.378   < 0.001
> summary(modelsum(skips~Opening + Solder + Mask, data=solder, family= poisson ))
RR  CI.lower.RR CI.upper.RR p.value
(Intercept) 1.533   1.397   1.678   < 0.001
Opening M   2.328   2.089   2.599   < 0.001
Opening S   7.491   6.805   8.267   < 0.001
(Intercept) 2.904   2.750   3.065   < 0.001
Solder Thin 2.808   2.637   2.992   < 0.001
(Intercept) 1.611   1.433   1.804   < 0.001
Mask A3 1.469   1.280   1.690   < 0.001
Mask A6 8.331   7.341   9.487   < 0.001
Mask B3 3.328   2.923   3.800   < 0.001
Mask B6 6.466   5.724   7.331   < 0.001
Example 2: fit and summarize a Poisson regression model
This second example uses the survival endpoint available in the mockstudy dataset. There is a close relationship between survival and Poisson models, and often it is easier to fit the model using Poisson regression, especially if you want to present absolute risk.

> # add .01 to the follow-up time (.01*1 day) in order to keep everyone in the analysis
> fit <- glm(fu.stat ~ offset(log(fu.time+.01)) + age + sex + arm, data=mockstudy, family=poisson)
> summary(fit)

Call:
glm(formula = fu.stat ~ offset(log(fu.time + 0.01)) + age + sex + 
    arm, family = poisson, data = mockstudy)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.1188  -0.4041   0.3242   0.9727   4.3588  

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -5.875627   0.108984 -53.913  < 2e-16 ***
age           0.003724   0.001705   2.184   0.0290 *  
sexFemale     0.027321   0.038575   0.708   0.4788    
armF: FOLFOX -0.335141   0.044600  -7.514 5.72e-14 ***
armG: IROX   -0.107776   0.050643  -2.128   0.0333 *  

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 2113.5  on 1498  degrees of freedom
Residual deviance: 2048.0  on 1494  degrees of freedom
AIC: 5888.2

Number of Fisher Scoring iterations: 5
> 1-pchisq(fit$deviance, fit$df.residual)
[1] 0
> 
> coef(coxph(Surv(fu.time,fu.stat) ~ age + sex + arm, data=mockstudy))
         age    sexFemale armF: FOLFOX   armG: IROX 
 0.004600011  0.039892735 -0.454650445 -0.140784996 
> coef(fit)[-1]
         age    sexFemale armF: FOLFOX   armG: IROX 
 0.003723763  0.027320917 -0.335141090 -0.107775577 
> 
> # results from the Poisson model can then be described as risk ratios (similar to the hazard ratio)
> exp(coef(fit)[-1])
         age    sexFemale armF: FOLFOX   armG: IROX 
   1.0037307    1.0276976    0.7152372    0.8978291 
> 
> # As before, we can model the dispersion which alters the standard error
> fit2 <- glm(fu.stat ~ offset(log(fu.time+.01)) + age + sex + arm, 
+             data=mockstudy, family=quasipoisson)
> summary(fit2)

Call:
glm(formula = fu.stat ~ offset(log(fu.time + 0.01)) + age + sex + 
    arm, family = quasipoisson, data = mockstudy)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.1188  -0.4041   0.3242   0.9727   4.3588  

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -5.875627   0.566666 -10.369   <2e-16 ***
age           0.003724   0.008867   0.420    0.675    
sexFemale     0.027321   0.200572   0.136    0.892    
armF: FOLFOX -0.335141   0.231899  -1.445    0.149    
armG: IROX   -0.107776   0.263318  -0.409    0.682    

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for quasipoisson family taken to be 27.03493)

    Null deviance: 2113.5  on 1498  degrees of freedom
Residual deviance: 2048.0  on 1494  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5
Extract data using broom package
The broom package makes it easy to extract information from the fit.

> tidy(fit) ##coefficients, p-values
# A tibble: 5 x 5
  term         estimate std.error statistic  p.value
  <chr>           <dbl>     <dbl>     <dbl>    <dbl>
1 (Intercept)  -5.88      0.109     -53.9   0.      
2 age           0.00372   0.00171     2.18  2.90e- 2
3 sexFemale     0.0273    0.0386      0.708 4.79e- 1
4 armF: FOLFOX -0.335     0.0446     -7.51  5.72e-14
5 armG: IROX   -0.108     0.0506     -2.13  3.33e- 2
> 
> glance(fit) ##model summary statistics
# A tibble: 1 x 7
  null.deviance df.null logLik   AIC   BIC deviance df.residual
          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int>
1         2114.    1498 -2939. 5888. 5915.    2048.        1494
Create a summary table using modelsum
Remember that the result from modelsum is different from the fit above. The modelsum summary shows the results for age + offset(log(fu.time+.01)) then sex + offset(log(fu.time+.01)) instead of age + sex + arm + offset(log(fu.time+.01)).

> summary(modelsum(fu.stat ~ age, adjust=~offset(log(fu.time+.01))+ sex + arm, 
+                  data=mockstudy, family=poisson))
RR  CI.lower.RR CI.upper.RR p.value
(Intercept) 0.003   0.002   0.003   < 0.001
Age in Years    1.004   1.000   1.007   0.029
sexFemale   1.028   0.953   1.108   0.479
armF: FOLFOX    0.715   0.656   0.781   < 0.001
armG: IROX  0.898   0.813   0.991   0.033
Additional Examples
Here are multiple examples showing how to use some of the different options.

1. Change summary statistics globally
There are standard settings for each type of model regarding what information is summarized in the table. This behavior can be modified using the modelsum.control function. In fact, you can save your standard settings and use that for future tables.

> mycontrols  <- modelsum.control(gaussian.stats=c( estimate , std.error , adj.r.squared , Nmiss ),
+                                 show.adjust=FALSE, show.intercept=FALSE)                            
> tab2 <- modelsum(bmi ~ age, adjust=~sex, data=mockstudy, control=mycontrols)
> summary(tab2)
estimate    std.error   adj.r.squared
Age in Years    0.012   0.012   0.004
You can also change these settings directly in the modelsum call.

> tab3 <- modelsum(bmi ~  age, adjust=~sex, data=mockstudy,
+                  gaussian.stats=c( estimate , std.error , adj.r.squared , Nmiss ), 
+                  show.intercept=FALSE, show.adjust=FALSE)
> summary(tab3)
estimate    std.error   adj.r.squared
Age in Years    0.012   0.012   0.004
2. Add labels to independent variables
In the above example, age is shown with a label (Age in Years), but sex is listed ‚Äúas is‚Äù. This is because the data was created in SAS and in the SAS dataset, age had a label but sex did not. The label is stored as an attribute within R.

> ## Look at one variable's label
> attr(mockstudy$age,'label')
[1]  Age in Years 
> 
> ## See all the variables with a label
> unlist(lapply(mockstudy,'attr','label'))
                       age                        arm 
             Age in Years              Treatment Arm  
                      race                        bmi 
                     Race   Body Mass Index (kg/m^2)  
> 
> ## or
> cbind(sapply(mockstudy,attr,'label'))
            [,1]                      
case        NULL                      
age          Age in Years             
arm          Treatment Arm            
sex         NULL                      
race         Race                     
fu.time     NULL                      
fu.stat     NULL                      
ps          NULL                      
hgb         NULL                      
bmi          Body Mass Index (kg/m^2) 
alk.phos    NULL                      
ast         NULL                      
mdquality.s NULL                      
age.ord     NULL                      
If you want to add labels to other variables, there are a couple of options. First, you could add labels to the variables in your dataset.

> attr(mockstudy$age,'label')  <- 'Age, yrs'
> 
> tab1 <- modelsum(bmi ~  age, adjust=~sex, data=mockstudy)
> summary(tab1)
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
sex Female  -0.718  0.291   0.014   
You can also use the built-in data.frame method for labels<-:

> labels(mockstudy)  <- c(age = 'Age, yrs')
> 
> tab1 <- modelsum(bmi ~  age, adjust=~sex, data=mockstudy)
> summary(tab1)
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
sex Female  -0.718  0.291   0.014   
Another option is to add labels after you have created the table

> mylabels <- list(sexFemale =  Female , age = Age, yrs )
> summary(tab1, labelTranslations = mylabels)
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Age, yrs    0.012   0.012   0.348   
Female  -0.718  0.291   0.014   
Alternatively, you can check the variable labels and manipulate them with a function called labels, which works on the modelsum object.

> labels(tab1)
                       bmi                        age 
 Body Mass Index (kg/m^2)                   Age, yrs  
                 sexFemale 
               sex Female  
> labels(tab1) <- c(sexFemale= Female , age= Baseline Age (yrs) )
> labels(tab1)
                       bmi                        age 
 Body Mass Index (kg/m^2)         Baseline Age (yrs)  
                 sexFemale 
                   Female  
> summary(tab1)
estimate    std.error   p.value adj.r.squared
(Intercept) 26.793  0.766   < 0.001 0.004
Baseline Age (yrs)  0.012   0.012   0.348   
Female  -0.718  0.291   0.014   
3. Don‚Äôt show intercept values
> summary(modelsum(age~mdquality.s+sex, data=mockstudy), show.intercept=FALSE)
estimate    std.error   p.value adj.r.squared   Nmiss
mdquality.s -0.326  1.093   0.766   -0.001  252
sex Female  -1.208  0.610   0.048   0.002   0
4. Don‚Äôt show results for adjustment variables
> summary(modelsum(mdquality.s ~ age + bmi, data=mockstudy, adjust=~sex, family=binomial),
+         show.adjust=FALSE)  
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 10.272  3.831   28.876  < 0.001 0.507   0
Age, yrs    0.998   0.981   1.014   0.776       
(Intercept) 4.814   1.709   13.221  0.003   0.550   33
Body Mass Index (kg/m^2)    1.023   0.987   1.063   0.220       
5. Summarize multiple variables without typing them out
Often one wants to summarize a number of variables. Instead of typing by hand each individual variable, an alternative approach is to create a formula using the paste command with the collapse= +  option.

> # create a vector specifying the variable names
> myvars <- names(mockstudy)
> 
> # select the 8th through the 12th
> # paste them together, separated by the + sign
> RHS <- paste(myvars[8:12], collapse= + )
> RHS
[1] ‚Äúps+hgb+bmi+alk.phos+ast‚Äù

> 
> # create a formula using the as.formula function
> as.formula(paste('mdquality.s ~ ', RHS))
mdquality.s ~ ps + hgb + bmi + alk.phos + ast

> 
> # use the formula in the modelsum function
> summary(modelsum(as.formula(paste('mdquality.s ~', RHS)), family=binomial, data=mockstudy))
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 14.628  10.755  20.399  < 0.001 0.620   266
ps  0.461   0.332   0.639   < 0.001     
(Intercept) 1.236   0.272   5.560   0.783   0.573   266
hgb 1.176   1.040   1.334   0.011       
(Intercept) 4.963   1.818   13.292  0.002   0.549   33
Body Mass Index (kg/m^2)    1.023   0.987   1.062   0.225       
(Intercept) 10.622  7.687   14.794  < 0.001 0.552   266
alk.phos    0.999   0.998   1.000   0.159       
(Intercept) 10.936  7.912   15.232  < 0.001 0.545   266
ast 0.995   0.988   1.001   0.099       
These steps can also be done using the formulize function.

> ## The formulize function does the paste and as.formula steps
> tmp <- formulize('mdquality.s',myvars[8:10])
> tmp
mdquality.s ~ ps + hgb + bmi

> 
> ## More complex formulas could also be written using formulize
> tmp2 <- formulize('mdquality.s',c('ps','hgb','sqrt(bmi)'))
> 
> ## use the formula in the modelsum function
> summary(modelsum(tmp, data=mockstudy, family=binomial))
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 14.628  10.755  20.399  < 0.001 0.620   266
ps  0.461   0.332   0.639   < 0.001     
(Intercept) 1.236   0.272   5.560   0.783   0.573   266
hgb 1.176   1.040   1.334   0.011       
(Intercept) 4.963   1.818   13.292  0.002   0.549   33
Body Mass Index (kg/m^2)    1.023   0.987   1.062   0.225       
6. Subset the dataset used in the analysis
Here are two ways to get the same result (limit the analysis to subjects age>50 and in the F: FOLFOX treatment group).

The first approach uses the subset function applied to the dataset mockstudy. This example also selects a subset of variables. The modelsum function is then applied to this subsetted data.
> newdata <- subset(mockstudy, subset=age>50 & arm=='F: FOLFOX', select = c(age,sex, bmi:alk.phos))
> dim(mockstudy)
[1] 1499   14
> table(mockstudy$arm)

   A: IFL F: FOLFOX   G: IROX 
      428       691       380 
> dim(newdata)
[1] 557   4
> names(newdata)
[1]  age        sex        bmi        alk.phos 
> summary(modelsum(alk.phos ~ ., data=newdata))
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 122.577 46.924  0.009   -0.001  0
age 0.619   0.719   0.390       
(Intercept) 164.814 7.673   < 0.001 -0.002  0
sex Female  -5.497  12.118  0.650       
(Intercept) 238.658 33.705  < 0.001 0.010   15
bmi -2.776  1.207   0.022       
The second approach does the same analysis but uses the subset argument within modelsum to subset the data.
> summary(modelsum(log(alk.phos) ~ sex + ps + bmi, subset=age>50 & arm== F: FOLFOX , data=mockstudy))
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 4.872   0.039   < 0.001 -0.002  0
sex Female  -0.005  0.062   0.931       
(Intercept) 4.770   0.040   < 0.001 0.027   108
ps  0.183   0.050   < 0.001     
(Intercept) 5.207   0.172   < 0.001 0.007   15
Body Mass Index (kg/m^2)    -0.012  0.006   0.044       
> summary(modelsum(alk.phos ~ ps + bmi, adjust=~sex, subset = age>50 & bmi<24, data=mockstudy))
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 178.812 14.550  < 0.001 0.007   77
ps  20.834  13.440  0.122       
sex Female  -17.542 16.656  0.293       
(Intercept) 373.008 104.272 < 0.001 0.009   24
Body Mass Index (kg/m^2)    -8.239  4.727   0.083       
sex Female  -24.058 16.855  0.155       
> summary(modelsum(alk.phos ~ ps + bmi, adjust=~sex, subset=1:30, data=mockstudy))
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 169.112 57.013  0.006   0.294   0
ps  254.901 68.100  < 0.001     
sex Female  49.566  67.643  0.470       
(Intercept) 453.070 200.651 0.033   -0.049  1
Body Mass Index (kg/m^2)    -5.993  7.408   0.426       
sex Female  -22.308 79.776  0.782       
7. Create combinations of variables on the fly
> ## create a variable combining the levels of mdquality.s and sex
> with(mockstudy, table(interaction(mdquality.s,sex)))

  0.Male   1.Male 0.Female 1.Female 
      77      686       47      437 
> summary(modelsum(age ~ interaction(mdquality.s,sex), data=mockstudy))
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 59.714  1.314   < 0.001 0.003   252
interaction(mdquality.s, sex) 1.Male    0.730   1.385   0.598       
interaction(mdquality.s, sex) 0.Female  0.988   2.134   0.643       
interaction(mdquality.s, sex) 1.Female  -1.021  1.425   0.474       
8. Transform variables on the fly
Certain transformations need to be surrounded by I() so that R knows to treat it as a variable transformation and not some special model feature. If the transformation includes any of the symbols / - + ^ * then surround the new variable by I().

> summary(modelsum(arm== F: FOLFOX  ~ I(age/10) + log(bmi) + mdquality.s,
+                  data=mockstudy, family=binomial))
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 0.656   0.382   1.124   0.126   0.514   0
Age, yrs    1.045   0.957   1.142   0.326       
(Intercept) 0.633   0.108   3.698   0.611   0.508   33
Body Mass Index (kg/m^2)    1.092   0.638   1.867   0.748       
(Intercept) 0.722   0.503   1.029   0.074   0.502   252
mdquality.s 1.045   0.719   1.527   0.819       
9. Change the ordering of the variables or delete a variable
> mytab <- modelsum(bmi ~ sex + alk.phos + age, data=mockstudy)
> mytab2 <- mytab[c('age','sex','alk.phos')]
> summary(mytab2)
estimate    std.error   p.value adj.r.squared   Nmiss
(Intercept) 26.424  0.752   < 0.001 0.000   0
Age, yrs    0.013   0.012   0.290       
(Intercept) 27.491  0.181   < 0.001 0.004   0
sex Female  -0.731  0.290   0.012       
(Intercept) 27.944  0.253   < 0.001 0.011   266
alk.phos    -0.005  0.001   < 0.001     
> summary(mytab[c('age','sex')])
estimate    std.error   p.value adj.r.squared
(Intercept) 26.424  0.752   < 0.001 0.000
Age, yrs    0.013   0.012   0.290   
(Intercept) 27.491  0.181   < 0.001 0.004
sex Female  -0.731  0.290   0.012   
> summary(mytab[c(3,1)])
estimate    std.error   p.value adj.r.squared
(Intercept) 26.424  0.752   < 0.001 0.000
Age, yrs    0.013   0.012   0.290   
(Intercept) 27.491  0.181   < 0.001 0.004
sex Female  -0.731  0.290   0.012   
10. Merge two modelsum objects together
It is possible to combine two modelsum objects so that they print out together, however you need to pay attention to the columns that are being displayed. It is easier to combine two models of the same family (such as two sets of linear models). If you want to combine linear and logistic model results then you would want to display the beta coefficients for the logistic model.

> ## demographics
> tab1 <- modelsum(bmi ~ sex + age, data=mockstudy)
> ## lab data
> tab2 <- modelsum(mdquality.s ~ hgb + alk.phos, data=mockstudy, family=binomial)
>                 
> tab12 <- merge(tab1,tab2)
> class(tab12)
[1] ‚ÄúmodelsumList‚Äù

> 
> ##ERROR: The merge works, but not the summary
> #summary(tab12)
11. Add a title to the table
When creating a pdf the tables are automatically numbered and the title appears below the table. In Word and HTML, the titles appear un-numbered and above the table.

> t1 <- modelsum(bmi ~ sex + age, data=mockstudy)
> summary(t1, title='Demographics')
Demographics
estimate    std.error   p.value adj.r.squared
(Intercept) 27.491  0.181   < 0.001 0.004
sex Female  -0.731  0.290   0.012   
(Intercept) 26.424  0.752   < 0.001 0.000
Age, yrs    0.013   0.012   0.290   
12. Modify how missing values are treated
Depending on the report you are writing you have the following options:

Use all values available for each variable

Use only those subjects who have measurements available for all the variables

> ## look at how many missing values there are for each variable
> apply(is.na(mockstudy),2,sum)
       case         age         arm         sex        race     fu.time 
          0           0           0           0           7           0 
    fu.stat          ps         hgb         bmi    alk.phos         ast 
          0         266         266          33         266         266 
mdquality.s     age.ord 
        252           0 
> ## Show how many subjects have each variable (non-missing)
> summary(modelsum(bmi ~ ast + age, data=mockstudy,
+                 control=modelsum.control(gaussian.stats=c( N , estimate ))))
estimate    N
(Intercept) 27.331  1233
ast -0.005  
(Intercept) 26.424  1499
Age, yrs    0.013   
> 
> ## Always list the number of missing values
> summary(modelsum(bmi ~ ast + age, data=mockstudy,
+                 control=modelsum.control(gaussian.stats=c( Nmiss2 , estimate ))))
estimate    Nmiss2
(Intercept) 27.331  266
ast -0.005  
(Intercept) 26.424  0
Age, yrs    0.013   
> 
> ## Only show the missing values if there are some (default)
> summary(modelsum(bmi ~ ast + age, data=mockstudy, 
+                 control=modelsum.control(gaussian.stats=c( Nmiss , estimate ))))
estimate    Nmiss
(Intercept) 27.331  266
ast -0.005  
(Intercept) 26.424  0
Age, yrs    0.013   
> 
> ## Don't show N at all
> summary(modelsum(bmi ~ ast + age, data=mockstudy, 
+                 control=modelsum.control(gaussian.stats=c( estimate ))))
estimate
(Intercept) 27.331
ast -0.005
(Intercept) 26.424
Age, yrs    0.013
13. Modify the number of digits used
Within modelsum.control function there are 3 options for controlling the number of significant digits shown.

digits: controls the number of digits after the decimal point for continuous values

digits.ratio: controls the number of digits after the decimal point for continuous values

digits.p: controls the number of digits after the decimal point for continuous values

> summary(modelsum(bmi ~ sex + age + fu.time, data=mockstudy), digits=4, digits.test=2)
Warning: Using 'digits.test = ' is deprecated. Use 'digits.p = ' instead.
estimate    std.error   p.value adj.r.squared
(Intercept) 27.4915 0.1813  < 0.001 0.0036
sex Female  -0.7311 0.2903  0.012   
(Intercept) 26.4237 0.7521  < 0.001 0.0001
Age, yrs    0.0130  0.0123  0.290   
(Intercept) 26.4937 0.2447  < 0.001 0.0079
fu.time 0.0011  0.0003  < 0.001 
14. Use case-weights in the models
Occasionally it is of interest to fit models using case weights. The modelsum function allows you to pass on the weights to the models and it will do the appropriate fit.

> mockstudy$agegp <- cut(mockstudy$age, breaks=c(18,50,60,70,90), right=FALSE)
> 
> ## create weights based on agegp and sex distribution
> tab1 <- with(mockstudy,table(agegp, sex))
> tab1
         sex
agegp     Male Female
  [18,50)  152    110
  [50,60)  258    178
  [60,70)  295    173
  [70,90)  211    122
> tab2 <- with(mockstudy, table(agegp, sex, arm))
> gpwts <- rep(tab1, length(unique(mockstudy$arm)))/tab2
> 
> ## apply weights to subjects
> index <- with(mockstudy, cbind(as.numeric(agegp), as.numeric(sex), as.numeric(as.factor(arm)))) 
> mockstudy$wts <- gpwts[index]
> 
> ## show weights by treatment arm group
> tapply(mockstudy$wts,mockstudy$arm, summary)
$`A: IFL`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  2.923   3.225   3.548   3.502   3.844   4.045 

$`F: FOLFOX`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  2.033   2.070   2.201   2.169   2.263   2.303 

$`G: IROX`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  3.667   3.734   4.023   3.945   4.031   4.471 
> mockstudy$newvarA <- as.numeric(mockstudy$arm=='A: IFL')
> tab1 <- modelsum(newvarA ~ ast + bmi + hgb, data=mockstudy, subset=(arm !='G: IROX'), 
+                  family=binomial)
> summary(tab1, title='No Case Weights used')
No Case Weights used
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 0.590   0.473   0.735   < 0.001 0.550   210
ast 1.003   0.998   1.008   0.258       
(Intercept) 0.578   0.306   1.093   0.091   0.500   29
Body Mass Index (kg/m^2)    1.003   0.980   1.026   0.808       
(Intercept) 1.006   0.386   2.631   0.990   0.514   210
hgb 0.965   0.894   1.043   0.372       
> 
> suppressWarnings({
+ tab2 <- modelsum(newvarA ~ ast + bmi + hgb, data=mockstudy, subset=(arm !='G: IROX'), 
+                  weights=wts, family=binomial)
+ summary(tab2, title='Case Weights used')
+ })
Case Weights used
OR  CI.lower.OR CI.upper.OR p.value concordance Nmiss
(Intercept) 0.956   0.837   1.091   0.504   0.550   210
ast 1.003   1.000   1.006   0.068       
(Intercept) 0.957   0.658   1.393   0.820   0.500   29
Body Mass Index (kg/m^2)    1.002   0.988   1.016   0.780       
(Intercept) 1.829   1.031   3.248   0.039   0.514   210
hgb 0.956   0.913   1.001   0.058       
15. Use modelsum within an Sweave document
For those users who wish to create tables within an Sweave document, the following code seems to work.

\documentclass{article}

\usepackage{longtable}
\usepackage{pdfpages}

\begin{document}

\section{Read in Data}
<<echo=TRUE>>=
require(arsenal)
require(knitr)
require(rmarkdown)
data(mockstudy)

tab1 <- modelsum(bmi~sex+age, data=mockstudy)
@

\section{Convert Summary.modelsum to LaTeX}
<<echo=TRUE, results='hide', message=FALSE>>=
capture.output(summary(tab1), file= Test.md )

## Convert R Markdown Table to LaTeX
render( Test.md , pdf_document(keep_tex=TRUE))
@ 

\includepdf{Test.pdf}

\end{document}
16. Export modelsum results to a .CSV file
When looking at multiple variables it is sometimes useful to export the results to a csv file. The as.data.frame function creates a data frame object that can be exported or further manipulated within R.

> summary(tab2, text=T)


|                         |OR    |CI.lower.OR |CI.upper.OR |p.value |concordance |Nmiss |
|:|:--|:--|:--|:-|:--|:--|
|(Intercept)              |0.956 |0.837       |1.091       |0.504   |0.550       |210   |
|ast                      |1.003 |1.000       |1.006       |0.068   |            |      |
|(Intercept)              |0.957 |0.658       |1.393       |0.820   |0.500       |29    |
|Body Mass Index (kg/m^2) |1.002 |0.988       |1.016       |0.780   |            |      |
|(Intercept)              |1.829 |1.031       |3.248       |0.039   |0.514       |210   |
|hgb                      |0.956 |0.913       |1.001       |0.058   |            |      |
> tmp <- as.data.frame(tab2)
> tmp
  model        term                    label term.type        OR
1     1 (Intercept)              (Intercept) Intercept 0.9559704
2     1         ast                      ast      Term 1.0027311
3     2 (Intercept)              (Intercept) Intercept 0.9573694
4     2         bmi Body Mass Index (kg/m^2)      Term 1.0019251
5     3 (Intercept)              (Intercept) Intercept 1.8287083
6     3         hgb                      hgb      Term 0.9563507
  CI.lower.OR CI.upper.OR    p.value concordance Nmiss
1   0.8373522    1.090904 0.50443340   0.5499494   210
2   0.9998110    1.005696 0.06813456   0.5499494   210
3   0.6579225    1.392859 0.81981779   0.5002561    29
4   0.9884804    1.015561 0.78019163   0.5002561    29
5   1.0311954    3.247941 0.03911088   0.5138162   210
6   0.9132041    1.001419 0.05770821   0.5138162   210
> # write.csv(tmp, '/my/path/here/mymodel.csv')
17. Write modelsum object to a separate Word or HTML file
> ## write to an HTML document
> write2html(tab2,  ~/ibm/trash.html )
> 
> ## write to a Word document
> write2word(tab2,  ~/ibm/trash.doc , title= My table in Word )
18. Use modelsum in R Shiny
The easiest way to output a modelsum() object in an R Shiny app is to use the tableOutput() UI in combination with the renderTable() server function and as.data.frame(summary(modelsum())):

> # A standalone shiny app
> library(shiny)
> library(arsenal)
> data(mockstudy)
> 
> shinyApp(
+   ui = fluidPage(tableOutput( table )),
+   server = function(input, output) {
+     output$table <- renderTable({
+       as.data.frame(summary(modelsum(age ~ sex, data = mockstudy), text =  html ))
+     }, sanitize.text.function = function(x) x)
+   }
+ )
This can be especially powerful if you feed the selections from a selectInput(multiple = TRUE) into formulize() to make the table dynamic!

23. Use modelsum in bookdown
Since the backbone of modelsum() is knitr::kable(), tables still render well in bookdown. However, print.summary.modelsum() doesn‚Äôt use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID.

> summary(modelsum(age ~ sex, data = mockstudy), title= (\\#tab:mytableby) Caption here )
Available Function Options
Summary statistics
The available summary statistics, by varible type, are:

ordinal: Ordinal logistic regression models
default: Nmiss, OR, CI.lower.OR, CI.upper.OR, p.value
optional: estimate, CI.OR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, endpoint, std.error, statistic, logLik, AIC, BIC, edf, deviance, df.residual
binomial,quasibinomial: Logistic regression models
default: OR, CI.lower.OR, CI.upper.OR, p.value, concordance, Nmiss
optional: estimate, CI.OR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, endpoint, std.error, statistic, logLik, AIC, BIC, null.deviance, deviance, df.residual, df.null
gaussian: Linear regression models
default: estimate, std.error, p.value, adj.r.squared, Nmiss
optional: CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, statistic, standard.estimate, endpoint, r.squared, AIC, BIC, logLik, statistic.F, p.value.F
poisson, quasipoisson: Poisson regression models
default: RR, CI.lower.RR, CI.upper.RR, p.value, Nmiss
optional: CI.RR, CI.estimate, CI.lower.estimate, CI.upper.estimate, CI.RR, Nmiss2, std.error, estimate, statistic, endpoint, AIC, BIC, logLik, dispersion, null.deviance, deviance, df.residual, df.null
negbin: Negative binomial regression models
default: RR, CI.lower.RR, CI.upper.RR, p.value, Nmiss
optional: CI.RR, CI.estimate, CI.lower.estimate, CI.upper.estimate, CI.RR, Nmiss2, std.error, estimate, statistic, endpoint, AIC, BIC, logLik, dispersion, null.deviance, deviance, df.residual, df.null, theta, SE.theta
survival: Cox models
default: HR, CI.lower.HR, CI.upper.HR, p.value, concordance, Nmiss
optional: CI.HR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, estimate, std.error, endpoint, Nevents, statistic, r.squared, logLik, AIC, BIC, statistic.sc, p.value.sc, p.value.log, p.value.wald, N, std.error.concordance
The full description of these parameters that can be shown for models include:

N: a count of the number of observations used in the analysis
Nmiss: only show the count of the number of missing values if there are some missing values
Nmiss2: always show a count of the number of missing values for a model
endpoint: dependent variable used in the model
std.err: print the standard error
statistic: test statistic
statistic.F: test statistic (F test)
p.value: print the p-value
r.squared: print the model R-square
adj.r.squared: print the model adjusted R-square
r.squared: print the model R-square
concordance: print the model C statistic (which is the AUC for logistic models)
logLik: print the loglikelihood value
p.value.log: print the p-value for the overall model likelihood test
p.value.wald: print the p-value for the overall model wald test
p.value.sc: print the p-value for overall model score test
AIC: print the Akaike information criterion
BIC: print the Bayesian information criterion
null.deviance: null deviance
deviance: model deviance
df.residual: degrees of freedom for the residual
df.null: degrees of freedom for the null model
dispersion: This is used in Poisson models and is defined as the deviance/df.residual
statistic.sc: overall model score statistic
std.error.concordance: standard error for the C statistic
HR: print the hazard ratio (for survival models), i.e. exp(beta)
CI.lower.HR, CI.upper.HR: print the confidence interval for the HR
OR: print the odd‚Äôs ratio (for logistic models), i.e. exp(beta)
CI.lower.OR, CI.upper.OR: print the confidence interval for the OR
RR: print the risk ratio (for poisson models), i.e. exp(beta)
CI.lower.RR, CI.upper.RR: print the confidence interval for the RR
estimate: print beta coefficient
standardized.estimate: print the standardized beta coefficient
CI.lower.estimate, CI.upper.estimate: print the confidence interval for the beta coefficient
edf: print the effective degrees of freedom.
theta: print the estimate of theta.
SE.theta: print the estimate of theta‚Äôs standard error.
modelsum.control settings
A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in modelsum.control or in summary.modelsum.

> args(modelsum.control)
function (digits = 3L, digits.ratio = 3L, digits.p = 3L, format.p = TRUE, 
    show.adjust = TRUE, show.intercept = TRUE, conf.level = 0.95, 
    ordinal.stats = c( OR ,  CI.lower.OR ,  CI.upper.OR ,  p.value , 
         Nmiss ), binomial.stats = c( OR ,  CI.lower.OR ,  CI.upper.OR , 
         p.value ,  concordance ,  Nmiss ), gaussian.stats = c( estimate , 
         std.error ,  p.value ,  adj.r.squared ,  Nmiss ), poisson.stats = c( RR , 
         CI.lower.RR ,  CI.upper.RR ,  p.value ,  Nmiss ), negbin.stats = c( RR , 
         CI.lower.RR ,  CI.upper.RR ,  p.value ,  Nmiss ), survival.stats = c( HR , 
         CI.lower.HR ,  CI.upper.HR ,  p.value ,  concordance , 
         Nmiss ), stat.labels = list(), ...) 
NULL
summary.modelsum settings
The summary.modelsum function has options that modify how the table appears (such as adding a title or modifying labels).

> args(arsenal:::summary.modelsum)
function (object, ..., labelTranslations = NULL, text = FALSE, 
    title = NULL, term.name =   ) 
NULL




## The paired function


https://cran.r-project.org/web/packages/arsenal/vignettes/paired.html

The paired function
Ethan Heinzen, Beth Atkinson, Jason Sinnwell
09 November, 2018
Introduction
Simple Example
NAs
Available Function Options
Testing options
paired.control settings
summary.tableby settings
Introduction
Another one of the most common tables in medical literature includes summary statistics for a set of variables paired across two time points. Locally at Mayo, the SAS macro %paired was written to create summary tables with a single call. With the increasing interest in R, we have developed the function paired() to create similar tables within the R environment.

This vignette is light on purpose; paired() piggybacks off of tableby, so most documentation there applies here, too.

Simple Example
The first step when using the paired() function is to load the arsenal package. We can‚Äôt use mockstudy here because we need a dataset with paired observations, so we‚Äôll create our own dataset.

library(arsenal)
dat <- data.frame(
  tp = paste0( Time Point  , c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)),
  id = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 6),
  Cat = c( A ,  A ,  A ,  B ,  B ,  B ,  B ,  A , NA,  B ),
  Fac = factor(c( A ,  B ,  C ,  A ,  B ,  C ,  A ,  B ,  C ,  A )),
  Num = c(1, 2, 3, 4, 4, 3, 3, 4, 0, NA),
  Ord = ordered(c( I ,  II ,  II ,  III ,  III ,  III ,  I ,  III ,  II ,  I )),
  Lgl = c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE),
  Dat = as.Date( 2018-05-01 ) + c(1, 1, 2, 2, 3, 4, 5, 6, 3, 4),
  stringsAsFactors = FALSE
)
To create a simple table stratified by time point, use a formula= statement to specify the variables that you want summarized and the id= argument to specify the paired observations.

p <- paired(tp ~ Cat + Fac + Num + Ord + Lgl + Dat, data = dat, id = id, signed.rank.exact = FALSE)
summary(p)
Time Point 1 (N=4)  Time Point 2 (N=4)  Difference (N=4)    p value
Cat             1.000
   A    2 (50.0%)   2 (50.0%)   1 (50.0%)   
   B    2 (50.0%)   2 (50.0%)   1 (50.0%)   
Fac             0.261
   A    2 (50.0%)   1 (25.0%)   2 (100.0%)  
   B    1 (25.0%)   2 (50.0%)   1 (100.0%)  
   C    1 (25.0%)   1 (25.0%)   1 (100.0%)  
Num             0.391
   Mean (SD)    2.750 (1.258)   3.250 (0.957)   0.500 (1.000)   
   Range    1.000 - 4.000   2.000 - 4.000   -1.000 - 1.000  
Ord             0.174
   I    2 (50.0%)   0 (0.0%)    2 (100.0%)  
   II   1 (25.0%)   1 (25.0%)   1 (100.0%)  
   III  1 (25.0%)   3 (75.0%)   0 (0.0%)    
Lgl             1.000
   FALSE    2 (50.0%)   1 (25.0%)   2 (100.0%)  
   TRUE 2 (50.0%)   3 (75.0%)   1 (50.0%)   
Dat             0.182
   median   2018-05-03  2018-05-04  0.500   
   Range    2018-05-02 - 2018-05-06 2018-05-02 - 2018-05-07 0.000 - 1.000   
The third column shows the difference between time point 1 and time point 2. For categorical variables, it reports the percent of observations from time point 1 which changed in time point 2.

NAs
Note that by default, observations which do not have both timepoints are removed. This is easily changed using the na.action = na.paired( <arg> ) argument. For example:

p <- paired(tp ~ Cat + Fac + Num + Ord + Lgl + Dat, data = dat, id = id,
            signed.rank.exact = FALSE, na.action = na.paired( fill ))
summary(p)
Time Point 1 (N=6)  Time Point 2 (N=6)  Difference (N=6)    p value
Cat             1.000
   N-Miss   2   1   2   
   A    2 (50.0%)   2 (40.0%)   1 (50.0%)   
   B    2 (50.0%)   3 (60.0%)   1 (50.0%)   
Fac             0.261
   N-Miss   1   1   2   
   A    2 (40.0%)   2 (40.0%)   2 (100.0%)  
   B    1 (20.0%)   2 (40.0%)   1 (100.0%)  
   C    2 (40.0%)   1 (20.0%)   1 (100.0%)  
Num             0.391
   N-Miss   1   2   2   
   Mean (SD)    2.200 (1.643)   3.250 (0.957)   0.500 (1.000)   
   Range    0.000 - 4.000   2.000 - 4.000   -1.000 - 1.000  
Ord             0.174
   N-Miss   1   1   2   
   I    2 (40.0%)   1 (20.0%)   2 (100.0%)  
   II   2 (40.0%)   1 (20.0%)   1 (100.0%)  
   III  1 (20.0%)   3 (60.0%)   0 (0.0%)    
Lgl             1.000
   N-Miss   1   1   2   
   FALSE    3 (60.0%)   2 (40.0%)   2 (100.0%)  
   TRUE 2 (40.0%)   3 (60.0%)   1 (50.0%)   
Dat             0.182
   N-Miss   1   1   2   
   median   2018-05-04  2018-05-05  0.500   
   Range    2018-05-02 - 2018-05-06 2018-05-02 - 2018-05-07 0.000 - 1.000   
For more details, see the help page for na.paired().

Available Function Options
Testing options
The tests used to calculate p-values differ by the variable type, but can be specified explicitly in the formula statement or in the control function.

The following tests are accepted:

paired.t: A paired t-test.

mcnemar: McNemar‚Äôs test.

signed.rank: the signed-rank test.

sign.test: the sign test.

notest: Don‚Äôt perform a test.

paired.control settings
A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in paired.control or in summary.tableby.

args(paired.control)
## function (test = TRUE, diff = TRUE, test.pname = NULL, numeric.test =  paired.t , 
##     cat.test =  mcnemar , ordered.test =  signed.rank , date.test =  paired.t , 
##     numeric.stats = c( Nmiss ,  meansd ,  range ), cat.stats = c( Nmiss , 
##          countpct ), ordered.stats = c( Nmiss ,  countpct ), 
##     date.stats = c( Nmiss ,  median ,  range ), stats.labels = list(Nmiss =  N-Miss , 
##         Nmiss2 =  N-Miss , meansd =  Mean (SD) , medianq1q3 =  Median (Q1, Q3) , 
##         q1q3 =  Q1, Q3 , range =  Range , countpct =  Count (Pct) ), 
##     digits = 3L, digits.count = 0L, digits.p = 3L, format.p = TRUE, 
##     conf.level = 0.95, mcnemar.correct = TRUE, signed.rank.exact = NULL, 
##     signed.rank.correct = TRUE, ...) 
## NULL
summary.tableby settings
Since the ‚Äúpaired‚Äù object inherits ‚Äútableby‚Äù, the summary.tableby function is what‚Äôs actually used to format and print the table.

args(arsenal:::summary.tableby)
## function (object, ..., labelTranslations = NULL, text = FALSE, 
##     title = NULL, pfootnote = FALSE, term.name =   ) 
## NULL




## The tableby function


https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html

The tableby function
Beth Atkinson, Ethan Heinzen, Jason Sinnwell, Shannon McDonnell and Greg Dougherty
09 November, 2018
Introduction
Simple Example
Pretty text version of table
Pretty Rmarkdown version of table
Data frame version of table
Summaries using standard R code
Modifying Output
Add labels
Change summary statistics globally
Change summary statistics within the formula
Controlling Options for Categorical Tests (Chisq and Fisher‚Äôs)
Modifying the look & feel in Word documents
Additional Examples
1. Summarize without a group/by variable
2. Display footnotes indicating which ‚Äútest‚Äù was used
3. Summarize an ordered factor
4. Summarize a survival variable
5. Summarize date variables
6. Summarize multiple variables without typing them out
7. Subset the dataset used in the analysis
8. Create combinations of variables on the fly
9. Transform variables on the fly
10. Subsetting (change the ordering of the variables, delete a variable, sort by p-value, filter by p-value)
11. Merge two tableby objects together
12. Add a title to the table
13. Modify how missing values are displayed
14. Modify the number of digits used
15. Create a user-defined summary statistic
16. Use case-weights for creating summary statistics
17. Create your own p-value and add it to the table
18. For two-level categorical variables or one-line numeric variables, simplify the output.
19. Use tableby within an Sweave document
20. Export tableby object to a .CSV file
21. Write tableby object to a separate Word or HTML file
22. Use tableby in R Shiny
23. Use tableby in bookdown
24. Adjust tableby for multiple p-values
Available Function Options
Summary statistics
Testing options
tableby.control settings
summary.tableby settings
Introduction
One of the most common tables in medical literature includes summary statistics for a set of variables, often stratified by some group (e.g. treatment arm). Locally at Mayo, the SAS macros %table and %summary were written to create summary tables with a single call. With the increasing interest in R, we have developed the function tableby to create similar tables within the R environment.

In developing the tableby() function, the goal was to bring the best features of these macros into an R function. However, the task was not simply to duplicate all the functionality, but rather to make use of R‚Äôs strengths (modeling, method dispersion, flexibility in function definition and output format) and make a tool that fits the needs of R users. Additionally, the results needed to fit within the general reproducible research framework so the tables could be displayed within an R markdown report.

This report provides step-by-step directions for using the functions associated with tableby(). All functions presented here are available within the arsenal package. An assumption is made that users are somewhat familiar with R Markdown documents. For those who are new to the topic, a good initial resource is available at rmarkdown.rstudio.com.

Simple Example
The first step when using the tableby function is to load the arsenal package. All the examples in this report use a dataset called mockstudy made available by Paul Novotny which includes a variety of types of variables (character, numeric, factor, ordered factor, survival) to use as examples.

require(arsenal)
require(knitr)
require(survival)
data(mockstudy) ##load data
dim(mockstudy)  ##look at how many subjects and variables are in the dataset 
## [1] 1499   14
# help(mockstudy) ##learn more about the dataset and variables
str(mockstudy) ##quick look at the data
## 'data.frame':    1499 obs. of  14 variables:
##  $ case       : int  110754 99706 105271 105001 112263 86205 99508 90158 88989 90515 ...
##  $ age        : atomic  67 74 50 71 69 56 50 57 51 63 ...
##   ..- attr(*,  label )= chr  Age in Years 
##  $ arm        : atomic  F: FOLFOX A: IFL A: IFL G: IROX ...
##   ..- attr(*,  label )= chr  Treatment Arm 
##  $ sex        : Factor w/ 2 levels  Male , Female : 1 2 2 2 2 1 1 1 2 1 ...
##  $ race       : atomic  Caucasian Caucasian Caucasian Caucasian ...
##   ..- attr(*,  label )= chr  Race 
##  $ fu.time    : int  922 270 175 128 233 120 369 421 387 363 ...
##  $ fu.stat    : int  2 2 2 2 2 2 2 2 2 2 ...
##  $ ps         : int  0 1 1 1 0 0 0 0 1 1 ...
##  $ hgb        : num  11.5 10.7 11.1 12.6 13 10.2 13.3 12.1 13.8 12.1 ...
##  $ bmi        : atomic  25.1 19.5 NA 29.4 26.4 ...
##   ..- attr(*,  label )= chr  Body Mass Index (kg/m^2) 
##  $ alk.phos   : int  160 290 700 771 350 569 162 152 231 492 ...
##  $ ast        : int  35 52 100 68 35 27 16 12 25 18 ...
##  $ mdquality.s: int  NA 1 1 1 NA 1 1 1 1 1 ...
##  $ age.ord    : Ord.factor w/ 8 levels  10-19 < 20-29 <..: 6 7 4 7 6 5 4 5 5 6 ...
To create a simple table stratified by treament arm, use a formula statement to specify the variables that you want summarized. The example below uses age (a continuous variable) and sex (a factor).

tab1 <- tableby(arm ~ sex + age, data=mockstudy)
If you want to take a quick look at the table, you can use summary() on your tableby object and the table will print out as text in your R console window. If you use summary() without any options you will see a number of &nbsp; statements which translates to ‚Äúspace‚Äù in HTML.

Pretty text version of table
If you want a nicer version in your console window then add the text=TRUE option.

summary(tab1, text=TRUE)
## 
## 
## |             | A: IFL (N=428)  | F: FOLFOX (N=691) | G: IROX (N=380) | Total (N=1499)  | p value|
## |:|::|:--:|::|::|-:|
## |sex          |                 |                   |                 |                 |   0.190|
## |-  Male      |   277 (64.7%)   |    411 (59.5%)    |   228 (60.0%)   |   916 (61.1%)   |        |
## |-  Female    |   151 (35.3%)   |    280 (40.5%)    |   152 (40.0%)   |   583 (38.9%)   |        |
## |Age in Years |                 |                   |                 |                 |   0.614|
## |-  Mean (SD) | 59.673 (11.365) |  60.301 (11.632)  | 59.763 (11.499) | 59.985 (11.519) |        |
## |-  Range     | 27.000 - 88.000 |  19.000 - 88.000  | 26.000 - 85.000 | 19.000 - 88.000 |        |
Pretty Rmarkdown version of table
In order for the report to look nice within an R markdown (knitr) report, you just need to specify results= asis  when creating the r chunk. This changes the layout slightly (compresses it) and bolds the variable names.

summary(tab1)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
sex                 0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age in Years                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Data frame version of table
If you want a data.frame version, simply use as.data.frame.

as.data.frame(tab1)
##   variable     term        label variable.type              A: IFL           F: FOLFOX
## 1      sex      sex          sex   categorical                                        
## 2      sex countpct         Male   categorical 277.00000, 64.71963 411.00000, 59.47902
## 3      sex countpct       Female   categorical 151.00000, 35.28037 280.00000, 40.52098
## 4      age      age Age in Years       numeric                                        
## 5      age   meansd    Mean (SD)       numeric  59.67290, 11.36454  60.30101, 11.63225
## 6      age    range        Range       numeric              27, 88              19, 88
##              G: IROX              Total                       test   p.value
## 1                                       Pearson's Chi-squared test 0.1904388
## 2            228, 60  916.0000, 61.1074 Pearson's Chi-squared test 0.1904388
## 3            152, 40  583.0000, 38.8926 Pearson's Chi-squared test 0.1904388
## 4                                               Linear Model ANOVA 0.6143859
## 5 59.76316, 11.49930 59.98532, 11.51877         Linear Model ANOVA 0.6143859
## 6             26, 85             19, 88         Linear Model ANOVA 0.6143859
Summaries using standard R code
## base R frequency example
tmp <- table(Gender=mockstudy$sex,  Study Arm =mockstudy$arm)
tmp
##         Study Arm
## Gender   A: IFL F: FOLFOX G: IROX
##   Male      277       411     228
##   Female    151       280     152
# Note: The continuity correction is applied by default in R (not used in %table)
chisq.test(tmp)
## 
##  Pearson's Chi-squared test
## 
## data:  tmp
## X-squared = 3.3168, df = 2, p-value = 0.1904
## base R numeric summary example
tapply(mockstudy$age, mockstudy$arm, summary)
## $`A: IFL`
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   27.00   53.00   61.00   59.67   68.00   88.00 
## 
## $`F: FOLFOX`
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    19.0    52.0    61.0    60.3    69.0    88.0 
## 
## $`G: IROX`
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   26.00   52.00   61.00   59.76   68.00   85.00
summary(aov(age ~ arm, data=mockstudy))
##               Df Sum Sq Mean Sq F value Pr(>F)
## arm            2    129    64.7   0.487  0.614
## Residuals   1496 198628   132.8
Modifying Output
Add labels
In the above example, age is shown with a label (Age in Years), but sex is listed ‚Äúas is‚Äù with lower case letters. This is because the data was created in SAS and in the SAS dataset, age had a label but sex did not. The label is stored as an attribute within R.

## Look at one variable's label
attr(mockstudy$age,'label')
## [1]  Age in Years 
## See all the variables with a label
unlist(lapply(mockstudy,'attr','label'))
##                        age                        arm                       race 
##              Age in Years              Treatment Arm                       Race  
##                        bmi 
##  Body Mass Index (kg/m^2) 
# Can also use labels(mockstudy)
If you want to add labels to other variables, there are a couple of options. First, you could add labels to the variables in your dataset.

attr(mockstudy$sex,'label')  <- 'Gender'

tab1 <- tableby(arm ~ sex + age, data=mockstudy)
summary(tab1)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age in Years                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
You can also use the built-in data.frame method for labels<-:

labels(mockstudy)  <- c(age = 'Age, yrs', sex =  Gender )

tab1 <- tableby(arm ~ sex + age, data=mockstudy)
summary(tab1)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Another option is to add labels after you have created the table

mylabels <- list(sex =  SEX , age =  Age, yrs )
summary(tab1, labelTranslations = mylabels)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
SEX                 0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Alternatively, you can check the variable labels and manipulate them with a function called labels, which works on the tableby object.

labels(tab1)
##        arm        sex        age 
##       arm     Gender   Age, yrs 
labels(tab1) <- c(arm= Treatment Assignment , age= Baseline Age (yrs) )
labels(tab1)
##                    arm                    sex                    age 
##  Treatment Assignment                 Gender     Baseline Age (yrs) 
summary(tab1)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Baseline Age (yrs)                  0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Change summary statistics globally
Currently the default behavior is to summarize continuous variables with: Number of missing values, Mean (SD), 25th - 75th quantiles, and Minimum-Maximum values with an ANOVA (t-test with equal variances) p-value. For categorical variables the default is to show: Number of missing values and count (column percent) with a chi-square p-value. This behavior can be modified using the tableby.control function. In fact, you can save your standard settings and use that for future tables. Note that test=FALSE and total=FALSE results in the total column and p-value column not being printed.

mycontrols  <- tableby.control(test=FALSE, total=FALSE,
                               numeric.test= kwt , cat.test= chisq ,
                               numeric.stats=c( N ,  median ,  q1q3 ),
                               cat.stats=c( countpct ),
                               stats.labels=list(N='Count', median='Median', q1q3='Q1,Q3'))
tab2 <- tableby(arm ~ sex + age, data=mockstudy, control=mycontrols)
summary(tab2)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380)
Gender          
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%)
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%)
Age, yrs            
   Count    428 691 380
   Median   61.000  61.000  61.000
   Q1,Q3    53.000, 68.000  52.000, 69.000  52.000, 68.000
You can also change these settings directly in the tableby call.

tab3 <- tableby(arm ~ sex + age, data=mockstudy, test=FALSE, total=FALSE, 
                numeric.stats=c( median , q1q3 ), numeric.test= kwt )
summary(tab3)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380)
Gender          
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%)
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%)
Age, yrs            
   Median   61.000  61.000  61.000
   Q1, Q3   53.000, 68.000  52.000, 69.000  52.000, 68.000
Change summary statistics within the formula
In addition to modifying summary options globally, it is possible to modify the test and summary statistics for specific variables within the formula statement. For example, both the kwt (Kruskal-Wallis rank-based) and anova (asymptotic analysis of variance) tests apply to numeric variables, and we can use one for the variable ‚Äúage‚Äù, another for the variable ‚Äúbmi‚Äù, and no test for the variable ‚Äúast‚Äù. A list of all the options is shown at the end of the vignette.

The tests function can do a quick check on what tests were performed on each variable in tableby.

tab.test <- tableby(arm ~ kwt(age) + anova(bmi) + notest(ast), data=mockstudy)
tests(tab.test)
##                     Variable   p.value                       Method
## age                 Age, yrs 0.6390614 Kruskal-Wallis rank sum test
## bmi Body Mass Index (kg/m^2) 0.8916552           Linear Model ANOVA
## ast                      ast        NA                      No test
summary(tab.test)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.639
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Body Mass Index (kg/m^2)                    0.892
   N-Miss   9   20  4   33  
   Mean (SD)    27.290 (5.552)  27.210 (5.173)  27.106 (5.751)  27.206 (5.432)  
   Range    14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 
ast                 
   N-Miss   69  141 56  266 
   Mean (SD)    37.292 (28.036) 35.202 (26.659) 35.670 (25.807) 35.933 (26.843) 
   Range    10.000 - 205.000    7.000 - 174.000 5.000 - 176.000 5.000 - 205.000 
Summary statistics for any individual variable can also be modified, but it must be done as secondary arguments to the test function. The function names must be strings that are functions already written for tableby, built-in R functions like mean and range, or user-defined functions.

tab.test <- tableby(arm ~ kwt(ast,  Nmiss2 , median ) + anova(age,  N , mean ) +
                    notest(bmi,  Nmiss , median ), data=mockstudy)
summary(tab.test)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
ast                 0.039
   N-Miss   69  141 56  266 
   Median   29.000  25.500  27.000  27.000  
Age, yrs                    0.614
   N    428 691 380 1499    
   mean 59.7    60.3    59.8    60  
Body Mass Index (kg/m^2)                    
   N-Miss   9   20  4   33  
   Median   26.234  26.525  25.978  26.325  
Controlling Options for Categorical Tests (Chisq and Fisher‚Äôs)
The formal tests for categorical variables against the levels of the by variable, chisq and fe, have options to simulate p-values. We show how to turn on the simulations for these with 500 replicates for the Fisher‚Äôs test (fe).

set.seed(100)
tab.catsim <- tableby(arm ~ sex + race, cat.test= fe , simulate.p.value=TRUE, B=500, data=mockstudy)
tests(tab.catsim)
 Variable   p.value
sex Gender 0.2195609 race Race 0.3093812 Method sex Fisher‚Äôs Exact Test for Count Data with simulated p-value(based on 500 replicates) race Fisher‚Äôs Exact Test for Count Data with simulated p-value(based on 500 replicates)

The chis-square test on 2x2 tables applies Yates‚Äô continuity correction by default, so we provide an option to turn off the correction. We show the results with and without the correction that is applied to treatment arm by sex, if we use subset to ignore one of the three treatment arms.

cat.correct <- tableby(arm ~ sex + race, cat.test= chisq , subset = !grepl( ^F , arm), data=mockstudy)
tests(cat.correct)
 Variable   p.value                     Method
sex Gender 0.1666280 Pearson‚Äôs Chi-squared test race Race 0.8108543 Pearson‚Äôs Chi-squared test

cat.nocorrect <- tableby(arm ~ sex + race, cat.test= chisq , subset = !grepl( ^F , arm),
     chisq.correct=FALSE, data=mockstudy)
tests(cat.nocorrect)
 Variable   p.value                     Method
sex Gender 0.1666280 Pearson‚Äôs Chi-squared test race Race 0.8108543 Pearson‚Äôs Chi-squared test

Modifying the look & feel in Word documents
You can easily create Word versions of tableby output via an Rmarkdown report and the default options will give you a reasonable table in Word - just select the ‚ÄúKnit Word‚Äù option in RStudio.

The functionality listed in this next paragraph is coming soon but needs an upgraded version of RStudio If you want to modify fonts used for the table, then you‚Äôll need to add an extra line to your header at the beginning of your file. You can take the WordStylesReference01.docx file and modify the fonts (storing the format preferences in your project directory). To see how this works, run your report once using WordStylesReference01.docx and then WordStylesReference02.docx.

output: word_document
  reference_docx: /projects/bsi/gentools/R/lib320/arsenal/doc/WordStylesReference01.docx 
For more informating on changing the look/feel of your Word document, see the Rmarkdown documentation website.

Additional Examples
Here are multiple examples showing how to use some of the different options.

1. Summarize without a group/by variable
tab.noby <- tableby(~ bmi + sex + age, data=mockstudy)
summary(tab.noby)
Overall (N=1499)
Body Mass Index (kg/m^2)    
   N-Miss   33
   Mean (SD)    27.206 (5.432)
   Range    14.053 - 60.243
Gender  
   Male 916 (61.1%)
   Female   583 (38.9%)
Age, yrs    
   Mean (SD)    59.985 (11.519)
   Range    19.000 - 88.000
2. Display footnotes indicating which ‚Äútest‚Äù was used
summary(tab.test) #, pfootnote=TRUE)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
ast                 0.039
   N-Miss   69  141 56  266 
   Median   29.000  25.500  27.000  27.000  
Age, yrs                    0.614
   N    428 691 380 1499    
   mean 59.7    60.3    59.8    60  
Body Mass Index (kg/m^2)                    
   N-Miss   9   20  4   33  
   Median   26.234  26.525  25.978  26.325  
3. Summarize an ordered factor
When comparing groups of ordered data there are a couple of options. The default uses a general independence test available from the coin package. For two-group comparisons, this is essentially the Armitage trend test. The other option is to specify the Kruskal Wallis test. The example below shows both options.

mockstudy$age.ordnew <- ordered(c( a ,NA,as.character(mockstudy$age.ord[-(1:2)])))
table(mockstudy$age.ord, mockstudy$sex)
##        
##         Male Female
##   10-19    1      0
##   20-29    8     11
##   30-39   37     30
##   40-49  127     83
##   50-59  257    179
##   60-69  298    170
##   70-79  168    101
##   80-89   20      9
table(mockstudy$age.ordnew, mockstudy$sex)
##        
##         Male Female
##   10-19    1      0
##   20-29    8     11
##   30-39   37     30
##   40-49  127     83
##   50-59  257    179
##   60-69  297    170
##   70-79  168    100
##   80-89   20      9
##   a        1      0
class(mockstudy$age.ord)
## [1]  ordered   factor 
summary(tableby(sex ~ age.ordnew, data = mockstudy)) #, pfootnote = TRUE)
Male (N=916)    Female (N=583)  Total (N=1499)  p value
age.ordnew              0.040
   N-Miss   0   1   1   
   10-19    1 (0.1%)    0 (0.0%)    1 (0.1%)    
   20-29    8 (0.9%)    11 (1.9%)   19 (1.3%)   
   30-39    37 (4.0%)   30 (5.2%)   67 (4.5%)   
   40-49    127 (13.9%) 83 (14.3%)  210 (14.0%) 
   50-59    257 (28.1%) 179 (30.8%) 436 (29.1%) 
   60-69    297 (32.4%) 170 (29.2%) 467 (31.2%) 
   70-79    168 (18.3%) 100 (17.2%) 268 (17.9%) 
   80-89    20 (2.2%)   9 (1.5%)    29 (1.9%)   
   a    1 (0.1%)    0 (0.0%)    1 (0.1%)    
summary(tableby(sex ~ kwt(age.ord), data = mockstudy)) #) #, pfootnote = TRUE)
Male (N=916)    Female (N=583)  Total (N=1499)  p value
age.ord             0.067
   10-19    1 (0.1%)    0 (0.0%)    1 (0.1%)    
   20-29    8 (0.9%)    11 (1.9%)   19 (1.3%)   
   30-39    37 (4.0%)   30 (5.1%)   67 (4.5%)   
   40-49    127 (13.9%) 83 (14.2%)  210 (14.0%) 
   50-59    257 (28.1%) 179 (30.7%) 436 (29.1%) 
   60-69    298 (32.5%) 170 (29.2%) 468 (31.2%) 
   70-79    168 (18.3%) 101 (17.3%) 269 (17.9%) 
   80-89    20 (2.2%)   9 (1.5%)    29 (1.9%)   
4. Summarize a survival variable
First look at the information that is presented by the survfit() function, then see how the same results can be seen with tableby. The default is to show the median survival (time at which the probability of survival = 50%).

survfit(Surv(fu.time, fu.stat)~sex, data=mockstudy)
## Call: survfit(formula = Surv(fu.time, fu.stat) ~ sex, data = mockstudy)
## 
##              n events median 0.95LCL 0.95UCL
## sex=Male   916    829    550     515     590
## sex=Female 583    527    543     511     575
survdiff(Surv(fu.time, fu.stat)~sex, data=mockstudy)
## Call:
## survdiff(formula = Surv(fu.time, fu.stat) ~ sex, data = mockstudy)
## 
##              N Observed Expected (O-E)^2/E (O-E)^2/V
## sex=Male   916      829      830  0.000370  0.000956
## sex=Female 583      527      526  0.000583  0.000956
## 
##  Chisq= 0  on 1 degrees of freedom, p= 1
summary(tableby(sex ~ Surv(fu.time, fu.stat), data=mockstudy))
Male (N=916)    Female (N=583)  Total (N=1499)  p value
Surv(fu.time, fu.stat)              0.975
   Events   829 527 1356    
   Median Survival  550.000 543.000 546.000 
It is also possible to obtain summaries of the % survival at certain time points (say the probability of surviving 1-year).

summary(survfit(Surv(fu.time/365.25, fu.stat)~sex, data=mockstudy), times=1:5)
## Call: survfit(formula = Surv(fu.time/365.25, fu.stat) ~ sex, data = mockstudy)
## 
##                 sex=Male 
##  time n.risk n.event survival std.err lower 95% CI upper 95% CI
##     1    626     286   0.6870  0.0153       0.6576       0.7177
##     2    309     311   0.3437  0.0158       0.3142       0.3761
##     3    152     151   0.1748  0.0127       0.1516       0.2015
##     4     57      61   0.0941  0.0104       0.0759       0.1168
##     5     24      16   0.0628  0.0095       0.0467       0.0844
## 
##                 sex=Female 
##  time n.risk n.event survival std.err lower 95% CI upper 95% CI
##     1    380     202   0.6531  0.0197       0.6155        0.693
##     2    190     189   0.3277  0.0195       0.2917        0.368
##     3     95      90   0.1701  0.0157       0.1420        0.204
##     4     51      32   0.1093  0.0133       0.0861        0.139
##     5     18      12   0.0745  0.0126       0.0534        0.104
summary(tableby(sex ~ Surv(fu.time/365.25, fu.stat), data=mockstudy, times=1:5, surv.stats=c( NeventsSurv , NriskSurv )))
Male (N=916)    Female (N=583)  Total (N=1499)  p value
Surv(fu.time/365.25, fu.stat)               0.975
   time = 1 286 (68.7)  202 (65.3)  488 (67.4)  
   time = 2 597 (34.4)  391 (32.8)  988 (33.7)  
   time = 3 748 (17.5)  481 (17.0)  1229 (17.3) 
   time = 4 809 (9.4)   513 (10.9)  1322 (10.1) 
   time = 5 825 (6.3)   525 (7.4)   1350 (6.8)  
   time = 1 626 380 1006    
   time = 2 309 190 499 
   time = 3 152 95  247 
   time = 4 57  51  108 
   time = 5 24  18  42  
5. Summarize date variables
Date variables by default are summarized with the number of missing values, the median, and the range. For example purposes we‚Äôve created a random date. Missing values are introduced for impossible February dates.

set.seed(100)
N <- nrow(mockstudy)
mockstudy$dtentry <- mdy.Date(month=sample(1:12,N,replace=T), day=sample(1:29,N,replace=T), 
                              year=sample(2005:2009,N,replace=T))
summary(tableby(sex ~ dtentry, data=mockstudy))
Male (N=916)    Female (N=583)  Total (N=1499)  p value
dtentry             0.554
   N-Miss   3   2   5   
   Median   2007-06-16  2007-06-15  2007-06-15  
   Range    2005-01-03 - 2009-12-27 2005-01-01 - 2009-12-28 2005-01-01 - 2009-12-28 
6. Summarize multiple variables without typing them out
Often one wants to summarize a number of variables. Instead of typing by hand each individual variable, an alternative approach is to create a formula using the paste command with the collapse= +  option.

## create a vector specifying the variable names
myvars <- names(mockstudy)

## select the 8th through the last variables
## paste them together, separated by the + sign
RHS <- paste(myvars[8:10], collapse= + )
RHS
[1] ‚Äúps+hgb+bmi‚Äù

## create a formula using the as.formula function
as.formula(paste('arm ~ ', RHS))
arm ~ ps + hgb + bmi

## use the formula in the tableby function
summary(tableby(as.formula(paste('arm ~', RHS)), data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
ps                  0.903
   N-Miss   69  141 56  266 
   Mean (SD)    0.529 (0.597)   0.547 (0.595)   0.537 (0.606)   0.539 (0.598)   
   Range    0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   
hgb                 0.639
   N-Miss   69  141 56  266 
   Mean (SD)    12.276 (1.686)  12.381 (1.763)  12.373 (1.680)  12.348 (1.719)  
   Range    9.060 - 17.300  9.000 - 18.200  9.000 - 17.000  9.000 - 18.200  
Body Mass Index (kg/m^2)                    0.892
   N-Miss   9   20  4   33  
   Mean (SD)    27.290 (5.552)  27.210 (5.173)  27.106 (5.751)  27.206 (5.432)  
   Range    14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 
These steps can also be done using the formulize function.

## The formulize function does the paste and as.formula steps
tmp <- formulize('arm',myvars[8:10])
tmp
arm ~ ps + hgb + bmi

## More complex formulas could also be written using formulize
tmp2 <- formulize('arm',c('ps','hgb^2','bmi'))

## use the formula in the tableby function
summary(tableby(tmp, data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
ps                  0.903
   N-Miss   69  141 56  266 
   Mean (SD)    0.529 (0.597)   0.547 (0.595)   0.537 (0.606)   0.539 (0.598)   
   Range    0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   
hgb                 0.639
   N-Miss   69  141 56  266 
   Mean (SD)    12.276 (1.686)  12.381 (1.763)  12.373 (1.680)  12.348 (1.719)  
   Range    9.060 - 17.300  9.000 - 18.200  9.000 - 17.000  9.000 - 18.200  
Body Mass Index (kg/m^2)                    0.892
   N-Miss   9   20  4   33  
   Mean (SD)    27.290 (5.552)  27.210 (5.173)  27.106 (5.751)  27.206 (5.432)  
   Range    14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 
7. Subset the dataset used in the analysis
Here are two ways to get the same result (limit the analysis to subjects age>5 and in the F: FOLFOX treatment group).

The first approach uses the subset function applied to the dataset mockstudy. This example also selects a subset of variables. The tableby function is then applied to this subsetted data.
newdata <- subset(mockstudy, subset=age>50 & arm=='F: FOLFOX', select = c(sex,ps:bmi))
dim(mockstudy)
## [1] 1499   16
table(mockstudy$arm)
## 
##    A: IFL F: FOLFOX   G: IROX 
##       428       691       380
dim(newdata)
## [1] 557   4
names(newdata)
## [1]  sex   ps    hgb   bmi 
summary(tableby(sex ~ ., data=newdata))
Male (N=333)    Female (N=224)  Total (N=557)   p value
ps              0.652
   N-Miss   64  44  108 
   Mean (SD)    0.554 (0.600)   0.528 (0.602)   0.543 (0.600)   
   Range    0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   
hgb             < 0.001
   N-Miss   64  44  108 
   Mean (SD)    12.720 (1.925)  12.063 (1.395)  12.457 (1.760)  
   Range    9.000 - 18.200  9.100 - 15.900  9.000 - 18.200  
bmi             0.650
   N-Miss   9   6   15  
   Mean (SD)    27.539 (4.780)  27.337 (5.508)  27.458 (5.081)  
   Range    17.927 - 47.458 16.649 - 49.130 16.649 - 49.130 
The second approach does the same analysis but uses the subset argument within tableby to subset the data.
summary(tableby(sex ~ ps + hgb + bmi, subset=age>50 & arm== F: FOLFOX , data=mockstudy))
Male (N=333)    Female (N=224)  Total (N=557)   p value
ps              0.652
   N-Miss   64  44  108 
   Mean (SD)    0.554 (0.600)   0.528 (0.602)   0.543 (0.600)   
   Range    0.000 - 2.000   0.000 - 2.000   0.000 - 2.000   
hgb             < 0.001
   N-Miss   64  44  108 
   Mean (SD)    12.720 (1.925)  12.063 (1.395)  12.457 (1.760)  
   Range    9.000 - 18.200  9.100 - 15.900  9.000 - 18.200  
Body Mass Index (kg/m^2)                0.650
   N-Miss   9   6   15  
   Mean (SD)    27.539 (4.780)  27.337 (5.508)  27.458 (5.081)  
   Range    17.927 - 47.458 16.649 - 49.130 16.649 - 49.130 
8. Create combinations of variables on the fly
## create a variable combining the levels of mdquality.s and sex
with(mockstudy, table(interaction(mdquality.s,sex)))
## 
##   0.Male   1.Male 0.Female 1.Female 
##       77      686       47      437
summary(tableby(arm ~ interaction(mdquality.s,sex), data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
interaction(mdquality.s, sex)                   0.493
   N-Miss   55  156 41  252 
   0.Male   29 (7.8%)   31 (5.8%)   17 (5.0%)   77 (6.2%)   
   1.Male   214 (57.4%) 285 (53.3%) 187 (55.2%) 686 (55.0%) 
   0.Female 12 (3.2%)   21 (3.9%)   14 (4.1%)   47 (3.8%)   
   1.Female 118 (31.6%) 198 (37.0%) 121 (35.7%) 437 (35.0%) 
## create a new grouping variable with combined levels of arm and sex
summary(tableby(interaction(mdquality.s, sex) ~  age + bmi, data=mockstudy, subset=arm== F: FOLFOX ))
0.Male (N=31)   1.Male (N=285)  0.Female (N=21) 1.Female (N=198)    Total (N=535)   p value
Age, yrs                        0.190
   Mean (SD)    63.065 (11.702) 60.653 (11.833) 60.810 (10.103) 58.924 (11.366) 60.159 (11.612) 
   Range    41.000 - 82.000 19.000 - 88.000 42.000 - 81.000 29.000 - 83.000 19.000 - 88.000 
Body Mass Index (kg/m^2)                        0.894
   N-Miss   0   6   1   5   12  
   Mean (SD)    26.633 (5.094)  27.387 (4.704)  27.359 (4.899)  27.294 (5.671)  27.307 (5.100)  
   Range    20.177 - 41.766 17.927 - 47.458 19.801 - 39.369 16.799 - 44.841 16.799 - 47.458 
9. Transform variables on the fly
Certain transformations need to be surrounded by I() so that R knows to treat it as a variable transformation and not some special model feature. If the transformation includes any of the symbols / - + ^ * then surround the new variable by I().

trans <- tableby(arm ~ I(age/10) + log(bmi) + factor(mdquality.s, levels=0:1, labels=c('N','Y')),
                 data=mockstudy)
summary(trans)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.614
   Mean (SD)    5.967 (1.136)   6.030 (1.163)   5.976 (1.150)   5.999 (1.152)   
   Range    2.700 - 8.800   1.900 - 8.800   2.600 - 8.500   1.900 - 8.800   
Body Mass Index (kg/m^2)                    0.811
   N-Miss   9   20  4   33  
   Mean (SD)    3.287 (0.197)   3.286 (0.183)   3.279 (0.200)   3.285 (0.192)   
   Range    2.643 - 3.970   2.812 - 3.894   2.736 - 4.098   2.643 - 4.098   
factor(mdquality.s, levels = 0:1, labels = c(‚ÄúN‚Äù, ‚ÄúY‚Äù))                 0.694
   N-Miss   55  156 41  252 
   N    41 (11.0%)  52 (9.7%)   31 (9.1%)   124 (9.9%)  
   Y    332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%)    
The labels for these variables isn‚Äôt exactly what we‚Äôd like so we can change modify those after the fact. Instead of typing out the very long variable names you can modify specific labels by position.

labels(trans)
##                                                           arm 
##                                                          arm  
##                                                     I(age/10) 
##                                                     Age, yrs  
##                                                      log(bmi) 
##                                     Body Mass Index (kg/m^2)  
##       factor(mdquality.s, levels = 0:1, labels = c( N ,  Y )) 
##  factor(mdquality.s, levels = 0:1, labels = c(\ N\ , \ Y\ )) 
labels(trans)[2:4] <- c('Age per 10 yrs', 'log(BMI)', 'MD Quality')
labels(trans)
##                                                     arm 
##                                                    arm  
##                                               I(age/10) 
##                                         Age per 10 yrs  
##                                                log(bmi) 
##                                               log(BMI)  
## factor(mdquality.s, levels = 0:1, labels = c( N ,  Y )) 
##                                             MD Quality 
summary(trans)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age per 10 yrs                  0.614
   Mean (SD)    5.967 (1.136)   6.030 (1.163)   5.976 (1.150)   5.999 (1.152)   
   Range    2.700 - 8.800   1.900 - 8.800   2.600 - 8.500   1.900 - 8.800   
log(BMI)                    0.811
   N-Miss   9   20  4   33  
   Mean (SD)    3.287 (0.197)   3.286 (0.183)   3.279 (0.200)   3.285 (0.192)   
   Range    2.643 - 3.970   2.812 - 3.894   2.736 - 4.098   2.643 - 4.098   
MD Quality                  0.694
   N-Miss   55  156 41  252 
   N    41 (11.0%)  52 (9.7%)   31 (9.1%)   124 (9.9%)  
   Y    332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%)    
Note that if we had not changed mdquality.s to a factor, it would have been summarized as though it were a continuous variable.

class(mockstudy$mdquality.s)
[1] ‚Äúinteger‚Äù

summary(tableby(arm~mdquality.s, data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
mdquality.s                 0.695
   N-Miss   55  156 41  252 
   Mean (SD)    0.890 (0.313)   0.903 (0.297)   0.909 (0.289)   0.901 (0.299)   
   Range    0.000 - 1.000   0.000 - 1.000   0.000 - 1.000   0.000 - 1.000   
Another option would be to specify the test and summary statistics. In fact, if I had a set of variables coded 0/1 and that was all I was summarizing, then I could change the global option for continuous variables to use the chi-square test and show countpct.

summary(tableby(arm ~ chisq(mdquality.s,  Nmiss , countpct ), data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
mdquality.s                 0.694
   N-Miss   55  156 41  252 
   0    41 (11.0%)  52 (9.7%)   31 (9.1%)   124 (9.9%)  
   1    332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%)    
10. Subsetting (change the ordering of the variables, delete a variable, sort by p-value, filter by p-value)
mytab <- tableby(arm ~ sex + alk.phos + age, data=mockstudy)
mytab2 <- mytab[c('age','sex','alk.phos')]
summary(mytab2)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
alk.phos                    0.226
   N-Miss   69  141 56  266 
   Mean (SD)    175.577 (128.608)   161.984 (121.978)   173.506 (138.564)   168.969 (128.492)   
   Range    11.000 - 858.000    10.000 - 1014.000   7.000 - 982.000 7.000 - 1014.000    
summary(mytab[c('age','sex')], digits = 2)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.614
   Mean (SD)    59.67 (11.36)   60.30 (11.63)   59.76 (11.50)   59.99 (11.52)   
   Range    27.00 - 88.00   19.00 - 88.00   26.00 - 85.00   19.00 - 88.00   
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
summary(mytab[c(3,1)], digits = 3)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
summary(sort(mytab, decreasing = TRUE))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
alk.phos                    0.226
   N-Miss   69  141 56  266 
   Mean (SD)    175.577 (128.608)   161.984 (121.978)   173.506 (138.564)   168.969 (128.492)   
   Range    11.000 - 858.000    10.000 - 1014.000   7.000 - 982.000 7.000 - 1014.000    
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
summary(mytab[mytab < 0.5])
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
alk.phos                    0.226
   N-Miss   69  141 56  266 
   Mean (SD)    175.577 (128.608)   161.984 (121.978)   173.506 (138.564)   168.969 (128.492)   
   Range    11.000 - 858.000    10.000 - 1014.000   7.000 - 982.000 7.000 - 1014.000    
head(mytab, 1) # can also use tail()
Tableby Object

Function Call: tableby(formula = arm ~ sex + alk.phos + age, data = mockstudy)

y variable: [1] ‚Äúarm‚Äù x variables: [1] ‚Äúsex‚Äù

11. Merge two tableby objects together
It is possible to combine two tableby objects so that they print out together.

## demographics
tab1 <- tableby(arm ~ sex + age, data=mockstudy,
                control=tableby.control(numeric.stats=c( Nmiss , meansd ), total=FALSE))
## lab data
tab2 <- tableby(arm ~ hgb + alk.phos, data=mockstudy,
                control=tableby.control(numeric.stats=c( Nmiss , median , q1q3 ),
                                        numeric.test= kwt , total=FALSE))
names(tab1$x)
[1] ‚Äúsex‚Äù ‚Äúage‚Äù

names(tab2$x)
[1] ‚Äúhgb‚Äù ‚Äúalk.phos‚Äù

tab12 <- merge(tab1,tab2)
class(tab12)
[1] ‚Äútableby‚Äù

names(tab12$x)
[1] ‚Äúsex‚Äù ‚Äúage‚Äù ‚Äúhgb‚Äù ‚Äúalk.phos‚Äù

summary(tab12) #, pfootnote=TRUE)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) p value
Gender              0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 
Age, yrs                0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 
hgb             0.570
   N-Miss   69  141 56  
   Median   12.100  12.200  12.400  
   Q1, Q3   11.000, 13.450  11.100, 13.600  11.175, 13.625  
alk.phos                0.104
   N-Miss   69  141 56  
   Median   133.000 116.000 122.000 
   Q1, Q3   89.000, 217.000 85.000, 194.750 87.750, 210.250 
12. Add a title to the table
When creating a pdf the tables are automatically numbered and the title appears below the table. In Word and HTML, the titles appear un-numbered and above the table.

t1 <- tableby(arm ~ sex + age, data=mockstudy)
summary(t1, title='Demographics')
Demographics
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 
   Range    27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 
13. Modify how missing values are displayed
Depending on the report you are writing you have the following options:

Show how many subjects have each variable

Show how many subjects are missing each variable

Show how many subjects are missing each variable only if there are any missing values

Don‚Äôt indicate missing values at all

## look at how many missing values there are for each variable
apply(is.na(mockstudy),2,sum)
##        case         age         arm         sex        race     fu.time     fu.stat          ps 
##           0           0           0           0           7           0           0         266 
##         hgb         bmi    alk.phos         ast mdquality.s     age.ord  age.ordnew     dtentry 
##         266          33         266         266         252           0           1           5
## Show how many subjects have each variable (non-missing)
summary(tableby(sex ~ ast + age, data=mockstudy,
                control=tableby.control(numeric.stats=c( N , median ), total=FALSE)))
Male (N=916)    Female (N=583)  p value
ast         0.921
   N    754 479 
   Median   27.000  27.000  
Age, yrs            0.048
   N    916 583 
   Median   61.000  60.000  
## Always list the number of missing values
summary(tableby(sex ~ ast + age, data=mockstudy,
                control=tableby.control(numeric.stats=c( Nmiss2 , median ), total=FALSE)))
Male (N=916)    Female (N=583)  p value
ast         0.921
   N-Miss   162 104 
   Median   27.000  27.000  
Age, yrs            0.048
   N-Miss   0   0   
   Median   61.000  60.000  
## Only show the missing values if there are some (default)
summary(tableby(sex ~ ast + age, data=mockstudy, 
                control=tableby.control(numeric.stats=c( Nmiss , mean ),total=FALSE)))
Male (N=916)    Female (N=583)  p value
ast         0.921
   N-Miss   162 104 
   mean 35.9    36  
Age, yrs            0.048
   mean 60.5    59.2    
## Don't show N at all
summary(tableby(sex ~ ast + age, data=mockstudy, 
                control=tableby.control(numeric.stats=c( mean ),total=FALSE)))
Male (N=916)    Female (N=583)  p value
ast         0.921
   mean 35.9    36  
Age, yrs            0.048
   mean 60.5    59.2    
One might also consider the use of includeNA() to include NAs in the counts and percents for categorical variables.

mockstudy$ps.cat <- factor(mockstudy$ps)
attr(mockstudy$ps.cat,  label ) <-  ps 
summary(tableby(sex ~ includeNA(ps.cat), data = mockstudy, cat.stats =  countpct ))
Male (N=916)    Female (N=583)  Total (N=1499)  p value
ps              0.354
   0    391 (42.7%) 244 (41.9%) 635 (42.4%) 
   1    329 (35.9%) 202 (34.6%) 531 (35.4%) 
   2    34 (3.7%)   33 (5.7%)   67 (4.5%)   
   (Missing)    162 (17.7%) 104 (17.8%) 266 (17.7%) 
14. Modify the number of digits used
Within tableby.control function there are 4 options for controlling the number of significant digits shown.

digits: controls the number of digits after the decimal place for continuous values

digits.count: controls the number of digits after the decimal point for counts

digits.pct: controls the number of digits after the decimal point for percents

digits.p: controls the number of digits after the decimal point for p-values

summary(tableby(arm ~ sex + age + fu.time, data=mockstudy), digits=4, digits.p=2, digits.pct=1)
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.19
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.61
   Mean (SD)    59.6729 (11.3645)   60.3010 (11.6323)   59.7632 (11.4993)   59.9853 (11.5188)   
   Range    27.0000 - 88.0000   19.0000 - 88.0000   26.0000 - 85.0000   19.0000 - 88.0000   
fu.time                 < 0.01
   Mean (SD)    553.5841 (419.6065) 731.2460 (487.7443) 607.2421 (435.5092) 649.0841 (462.5109) 
   Range    9.0000 - 2170.0000  0.0000 - 2472.0000  17.0000 - 2118.0000 0.0000 - 2472.0000  
With the exception of digits.p, all of these can be specified on a per-variable basis using the in-formula functions that specify which tests are run:

summary(tableby(arm ~ chisq(sex, digits.pct=1) + anova(age, digits=4) +
                  anova(fu.time, digits = 1), data=mockstudy))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Gender                  0.190
   Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) 
   Female   151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 
Age, yrs                    0.614
   Mean (SD)    59.6729 (11.3645)   60.3010 (11.6323)   59.7632 (11.4993)   59.9853 (11.5188)   
   Range    27.0000 - 88.0000   19.0000 - 88.0000   26.0000 - 85.0000   19.0000 - 88.0000   
fu.time                 < 0.001
   Mean (SD)    553.6 (419.6)   731.2 (487.7)   607.2 (435.5)   649.1 (462.5)   
   Range    9.0 - 2170.0    0.0 - 2472.0    17.0 - 2118.0   0.0 - 2472.0    
15. Create a user-defined summary statistic
For purposes of this example, the code below creates a trimmed mean function (trims 10%) and use that to summarize the data. Note the use of the ... which tells R to pass extra arguments on - this is required for user-defined functions. In this case, na.rm=T is passed to myfunc. The weights argument is also required, even though it isn‚Äôt passed on to the internal function in this particular example.

myfunc <- function(x, weights=rep(1,length(x)), ...){
  mean(x, trim=.1, ...)
}

summary(tableby(sex ~ hgb, data=mockstudy, 
                control=tableby.control(numeric.stats=c( Nmiss , myfunc ), numeric.test= kwt ,
                    stats.labels=list(Nmiss='Missing values', myfunc= Trimmed Mean, 10% ))))
Male (N=916)    Female (N=583)  Total (N=1499)  p value
hgb             < 0.001
   Missing values   162 104 266 
   Trimmed Mean, 10%    12.6    11.9    NA  
16. Use case-weights for creating summary statistics
When comparing groups, they are often unbalanced when it comes to nuisances such as age and sex. The tableby function allows you to create weighted summary statistics. If this option us used then p-values are not calculated (test=FALSE).

##create fake group that is not balanced by age/sex 
set.seed(200)
mockstudy$fake_arm <- ifelse(mockstudy$age>60 & mockstudy$sex=='Female',sample(c('A','B'),replace=T, prob=c(.2,.8)),
                            sample(c('A','B'),replace=T, prob=c(.8,.4)))

mockstudy$agegp <- cut(mockstudy$age, breaks=c(18,50,60,70,90), right=FALSE)

## create weights based on agegp and sex distribution
tab1 <- with(mockstudy,table(agegp, sex))
tab2 <- with(mockstudy, table(agegp, sex, fake_arm))
tab2
## , , fake_arm = A
## 
##          sex
## agegp     Male Female
##   [18,50)   73     62
##   [50,60)  128     94
##   [60,70)  139      7
##   [70,90)  102      0
## 
## , , fake_arm = B
## 
##          sex
## agegp     Male Female
##   [18,50)   79     48
##   [50,60)  130     84
##   [60,70)  156    166
##   [70,90)  109    122
gpwts <- rep(tab1, length(unique(mockstudy$fake_arm)))/tab2
gpwts[gpwts>50] <- 30

## apply weights to subjects
index <- with(mockstudy, cbind(as.numeric(agegp), as.numeric(sex), as.numeric(as.factor(fake_arm)))) 
mockstudy$wts <- gpwts[index]

## show weights by treatment arm group
tapply(mockstudy$wts,mockstudy$fake_arm, summary)
## $A
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.774   1.894   2.069   2.276   2.082  24.714 
## 
## $B
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.000   1.042   1.924   1.677   1.985   2.292
orig <- tableby(fake_arm ~ age + sex + Surv(fu.time/365, fu.stat), data=mockstudy, test=FALSE)
summary(orig, title='No Case Weights used')
No Case Weights used
A (N=605)   B (N=894)   Total (N=1499)
Age, yrs            
   Mean (SD)    57.413 (11.618) 61.726 (11.125) 59.985 (11.519)
   Range    22.000 - 85.000 19.000 - 88.000 19.000 - 88.000
Gender          
   Male 442 (73.1%) 474 (53.0%) 916 (61.1%)
   Female   163 (26.9%) 420 (47.0%) 583 (38.9%)
Surv(fu.time/365, fu.stat)          
   Events   554 802 1356
   Median Survival  1.504   1.493   1.496
tab1 <- tableby(fake_arm ~ age + sex + Surv(fu.time/365, fu.stat), data=mockstudy, weights=wts)
summary(tab1, title='Case Weights used')
Case Weights used
A (N=605)   B (N=894)   Total (N=1499)
Age, yrs            
   Mean (SD)    58.009 (10.925) 60.151 (11.428) 59.126 (11.235)
   Range    22.000 - 85.000 19.000 - 88.000 19.000 - 88.000
Gender          
   Male 916 (66.5%) 916 (61.1%) 1832 (63.7%)
   Female   461 (33.5%) 583 (38.9%) 1044 (36.3%)
Surv(fu.time/365, fu.stat)          
   Events   1252    1348    2599
   Median Survival  1.534   1.496   1.532
17. Create your own p-value and add it to the table
When using weighted summary statistics, it is often desirable to then show a p-value from a model that corresponds to the weighted analysis. It is possible to add your own p-value and modify the column title for that new p-value. Another use for this would be to add standardized differences or confidence intervals instead of a p-value.

To add the p-value you simply need to create a data frame and use the function modpval.tableby. The first 2 columns in the dataframe are required and are the variable name and the new p-value. The third column can be used to indicate what method was used to calculate the p-value. If you specify use.pname=TRUE then the column name indicating the p-value will be also be used in the tableby summary.

mypval <- data.frame(variable=c('age','sex','Surv(fu.time/365, fu.stat)'), 
                     adj.pvalue=c(.953,.811,.01), 
                     method=c('Age/Sex adjusted model results'))
tab2 <- modpval.tableby(tab1, mypval, use.pname=TRUE)
summary(tab2, title='Case Weights used, p-values added') #, pfootnote=TRUE)
Case Weights used, p-values added
A (N=605)   B (N=894)   Total (N=1499)  adj.pvalue
Age, yrs                0.953
   Mean (SD)    58.009 (10.925) 60.151 (11.428) 59.126 (11.235) 
   Range    22.000 - 85.000 19.000 - 88.000 19.000 - 88.000 
Gender              0.811
   Male 916 (66.5%) 916 (61.1%) 1832 (63.7%)    
   Female   461 (33.5%) 583 (38.9%) 1044 (36.3%)    
Surv(fu.time/365, fu.stat)              0.010
   Events   1252    1348    2599    
   Median Survival  1.534   1.496   1.532   
18. For two-level categorical variables or one-line numeric variables, simplify the output.
If the cat.simplify option is set to TRUE, then only the second level of two-level categorical varialbes is shown. In the example below, sex has two levels, and ‚ÄúFemale‚Äù is the second level, hence only the counts and percents for Female are shown. Similarly, ‚Äúmdquality.s‚Äù was turned to a factor, and ‚Äú1‚Äù is the second level, but since there are missings, the table ignores cat.simplify and displays all levels (since the output can no longer be displayed on one line).

table2 <- tableby(arm~sex + factor(mdquality.s), data=mockstudy, cat.simplify=TRUE)
summary(table2, labelTranslations=c(sex= Female ,  factor(mdquality.s) = MD Quality ))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Female  151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 0.190
MD Quality                  0.694
   N-Miss   55  156 41  252 
   0    41 (11.0%)  52 (9.7%)   31 (9.1%)   124 (9.9%)  
   1    332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%)    
Similarly, if numeric.simplify is set to TRUE, then any numerics which only have one row of summary statistics are simplified into a single row. Note again that ast has missing values and so is not simplified to a single row.

summary(tableby(arm ~ age + ast, data = mockstudy,
                numeric.simplify=TRUE, numeric.stats=c( Nmiss ,  meansd )))
A: IFL (N=428)  F: FOLFOX (N=691)   G: IROX (N=380) Total (N=1499)  p value
Age, yrs    59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 0.614
ast                 0.507
   N-Miss   69  141 56  266 
   Mean (SD)    37.292 (28.036) 35.202 (26.659) 35.670 (25.807) 35.933 (26.843) 
The in-formula functions to change which tests are run can also be used to specify these options for each variable at a time.

summary(tableby(arm ~ anova(age,  meansd , numeric.simplify=TRUE) +
                  chisq(sex, cat.simplify=TRUE), data = mockstudy))
## 
## 
## |             | A: IFL (N=428)  | F: FOLFOX (N=691) | G: IROX (N=380) | Total (N=1499)  | p value|
## |:|::|:--:|::|::|-:|
## |**Age, yrs** | 59.673 (11.365) |  60.301 (11.632)  | 59.763 (11.499) | 59.985 (11.519) |   0.614|
## |**Gender**   |   151 (35.3%)   |    280 (40.5%)    |   152 (40.0%)   |   583 (38.9%)   |   0.190|
19. Use tableby within an Sweave document
For those users who wish to create tables within an Sweave document, the following code seems to work.

\documentclass{article}

\usepackage{longtable}
\usepackage{pdfpages}

\begin{document}

\section{Read in Data}
<<echo=TRUE>>=
require(arsenal)
require(knitr)
require(rmarkdown)
data(mockstudy)

tab1 <- tableby(arm~sex+age, data=mockstudy)
@

\section{Convert Summary.Tableby to LaTeX}
<<echo=TRUE, results='hide', message=FALSE>>=
capture.output(summary(tab1), file= Test.md )

## Convert R Markdown Table to LaTeX
render( Test.md , pdf_document(keep_tex=TRUE))
@ 

\includepdf{Test.pdf}

\end{document}
20. Export tableby object to a .CSV file
When looking at multiple variables it is sometimes useful to export the results to a csv file. The as.data.frame function creates a data frame object that can be exported or further manipulated within R.

tab1 <- tableby(arm~sex+age, data=mockstudy)
as.data.frame(tab1)
##   variable     term     label variable.type              A: IFL           F: FOLFOX
## 1      sex      sex    Gender   categorical                                        
## 2      sex countpct      Male   categorical 277.00000, 64.71963 411.00000, 59.47902
## 3      sex countpct    Female   categorical 151.00000, 35.28037 280.00000, 40.52098
## 4      age      age  Age, yrs       numeric                                        
## 5      age   meansd Mean (SD)       numeric  59.67290, 11.36454  60.30101, 11.63225
## 6      age    range     Range       numeric              27, 88              19, 88
##              G: IROX              Total                       test   p.value
## 1                                       Pearson's Chi-squared test 0.1904388
## 2            228, 60  916.0000, 61.1074 Pearson's Chi-squared test 0.1904388
## 3            152, 40  583.0000, 38.8926 Pearson's Chi-squared test 0.1904388
## 4                                               Linear Model ANOVA 0.6143859
## 5 59.76316, 11.49930 59.98532, 11.51877         Linear Model ANOVA 0.6143859
## 6             26, 85             19, 88         Linear Model ANOVA 0.6143859
# write.csv(tmp, '/my/path/here/mymodel.csv')
21. Write tableby object to a separate Word or HTML file
## write to an HTML document
tab1 <- tableby(arm ~ sex + age, data=mockstudy)
write2html(tab1,  ~/trash.html )

## write to a Word document
write2word(tab1,  ~/trash.doc , title= My table in Word )
22. Use tableby in R Shiny
The easiest way to output a tableby() object in an R Shiny app is to use the tableOutput() UI in combination with the renderTable() server function and as.data.frame(summary(tableby())):

# A standalone shiny app
library(shiny)
library(arsenal)
data(mockstudy)

shinyApp(
  ui = fluidPage(tableOutput( table )),
  server = function(input, output) {
    output$table <- renderTable({
      as.data.frame(summary(tableby(sex ~ age, data = mockstudy), text =  html ))
    }, sanitize.text.function = function(x) x)
  }
)
This can be especially powerful if you feed the selections from a selectInput(multiple = TRUE) into formulize() to make the table dynamic!

23. Use tableby in bookdown
Since the backbone of tableby() is knitr::kable(), tables still render well in bookdown. However, print.summary.tableby() doesn‚Äôt use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID.

summary(tableby(sex ~ age, data = mockstudy), title= (\\#tab:mytableby) Caption here )
24. Adjust tableby for multiple p-values
The padjust() function is a new S3 generic piggybacking off of p.adjust(). It works on both tableby and summary.tableby objects:

tab <- summary(tableby(sex ~ age + fu.time + bmi + mdquality.s, data = mockstudy))
tab
## 
## 
## |                             |   Male (N=916)    |  Female (N=583)   |  Total (N=1499)   | p value|
## |:-|:--:|:--:|:--:|-:|
## |**Age, yrs**                 |                   |                   |                   |   0.048|
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |  60.455 (11.369)  |  59.247 (11.722)  |  59.985 (11.519)  |        |
## |&nbsp;&nbsp;&nbsp;Range      |  19.000 - 88.000  |  22.000 - 88.000  |  19.000 - 88.000  |        |
## |**fu.time**                  |                   |                   |                   |   0.978|
## |&nbsp;&nbsp;&nbsp;Mean (SD)  | 649.345 (454.332) | 648.674 (475.472) | 649.084 (462.511) |        |
## |&nbsp;&nbsp;&nbsp;Range      | 0.000 - 2472.000  | 9.000 - 2441.000  | 0.000 - 2472.000  |        |
## |**Body Mass Index (kg/m^2)** |                   |                   |                   |   0.012|
## |&nbsp;&nbsp;&nbsp;N-Miss     |        22         |        11         |        33         |        |
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |  27.491 (5.030)   |  26.760 (5.984)   |  27.206 (5.432)   |        |
## |&nbsp;&nbsp;&nbsp;Range      |  14.053 - 60.243  |  15.430 - 53.008  |  14.053 - 60.243  |        |
## |**mdquality.s**              |                   |                   |                   |   0.827|
## |&nbsp;&nbsp;&nbsp;N-Miss     |        153        |        99         |        252        |        |
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |   0.899 (0.301)   |   0.903 (0.296)   |   0.901 (0.299)   |        |
## |&nbsp;&nbsp;&nbsp;Range      |   0.000 - 1.000   |   0.000 - 1.000   |   0.000 - 1.000   |        |
padjust(tab, method =  bonferroni )
## 
## 
## |                             |   Male (N=916)    |  Female (N=583)   |  Total (N=1499)   | p value|
## |:-|:--:|:--:|:--:|-:|
## |**Age, yrs**                 |                   |                   |                   |   0.191|
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |  60.455 (11.369)  |  59.247 (11.722)  |  59.985 (11.519)  |        |
## |&nbsp;&nbsp;&nbsp;Range      |  19.000 - 88.000  |  22.000 - 88.000  |  19.000 - 88.000  |        |
## |**fu.time**                  |                   |                   |                   |   1.000|
## |&nbsp;&nbsp;&nbsp;Mean (SD)  | 649.345 (454.332) | 648.674 (475.472) | 649.084 (462.511) |        |
## |&nbsp;&nbsp;&nbsp;Range      | 0.000 - 2472.000  | 9.000 - 2441.000  | 0.000 - 2472.000  |        |
## |**Body Mass Index (kg/m^2)** |                   |                   |                   |   0.048|
## |&nbsp;&nbsp;&nbsp;N-Miss     |        22         |        11         |        33         |        |
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |  27.491 (5.030)   |  26.760 (5.984)   |  27.206 (5.432)   |        |
## |&nbsp;&nbsp;&nbsp;Range      |  14.053 - 60.243  |  15.430 - 53.008  |  14.053 - 60.243  |        |
## |**mdquality.s**              |                   |                   |                   |   1.000|
## |&nbsp;&nbsp;&nbsp;N-Miss     |        153        |        99         |        252        |        |
## |&nbsp;&nbsp;&nbsp;Mean (SD)  |   0.899 (0.301)   |   0.903 (0.296)   |   0.901 (0.299)   |        |
## |&nbsp;&nbsp;&nbsp;Range      |   0.000 - 1.000   |   0.000 - 1.000   |   0.000 - 1.000   |        |
Available Function Options
Summary statistics
The default summary statistics, by varible type, are:

numeric.stats: Continuous variables will show by default Nmiss, meansd, range
cat.stats: Categorical and factor variables will show by default Nmiss, countpct
ordered.stats: Ordered factors will show by default Nmiss, countpct
surv.stats: Survival variables will show by default Nmiss, Nevents, medsurv
date.stats: Date variables will show by default Nmiss, median, range
Any summary statistics standardly defined in R (e.g. mean, median, sd, med, range) can be specified, however there are a number of extra functions defined specifically for the tableby function.

N: a count of the number of observations for a particular group
Nmiss: only show the count of the number of missing values if there are some missing values
Nmiss2: always show a count of the number of missing values for a variable within each group
meansd: print the mean and standard deviation in the format mean(sd)
countpct: print the number of values in a category plus the column-percentage in the format N (%)
countrowpct: print the number of values in a category plus the row-percentage in the format N (%)
countcellpct: print the number of values in a category plus the cell-percentage in the format N (%)
binomCI: print the proportion in a category plus a binomial confidence interval.
rowbinomCI: print the row proportion in a category plus a binomial confidence interval.
medianq1q3: print the median, 25th, and 75th quantiles median (Q1, Q3)
q1q3: print the 25th and 75th quantiles Q1, Q3
iqr: print the inter-quartile range.
medianrange: print the median, minimum and maximum values median (minimum, maximum)
Nevents: print number of events for a survival object within each grouping level
medsurv: print the median survival
NeventsSurv: print number of events and survival at given times
NriskSurv: print the number still at risk at given times
medTime: print the median follow-up time
Testing options
The tests used to calculate p-values differ by the variable type, but can be specified explicitly in the formula statement or in the control function.

The following tests are accepted:

anova: analysis of variance test; the default test for continuous variables. When the grouping variable has two levels, it is equivalent to the two-sample t-test with equal variance.

kwt: Kruskal-Wallis test, optional test for continuous variables. When the grouping variable has two levels, it is equivalent to the Wilcoxon Rank Sum test.

chisq: chi-square goodness of fit test for equal counts of a categorical variable across categories; the default for categorical or factor variables

fe: Fisher‚Äôs exact test for categorical variables; optional

logrank: log-rank test, the default test for time-to-event variables

trend: The independence_test function from the coin is used to test for trends. Whenthe grouping variable has two levels, it is equivalent to the Armitage trend test. This is the default for ordered factors

notest: Don‚Äôt perform a test.

tableby.control settings
A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in tableby.control or in summary.tableby.

args(tableby.control)
## function (test = TRUE, total = TRUE, test.pname = NULL, cat.simplify = FALSE, 
##     numeric.simplify = FALSE, numeric.test =  anova , cat.test =  chisq , 
##     ordered.test =  trend , surv.test =  logrank , date.test =  kwt , 
##     numeric.stats = c( Nmiss ,  meansd ,  range ), cat.stats = c( Nmiss , 
##          countpct ), ordered.stats = c( Nmiss ,  countpct ), 
##     surv.stats = c( Nevents ,  medSurv ), date.stats = c( Nmiss , 
##          median ,  range ), stats.labels = list(Nmiss =  N-Miss , 
##         Nmiss2 =  N-Miss , meansd =  Mean (SD) , medianrange =  Median (Range) , 
##         median =  Median , medianq1q3 =  Median (Q1, Q3) , q1q3 =  Q1, Q3 , 
##         iqr =  IQR , range =  Range , countpct =  Count (Pct) , 
##         Nevents =  Events , medSurv =  Median Survival , medTime =  Median Follow-Up ), 
##     digits = 3L, digits.count = 0L, digits.pct = 1L, digits.p = 3L, 
##     format.p = TRUE, conf.level = 0.95, chisq.correct = FALSE, 
##     simulate.p.value = FALSE, B = 2000, ...) 
## NULL
summary.tableby settings
The summary.tableby function has options that modify how the table appears (such as adding a title or modifying labels).

args(arsenal:::summary.tableby)
## function (object, ..., labelTranslations = NULL, text = FALSE, 
##     title = NULL, pfootnote = FALSE, term.name =   ) 
## NULL





## The write2 function

https://cran.r-project.org/web/packages/arsenal/vignettes/write2.html

The write2 function
Ethan Heinzen
09 November, 2018
Introduction
A note on piping
Examples Using arsenal Objects
tableby
modelsum
freqlist
compare
Examples Using Other Objects
knitr::kable()
xtable::xtable()
pander::pander_return()
Output Multiple Tables to One Document
Output Other Objects Monospaced (as if in a terminal)
Add a YAML Header to the Output
FAQs
How do I suppress the note about my document getting rendered?
How do I look at the temporary .md file?
How do I prevent my document from being rendered?
How do I output headers, raw HTML/LaTeX, paragraphs, etc.?
How do I tweak the default format from write2word(), write2html(), or write2pdf()?
How do I output to a file format other than word, HTML, and PDF?
How do I avoid prefixes on my table captions in PDF?
How do I output multiple tables with different titles?
Introduction
The write2*() functions were designed as an alternative to SAS‚Äôs ODS procedure for useRs who want to save R Markdown tables to separate Word, HTML, or PDF files without needing separate R Markdown programs.

There are three shortcut functions for the most common output types: HTML, PDF, and Word. Each of these three functions calls write2(), an S3 function which accepts many file output types (see the help pages for rmarkdown::render()). Methods have been implemented for tableby(), modelsum(), and freqlist(), but also knitr::kable(), xtable::xtable(), and pander::pander_return().

The two most important things to recognize with write2() are the following:

Which function is being used to output the object. Sometimes the write2 functions use summary(), while other times they will use print(). The details for each object specifically are described below.

How the ... arguments are passed. To change the options for the summary-like or print-like function, you can pass named arguments which will in turn get passed to the appropriate function. Details for each object specifically are described below.

A note on piping
arsenal is piping-compatible!

The write2*() functions are probably the most useful place to take advantage of the magrittr package‚Äôs piping framework, since commands are often nested several functions deep in the context of write2*(). Piping also allows the arsenal package to become a part of more standard analysis pipelines; instead of needing to write separate R Markdown programs, intermediate analysis tables and output can be easily incorporated into piped statements.

This vignette will sprinkle the foward pipe (%>%) throughout as a hint at the power and flexibility of arsenal and piping.

Examples Using arsenal Objects
library(arsenal)
library(magrittr)
data(mockstudy)
tmpdir <- tempdir()
tableby
For tableby objects, the output function in write2() is summary(). For summary.tableby objects, the output function is print(). For available arguments, see the help pages for summary.tableby(). Don‚Äôt use the option text = TRUE with the write2 functions.

mylabels <- list(sex =  SEX , age = Age, yrs )
tab1 <- tableby(arm ~ sex + age, data=mockstudy)

write2html(
  tab1, paste0(tmpdir,  /test.tableby.html ), quiet = TRUE,
  title =  My test table ,      # passed to summary.tableby
  labelTranslations = mylabels, # passed to summary.tableby
  total = FALSE                 # passed to summary.tableby
)
modelsum
For modelsum objects, the output function in write2() is summary(). For summary.modelsum objects, the output function is print(). For available arguments, see the help pages for summary.modelsum(). Don‚Äôt use the option text = TRUE with the write2 functions.

tab2 <- modelsum(alk.phos ~ arm + ps + hgb, adjust= ~ age + sex, family =  gaussian , data = mockstudy)

write2pdf(
  tab2, paste0(tmpdir,  /test.modelsum.pdf ), quiet = TRUE,
  title =  My test table , # passed to summary.modelsum
  show.intercept = FALSE,  # passed to summary.modelsum
  digits = 5               # passed to summary.modelsum
)
freqlist
For freqlist objects, the output function in write2() is summary(). For summary.freqlist objects, the output function is print(). For available arguments, see the help pages for summary.freqlist().

mockstudy[, c( arm ,  sex ,  mdquality.s )] %>% 
  table(useNA =  ifany ) %>% 
  freqlist(groupBy = c( arm ,  sex )) %>% 
  write2word(
    paste0(tmpdir,  /test.freqlist.doc ), quiet = TRUE,
    single = FALSE,         # passed to summary.freqlist
    title =  My cool title  # passed to summary.freqlist
  )
compare
For compare.data.frame objects, the output function in write2() is summary(). For summary.compare.data.frame objects, the output function is print().

Examples Using Other Objects
knitr::kable()
For objects resulting from a call to kable(), the output function in write2() is print(). There aren‚Äôt any arguments to the print.knitr_kable() function.

mockstudy %>% 
  head() %>% 
  knitr::kable() %>% 
  write2html(paste0(tmpdir,  /test.kable.html ), quiet = TRUE)
xtable::xtable()
For xtable objects, the output function in write2() is print(). For available arguments, see the help pages for print.xtable().

mockstudy %>% 
  head() %>% 
  xtable::xtable(caption =  My xtable ) %>% 
  write2pdf(
    paste0(tmpdir,  /test.xtable.pdf ), quiet = TRUE,
    comment = FALSE, # passed to print.xtable to turn off the default message about xtable version
    include.rownames = FALSE, # passed to print.xtable
    caption.placement =  top  # passed to print.xtable
  )
To make an HTML document, use the print.xtable() option type =  html .

mockstudy %>% 
  head() %>% 
  xtable::xtable(caption =  My xtable ) %>% 
  write2html(
    paste0(tmpdir,  /test.xtable.html ), quiet = TRUE,
    type =  html ,            # passed to print.xtable
    comment = FALSE, # passed to print.xtable to turn off the default message about xtable version
    include.rownames = FALSE, # passed to print.xtable
    caption.placement =  top  # passed to print.xtable
  )
User beware! xtable() is not compatible with write2word().

pander::pander_return()
Pander is a little bit more tricky. Since pander::pander() doesn‚Äôt return an object, the useR should instead use pander::pander_return(). For this (and for all character vectors), the the output function in write2() is cat(sep = '\n').

write2word(pander::pander_return(head(mockstudy)), file = paste0(tmpdir,  /test.pander.doc ), quiet = TRUE)
Output Multiple Tables to One Document
To output multiple tables into a document, simply make a list of them and call the same function as before.

mylist <- list(
  tableby(sex ~ age, data = mockstudy),
  freqlist(table(mockstudy[, c( sex ,  arm )])),
  knitr::kable(head(mockstudy))
)

write2pdf(mylist, paste0(tmpdir,  /test.mylist.pdf ), quiet = TRUE)
One neat side-effect of this function is that you can output text and headers, etc. The possibilities are endless!

mylist2 <- list(
   # Header 1 ,
   This is a small paragraph introducing tableby. ,
  tableby(sex ~ age, data = mockstudy),
   <hr> ,
   # Header 2 ,
   <font color='red'>I can change color of my text!</font> 
)
write2html(mylist2, paste0(tmpdir,  /test.mylist2.html ), quiet = TRUE)
In fact, you can even recurse on the lists!

write2pdf(list(mylist2, mylist), paste0(tmpdir,  /test.mylists.pdf ), quiet = TRUE)
Output Other Objects Monospaced (as if in a terminal)
It may be useful at times to write output that would normally be copied from the terminal. The default method for write2() does this automatically. To output the results of summary.lm(), for example:

lm(age ~ sex, data = mockstudy) %>% 
  summary() %>% 
  write2pdf(paste0(tmpdir,  /test.lm.pdf ), quiet = TRUE)
The verbatim() function is another option to explicitly alert write2() to do this. This becomes particularly helpful to overrule existing S3 methods.

For example, suppose you wanted to just print a tableby object (as if it were to print in the terminal):

tab4 <- tableby(arm ~ sex + age, data=mockstudy)
write2html(verbatim(tab4), paste0(tmpdir,  /test.print.tableby.html ), quiet = TRUE)
Or suppose you wanted to print a character vector (as if it were to print in the terminal):

chr <- paste0( MyVector , 1:10)
write2pdf(verbatim(chr), paste0(tmpdir,  /test.character.pdf ), quiet = TRUE)
Add a YAML Header to the Output
You can add a YAML header to write2() output using the yaml() function.

mylist3 <- list(
  yaml(title =  Test YAML Title , author =  My cool author name ),
   # Header 1 ,
   This is a small paragraph introducing tableby. ,
  tableby(sex ~ age, data = mockstudy)
)
write2html(mylist3, paste0(tmpdir,  /test.yaml.html ), quiet = TRUE)
In fact, all detected YAML pieces will be moved as the first output, so that the above code chunk gives the same output as this one:

mylist4 <- list(
   # Header 1 ,
   This is a small paragraph introducing tableby. ,
  yaml(title =  Test YAML Title ),
  tableby(sex ~ age, data = mockstudy),
  yaml(author =  My cool author name )
)
write2html(mylist3, paste0(tmpdir,  /test.yaml2.html ), quiet = TRUE)
FAQs
How do I suppress the note about my document getting rendered?
This is easily accomplished by using the argument quiet = TRUE (passed to the rmarkdown::render() function).

write2html(
  knitr::kable(head(mockstudy)), paste0(tmpdir,  /test.kable.quiet.html ),
  quiet = TRUE # passed to rmarkdown::render
)
How do I look at the temporary .md file?
This is easily accomplished by using the option keep.md = TRUE.

write2html(
  knitr::kable(head(mockstudy)), paste0(tmpdir,  /test.kable.keep.md.html ),
  quiet = TRUE, # passed to rmarkdown::render
  keep.md = TRUE
)
How do I prevent my document from being rendered?
This is easily accomplished by using the option render. = FALSE. Note that this will then default to keep.md = TRUE.

write2html(
  knitr::kable(head(mockstudy)), paste0(tmpdir,  /test.kable.dont.render.html ),
  render. = FALSE
)
How do I output headers, raw HTML/LaTeX, paragraphs, etc.?
One can simply abuse the list S3 method for write2()!

mylist2 <- list(
   # Header 1 ,
   This is a small paragraph introducing tableby. ,
  tableby(sex ~ age, data = mockstudy),
   <hr> ,
   # Header 2 ,
   <font color='red'>I can change color of my text!</font> 
)
write2html(mylist2, paste0(tmpdir,  /test.mylist2.html ), quiet = TRUE)
How do I tweak the default format from write2word(), write2html(), or write2pdf()?
You can pass arguments to the format functions used behind the scenes.

write2html(
  knitr::kable(head(mockstudy)), paste0(tmpdir,  /test.kable.theme.html ),
  quiet = TRUE,  # passed to rmarkdown::render
  theme =  yeti  # passed to rmarkdown::html_document
)
See the help pages for rmarkdown::word_document(), rmarkdown::html_document(), and rmarkdown::pdf_document().

How do I output to a file format other than word, HTML, and PDF?
This can be done using the generic write2() function. The last argument in the function can be another format specification. For details on the acceptable inputs, see the help page for write2().

write2(
  knitr::kable(head(mockstudy[, 1:4])), paste0(tmpdir,  /test.kable.rtf ),
  quiet = TRUE,  # passed to rmarkdown::render
  output_format = rmarkdown::rtf_document
)
How do I avoid prefixes on my table captions in PDF?
You can do this pretty easily with the yaml() function:

mylist5 <- list(
  yaml( header-includes  = list( \\usepackage[labelformat=empty]{caption} )),
   # Header 1 ,
   This is a small paragraph introducing tableby. ,
  tableby(sex ~ age, data = mockstudy)
)
write2pdf(mylist5, paste0(tmpdir,  /test.noprefixes.pdf ), title =  My tableby )
How do I output multiple tables with different titles?
There are now write2() methods for the summary objects of arsenal functions. This allows you to specify a title for each table:

mylist6 <- list(
  summary(tableby(sex ~ age, data = mockstudy), title =  A Title for tableby ),
  summary(modelsum(age ~ sex, data = mockstudy), title =  A Title for modelsum ),
  summary(freqlist(~ sex, data = mockstudy), title =  A Title for freqlist )
)
write2pdf(mylist6, paste0(tmpdir,  /test.multiple.titles.pdf ))
\end{verbatim}

\hypertarget{dashboard-visualizations-in-r-deviation}{%
\chapter{Dashboard visualizations in R: Deviation}\label{dashboard-visualizations-in-r-deviation}}

\begin{verbatim}
author:  Kristian Larsen 
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
\end{verbatim}

\begin{verbatim}
from: https://datascienceplus.com/automated-dashboard-visualizations-with-deviation-in-r/?fbclid=IwAR2JcAMQ4eNRMrEBPGL79HDbS818vGZX0evs-ateBX0d9SRFIilY7U44Szw
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
library(flexdashboard)
library(ggplot2)
library(plotly)
theme_set(theme_bw())  

# Data Prep
data( mtcars )  # load data
mtcars$`car name` <- rownames(mtcars)  # create new column for car names
mtcars$mpg_z <- round((mtcars$mpg - mean(mtcars$mpg))/sd(mtcars$mpg), 2)  # compute normalized mpg
mtcars$mpg_type <- ifelse(mtcars$mpg_z < 0,  below ,  above )  # above / below avg flag
mtcars <- mtcars[order(mtcars$mpg_z), ]  # sort
mtcars$`car name` <- factor(mtcars$`car name`, levels = mtcars$`car name`)  # convert to factor to retain sorted order in plot.
\end{verbatim}

\hypertarget{row}{%
\section{Row}\label{row}}

\hypertarget{chart-a-diverging-barcharts}{%
\subsection{Chart A: Diverging Barcharts}\label{chart-a-diverging-barcharts}}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
ggplot(mtcars, aes(x=`car name`, y=mpg_z, label=mpg_z)) + 
  geom_bar(stat='identity', aes(fill=mpg_type), width=.5)  +
  scale_fill_manual(name= Mileage , 
                    labels = c( Above Average ,  Below Average ), 
                    values = c( above = #00ba38 ,  below = #f8766d )) + 
  labs(subtitle= Normalised mileage from 'mtcars' , 
       title=  Diverging Bars ) + 
  coord_flip()
ggplotly(p = ggplot2::last_plot())
\end{verbatim}

\hypertarget{chart-b-diverging-lollipop-chart}{%
\subsection{Chart B: Diverging Lollipop Chart}\label{chart-b-diverging-lollipop-chart}}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
theme_set(theme_bw())

ggplot(mtcars, aes(x=`car name`, y=mpg_z, label=mpg_z)) + 
  geom_point(stat='identity', fill= black , size=6)  +
  geom_segment(aes(y = 0, 
                   x = `car name`, 
                   yend = mpg_z, 
                   xend = `car name`), 
               color =  black ) +
  geom_text(color= white , size=2) +
  labs(title= Diverging Lollipop Chart , 
       subtitle= Normalized mileage from 'mtcars': Lollipop ) + 
  ylim(-2.5, 2.5) +
  coord_flip()
ggplotly(p = ggplot2::last_plot())
\end{verbatim}

\hypertarget{row-1}{%
\section{Row}\label{row-1}}

\hypertarget{cart-c-diverging-dot-plot}{%
\subsection{Cart C: Diverging Dot Plot}\label{cart-c-diverging-dot-plot}}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
theme_set(theme_bw())

# Plot
ggplot(mtcars, aes(x=`car name`, y=mpg_z, label=mpg_z)) + 
  geom_point(stat='identity', aes(col=mpg_type), size=6)  +
  scale_color_manual(name= Mileage , 
                     labels = c( Above Average ,  Below Average ), 
                     values = c( above = #00ba38 ,  below = #f8766d )) + 
  geom_text(color= white , size=2) +
  labs(title= Diverging Dot Plot , 
       subtitle= Normalized mileage from 'mtcars': Dotplot ) + 
  ylim(-2.5, 2.5) +
  coord_flip()
ggplotly(p = ggplot2::last_plot())
\end{verbatim}

\hypertarget{autoreport-1}{%
\chapter{autoreport}\label{autoreport-1}}

\begin{verbatim}
print(paste0( Git Update Started at:  , Sys.time()))
CommitMessage <- paste( updated on:  , Sys.time(), sep =   )
wd <-  ~/serdarbalci 
setorigin <-  git remote set-url origin git@github.com:sbalci/MyJournalWatch.git \n 
gitCommand <- paste( cd  , wd,   \n git add . \n git commit --message ' , CommitMessage,  ' \n , setorigin,  git push origin master \n ,  sep =   )
system(command = paste(gitCommand,  \n ) , intern = TRUE, wait = TRUE)
Sys.sleep(5)
print(paste0( Git Update Ended at:  , Sys.time()))
\end{verbatim}

\hypertarget{describe-results-of-analysis}{%
\section{Describe results of analysis}\label{describe-results-of-analysis}}

Copy/paste t-tests Directly to Manuscripts: \url{https://neuropsychology.github.io/psycho.R//2018/06/19/analyze_ttest.html}

\url{https://github.com/neuropsychology/psycho.R}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
# Load packages
library(tidyverse)

# devtools::install_github( neuropsychology/psycho.R )  # Install the latest psycho version
library(psycho)
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
df <- psycho::affective  # Load the data

df
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}

results <- t.test(df$Age ~ df$Sex)  # Perform a simple t-test
results
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
psycho::analyze(results)
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
t.test(df$Adjusting ~ df$Sex,
       var.equal=TRUE, 
       conf.level = .90) %>% 
  psycho::analyze()
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}

t.test(df$Adjusting, 
       mu = 0,
       conf.level = .90) %>% 
      psycho::analyze()
\end{verbatim}

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}

t.test(df$Adjusting ~ df$Sex) %>% 
  psycho::analyze() %>% 
  summary()
\end{verbatim}

\hypertarget{citation}{%
\chapter{citation}\label{citation}}

\begin{verbatim}
{ PubMed references, eval=FALSE, include=FALSE, echo=TRUE}
PMID_25783680 <- RefManageR::ReadPubMed( 25783680 , database =  PubMed )
cit_25783680 <- paste0(PMID_25783680$title,    , PMID_25783680$journal,    ,  PMID: https://www.ncbi.nlm.nih.gov/pubmed/?term= , PMID_25783680$eprint,    ,  doi: https://doi.org/ , PMID_25783680$doi)
\end{verbatim}

My next citation is here\footnote{r cit\_25783680 }.

\begin{verbatim}
{ dimension badge, eval=FALSE, include=FALSE, echo=TRUE}
PMID_25783680 <- RefManageR::ReadPubMed( 25783680 , database =  PubMed )
dimensionBadge <- paste0(
     <script async='' charset='utf-8' src='https://badge.dimensions.ai/badge.js'></script>
<span class='__dimensions_badge_embed__' data-doi=' ,
PMID_25783680$doi,
 ' data-style='small_circle'></span> 
)
\end{verbatim}

r dimensionBadge

\begin{verbatim}
{ eval=FALSE, include=FALSE, echo=TRUE}
PMID_25783680 <- RefManageR::ReadPubMed( 25783680 , database =  PubMed )
altmetricBadge <- paste0(
     <script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
<span class='altmetric-embed' data-badge-popover='right' data-badge-type='donut' data-doi=' ,
    PMID_25783680$doi,
     '></span> 
)
\end{verbatim}

r altmetricBadge

\hypertarget{bbplot}{%
\chapter{bbplot}\label{bbplot}}

\hypertarget{bbc-visual-and-data-journalism-cookbook-for-r-graphics}{%
\section{BBC Visual and Data Journalism cookbook for R graphics}\label{bbc-visual-and-data-journalism-cookbook-for-r-graphics}}

\url{https://bbc.github.io/rcookbook/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github('bbc/bbplot')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#This line of code installs the pacman page if you do not have it installed - if you do, it simply loads the package
if(!require(pacman))install.packages( pacman )

pacman::p_load('dplyr', 'tidyr', 'gapminder',
               'ggplot2',  'ggalt',
               'forcats', 'R.utils', 'png', 
               'grid', 'ggpubr', 'scales',
               'bbplot')
\end{verbatim}

\hypertarget{bibliography-1}{%
\chapter{Bibliography}\label{bibliography-1}}

A brief introduction to bibliometrix

\url{https://cran.r-project.org/web/packages/bibliometrix/vignettes/bibliometrix-vignette.html}

Bibliographic Network Visualization for Academic Literature Reviews

\url{http://www.mburnamfink.com/blog/bibliographic-network-visualization-for-academic-literature-reviews}

\url{https://embed.kumu.io/0b991b02bb20975fde904f4bf7433333\#jpsp-top-50?s=\%23doi-101037-0022-35147451252}

More Than Words? Computer-Aided Text Analysis in Organizational Behavior and Psychology Research

\url{https://www.annualreviews.org/doi/10.1146/annurev-orgpsych-032117-104622}

\url{https://www.kumu.io/nicholasjkelley/jpsp-top-50}

\hypertarget{knitcitations}{%
\chapter{knitcitations}\label{knitcitations}}

\url{https://github.com/cboettig/knitcitations}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(devtools)
# install_github( cboettig/knitcitations )
install.packages( knitcitations )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( knitcitations )
cleanbib()
options( citation_format  =  pandoc )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitcitations::citep( 10.1890/11-0011.1 )
\end{verbatim}

\begin{verbatim}
citation  r citep( 10.1890/11-0011.1 )  in text
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitcitations::citet( 10.1098/rspb.2013.1372 )
\end{verbatim}

\begin{verbatim}
citation  r citet( 10.1098/rspb.2013.1372 )  in text
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitcitations::citep( http://knowledgeblog.org/greycite )
\end{verbatim}

\begin{verbatim}
write.bibtex(file= references.bib )
\end{verbatim}

\hypertarget{rcrossref}{%
\chapter{rcrossref}\label{rcrossref}}

\url{https://github.com/ropensci/rcrossref}

\hypertarget{rorcid-tutorial}{%
\chapter{rorcid tutorial}\label{rorcid-tutorial}}

\url{https://ropensci.org/tutorials/rorcid_tutorial/}

\hypertarget{rentrez-tutorial}{%
\chapter{rentrez tutorial}\label{rentrez-tutorial}}

\url{https://ropensci.org/tutorials/rentrez_tutorial/}

\hypertarget{webscicorpus}{%
\chapter{WebSciCorpus}\label{webscicorpus}}

\url{https://www.clarehooper.net/WebSciCorpus/}

\hypertarget{web-of-science-wos-corpus-parsing-script}{%
\chapter{WEB OF SCIENCE (WOS) CORPUS \textbar{} PARSING SCRIPT}\label{web-of-science-wos-corpus-parsing-script}}

\url{https://docs.cortext.net/question/web-of-science-wos-corpus-parsing-script-2/}

\hypertarget{t-lab-plus-2019}{%
\chapter{T-LAB PLUS 2019}\label{t-lab-plus-2019}}

\url{https://tlab.it/en/allegati/help_en_online/mmappe2.htm}

\hypertarget{tools-for-bibliometric-analyses}{%
\chapter{Tools for bibliometric analyses}\label{tools-for-bibliometric-analyses}}

\url{https://ju.se/library/research--teaching-support/bibliometrics/tools-for-bibliometric-analyses.html}

\hypertarget{evidencepartners}{%
\chapter{evidencepartners}\label{evidencepartners}}

\url{https://www.evidencepartners.com/}

\hypertarget{r-script-for-creating-a-cross-citation-network}{%
\chapter{R script for creating a cross-citation network}\label{r-script-for-creating-a-cross-citation-network}}

\url{https://www.researchgate.net/publication/327790285_R_script_for_creating_a_cross-citation_network}

Repository: \url{https://github.com/arsiders/citation-network}

\begin{verbatim}
# RCitation - Quick Citation Network 
# Fall 2018 
# A.R. Siders (siders@alumni.stanford.edu)

# Creates a network of the citations among a set of academic papers. 
# Rationale: If full title of Article 2 is present in text of Article 1, Article 1 cites Article 2. 
# NOTE: Will only work in fields where full, unabbreviated titles are used in reference/bibliography citation format. 
# NOTE: Will have high error rate if titles are very short or comprised of common words (e.g., paper  Vulnerability  produced many false positives). Some errors result from authors using a shortened version of a title (e.g., only text before a colon) or incorrect citations or typos. Citation networks produced are therefore approximate and to be used primarily for exploration of the data.
# NOTE: Error rate may be reduced by using only reference sections of the articles of interest, rather than full texts, but this will increase work required to prepare articles. 


# ==> FIVE STEPS TO CITATION NETWORK

# STEP 1. FORMAT INPUT
# a. Papers: Folder of papers in txt format (UTF-8) organized *in SAME ORDER* as Titles 
# b. Titles: Column of paper titles in csv spreadsheet (Column #1) *in SAME ORDER* as documents in Papers folder. Need a header cell or top title will be removed.
# Recommend naming all texts in Papers folder using author last name listed alphabetically. Organize Titles using same order.


# STEP 2.  PREP
# set working directory
setwd( C:\[name of working space] ) # make sure \ not / in name
setwd( C:/Users/User/OneDrive/Adaptive Capacity Text Mining/Citation Network Test/CitationNetwork Test Data )
# load packages
install.packages(c( tm , plyr ))
library(tm)
library(plyr)


# STEP 3. LOAD INPUTS
# a. Papers 
papers<-Corpus(DirSource( [name of folder where papers located] ))
papers<-Corpus(DirSource( Papers ))
# b. Titles
titletable<-read.csv( [name of titles file].csv ) #make sure column has a header
titletable<-read.csv( TestTitles.csv )
titles<-as.vector(titletable[,1])
# load functions at bottom of this script (below Step 5)

length(papers)
length(titles)

# STEP 4. RUN FUNCTION 

CitationNetwork<-CreateCitationNetwork(papers,titles)
# add date
currentDate <- Sys.Date()
csvFileName <- paste( CitationEdges ,currentDate, .csv ,sep=  )
# save results
write.csv(CitationNetwork, file=csvFileName) 

  
# STEP 5. VISUALIZE NETWORK

# Install Gephi or other network visualization software and load CitationEdges.csv 
# Load list of titles or other spreadsheet as nodes to visualize network 
# Gephi available at https://gephi.org/


# ===> FUNCTIONS TO LOAD 

CreateCitationNetwork<-function(papers,titles){
  # prep papers corpus
  papers<-tm_map(papers, content_transformer(tolower))
  papers<-tm_map(papers, removePunctuation)
  papers<-tm_map(papers, removeNumbers)
  papers<-tm_map(papers, stripWhitespace)
  # prep titles 
  titles<-removePunctuation(titles)
  titles<-stripWhitespace(titles)
  titles<-tolower(titles)
  # create citation true/false matrix
  Cites.TF<-CiteMatrix(titles, papers)
  # format matrix into edges file 
  CitationEdges<-EdgesFormat(Cites.TF, titles)
  return(CitationEdges)
}  

# format true/false matrix into edges file 
EdgesFormat<-function(Cites.TF, titles){
  #create an empty object to put information in
  edges<-data.frame(matrix(NA), nrow=NA, ncol=NA)
  colnames(edges)<- c( Source , Target , Weight )
  for (i in 1:length(Cites.TF)){
  #for each document, run through all titles accross columns
    for (j in 1:ncol(Cites.TF)){
      # for each title, see if document [row] cited that title [column]
      if (Cites.TF[i,j]==TRUE){  #if document is cited
        temp<-data.frame(matrix(NA), nrow=NA, ncol=NA)
        colnames(temp)<- c( Source , Target , Weight )
        # first column <- document doing the citing 
        temp[1,1]<-titles[i]
        # second column <- document being cited
        temp[1,2]<-titles[j]
        # third column the yes/no [weight]
        temp[1,3]<-1  
        temp[1,4]<- Directed 
        edges<-rbind(edges,temp)    
      } 
    }
  }  
  return(edges[-1,]) #-1 removes initial row of null values
}

# Citation true/false matrix 
CiteMatrix<-function(search.vector, Ref.corpus){
  # Creates a csv matrix with True/False for citation patterns 
  citations<-data.frame(matrix(NA, nrow = length(Ref.corpus), ncol=length(search.vector)))
  #Columns are the document being cited
  colnames(citations)<-search.vector
  #Rows are the document doing the citing 
  rownames(citations)<-search.vector
  for (i in 1:length(search.vector)){
    searchi<-search.vector[i]
    papercite<-grepl(searchi, Ref.corpus$content, fixed=TRUE)
    citations[,i]<-papercite
  }
  return(citations)
}
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The application of methods of social network analysis in bibliometrics and webometrics. Measures and tools
\end{itemize}

\url{https://www.researchgate.net/publication/327817518_The_application_of_methods_of_social_network_analysis_in_bibliometrics_and_webometrics_Measures_and_tools}

\hypertarget{scientominer-icr}{%
\chapter{ScientoMiner ICR}\label{scientominer-icr}}

\url{https://zenodo.org/record/1432557\#.XItjfxO2k1J}

\hypertarget{onodo}{%
\chapter{onodo}\label{onodo}}

\url{https://onodo.org/dashboard}

\url{https://onodo.org/tutorials}

\hypertarget{bibexcel}{%
\chapter{BibExcel}\label{bibexcel}}

\url{https://homepage.univie.ac.at/juan.gorraiz/bibexcel/}

\hypertarget{scientometric-portal}{%
\chapter{Scientometric Portal}\label{scientometric-portal}}

\url{https://sites.google.com/site/hjamali/scientometric-portal}

\hypertarget{leydesdorff}{%
\chapter{leydesdorff}\label{leydesdorff}}

\url{https://www.leydesdorff.net/software.htm}

\hypertarget{publish-or-perish}{%
\chapter{Publish or Perish}\label{publish-or-perish}}

\url{https://harzing.com/resources/publish-or-perish}

\hypertarget{pajek-analysis-and-visualization-of-large-networks}{%
\chapter{Pajek: analysis and visualization of large networks}\label{pajek-analysis-and-visualization-of-large-networks}}

\url{http://mrvar.fdv.uni-lj.si/pajek/}

\hypertarget{r-bioconductor}{%
\chapter{R Bioconductor}\label{r-bioconductor}}

\begin{itemize}
\tightlist
\item
  \url{https://www.bioconductor.org/}
\end{itemize}

\begin{verbatim}
## try http:// if https:// URLs are not supported
source( https://bioconductor.org/biocLite.R )
biocLite()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The Bioconductor 2018 Workshop Compilation
  \url{https://bioconductor.github.io/BiocWorkshops/index.html}
\end{itemize}

\url{https://github.com/Bioconductor/BiocWorkshops}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fname <- file.choose()
fname
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
file.exists(fname)
\end{verbatim}

\url{https://raw.githubusercontent.com/Bioconductor/BiocWorkshops/master/100_Morgan_RBiocForAll/ALL-phenoData.csv}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata <- read.csv(fname)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dim(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
head(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tail(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(fname)
class(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata <- read.csv(
    fname,
    colClasses = c( character ,  factor ,  integer ,  factor )
)
summary(pdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata[1:5, c( sex ,  mol.biol )]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata[1:5, c(2, 3)]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata[1:5, ]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata$age
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata[[ age ]]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(pdata$age)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(pdata$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(is.na(pdata$age))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
levels(pdata$sex)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata$sex ==  F 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(pdata$sex ==  F ) & (pdata$age > 50)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table( pdata$mol.biol )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pdata$mol.biol %in% c( BCR/ABL ,  NEG )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
subset(pdata, sex ==  F  & age > 50)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
bcrabl <- subset(pdata, mol.biol %in% c( BCR/ABL ,  NEG ))
dim( bcrabl )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(bcrabl$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(bcrabl$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
factor(bcrabl$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
bcrabl$mol.biol <- factor(bcrabl$mol.biol)
table(bcrabl$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(bcrabl$mol.biol)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
boxplot(age ~ mol.biol, bcrabl)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
t.test(age ~ mol.biol, bcrabl)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
ggplot(bcrabl, aes(x = mol.biol, y = age))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(bcrabl, aes(x = mol.biol, y = age)) + geom_boxplot()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (! BiocManager  %in% rownames(installed.packages()))
    install.packages( BiocManager , repos= https://cran.r-project.org )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
BiocManager::install(c( rtracklayer ,  GenomicRanges ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
BiocManager::valid()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
BiocManager::available( TxDb.Hsapiens )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( simpleSingleCell )
\end{verbatim}

\url{https://support.bioconductor.org/}

\url{https://bioconductor.org/help/course-materials/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( rtracklayer )
library( GenomicRanges )
\end{verbatim}

\url{https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=578954849_wF1QP81SIHdfr8b0kmZUOcsZcHYr\&clade=mammal\&org=Human\&db=hg38\&hgta_group=regulation\&hgta_track=knownGene\&hgta_table=0\&hgta_regionType=genome\&position=chr9\%3A133252000-133280861\&hgta_outputType=primaryTable\&hgta_outFileName=}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fname <- file.choose()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cpg <- rtracklayer::import(fname)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
file.exists(fname)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cpg
\end{verbatim}

\url{https://bioconductor.github.io/BiocWorkshops/r-and-bioconductor-for-everyone-an-introduction.html}

\begin{itemize}
\tightlist
\item
  \textbf{Introduction to Bioconductor}
\end{itemize}

\url{https://www}..com/community/tutorials/intro-bioconductor

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
source( https://bioconductor.org/biocLite.R )
biocLite()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
source( https://bioconductor.org/biocLite.R )
biocLite(c(  Biostrings ,  GenomicRanges ,  IMMAN ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(Biostrings)

dnaSequence <- DNAStringSet( c( AAACTG ,  CCCAACCA ) )
dnaSequence
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
complement(dnaSequence)
\end{verbatim}

Important packages:\\
- DNAStringSet\\
- Biostrings\\
- GenomicRanges

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(GenomicRanges)

grangeObj <-
  GRanges(seqnames =
            Rle(c( chr1 ,  chr2 ,  chr1 ,  chr3 ), c(1, 3, 2, 4)),
          ranges =
            IRanges(1:10, end = 7:16, names = head(letters, 10)),
          strand =
            Rle(strand(c( - ,  + ,  * ,  + ,  - )),
                c(1, 2, 2, 3, 2)),
          score = 1:10,
          GC = seq(1, 0, length=10))


grangeObj
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
seqnames(grangeObj)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ranges(grangeObj)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
strand(grangeObj)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( clusterProfiler )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( DOSE )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( org.Hs.eg.db )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(geneList, package= DOSE )

gene <- names(geneList)[abs(geneList) > 2]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ego <- enrichGO(gene          = gene,
                universe      = names(geneList),
                OrgDb         = org.Hs.eg.db,
                ont           =  CC ,
                pAdjustMethod =  BH ,
                pvalueCutoff  = 0.01,
                qvalueCutoff  = 0.05,
                readable      = TRUE)

head(ego)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
emapplot(ego)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(dnaSequence)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
methods(class =  DNAStringSet )
\end{verbatim}

\url{https://bioconductor.org/packages}

\url{https://support.bioconductor.org/}

\url{http://bioconductor.org/help/course-materials/}

\hypertarget{biyoinformatik}{%
\chapter{Biyoinformatik}\label{biyoinformatik}}

\begin{itemize}
\tightlist
\item
  DESeq results to pathways in 60 Seconds with the fgsea package
\end{itemize}

\url{https://stephenturner.github.io/deseq-to-fgsea/}

\hypertarget{bioconductor-1}{%
\chapter{Bioconductor}\label{bioconductor-1}}

\url{https://www.youtube.com/user/bioconductor}

\hypertarget{courses-conferences}{%
\section{Courses \& Conferences}\label{courses-conferences}}

\url{https://www.bioconductor.org/help/course-materials/}

\hypertarget{neuroconductor-tutorials}{%
\chapter{Neuroconductor Tutorials}\label{neuroconductor-tutorials}}

\url{https://neuroconductor.org/tutorials}

\hypertarget{neuroconductor-courses}{%
\chapter{Neuroconductor Courses}\label{neuroconductor-courses}}

\url{https://neuroconductor.org/courses}

\hypertarget{cancerinsilico}{%
\chapter{CancerInSilico}\label{cancerinsilico}}

An R interface for computational modeling of tumor progression

\url{https://bioconductor.org/packages/release/bioc/html/CancerInSilico.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager ))
    install.packages( BiocManager )
BiocManager::install()

if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( CancerInSilico , version =  3.8 )
library(CancerInSilico)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( CancerInSilico )
\end{verbatim}

\url{https://bioconductor.org/packages/release/bioc/vignettes/CancerInSilico/inst/doc/CancerInSilico.html}

\hypertarget{running-a-cell-simulation}{%
\chapter{Running a Cell Simulation}\label{running-a-cell-simulation}}

\hypertarget{run-simple-simulation}{%
\section{Run Simple Simulation}\label{run-simple-simulation}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
simple_mod <- suppressMessages(inSilicoCellModel(initialNum=30, runTime=72,
    density=0.1, outputIncrement=24, randSeed=123))
\end{verbatim}

\hypertarget{plot-cellmodel-object}{%
\section{Plot CellModel Object}\label{plot-cellmodel-object}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plotCells(simple_mod, time=0)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plotCells(simple_mod, time=36)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plotCells(simple_mod, time=72)
\end{verbatim}

\hypertarget{query-cell-information}{%
\section{Query Cell Information}\label{query-cell-information}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# hours in simulation
times <- 0:simple_mod@runTime

# plot number of cells over time
nCells <- sapply(times, getNumberOfCells, model=simple_mod)
plot(times, nCells, type= l , xlab= hour , ylab= number of cells )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# plot population density over time
den <- sapply(times, getDensity, model=simple_mod)
plot(times, den, type= l , xlab= hour , ylab= population density )
\end{verbatim}

\hypertarget{drugs}{%
\chapter{Drugs}\label{drugs}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
drug <- new( Drug , name= Drug_A , timeAdded=24,
    cycleLengthEffect=function(type, length) length * 2)
drug_mod <- suppressMessages(inSilicoCellModel(initialNum=30, runTime=72,
    density=0.1, drugs=c(drug), outputIncrement=24, randSeed=123))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# hours in simulation
times <- 0:simple_mod@runTime

# plot number of cells over time
nCells <- sapply(times, getNumberOfCells, model=simple_mod)
nCells_drug <- sapply(times, getNumberOfCells, model=drug_mod)
plot(times, nCells, type= l , xlab= hour , ylab= number of cells )
lines(times, nCells_drug, type= l , xlab= hour , ylab= number of cells ,
    col= red )
\end{verbatim}

\hypertarget{cell-types}{%
\chapter{Cell Types}\label{cell-types}}

\hypertarget{adding-a-single-cell-type}{%
\section{Adding a Single Cell Type}\label{adding-a-single-cell-type}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
type_A <- new( CellType , name= A , minCycle=16, cycleLength=function() 16)
fast_cells_mod <- suppressMessages(inSilicoCellModel(initialNum=30, runTime=72,
    density=0.1, cellTypes=c(type_A), outputIncrement=24, randSeed=123))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# hours in simulation
times <- 0:fast_cells_mod@runTime

# plot number of cells over time
nCells <- sapply(times, getNumberOfCells, model=simple_mod)
nCells_fast <- sapply(times, getNumberOfCells, model=fast_cells_mod)
plot(times, nCells, type= l , xlab= hour , ylab= number of cells )
lines(times, nCells_fast, type= l , xlab= hour , ylab= number of cells ,
    col= red )
\end{verbatim}

\hypertarget{adding-multiple-cell-types}{%
\section{Adding Multiple Cell Types}\label{adding-multiple-cell-types}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
type_B <- new( CellType , name= B , size=1, minCycle=16,
    cycleLength=function() 16 + rexp(1,1/4))
type_C <- new( CellType , name= C , size=1, minCycle=32,
    cycleLength=function() 32 + rexp(1,1/4))
two_types_mod <- suppressMessages(inSilicoCellModel(initialNum=30, runTime=72,
    density=0.1, cellTypes=c(type_B, type_C), cellTypeInitFreq=c(0.4,0.6),
    outputIncrement=24, randSeed=123))
\end{verbatim}

\hypertarget{getting-cell-type}{%
\section{Getting Cell Type}\label{getting-cell-type}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
getTypeBProportion <- function(time)
{
    N <- getNumberOfCells(two_types_mod, time)
    sum(sapply(1:N, function(i) getCellType(two_types_mod, time, i) == 1)) / N
}
times <- 0:two_types_mod@runTime
Bprop <- sapply(times, getTypeBProportion)
plot(times, Bprop, type= l , xlab= hour , ylab= type B proportion )
\end{verbatim}

\hypertarget{pathways}{%
\chapter{Pathways}\label{pathways}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mitosisGeneNames <- paste( m_ , letters[1:20], sep=  )
mitosisExpression <- function(model, cell, time)
{
    ifelse(getCellPhase(model, time, cell) ==  M , 1, 0)
}

pwyMitosis <- new( Pathway , genes=mitosisGeneNames,
    expressionScale=mitosisExpression)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
contactInhibitionGeneNames <- paste( ci_ , letters[1:15], sep=  )
contactInhibitionExpression <- function(model, cell, time)
{
    getLocalDensity(model, time, cell, 3.3)
}
pwyContactInhibition <- new( Pathway , genes=contactInhibitionGeneNames,
    expressionScale=contactInhibitionExpression)
\end{verbatim}

\hypertarget{calibrate-gene-expression-range}{%
\section{Calibrate Gene Expression Range}\label{calibrate-gene-expression-range}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# create simulated data set
allGenes <- c(mitosisGeneNames, contactInhibitionGeneNames)
geneMeans <- 2 + rexp(length(allGenes), 1/20)
data <- t(pmax(sapply(geneMeans, rnorm, n=25, sd=2), 0))
rownames(data) <- allGenes

# calibrate pathways
pwyMitosis <- calibratePathway(pwyMitosis, data)
pwyContactInhibition <- calibratePathway(pwyContactInhibition, data)
\end{verbatim}

\hypertarget{generate-pathway-activity}{%
\section{Generate Pathway Activity}\label{generate-pathway-activity}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
params <- new( GeneExpressionParams )
params@randSeed <- 123 # control this for reporducibility
params@nCells <- 30 # sample 30 cells at each time point to measure activity
params@sampleFreq <- 6 # measure activity every 6 hours

pwys <- c(pwyMitosis, pwyContactInhibition)
pwyActivity <- inSilicoGeneExpression(simple_mod, pwys, params)$pathways
\end{verbatim}

\hypertarget{visualize-pathway-activity}{%
\section{Visualize Pathway Activity}\label{visualize-pathway-activity}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# mitosis
plot(seq(0,72,6), pwyActivity[[1]], type= l , col= orange , ylim=c(0,1))
# contact inhibition
lines(seq(0,72,6), pwyActivity[[2]], col= blue )
\end{verbatim}

\hypertarget{accounting-for-model-effects}{%
\section{Accounting for Model Effects}\label{accounting-for-model-effects}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pwyMitosis@expressionScale = function(model, cell, time)
{
    window <- c(max(time - 2, 0), min(time + 2, model@runTime))
    a1 <- getAxisLength(model, window[1], cell)
    a2 <- getAxisLength(model, window[2], cell)
    if (is.na(a1)) a1 <- 0 # in case cell was just born
    return(ifelse(a2 < a1, 1, 0))
}
pwys <- c(pwyMitosis, pwyContactInhibition)
pwyActivity <- inSilicoGeneExpression(simple_mod, pwys, params)$pathways
# mitosis
plot(seq(0,72,6), pwyActivity[[1]], type= l , col= orange , ylim=c(0,1))
# contact inhibition
lines(seq(0,72,6), pwyActivity[[2]], col= blue )
\end{verbatim}

\hypertarget{normalize-pathway-activity}{%
\section{Normalize Pathway Activity}\label{normalize-pathway-activity}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pwyMitosis@transformMidpoint = 0.1  
pwyMitosis@transformSlope = 5 / 0.1
pwys <- c(pwyMitosis, pwyContactInhibition)
pwyActivity <- inSilicoGeneExpression(simple_mod, pwys, params)$pathways
# mitosis
plot(seq(0,72,6), pwyActivity[[1]], type= l , col= orange , ylim=c(0,1))
# contact inhibition
lines(seq(0,72,6), pwyActivity[[2]], col= blue )
\end{verbatim}

\hypertarget{simulating-bulk-gene-expression-data}{%
\chapter{Simulating Bulk Gene Expression Data}\label{simulating-bulk-gene-expression-data}}

\hypertarget{simulating-microarray-data}{%
\section{Simulating Microarray Data}\label{simulating-microarray-data}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
params@RNAseq <- FALSE # generate microarray data
params@singleCell <- FALSE # generate bulk data
params@perError <- 0.1 # parameter for simulated noise

pwys <- c(pwyMitosis, pwyContactInhibition)
ge <- inSilicoGeneExpression(simple_mod, pwys, params)$expression
\end{verbatim}

\hypertarget{visualize-bulk-gene-expression-data}{%
\section{Visualize Bulk Gene Expression Data}\label{visualize-bulk-gene-expression-data}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ndx <- apply(ge, 1, var) == 0 # remove zero variance rows
gplots::heatmap.2(ge[!ndx,], 
    col =  greenred , scale= row ,
    trace= none , hclust=function(x) hclust(x,method =  complete ),
    distfun=function(x) as.dist((1-cor(t(x)))/2), 
    Colv=FALSE, dendrogram= row ,
    RowSideColors = ifelse(rownames(ge[!ndx,]) %in%
        mitosisGeneNames,  orange ,  blue ),
    labRow = FALSE, labCol = seq(0,72,6),
    main= Bulk Gene Expression from Simple Cell Simulation )
\end{verbatim}

\hypertarget{simulating-single-cell-gene-expression-data}{%
\chapter{Simulating Single Cell Gene Expression Data}\label{simulating-single-cell-gene-expression-data}}

\hypertarget{cell-type-pathways}{%
\section{Cell Type Pathways}\label{cell-type-pathways}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# gene names
B_genes <- paste( b. , letters[1:20], sep=  )
C_genes <- paste( c. , letters[1:20], sep=  )

# pathway behavior
pwy_B <- new( Pathway , genes=B_genes, expressionScale=
    function(model, cell, time) ifelse(getCellType(model, time, cell)==1, 1, 0))
pwy_C <- new( Pathway , genes=C_genes, expressionScale=
    function(model, cell, time) ifelse(getCellType(model, time, cell)==2, 1, 0))

# calibrate pathways
geneMeans <- 2 + rexp(length(c(B_genes, C_genes)), 1/20)
data <- t(pmax(sapply(geneMeans, rnorm, n=25, sd=2), 0))
rownames(data) <- c(B_genes, C_genes)
pwy_B <- calibratePathway(pwy_B, data)
pwy_C <- calibratePathway(pwy_C, data)
\end{verbatim}

\hypertarget{simulating-single-cell-rna-seq}{%
\section{Simulating Single Cell RNA-seq}\label{simulating-single-cell-rna-seq}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
params@RNAseq <- TRUE
params@singleCell <- TRUE
params@dropoutPresent <- TRUE
ge <- inSilicoGeneExpression(two_types_mod, c(pwy_B, pwy_C), params)$expression
\end{verbatim}

\hypertarget{visualize-single-cell-data}{%
\section{Visualize Single Cell Data}\label{visualize-single-cell-data}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cells <- unname(sapply(colnames(ge), function(x) strsplit(x, _ )[[1]][1]))
cells <- as.numeric(gsub( c ,   , cells))
type <- sapply(cells, getCellType, model=two_types_mod,
    time=two_types_mod@runTime)
type[type==1] <-  red 
type[type==2] <-  blue 

pca <- prcomp(ge, center=FALSE, scale.=FALSE)
plot(pca$rotation[,c(1,2)], col=type)
\end{verbatim}

\hypertarget{cancer-packages}{%
\chapter{Cancer Packages}\label{cancer-packages}}

\hypertarget{bcra}{%
\chapter{BCRA}\label{bcra}}

\url{https://cran.r-project.org/web/packages/BCRA/index.html}

\hypertarget{cgdsr}{%
\chapter{cgdsr}\label{cgdsr}}

cgdsr: R-Based API for Accessing the MSKCC Cancer Genomics Data Server (CGDS)

\url{https://cran.r-project.org/web/packages/cgdsr/index.html}

\hypertarget{tcgabiolinksgui}{%
\chapter{TCGAbiolinksGUI}\label{tcgabiolinksgui}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( TCGAbiolinksGUI , version =  3.8 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( TCGAbiolinksGUI )
\end{verbatim}

\url{https://bioconductor.org/packages/release/bioc/html/TCGAbiolinksGUI.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(TCGAbiolinksGUI)
TCGAbiolinksGUI()
\end{verbatim}

\hypertarget{rtcga}{%
\chapter{RTCGA}\label{rtcga}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( RTCGA , version =  3.8 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( RTCGA )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
RTCGA::infoTCGA()
\end{verbatim}

\hypertarget{cancersubtypes}{%
\chapter{CancerSubtypes}\label{cancersubtypes}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( CancerSubtypes , version =  3.8 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( CancerSubtypes )
\end{verbatim}

\hypertarget{cancermutationanalysis}{%
\chapter{CancerMutationAnalysis}\label{cancermutationanalysis}}

\hypertarget{cancerclass}{%
\chapter{cancerclass}\label{cancerclass}}

\hypertarget{cancer}{%
\chapter{canceR}\label{cancer}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( canceR , version =  3.8 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( canceR )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
canceR::canceR()
\end{verbatim}

\hypertarget{biocancer}{%
\chapter{bioCancer}\label{biocancer}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!requireNamespace( BiocManager , quietly = TRUE))
    install.packages( BiocManager )
BiocManager::install( bioCancer , version =  3.8 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
browseVignettes( bioCancer )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
bioCancer::bioCancer()
\end{verbatim}

\hypertarget{tcgaretriever}{%
\chapter{TCGAretriever}\label{tcgaretriever}}

TCGAretriever: Retrieve Genomic and Clinical Data from TCGA

\url{https://cran.r-project.org/web/packages/TCGAretriever/index.html}

\hypertarget{tcga2stat}{%
\chapter{TCGA2STAT}\label{tcga2stat}}

\url{https://cran.r-project.org/web/packages/TCGA2STAT/vignettes/TCGA2STAT.html}

\hypertarget{tciapathfinder}{%
\chapter{TCIApathfinder}\label{tciapathfinder}}

TCIApathfinder: Client for the Cancer Imaging Archive REST API

\url{https://cran.r-project.org/web/packages/TCIApathfinder/index.html}

\hypertarget{milc}{%
\chapter{MILC}\label{milc}}

MILC: MIcrosimulation Lung Cancer (MILC) model

\url{https://cran.r-project.org/web/packages/MILC/index.html}

\hypertarget{infiniumpurify}{%
\chapter{InfiniumPurify}\label{infiniumpurify}}

InfiniumPurify: Estimate and Account for Tumor Purity in Cancer Methylation Data Analysis

\url{https://cran.r-project.org/web/packages/InfiniumPurify/index.html}

\hypertarget{using-cloud-for-research}{%
\chapter{Using Cloud for Research}\label{using-cloud-for-research}}

\hypertarget{rclone}{%
\chapter{rclone}\label{rclone}}

\url{https://rclone.org/drive/}

\hypertarget{rmdrive}{%
\chapter{rmdrive}\label{rmdrive}}

\url{https://github.com/ekothe/rmdrive}

\hypertarget{my-r-codes-for-data-analysis-1}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-1}}

rstudioapi::selectDirectory()

xaringan:::inf\_mr()

\textbf{Load required packages}

\texttt{Load\ required\ packages}

\begin{itemize}
\tightlist
\item
  Load required packages
\end{itemize}

\begin{quote}
Gerekli paketleri y√ºkle
\end{quote}

\begin{verbatim}
{r  1, message=FALSE, warning=FALSE}
library(tidyverse)
\end{verbatim}

\hypertarget{tips}{%
\chapter{tips}\label{tips}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
my_string1 <-  3+4 
my_string2 <-  plot(cars) 
eval(parse(text = my_string1))
eval(parse(text = my_string2))
\end{verbatim}

\hypertarget{environment-memory}{%
\chapter{environment memory}\label{environment-memory}}

\url{http://r-statistics.co/R-Tutorial.html}

As you create new variables, by default they get store in what is called a global environment.

a \textless- 10
b \textless- 20
ls() \# list objects in global env
rm(a) \# delete the object `a'
rm(list = ls()) \# caution: delete all objects in .GlobalEnv
gc() \# free system memory

However if you choose, you can create a new environment and store them there.

rm(list=ls()) \# remove all objects in work space
env1 \textless- new.env() \# create a new environment
assign( a , 3, envir = env1) \# store a=3 inside env1
ls() \# returns objects in .GlobalEnv
ls(env1) \# returns objects in env1
get(`a', envir=env1) \# retrieve value from env1

sort(vec1) \# ascending sort
sort(vec1, decreasing = TRUE) \# Descending sort
Sorting can also be achieved using the order() function which returns the indices of elements in ascending order.

vec1{[}order(vec1){]} \# ascending sort
vec1{[}rev(order(vec1)){]} \# descending sort

seq(1, 10, by = 2) \# diff between adj elements is 2
seq(1, 10, length=25) \# length of the vector is 25
rep(1, 5) \# repeat 1, five times.
rep(1:3, 5) \# repeat 1:3, 5 times
rep(1:3, each=5) \# repeat 1 to 3, each 5 times.

subset(airquality, Day == 1, select = -Temp) \# select Day=1 and exclude `Temp'
airquality{[}which(airquality\$Day==1), -c(4){]} \# same as above

set.seed(100)
trainIndex \textless- sample(c(1:nrow(airquality)), size=nrow(airquality)*0.7, replace=F) \# get test sample indices
airquality{[}trainIndex, {]} \# training data
airquality{[}-trainIndex, {]} \# test data

if(checkConditionIfTrue) \{
\ldots.statements..
\ldots.statements..
\} else \{ \# place the `else' in same line as `\}'
\ldots.statements..
\ldots.statements..
\}

for(counterVar in c(1:n))\{
\ldots. statements..
\}

\hypertarget{my-r-codes-for-data-analysis-2}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-2}}

sub\# In this repository I am going to collect \texttt{R\ codes} for data analysis. Codes are from various resources and I try to give original link as much as possible.
author: \href{https://www.serdarbalci.com/}{Serdar Balcƒ±, MD, Pathologist}
date: `\texttt{\{r\ \#\ \ format(Sys.Date())}'

\hypertarget{compare-means-1}{%
\subsection{Compare Means}\label{compare-means-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
t.test(scabies$age[scabies$gender== male ],scabies$age[scabies$gender== female ])
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
test <- t.test(scabies$age[scabies$gender== male ],scabies$age[scabies$gender== female ])
psycho::analyze(test)
\end{verbatim}

\hypertarget{infer}{%
\chapter{infer}\label{infer}}

Randomization Examples using nycflights13 flights data

\url{https://cran.r-project.org/web/packages/infer/vignettes/flights_examples.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(nycflights13)
library(dplyr)
library(ggplot2)
library(stringr)
library(infer)
set.seed(2017)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fli_small <- flights %>% 
  na.omit() %>%
  sample_n(size = 500) %>% 
  mutate(season = case_when(
    month %in% c(10:12, 1:3) ~  winter ,
    month %in% c(4:9) ~  summer 
  )) %>% 
  mutate(day_hour = case_when(
    between(hour, 1, 12) ~  morning ,
    between(hour, 13, 24) ~  not morning 
  )) %>% 
  select(arr_delay, dep_delay, season, 
         day_hour, origin, carrier)
fli_small
\end{verbatim}

Hypothesis tests
One numerical variable (mean)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x_bar <- fli_small %>%
  summarize(mean(dep_delay)) %>%
  pull()
x_bar
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
null_distn <- fli_small %>%
  specify(response = dep_delay) %>%
  hypothesize(null =  point , mu = 10) %>%
  generate(reps = 1000, type =  bootstrap ) %>%
  calculate(stat =  mean )
null_distn
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(data = null_distn, mapping = aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = x_bar, color =  red )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
null_distn %>%
  summarize(p_value = mean(stat >= x_bar) * 2)
\end{verbatim}

One numerical variable (median)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x_tilde <- fli_small %>%
  summarize(median(dep_delay)) %>%
  pull()
x_tilde
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
null_distn <- fli_small %>%
  specify(response = dep_delay) %>%
  hypothesize(null =  point , med = -1) %>% 
  generate(reps = 1000, type =  bootstrap ) %>% 
  calculate(stat =  median )
null_distn
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(null_distn, aes(x = stat)) +
  geom_bar() +
  geom_vline(xintercept = x_tilde, color =  red )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
null_distn %>%
  summarize(p_value = mean(stat <= x_tilde) * 2)
\end{verbatim}

One categorical (one proportion)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
p_hat <- fli_small %>%
  summarize(mean(day_hour ==  morning )) %>%
  pull()
p_hat
\end{verbatim}

\begin{verbatim}
null_distn <- fli_small %>%
  specify(response = day_hour, success =  morning ) %>%
  hypothesize(null =  point , p = .5) %>%
  generate(reps = 1000, type =  simulate ) %>%
  calculate(stat =  prop )
ggplot(null_distn, aes(x = stat)) +
  geom_bar() +
  geom_vline(xintercept = p_hat, color =  red )

null_distn %>%
  summarize(p_value = mean(stat <= p_hat) * 2)
p_value
0.132
Logical variables will be coerced to factors:

null_distn <- fli_small %>%
  mutate(day_hour_logical = (day_hour ==  morning )) %>%
  specify(response = day_hour_logical, success =  TRUE ) %>%
  hypothesize(null =  point , p = .5) %>%
  generate(reps = 1000, type =  simulate ) %>%
  calculate(stat =  prop )
Two categorical (2 level) variables
d_hat <- fli_small %>%
  group_by(season) %>%
  summarize(prop = mean(day_hour ==  morning )) %>%
  summarize(diff(prop)) %>%
  pull()
null_distn <- fli_small %>%
  specify(day_hour ~ season, success =  morning ) %>%
  hypothesize(null =  independence ) %>% 
  generate(reps = 1000, type =  permute ) %>% 
  calculate(stat =  diff in props , order = c( winter ,  summer ))
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = d_hat, color =  red )

null_distn %>%
  summarize(p_value = mean(stat <= d_hat) * 2) %>%
  pull()
## [1] 0.758
One categorical (>2 level) - GoF
Chisq_hat <- fli_small %>%
  specify(response = origin) %>%
  hypothesize(null =  point , 
              p = c( EWR  = .33,  JFK  = .33,  LGA  = .34)) %>% 
  calculate(stat =  Chisq )
null_distn <- fli_small %>%
  specify(response = origin) %>%
  hypothesize(null =  point , 
              p = c( EWR  = .33,  JFK  = .33,  LGA  = .34)) %>% 
  generate(reps = 1000, type =  simulate ) %>% 
  calculate(stat =  Chisq )
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = pull(Chisq_hat), color =  red )

null_distn %>%
  summarize(p_value = mean(stat >= pull(Chisq_hat))) %>%
  pull()
## [1] 0.002
Two categorical (>2 level) variables
Chisq_hat <- fli_small %>%
  chisq_stat(formula = day_hour ~ origin)
null_distn <- fli_small %>%
  specify(day_hour ~ origin, success =  morning ) %>%
  hypothesize(null =  independence ) %>% 
  generate(reps = 1000, type =  permute ) %>% 
  calculate(stat =  Chisq )
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = pull(Chisq_hat), color =  red )

null_distn %>%
  summarize(p_value = mean(stat >= pull(Chisq_hat))) %>%
  pull()
## [1] 0.017
One numerical variable, one categorical (2 levels) (diff in means)
d_hat <- fli_small %>% 
  group_by(season) %>% 
  summarize(mean_stat = mean(dep_delay)) %>% 
  # Since summer - winter
  summarize(-diff(mean_stat)) %>% 
  pull()
null_distn <- fli_small %>%
  specify(dep_delay ~ season) %>% # alt: response = dep_delay, 
  # explanatory = season
  hypothesize(null =  independence ) %>%
  generate(reps = 1000, type =  permute ) %>%
  calculate(stat =  diff in means , order = c( summer ,  winter ))
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = d_hat, color =  red )

null_distn %>%
  summarize(p_value = mean(stat <= d_hat) * 2) %>%
  pull()
## [1] 1.574
One numerical variable, one categorical (2 levels) (diff in medians)
d_hat <- fli_small %>% 
  group_by(season) %>% 
  summarize(median_stat = median(dep_delay)) %>% 
  # Since summer - winter
  summarize(-diff(median_stat)) %>% 
  pull()
null_distn <- fli_small %>%
  specify(dep_delay ~ season) %>% # alt: response = dep_delay, 
  # explanatory = season
  hypothesize(null =  independence ) %>%
  generate(reps = 1000, type =  permute ) %>%
  calculate(stat =  diff in medians , order = c( summer ,  winter ))
ggplot(null_distn, aes(x = stat)) +
  geom_bar() +
  geom_vline(xintercept = d_hat, color =  red )

null_distn %>%
  summarize(p_value = mean(stat >= d_hat) * 2) %>%
  pull()
## [1] 0.068
One numerical, one categorical (>2 levels) - ANOVA
F_hat <- anova(
               aov(formula = arr_delay ~ origin, data = fli_small)
               )$`F value`[1]
null_distn <- fli_small %>%
   specify(arr_delay ~ origin) %>% # alt: response = arr_delay, 
   # explanatory = origin
   hypothesize(null =  independence ) %>%
   generate(reps = 1000, type =  permute ) %>%
   calculate(stat =  F )
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = F_hat, color =  red )  

null_distn %>% 
  summarize(p_value = mean(stat >= F_hat)) %>%
  pull()
## [1] 0.351
Two numerical vars - SLR
slope_hat <- lm(arr_delay ~ dep_delay, data = fli_small) %>% 
  broom::tidy() %>% 
  filter(term ==  dep_delay ) %>% 
  pull(estimate)
null_distn <- fli_small %>%
   specify(arr_delay ~ dep_delay) %>% 
   hypothesize(null =  independence ) %>%
   generate(reps = 1000, type =  permute ) %>%
   calculate(stat =  slope )
ggplot(null_distn, aes(x = stat)) +
  geom_density() +
  geom_vline(xintercept = slope_hat, color =  red )  

null_distn %>% 
  summarize(p_value = mean(stat >= slope_hat) * 2) %>%
  pull()
## [1] 0
Confidence intervals
One numerical (one mean)
x_bar <- fli_small %>%
   summarize(mean(arr_delay)) %>%
   pull()
boot <- fli_small %>%
   specify(response = arr_delay) %>%
   generate(reps = 1000, type =  bootstrap ) %>%
   calculate(stat =  mean ) %>%
   pull()
c(lower = x_bar - 2 * sd(boot),
  upper = x_bar + 2 * sd(boot))
##    lower    upper 
## 1.122209 8.021791
One categorical (one proportion)
p_hat <- fli_small %>%
 summarize(mean(day_hour ==  morning )) %>%
 pull()
boot <- fli_small %>%
 specify(response = day_hour, success =  morning ) %>%
 generate(reps = 1000, type =  bootstrap ) %>%
 calculate(stat =  prop ) %>%
 pull()
c(lower = p_hat - 2 * sd(boot),
 upper = p_hat + 2 * sd(boot))
##     lower     upper 
## 0.4194756 0.5125244
One numerical variable, one categorical (2 levels) (diff in means)
d_hat <- fli_small %>% 
  group_by(season) %>% 
  summarize(mean_stat = mean(arr_delay)) %>% 
  # Since summer - winter
  summarize(-diff(mean_stat)) %>% 
  pull()
boot <- fli_small %>%
   specify(arr_delay ~ season) %>%
   generate(reps = 1000, type =  bootstrap ) %>%
   calculate(stat =  diff in means , order = c( summer ,  winter )) %>% 
   pull()
c(lower = d_hat - 2 * sd(boot), 
  upper = d_hat + 2 * sd(boot))
##     lower     upper 
## -7.704370  6.213971
Two categorical variables (diff in proportions)
d_hat <- fli_small %>%
  group_by(season) %>%
  summarize(prop = mean(day_hour ==  morning )) %>%
  # Since summer - winter
  summarize(-diff(prop)) %>%
  pull()
boot <- fli_small %>%
  specify(day_hour ~ season, success =  morning ) %>%
  generate(reps = 1000, type =  bootstrap ) %>% 
  calculate(stat =  diff in props , order = c( summer ,  winter )) %>%
  pull()
c(lower = d_hat - 2 * sd(boot), 
  upper = d_hat + 2 * sd(boot))
##       lower       upper 
## -0.07149487  0.11258550
Two numerical vars - SLR
slope_hat <- lm(arr_delay ~ dep_delay, data = fli_small) %>% 
  broom::tidy() %>% 
  filter(term ==  dep_delay ) %>% 
  pull(estimate)
boot <- fli_small %>%
   specify(arr_delay ~ dep_delay) %>% 
   generate(reps = 1000, type =  bootstrap ) %>%
   calculate(stat =  slope ) %>% 
   pull()
c(lower = slope_hat - 2 * sd(boot), 
  upper = slope_hat + 2 * sd(boot))   
##     lower     upper 
## 0.9657595 1.0681384






Examples using mtcars data


https://cran.r-project.org/web/packages/infer/vignettes/mtcars_examples.html


Examples using mtcars data
Chester Ismay and Andrew Bray
2018-01-05
Note: The type argument in generate() is automatically filled based on the entries for specify() and hypothesize(). It can be removed throughout the examples that follow. It is left in to reiterate the type of generation process being performed.

Data preparation
library(infer)
library(dplyr)
mtcars <- mtcars %>%
  mutate(cyl = factor(cyl),
         vs = factor(vs),
         am = factor(am),
         gear = factor(gear),
         carb = factor(carb))
# For reproducibility         
set.seed(2018)         
One numerical variable (mean)

mtcars %>%
  specify(response = mpg) %>% # formula alt: mpg ~ NULL
  hypothesize(null =  point , mu = 25) %>% 
  generate(reps = 100, type =  bootstrap ) %>% 
  calculate(stat =  mean )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  26.6
##  2         2  25.1
##  3         3  25.2
##  4         4  24.7
##  5         5  24.6
##  6         6  25.8
##  7         7  24.7
##  8         8  25.6
##  9         9  25.0
## 10        10  25.1
## # ... with 90 more rows
One numerical variable (median)

mtcars %>%
  specify(response = mpg) %>% # formula alt: mpg ~ NULL
  hypothesize(null =  point , med = 26) %>% 
  generate(reps = 100, type =  bootstrap ) %>% 
  calculate(stat =  median )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  28.2
##  2         2  27.2
##  3         3  26.2
##  4         4  26  
##  5         5  26.5
##  6         6  24.5
##  7         7  26  
##  8         8  28.2
##  9         9  28.2
## 10        10  23.2
## # ... with 90 more rows
One categorical (2 level) variable

mtcars %>%
  specify(response = am, success =  1 ) %>% # formula alt: am ~ NULL
  hypothesize(null =  point , p = .25) %>% 
  generate(reps = 100, type =  simulate ) %>% 
  calculate(stat =  prop )
## # A tibble: 100 x 2
##    replicate   stat
##    <fct>      <dbl>
##  1 1         0.375 
##  2 2         0.0625
##  3 3         0.125 
##  4 4         0.25  
##  5 5         0.188 
##  6 6         0.406 
##  7 7         0.219 
##  8 8         0.375 
##  9 9         0.344 
## 10 10        0.188 
## # ... with 90 more rows
Two categorical (2 level) variables

mtcars %>%
  specify(am ~ vs, success =  1 ) %>% # alt: response = am, explanatory = vs
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  diff in props , order = c( 0 ,  1 ))
## # A tibble: 100 x 2
##    replicate    stat
##        <int>   <dbl>
##  1         1 -0.421 
##  2         2 -0.167 
##  3         3 -0.421 
##  4         4 -0.0397
##  5         5  0.0873
##  6         6 -0.0397
##  7         7 -0.0397
##  8         8 -0.0397
##  9         9  0.0873
## 10        10 -0.167 
## # ... with 90 more rows
One categorical (>2 level) - GoF

mtcars %>%
  specify(cyl ~ NULL) %>% # alt: response = cyl
  hypothesize(null =  point , p = c( 4  = .5,  6  = .25,  8  = .25)) %>%
  generate(reps = 100, type =  simulate ) %>%
  calculate(stat =  Chisq )
## # A tibble: 100 x 2
##    replicate  stat
##    <fct>     <dbl>
##  1 1         6.75 
##  2 2         1.69 
##  3 3         3.19 
##  4 4         1.69 
##  5 5         6    
##  6 6         2.69 
##  7 7         4.75 
##  8 8         0.75 
##  9 9         0.688
## 10 10        3.69 
## # ... with 90 more rows
Two categorical (>2 level) variables

mtcars %>%
  specify(cyl ~ am) %>% # alt: response = cyl, explanatory = am
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  Chisq )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1 1.34 
##  2         2 1.63 
##  3         3 1.63 
##  4         4 2.63 
##  5         5 3.90 
##  6         6 1.74 
##  7         7 0.126
##  8         8 1.74 
##  9         9 1.34 
## 10        10 1.34 
## # ... with 90 more rows
One numerical variable one categorical (2 levels) (diff in means)

mtcars %>%
  specify(mpg ~ am) %>% # alt: response = mpg, explanatory = am
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  diff in means , order = c( 0 ,  1 ))
## # A tibble: 100 x 2
##    replicate   stat
##        <int>  <dbl>
##  1         1 -1.10 
##  2         2  0.217
##  3         3 -1.08 
##  4         4 -3.80 
##  5         5  3.08 
##  6         6  0.489
##  7         7  2.34 
##  8         8  4.10 
##  9         9 -1.86 
## 10        10 -0.210
## # ... with 90 more rows
One numerical variable one categorical (2 levels) (diff in medians)

mtcars %>%
  specify(mpg ~ am) %>% # alt: response = mpg, explanatory = am
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  diff in medians , order = c( 0 ,  1 ))
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  0.5 
##  2         2 -1.10
##  3         3  5.20
##  4         4  1.8 
##  5         5  0.5 
##  6         6  3.3 
##  7         7 -1.60
##  8         8 -2.3 
##  9         9  2.90
## 10        10 -0.5 
## # ... with 90 more rows
One numerical one categorical (>2 levels) - ANOVA

mtcars %>%
  specify(mpg ~ cyl) %>% # alt: response = mpg, explanatory = cyl
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  F )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1 1.43 
##  2         2 1.65 
##  3         3 0.318
##  4         4 0.393
##  5         5 1.05 
##  6         6 0.826
##  7         7 1.32 
##  8         8 0.833
##  9         9 0.144
## 10        10 0.365
## # ... with 90 more rows
Two numerical vars - SLR

mtcars %>%
  specify(mpg ~ hp) %>% # alt: response = mpg, explanatory = cyl
  hypothesize(null =  independence ) %>%
  generate(reps = 100, type =  permute ) %>%
  calculate(stat =  slope )
## # A tibble: 100 x 2
##    replicate     stat
##        <int>    <dbl>
##  1         1 -0.0151 
##  2         2  0.00224
##  3         3 -0.0120 
##  4         4  0.00292
##  5         5  0.0203 
##  6         6 -0.00730
##  7         7 -0.0246 
##  8         8  0.00555
##  9         9  0.0109 
## 10        10  0.0176 
## # ... with 90 more rows
One numerical variable (standard deviation)

Not currently implemented

mtcars %>%
  specify(response = mpg) %>% # formula alt: mpg ~ NULL
  hypothesize(null =  point , sigma = 5) %>% 
  generate(reps = 100, type =  bootstrap ) %>% 
  calculate(stat =  sd )
Confidence intervals
One numerical (one mean)

mtcars %>%
  specify(response = mpg) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  mean )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  19.6
##  2         2  21.8
##  3         3  18.7
##  4         4  19.2
##  5         5  21.6
##  6         6  19.9
##  7         7  20.7
##  8         8  19.3
##  9         9  21.2
## 10        10  21.3
## # ... with 90 more rows
One numerical (one median)

mtcars %>%
  specify(response = mpg) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  median )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  19.2
##  2         2  20.1
##  3         3  21  
##  4         4  17.8
##  5         5  20.1
##  6         6  19.2
##  7         7  18.4
##  8         8  19.2
##  9         9  19.2
## 10        10  18.0
## # ... with 90 more rows
One numerical (standard deviation)

mtcars %>%
  specify(response = mpg) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  sd )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1  5.28
##  2         2  6.74
##  3         3  5.29
##  4         4  5.41
##  5         5  5.56
##  6         6  5.65
##  7         7  6.17
##  8         8  6.40
##  9         9  6.31
## 10        10  6.11
## # ... with 90 more rows
One categorical (one proportion)

mtcars %>%
  specify(response = am, success =  1 ) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  prop )
## # A tibble: 100 x 2
##    replicate  stat
##        <int> <dbl>
##  1         1 0.375
##  2         2 0.406
##  3         3 0.406
##  4         4 0.312
##  5         5 0.312
##  6         6 0.469
##  7         7 0.438
##  8         8 0.281
##  9         9 0.438
## 10        10 0.5  
## # ... with 90 more rows
One numerical variable one categorical (2 levels) (diff in means)

mtcars %>%
  specify(mpg ~ am) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  diff in means , order = c( 0 ,  1 ))
## # A tibble: 100 x 2
##    replicate   stat
##        <int>  <dbl>
##  1         1  -9.38
##  2         2  -5.11
##  3         3  -4.88
##  4         4  -5.39
##  5         5  -9.19
##  6         6  -7.20
##  7         7  -5.34
##  8         8  -3.20
##  9         9  -5.95
## 10        10 -11.0 
## # ... with 90 more rows
Two categorical variables (diff in proportions)

mtcars %>%
  specify(am ~ vs, success =  1 ) %>%
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  diff in props , order = c( 0 ,  1 ))
## # A tibble: 100 x 2
##    replicate   stat
##        <int>  <dbl>
##  1         1 -0.352
##  2         2 -0.15 
##  3         3 -0.294
##  4         4 -0.254
##  5         5 -0.438
##  6         6 -0.126
##  7         7 -0.188
##  8         8  0.167
##  9         9 -0.143
## 10        10 -0.5  
## # ... with 90 more rows
Two numerical vars - SLR

mtcars %>%
  specify(mpg ~ hp) %>% 
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  slope )
## # A tibble: 100 x 2
##    replicate    stat
##        <int>   <dbl>
##  1         1 -0.0850
##  2         2 -0.0512
##  3         3 -0.0736
##  4         4 -0.0569
##  5         5 -0.0930
##  6         6 -0.0659
##  7         7 -0.0710
##  8         8 -0.0767
##  9         9 -0.0556
## 10        10 -0.0627
## # ... with 90 more rows
Two numerical vars - correlation

mtcars %>%
  specify(mpg ~ hp) %>% 
  generate(reps = 100, type =  bootstrap ) %>%
  calculate(stat =  correlation )
## # A tibble: 100 x 2
##    replicate   stat
##        <int>  <dbl>
##  1         1 -0.821
##  2         2 -0.812
##  3         3 -0.802
##  4         4 -0.723
##  5         5 -0.885
##  6         6 -0.777
##  7         7 -0.752
##  8         8 -0.758
##  9         9 -0.826
## 10        10 -0.779
## # ... with 90 more rows




Two sample t test example using nycflights13 flights data

https://cran.r-project.org/web/packages/infer/vignettes/two_sample_t.html


Two sample t test example using nycflights13 flights data
Chester Ismay
2018-11-15
Note: The type argument in generate() is automatically filled based on the entries for specify() and hypothesize(). It can be removed throughout the examples that follow. It is left in to reiterate the type of generation process being performed.

Data preparation
library(nycflights13)
library(dplyr)
library(stringr)
library(infer)
set.seed(2017)
fli_small <- flights %>% 
  sample_n(size = 500) %>% 
  mutate(half_year = case_when(
    between(month, 1, 6) ~  h1 ,
    between(month, 7, 12) ~  h2 
  )) %>% 
  mutate(day_hour = case_when(
    between(hour, 1, 12) ~  morning ,
    between(hour, 13, 24) ~  not morning 
  )) %>% 
  select(arr_delay, dep_delay, half_year, 
         day_hour, origin, carrier)
Two numeric - arr_delay, dep_delay
Two categories
half_year ( h1 ,  h2 ),
day_hour ( morning ,  not morning )
Three categories - origin ( EWR ,  JFK ,  LGA )
Sixteen categories - carrier
One numerical variable, one categorical (2 levels)
Calculate observed statistic
The recommended approach is to use specify() %>% calculate():

obs_t <- fli_small %>%
  specify(arr_delay ~ half_year) %>%
  calculate(stat =  t , order = c( h1 ,  h2 ))
## Warning: Removed 15 rows containing missing values.
The observed t statistic is
stat
0.8685
.

Or using t_test in infer

obs_t <- fli_small %>% 
  t_test(formula = arr_delay ~ half_year, alternative =  two_sided ,
         order = c( h1 ,  h2 )) %>% 
  dplyr::pull(statistic)
The observed t statistic is 0.8685.

Or using another shortcut function in infer:

obs_t <- fli_small %>% 
  t_stat(formula = arr_delay ~ half_year, order = c( h1 ,  h2 ))
The observed t statistic is
statistic
0.8685
.

Randomization approach to t-statistic
t_null_perm <- fli_small %>%
  # alt: response = arr_delay, explanatory = half_year
  specify(arr_delay ~ half_year) %>%
  hypothesize(null =  independence ) %>%
  generate(reps = 1000, type =  permute ) %>%
  calculate(stat =  t , order = c( h1 ,  h2 ))
## Warning: Removed 15 rows containing missing values.
visualize(t_null_perm) +
  shade_p_value(obs_stat = obs_t, direction =  two_sided )

Calculate the randomization-based p-value
t_null_perm %>% 
  get_p_value(obs_stat = obs_t, direction =  two_sided )
p_value
0.408
Theoretical distribution
t_null_theor <- fli_small %>%
  # alt: response = arr_delay, explanatory = half_year
  specify(arr_delay ~ half_year) %>%
  hypothesize(null =  independence ) %>%
  # generate() ## Not used for theoretical
  calculate(stat =  t , order = c( h1 ,  h2 ))
## Warning: Removed 15 rows containing missing values.
visualize(t_null_theor, method =  theoretical ) +
  shade_p_value(obs_stat = obs_t, direction =  two_sided )
## Warning: Check to make sure the conditions have been met for the
## theoretical method. {infer} currently does not check these for you.

Overlay appropriate t distribution on top of permuted t-statistics
visualize(t_null_perm, method =  both ) +
  shade_p_value(obs_stat = obs_t, direction =  two_sided )
## Warning: Check to make sure the conditions have been met for the
## theoretical method. {infer} currently does not check these for you.

Compute theoretical p-value
fli_small %>% 
  t_test(formula = arr_delay ~ half_year,
         alternative =  two_sided ,
         order = c( h1 ,  h2 )) %>% 
  dplyr::pull(p_value)
## [1] 0.3855
\end{verbatim}

\hypertarget{compare-proportions-1}{%
\chapter{Compare Proportions}\label{compare-proportions-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
prop.test(numerator,denominator)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(impetigo = scabies$impetigo_active, scabies = scabies$scabies_infestation)
# dependent ~ independent
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#See that because 'no' is the 'base' level the table is laid out
#               No Disease      Has Disease

# Not-exposed

# Exposed

#This is dependent on how your data is coded so you need to check this before using epi.2by2
#If the table is laid out correctly then you can input straight into epi.2by2, otherwise you #need to recode or re-order the variables so that the table will be laid out correctly

#epi.2by2 wants the data with the exposed/disease group in top right corner
#So we just tell R to order the variables differently when we draw the table

epiR::epi.2by2(table(relevel(scabies$scabies_infestation, yes ), relevel(scabies$impetigo_active, yes )))
\end{verbatim}

\hypertarget{contingency-tables-1}{%
\chapter{contingency tables}\label{contingency-tables-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
?chisq.test()
\end{verbatim}

\begin{verbatim}
chisq.test {stats}  R Documentation
Pearson's Chi-squared Test for Count Data
Description
chisq.test performs chi-squared contingency table tests and goodness-of-fit tests.

Usage
chisq.test(x, y = NULL, correct = TRUE,
           p = rep(1/length(x), length(x)), rescale.p = FALSE,
           simulate.p.value = FALSE, B = 2000)
Arguments
x   
a numeric vector or matrix. x and y can also both be factors.

y   
a numeric vector; ignored if x is a matrix. If x is a factor, y should be a factor of the same length.

correct 
a logical indicating whether to apply continuity correction when computing the test statistic for 2 by 2 tables: one half is subtracted from all |O - E| differences; however, the correction will not be bigger than the differences themselves. No correction is done if simulate.p.value = TRUE.

p   
a vector of probabilities of the same length of x. An error is given if any entry of p is negative.

rescale.p   
a logical scalar; if TRUE then p is rescaled (if necessary) to sum to 1. If rescale.p is FALSE, and p does not sum to 1, an error is given.

simulate.p.value    
a logical indicating whether to compute p-values by Monte Carlo simulation.

B   
an integer specifying the number of replicates used in the Monte Carlo test.

Details
If x is a matrix with one row or column, or if x is a vector and y is not given, then a goodness-of-fit test is performed (x is treated as a one-dimensional contingency table). The entries of x must be non-negative integers. In this case, the hypothesis tested is whether the population probabilities equal those in p, or are all equal if p is not given.

If x is a matrix with at least two rows and columns, it is taken as a two-dimensional contingency table: the entries of x must be non-negative integers. Otherwise, x and y must be vectors or factors of the same length; cases with missing values are removed, the objects are coerced to factors, and the contingency table is computed from these. Then Pearson's chi-squared test is performed of the null hypothesis that the joint distribution of the cell counts in a 2-dimensional contingency table is the product of the row and column marginals.

If simulate.p.value is FALSE, the p-value is computed from the asymptotic chi-squared distribution of the test statistic; continuity correction is only used in the 2-by-2 case (if correct is TRUE, the default). Otherwise the p-value is computed for a Monte Carlo test (Hope, 1968) with B replicates.

In the contingency table case simulation is done by random sampling from the set of all contingency tables with given marginals, and works only if the marginals are strictly positive. Continuity correction is never used, and the statistic is quoted without it. Note that this is not the usual sampling situation assumed for the chi-squared test but rather that for Fisher's exact test.

In the goodness-of-fit case simulation is done by random sampling from the discrete distribution specified by p, each sample being of size n = sum(x). This simulation is done in R and may be slow.

Value
A list with class  htest  containing the following components:

statistic   
the value the chi-squared test statistic.

parameter   
the degrees of freedom of the approximate chi-squared distribution of the test statistic, NA if the p-value is computed by Monte Carlo simulation.

p.value 
the p-value for the test.

method  
a character string indicating the type of test performed, and whether Monte Carlo simulation or continuity correction was used.

data.name   
a character string giving the name(s) of the data.

observed    
the observed counts.

expected    
the expected counts under the null hypothesis.

residuals   
the Pearson residuals, (observed - expected) / sqrt(expected).

stdres  
standardized residuals, (observed - expected) / sqrt(V), where V is the residual cell variance (Agresti, 2007, section 2.4.5 for the case where x is a matrix, n * p * (1 - p) otherwise).

Source
The code for Monte Carlo simulation is a C translation of the Fortran algorithm of Patefield (1981).

References
Hope, A. C. A. (1968). A simplified Monte Carlo significance test procedure. Journal of the Royal Statistical Society Series B, 30, 582‚Äì598. http://www.jstor.org/stable/2984263.

Patefield, W. M. (1981). Algorithm AS 159: An efficient method of generating r x c tables with given row and column totals. Applied Statistics, 30, 91‚Äì97. doi: 10.2307/2346669.

Agresti, A. (2007). An Introduction to Categorical Data Analysis, 2nd ed. New York: John Wiley & Sons. Page 38.

See Also
For goodness-of-fit testing, notably of continuous distributions, ks.test.

Examples

## From Agresti(2007) p.39
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c( F ,  M ),
                    party = c( Democrat , Independent ,  Republican ))
(Xsq <- chisq.test(M))  # Prints test summary
Xsq$observed   # observed counts (same as M)
Xsq$expected   # expected counts under the null
Xsq$residuals  # Pearson residuals
Xsq$stdres     # standardized residuals


## Effect of simulating p-values
x <- matrix(c(12, 5, 7, 7), ncol = 2)
chisq.test(x)$p.value           # 0.4233
chisq.test(x, simulate.p.value = TRUE, B = 10000)$p.value
                                # around 0.29!

## Testing for population probabilities
## Case A. Tabulated data
x <- c(A = 20, B = 15, C = 25)
chisq.test(x)
chisq.test(as.table(x))             # the same
x <- c(89,37,30,28,2)
p <- c(40,20,20,15,5)
try(
chisq.test(x, p = p)                # gives an error
)
chisq.test(x, p = p, rescale.p = TRUE)
                                # works
p <- c(0.40,0.20,0.20,0.19,0.01)
                                # Expected count in category 5
                                # is 1.86 < 5 ==> chi square approx.
chisq.test(x, p = p)            #               maybe doubtful, but is ok!
chisq.test(x, p = p, simulate.p.value = TRUE)

## Case B. Raw data
x <- trunc(5 * runif(100))
chisq.test(table(x))            # NOT 'chisq.test(x)'!
[Package stats version 3.5.1 Index]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
observed_table <- matrix(c(35, 15, 50, 10, 30, 60), nrow = 2, ncol = 3, byrow = T)
rownames(observed_table) <- c('Female', 'Male')
colnames(observed_table) <- c('Archery', 'Boxing', 'Cycling')
observed_table
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
X <- chisq.test(observed_table)
X
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
X$expected
\end{verbatim}

\hypertarget{infer-1}{%
\chapter{infer}\label{infer-1}}

Chi-squared test example using nycflights13 flights data\\
\url{https://cran.r-project.org/web/packages/infer/vignettes/chisq_test.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(nycflights13)
library(dplyr)
library(ggplot2)
library(stringr)
library(infer)
set.seed(2017)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fli_small <- flights %>% 
  na.omit() %>% 
  sample_n(size = 500) %>% 
  mutate(season = case_when(
    month %in% c(10:12, 1:3) ~  winter ,
    month %in% c(4:9) ~  summer 
  )) %>% 
  mutate(day_hour = case_when(
    between(hour, 1, 12) ~  morning ,
    between(hour, 13, 24) ~  not morning 
  )) %>% 
  select(arr_delay, dep_delay, season, 
         day_hour, origin, carrier)

fli_small
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
obs_chisq <- fli_small %>%
  specify(origin ~ season) %>% # alt: response = origin, explanatory = season
  calculate(stat =  Chisq )

obs_chisq
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
obs_chisq <- fli_small %>% 
  chisq_test(formula = origin ~ season) %>% 
  dplyr::select(statistic)
obs_chisq
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
obs_chisq <- fli_small %>% 
  chisq_stat(formula = origin ~ season)
obs_chisq
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
chisq_null_perm <- fli_small %>%
  specify(origin ~ season) %>% # alt: response = origin, explanatory = season
  hypothesize(null =  independence ) %>%
  generate(reps = 1000, type =  permute ) %>%
  calculate(stat =  Chisq )

visualize(chisq_null_perm) +
  shade_p_value(obs_stat = obs_chisq, direction =  greater )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
chisq_null_perm %>% 
  get_p_value(obs_stat = obs_chisq, direction =  greater )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
chisq_null_theor <- fli_small %>%
  specify(origin ~ season) %>% 
  hypothesize(null =  independence ) %>%
  # generate() ## Not used for theoretical
  calculate(stat =  Chisq )
chisq_null_theor
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
visualize(chisq_null_theor, method =  theoretical ) +
  shade_p_value(obs_stat = obs_chisq, direction =  right )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
visualize(chisq_null_perm, method =  both ) +
  shade_p_value(obs_stat = obs_chisq, direction =  right )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fli_small %>% 
  chisq_test(formula = origin ~ season) %>% 
  dplyr::pull(p_value)
\end{verbatim}

\hypertarget{correlations}{%
\chapter{Correlations}\label{correlations}}

\hypertarget{comparisons-between-correlations}{%
\chapter{comparisons between correlations}\label{comparisons-between-correlations}}

\url{http://comparingcorrelations.org/}

\hypertarget{exploring-correlations-in-r-with-corrr}{%
\chapter{Exploring correlations in R with corrr}\label{exploring-correlations-in-r-with-corrr}}

\url{https://drsimonj.svbtle.com/exploring-correlations-in-r-with-corrr}

\hypertarget{d3rain}{%
\chapter{d3rain}\label{d3rain}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(dplyr)
library(d3rain)

armed_levels <- rev(c('Unarmed', 'Knife', 'Non-lethal firearm', 'Firearm'))
pk <- fivethirtyeight::police_killings %>% 
  mutate(armed = recode(armed, No =  Unarmed )) %>% 
  mutate(armed = factor(armed, levels = armed_levels)) %>% 
  filter(armed %in% armed_levels,
         !is.na(age))
pk %>% 
  arrange(age) %>% 
  d3rain(age, armed, toolTip = age, title =  2015 Police Killings by Age, Armed Status ) %>% 
  drip_settings(dripSequence = 'iterate',
                ease = 'linear',
                jitterWidth = 25,
                dripSpeed = 500,
                dripFill = 'firebrick',
                iterationSpeedX = 20) %>% 
  chart_settings(fontFamily = 'times',
                 yAxisTickLocation = 'left')  
\end{verbatim}

\hypertarget{data-list-1}{%
\chapter{Data List}\label{data-list-1}}

\begin{itemize}
\tightlist
\item
  Learning Clinical Epidemiology with R
\end{itemize}

\url{http://datacompass.lshtm.ac.uk/599/}

\begin{itemize}
\tightlist
\item
  ISLR
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(package =  ISLR )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  acs
\end{itemize}

Download, Manipulate, and Present American Community Survey and Decennial

Data from the US Census

\url{https://cran.r-project.org/web/packages/acs/index.html}

\begin{itemize}
\tightlist
\item
  eurostat
\end{itemize}

Tools for Eurostat Open Data

\url{https://cran.r-project.org/web/packages/eurostat/index.html}

\begin{itemize}
\tightlist
\item
  Rilostat
\end{itemize}

\url{https://github.com/ilostat/Rilostat}

\begin{itemize}
\tightlist
\item
  OECD
\end{itemize}

\url{https://cran.r-project.org/web/packages/OECD/vignettes/oecd_vignette_main.pdf}

\begin{itemize}
\tightlist
\item
  gapminder
\end{itemize}

Factfulness: Building Gapminder Income Mountains

\url{http://staff.math.su.se/hoehle/blog/2018/07/02/factfulness.html}

\begin{itemize}
\item
  nycflights13
\item
  fivethirtyeight
\item
  projects
\end{itemize}

\url{https://www.analyticsvidhya.com/blog/2014/11/data-science-projects-learn/}

\begin{itemize}
\tightlist
\item
  Miscellaneous Datasets
\end{itemize}

\url{http://users.stat.ufl.edu/~winner/datasets.html}

\begin{itemize}
\tightlist
\item
  datasets
\end{itemize}

\url{https://www.rdocumentation.org/packages/datasets/versions/3.5.1}

\hypertarget{data-science-live-book}{%
\chapter{Data Science Live Book}\label{data-science-live-book}}

\url{https://livebook.datascienceheroes.com/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Loading funModeling!
library(funModeling)
library(dplyr)
data(heart_disease)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Profiling the data input
df_status(heart_disease)
\end{verbatim}

\hypertarget{data.table-package}{%
\chapter{data.table package}\label{data.table-package}}

\hypertarget{rdatatable}{%
\chapter{Rdatatable}\label{rdatatable}}

\url{https://github.com/Rdatatable}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(data.table)
\end{verbatim}

\hypertarget{introduction-to-data.table}{%
\section{Introduction to data.table}\label{introduction-to-data.table}}

\url{https://cloud.r-project.org/web/packages/data.table/vignettes/datatable-intro.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
input <- if (file.exists( flights14.csv )) {
    flights14.csv 
} else {
   https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv 
}
flights <- fread(input)
flights
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
?fread
\end{verbatim}

\begin{verbatim}
DT = data.table(
  ID = c( b , b , b , a , a , c ),
  a = 1:6,
  b = 7:12,
  c = 13:18
)
DT


class(DT$ID)


getOption( datatable.print.nrows )



ans <- flights[origin ==  JFK  & month == 6L]
head(ans)


ans <- flights[1:2]
ans

ans <- flights[origin ==  JFK  & month == 6L][1:2]
head(ans)


ans <- flights[order(origin, -dest)]
head(ans)


ans <- flights[, arr_delay]
head(ans)



ans <- flights[, arr_delay, dest]
head(ans)

ans <- flights[, list(arr_delay)]
head(ans)


ans <- flights[, .(arr_delay)]
head(ans)

ans <- flights[, .(arr_delay, dep_delay)]
head(ans)


ans <- flights[, .(delay_arr = arr_delay, delay_dep = dep_delay)]
head(ans)


ans <- flights[, sum( (arr_delay + dep_delay) < 0 )]
ans

ans <- flights[origin ==  JFK  & month == 6L,
               .(m_arr = mean(arr_delay), m_dep = mean(dep_delay))]
ans

ans <- flights[origin ==  JFK  & month == 6L, length(dest)]
ans

ans <- flights[origin ==  JFK  & month == 6L, .N]
ans

ans <- flights[, c( arr_delay ,  dep_delay )]
head(ans)

select_cols = c( arr_delay ,  dep_delay )
flights[ , ..select_cols]


flights[ , select_cols, with = FALSE]

ans <- flights[, !c( arr_delay ,  dep_delay )]

ans <- flights[, -c( arr_delay ,  dep_delay )]

ans <- flights[, year:day]

ans <- flights[, day:year]

ans <- flights[, -(year:day)]
ans <- flights[, !(year:day)]


ans <- flights[, .(.N), by = .(origin)]
ans


ans <- flights[, .(.N), by =  origin ]
ans

ans <- flights[, .N, by = origin]
ans


ans <- flights[carrier ==  AA , .N, by = origin]
ans


ans <- flights[carrier ==  AA , .N, by = .(origin, dest)]
head(ans)


ans <- flights[carrier ==  AA , .N, by = c( origin ,  dest )]
ans


ans <- flights[carrier ==  AA ,
        .(mean(arr_delay), mean(dep_delay)),
        by = .(origin, dest, month)]
ans


ans <- flights[carrier ==  AA ,
        .(mean(arr_delay), mean(dep_delay)),
        keyby = .(origin, dest, month)]
ans


ans <- flights[carrier ==  AA , .N, by = .(origin, dest)]
ans


ans <- flights[carrier ==  AA , .N, by = .(origin, dest)][order(origin, -dest)]
head(ans, 10)


ans <- flights[, .N, .(dep_delay>0, arr_delay>0)]
ans

flights[, .N, .(dep_delayed = dep_delay>0, arr_delayed = arr_delay>0)]
\end{verbatim}

\hypertarget{cheat-sheet}{%
\chapter{cheat sheet}\label{cheat-sheet}}

\url{https://www}..com/community/tutorials/data-table-cheat-sheet

\url{https://s3.amazonaws.com/assets}..com/blog\_assets/datatable\_Cheat\_Sheet\_R.pdf

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(data.table)
\end{verbatim}

\url{http://r-datatable.com}

\url{https://github.com/Rdatatable/data.table/wiki}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
set.seed(45L)
DT <- data.table(V1 = c(1L,2L),
                 V2 = LETTERS[1:3],
                 V3 = round(rnorm(4),4),
                 V4 = 1:12)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
typeof(DT)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(DT)
\end{verbatim}

\hypertarget{subsetting-rows-using-i}{%
\section{Subsetting Rows Using i}\label{subsetting-rows-using-i}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[3:5,]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[3:5]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[V2== A ]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[V2 %in% c( A , C )]
\end{verbatim}

\hypertarget{manipulating-on-columns-in-j}{%
\section{Manipulating on Columns in j}\label{manipulating-on-columns-in-j}}

sonu√ß vekt√∂r olarak alƒ±nacaksa sadece s√ºtun ismi yazƒ±lƒ±yor

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,V2]
\end{verbatim}

sonu√ß data.frame olarak alƒ±nacaksa s√ºtun ismi √∂n√ºnde \texttt{.} yazƒ±lƒ±yor

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V2)]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V2,V3)]
\end{verbatim}

tek s√ºtun √ºzerinden √∂zet alma

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,sum(V1)]
\end{verbatim}

birden fazla s√ºtun √ºzerinden √∂zet alma

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(sum(V1),sd(V3))]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(Aggregate = sum(V1),
      Sd.V3 = sd(V3))]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V1,Sd.V3=sd(V3))]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(print(V2),
      plot(V3),
      NULL)]
\end{verbatim}

\hypertarget{doing-j-by-group}{%
\section{Doing j by Group}\label{doing-j-by-group}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V4.Sum = sum(V4)),by = V1]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V4.Sum = sum(V4)),
   by = .(V1,V2)]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V4.Sum = sum(V4)),
   by = sign(V1-1)]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.(V4.Sum = sum(V4)),
   by = .(V1.01 = sign(V1 - 1))]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[1:5,.(V4.Sum = sum(V4)), 
   by = V1]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,.N,by = V1]
\end{verbatim}

\hypertarget{addingupdating-columns-by-reference-in-j-using}{%
\section{Adding/Updating Columns By Reference in j Using :=}\label{addingupdating-columns-by-reference-in-j-using}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,V1:=round(exp(V1),2)]
DT
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,V5:=round(exp(V1),2)]
DT
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,c( V1 , V2 ):=list(round(exp(V1),2),
                       LETTERS[4:6])]
DT
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,':='(V1=round(exp(V1),2),
         V2=LETTERS[4:6])][]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,V1:=NULL]
DT
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[,c( V1 , V2 ):=NULL][]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Cols.chosen = c( A ,  B )
DT[,Cols.Chosen:=NULL]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Cols.chosen = c( A ,  B )
DT[,(Cols.Chosen):=NULL]
\end{verbatim}

\hypertarget{indexing-and-keys}{%
\section{Indexing And Keys}\label{indexing-and-keys}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
setkey(DT,V2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[ A ]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[c( A , C )]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[ A ,mult= first ]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[ A ,mult= last ]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[c( A , D )]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[c( A , D ),nomatch=0]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[c( A , C ),sum(V4)]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[c( A , C ),
   sum(V4),
   by=.EACHI]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
setkey(DT,V1,V2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[.(2, C )]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
DT[.(2,c( A , C ))]
\end{verbatim}

\hypertarget{data-tools-1}{%
\chapter{Data Tools}\label{data-tools-1}}

\begin{itemize}
\tightlist
\item
  Installations for Data Science. Anaconda, RStudio, Spark, TensorFlow, AWS (Amazon Web Services).
\end{itemize}

\url{https://medium.com/@GalarnykMichael}

\url{https://github.com/mGalarnyk/Installations_Mac_Ubuntu_Windows}

\begin{itemize}
\item
  Google Cloud for Data Science: Beginner's Guide
  \url{https://www}..com/community/tutorials/google-cloud-data-science
\item
  Deep Learning With Jupyter Notebooks In The Cloud
  \url{https://www}..com/community/tutorials/deep-learning-jupyter-aws
\end{itemize}

\url{https://www}..com/community/tutorials/homebrew-install-use

\begin{verbatim}
system() function works when I use R from terminal but not from RStudio #2193

https://github.com/rstudio/rstudio/issues/2193

myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(myTerm,  esearch -db pubmed -query '(diabetes AND pregnancy) AND (\ 2017/01/01\ [PDAT] : \ 2017/12/31\ [PDAT])' | efetch -format xml | xtract -pattern Grant -element Agency | sort-uniq-count-rank | head -n 10 > myquery.txt \n )
Sys.sleep(1)
repeat{
    Sys.sleep(0.1)
    if(rstudioapi::terminalBusy(myTerm) == FALSE){
        print( Code Executed )
        break
    }
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(datasets) # initialize
library(help=datasets) # display the datasets
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(airquality)  # get class
sapply(airquality, class)  # get class of all columns
str(airquality)  # structure
summary(airquality)  # summary of airquality
head(airquality)  # view the first 6 obs
fix(airquality)  # view spreadsheet like grid
View(airquality)
rownames(airquality)  # row names
colnames(airquality)  # columns names
nrow(airquality)  # number of rows
ncol(airquality)  # number of columns
\end{verbatim}

\hypertarget{my-r-codes-for-data-analysis-3}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-3}}

\hypertarget{decision-trees-1}{%
\chapter{Decision Trees}\label{decision-trees-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( ISLR )
library(ISLR)
data(package =  ISLR )
carseats <- Carseats
carseats
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( tree )
library(tree)
require(tree)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
names(carseats)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
hist(carseats$Sales)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
High <- ifelse(carseats$Sales <= 8,  No ,  Yes )
carseats <- data.frame(carseats, High)
carseats
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tree.carseats <- tree::tree(High~.-Sales, data = carseats)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tree.carseats
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
set.seed(101)
train <- sample(1:nrow(carseats), 250)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
train
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, fig.height=6, fig.width=12, include=FALSE}
tree.carseats <- tree(High~.-Sales, carseats, subset=train)
plot(tree.carseats)
text(tree.carseats, pretty=0)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tree.pred <- predict(tree.carseats, carseats[-train,], type =  class )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tree.pred
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
with(carseats[-train,], table(tree.pred, High))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
cv.carseats
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(cv.carseats)
\end{verbatim}

\begin{verbatim}
prune.carseats = prune.misclass(tree.carseats, best = 12)
plot(prune.carseats)
text(prune.carseats, pretty=0)
It's a bit shallower than previous trees, and you can actually read the labels. Let's evaluate it on the test dataset again.

tree.pred = predict(prune.carseats, carseats[-train,], type= class )
with(carseats[-train,], table(tree.pred, High))
(74 + 39) / 150
Seems like the correct classifications dropped a little bit. It has done about the same as your original tree, so pruning did not hurt much with respect to misclassification errors, and gave a simpler tree.

Often case, trees don't give very good prediction errors, so let's go ahead take a look at random forests and boosting, which tend to outperform trees as far as prediction and misclassification are concerned.

Random Forests
For this part, you will use the Boston housing data to explore random forests and boosting. The dataset is located in the MASS package. It gives housing values and other statistics in each of 506 suburbs of Boston based on a 1970 census.

library(MASS)
data(package= MASS )
boston<-Boston
dim(boston)
names(boston)
Let's also load the randomForest package.

require(randomForest)
To prepare data for random forest, let's set the seed and create a sample training set of 300 observations.

set.seed(101)
train = sample(1:nrow(boston), 300)
In this dataset, there are 506 surburbs of Boston. For each surburb, you have variables such as crime per capita, types of industry, average # of rooms per dwelling, average proportion of age of the houses etc. Let's use medv - the median value of owner-occupied homes for each of these surburbs, as the response variable.

Let's fit a random forest and see how well it performs. As being said, you use the response medv, the median housing value (in $1K dollars), and the training sample set.

rf.boston = randomForest(medv~., data = boston, subset = train)
rf.boston
Printing out the random forest gives its summary: the # of trees (500 were grown), the mean squared residuals (MSR), and the percentage of variance explained. The MSR and % variance explained are based on the out-of-bag estimates, a very clever device in random forests to get honest error estimates.

The only tuning parameter in a random Forests is the argument called mtry, which is the number of variables that are selected at each split of each tree when you make a split. As seen here, mtry is 4 of the 13 exploratory variables (excluding medv) in the Boston Housing data - meaning that each time the tree comes to split a node, 4 variables would be selected at random, then the split would be confined to 1 of those 4 variables. That's how randomForests de-correlates the trees.

You're going to fit a series of random forests. There are 13 variables, so let's have mtry range from 1 to 13:

In order to record the errors, you set up 2 variables oob.err and test.err.

In a loop of mtry from 1 to 13, you first fit the randomForest with that value of mtry on the train dataset, restricting the number of trees to be 350.

Then you extract the mean-squared-error on the object (the out-of-bag error).

Then you predict on the test dataset (boston[-train]) using fit (the fit of randomForest).

Lastly, you compute the test error: mean-squared error, which is equals to mean( (medv - pred) ^ 2 ).

oob.err = double(13)
test.err = double(13)
for(mtry in 1:13){
  fit = randomForest(medv~., data = boston, subset=train, mtry=mtry, ntree = 350)
  oob.err[mtry] = fit$mse[350]
  pred = predict(fit, boston[-train,])
  test.err[mtry] = with(boston[-train,], mean( (medv-pred)^2 ))
}
Basically you just grew 4550 trees (13 times 350). Now let's make a plot using the matplot command. The test error and the out-of-bag error are binded together to make a 2-column matrix. There are a few other arguments in the matrix, including the plotting character values (pch = 23 means filled diamond), colors (red and blue), type equals both (plotting both points and connecting them with the lines), and name of y-axis (Mean Squared Error). You can also put a legend at the top right corner of the plot.

matplot(1:mtry, cbind(test.err, oob.err), pch = 23, col = c( red ,  blue ), type =  b , ylab= Mean Squared Error )
legend( topright , legend = c( OOB ,  Test ), pch = 23, col = c( red ,  blue ))
Ideally, these 2 curves should line up, but it seems like the test error is a bit lower. However, there's a lot of variability in these test error estimates. Since the out-of-bag error estimate was computed on one dataset and the test error estimate was computed on another dataset, these differences are pretty much well within the standard errors.

Notice that the red curve is smoothly above the blue curve? These error estimates are very correlated, because the randomForest with mtry = 4 is very similar to the one with mtry = 5. That's why each of the curves is quite smooth. What you see is that mtry around 4 seems to be the most optimal choice, at least for the test error. This value of mtry for the out-of-bag error equals 9.

So with very few tiers, you have fitted a very powerful prediction model using random forests. How so? The left-hand side shows the performance of a single tree. The mean squared error on out-of-bag is 26, and you've dropped down to about 15 (just a bit above half). This means you reduced the error by half. Likewise for the test error, you reduced the error from 20 to 12.

Boosting
Compared to random forests, boosting grows smaller and stubbier trees and goes at the bias. You will use the package GBM (Gradient Boosted Modeling), in R.

require(gbm)
GBM asks for the distribution, which is Gaussian, because you'll be doing squared error loss. You're going to ask GBM for 10,000 trees, which sounds like a lot, but these are going to be shallow trees. Interaction depth is the number of splits, so you want 4 splits in each tree. Shrinkage is 0.01, which is how much you're going to shrink the tree step back.

boost.boston = gbm(medv~., data = boston[train,], distribution =  gaussian , n.trees = 10000, shrinkage = 0.01, interaction.depth = 4)
summary(boost.boston)
The summary function gives a variable importance plot. It seems like there are 2 variables that have high relative importance: rm (number of rooms) and lstat (percentage of lower economic status people in the community). Let's plot these 2 variables:

plot(boost.boston,i= lstat )
plot(boost.boston,i= rm )
The 1st plot shows that the higher the proportion of lower status people in the suburb, the lower the value of the housing prices. The 2nd plot shows the reversed relationship with the number of rooms: the average number of rooms in the house increases as the price increases.

It's time to predict a boosted model on the test dataset. Let's look at the test performance as a function of the number of trees:

First, you make a grid of number of trees in steps of 100 from 100 to 10,000.

Then, you run the predict function on the boosted model. It takes n.trees as an argument, and produces a matrix of predictions on the test data.

The dimensions of the matrix are 206 test observations and 100 different predict vectors at the 100 different values of tree.

n.trees = seq(from = 100, to = 10000, by = 100)
predmat = predict(boost.boston, newdata = boston[-train,], n.trees = n.trees)
dim(predmat)
It's time to compute the test error for each of the predict vectors:

predmat is a matrix, medv is a vector, thus (predmat - medv) is a matrix of differences. You can use the apply function to the columns of these square differences (the mean). That would compute the column-wise mean squared error for the predict vectors.

Then you make a plot using similar parameters to that one used for Random Forest. It would show a boosting error plot.

boost.err = with(boston[-train,], apply( (predmat - medv)^2, 2, mean) )
plot(n.trees, boost.err, pch = 23, ylab =  Mean Squared Error , xlab =  # Trees , main =  Boosting Test Error )
abline(h = min(test.err), col =  red )
The boosting error pretty much drops down as the number of trees increases. This is an evidence showing that boosting is reluctant to overfit. Let's also include the best test error from the randomForest into the plot. Boosting actually gets a reasonable amount below the test error for randomForest.

Conclusion
So that's the end of this R tutorial on building decision tree models: classification trees, random forests, and boosted trees. The latter 2 are powerful methods that you can use anytime as needed. In my experience, boosting usually outperforms RandomForest, but RandomForest is easier to implement. In RandomForest, the only tuning parameter is the number of trees; while in boosting, more tuning parameters are required besides the number of trees, including the shrinkage and the interaction depth.

If you would like to learn more, be sure to take a look at our Machine Learning Toolbox course for R.
\end{verbatim}

\hypertarget{decision-tree}{%
\chapter{decision tree}\label{decision-tree}}

\url{https://analytics4all.org/2016/11/23/r-decision-trees-regression/}

\hypertarget{decision-tree-classifier-implementation-in-r}{%
\chapter{DECISION TREE CLASSIFIER IMPLEMENTATION IN R}\label{decision-tree-classifier-implementation-in-r}}

\url{https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/}

\url{https://dataaspirant.com/2017/02/03/decision-tree-classifier-implementation-in-r/}

\hypertarget{caret}{%
\chapter{caret}\label{caret}}

Classification And REgression Training

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(caret)
library(rpart.plot)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data_url <- c( https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data )
download.file(url = data_url, destfile =  data/car.data )

car_df <- read.csv( data/car.data , sep = ',', header = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
set.seed(3033)
intrain <- createDataPartition(y = car_df$V7, p= 0.7, list = FALSE)
training <- car_df[intrain,]
testing <- car_df[-intrain,]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#check dimensions of train & test set
dim(training); dim(testing);
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
anyNA(car_df)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(car_df)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
trctrl <- trainControl(method =  repeatedcv , number = 10, repeats = 3)

# The ‚Äúmethod‚Äù parameter holds the details about resampling method. We can set ‚Äúmethod‚Äù with many values like  ‚Äúboot‚Äù, ‚Äúboot632‚Äù, ‚Äúcv‚Äù, ‚Äúrepeatedcv‚Äù, ‚ÄúLOOCV‚Äù, ‚ÄúLGOCV‚Äù etc. For this tutorial, let‚Äôs try to use repeatedcv i.e, repeated cross-validation.
# 
# The ‚Äúnumber‚Äù parameter holds the number of resampling iterations. The ‚Äúrepeats ‚Äù parameter contains the complete sets of folds to compute for our repeated cross-validation. We are using setting number =10 and repeats =3. This trainControl() methods returns a list. We are going to pass this on our train() method.


set.seed(3333)

dtree_fit <- train(V7 ~., data = training, method =  rpart ,
                   parms = list(split =  information ),
                   trControl=trctrl,
                   tuneLength = 10)


# train() method should be passed with ‚Äúmethod‚Äù parameter as ‚Äúrpart‚Äù. There is another package ‚Äúrpart‚Äù, it is specifically available for decision tree implementation. Caret links its train function with others to make our work simple.
# 
# We are passing our target variable V7. The ‚ÄúV7~.‚Äù denotes a formula for using all attributes in our classifier and V7 as the target variable. The ‚ÄútrControl‚Äù parameter should be passed with results from our trianControl() method.




\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
?rpart
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dtree_fit
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
prp(dtree_fit$finalModel, box.palette =  Reds , tweak = 1.2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
testing[1,]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
predict(dtree_fit, newdata = testing[1,])
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
test_pred <- predict(dtree_fit, newdata = testing)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
confusionMatrix(test_pred, testing$V7 )  #check accuracy
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
set.seed(3333)
dtree_fit_gini <- train(V7 ~., data = training, method =  rpart ,
                   parms = list(split =  gini ),
                   trControl=trctrl,
                   tuneLength = 10)
dtree_fit_gini
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
prp(dtree_fit_gini$finalModel, box.palette =  Blues , tweak = 1.2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
test_pred_gini <- predict(dtree_fit_gini, newdata = testing)
confusionMatrix(test_pred_gini, testing$V7 )  #check accuracy
\end{verbatim}

\hypertarget{my-r-codes-for-data-analysis-4}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-4}}

\hypertarget{descriptive-statistics}{%
\section{Descriptive Statistics}\label{descriptive-statistics}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Epi::stat.table(gender,mean(age), data = scabies)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table <- Epi::stat.table(gender,mean(age), data = scabies)

pander::pander(table)

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#Tabulate, by gender, the mean age from the scabies dataset

Epi::stat.table(gender,list(mean(age),median(age)), data = scabies)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary_data <- arsenal::tableby(gender~age+scabies_infestation,data=scabies)
summary(summary_data)
\end{verbatim}

\hypertarget{skimr}{%
\section{skimr}\label{skimr}}

\url{https://cran.r-project.org/web/packages/skimr/vignettes/Using_skimr.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
require(skimr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(iris$Sepal.Length)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fivenum(iris$Sepal.Length)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(iris$Species)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
skim(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
iris_results <- skim(iris)
str(iris_results)
iris_results$variable
iris_results$type
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
skimr::skim(iris) %>%
  dplyr::filter(stat ==  mean )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
head(iris_results, n=15)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mtcars %>%
  dplyr::group_by(gear) %>%
  skim()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
skim(iris, Sepal.Length, Species)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
skim(iris, starts_with( Sepal ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
skim(datasets::lynx)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Exploratory Data Analysis in R (introduction)
\end{itemize}

\url{https://blog.datascienceheroes.com/exploratory-data-analysis-in-r-intro/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
library(summarytools)
# library(funModeling) 
library(tidyverse) 
library(Hmisc)

basic_eda <- function(data)
{
  glimpse(data)
 # df_status(data)
 # freq(data) 
 # profiling_num(data)
 # plot_num(data)
  describe(data)
}

basic_eda(irisdata)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{What's so hard about histograms?}
\end{itemize}

\url{http://tinlizzie.org/~aran/histograms/}

\hypertarget{dataexplorer}{%
\chapter{DataExplorer}\label{dataexplorer}}

\hypertarget{webinar-tidyverse-exploratory-analysis-emily-robinson}{%
\chapter{Webinar: Tidyverse Exploratory Analysis (Emily Robinson)}\label{webinar-tidyverse-exploratory-analysis-emily-robinson}}

\textless iframe width= 560 height= 315 src= \url{https://www.youtube.com/embed/uG3igAGX7UE} frameborder= 0 allow= accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture allowfullscreen\textgreater{}

\url{https://hookedondata.org/the-lesser-known-stars-of-the-tidyverse/}

\url{https://www.rstudio.com/resources/videos/the-lesser-known-stars-of-the-tidyverse/}

\url{https://github.com/robinsones/robinsones_blog/blob/master/content/post/multipleChoiceResponses.csv}

\url{https://github.com/robinsones/robinsones_blog/blob/master/content/post/2018-11-16-the-lesser-known-stars-of-the-tidyverse.Rmd}

\hypertarget{i-only-use-r-for-descriptive-stats-and-thats-ok}{%
\chapter{I ``only'' use R for descriptive stats --- and that's OK}\label{i-only-use-r-for-descriptive-stats-and-thats-ok}}

\url{https://rforeval.com/descriptive-stats-r/}

\hypertarget{histograms}{%
\chapter{histograms}\label{histograms}}

\url{http://tinlizzie.org/histograms/}

\hypertarget{bibliographic-studies-2}{%
\chapter{Bibliographic Studies}\label{bibliographic-studies-2}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.path = 'figure/', echo = TRUE, warning = FALSE, message = FALSE, error = FALSE, eval = TRUE, tidy = TRUE, comment = NA)
\end{verbatim}

\begin{verbatim}
{r , include=FALSE}
library(tidyverse)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
state.name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( maps )
# library(maps)
# x <- map( world , plot=FALSE)
# glimpse(x)
# x$names
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( rworldmap )
library(rworldmap)
vignette('rworldmap')
data(countryExData)
countryExData
\end{verbatim}

SEER China vs others

\url{https://www.rdocumentation.org/packages/bayesTFR/versions/6.1-2/topics/country.names}

\url{https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/state.html}

\hypertarget{who-works-on-seer}{%
\chapter{Who works on SEER}\label{who-works-on-seer}}

If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page.\\
Select from the tabs below.

\hypertarget{aim}{%
\section{Aim}\label{aim}}

\textbf{Aim:}

\hypertarget{data-retriveal-from-pubmed-using-edirect}{%
\section{Data retriveal from PubMed using EDirect}\label{data-retriveal-from-pubmed-using-edirect}}

Articles are downloaded as \texttt{xml}.

\begin{verbatim}
{r Search PubMed write all data as xml, eval=FALSE, include=FALSE, echo=TRUE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(
    myTerm,
     esearch -db pubmed -query \ 'SEER Program'[Mesh]
\  -datetype PDAT -mindate 1800 -maxdate 3000 | efetch -format xml > data/pubmed_result_SEER_MeSH.xml \n 
)
Sys.sleep(1)
repeat {
    Sys.sleep(0.1)
    if (rstudioapi::terminalBusy(myTerm) == FALSE) {
        print( Code Executed )
        break
    }
}
\end{verbatim}

\begin{verbatim}
{r extract journal names from all data xml, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
myTerm <- rstudioapi::terminalCreate(show = FALSE)
rstudioapi::terminalSend(
myTerm,
 xtract -input data/pubmed_result_SEER_MeSH.xml -pattern PubmedArticle -sep ' ' -def 'na' -element MedlineCitation/PMID PubDate/Year Affiliation> data/SEER_countries.csv \n 
)
Sys.sleep(1)
repeat {
Sys.sleep(0.1)
if (rstudioapi::terminalBusy(myTerm) == FALSE) {
print( Code Executed )
break
}
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(readr)
SEER_countries <- read_delim( data/SEER_countries.csv , 
     \t , escape_double = FALSE, col_names = c( PMID ,  year ,  Affiliations ), 
    na =  NA , trim_ws = TRUE)
# View(SEER_countries)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
countries <- read_delim( data/countries.txt , delim =  | , col_names = c( abb ,  country ))

country <- countries$country

country <- c(country, state.name)

country[80] <-  Georgia_ 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# SEER_countries <- cbind(SEER_countries, setNames(lapply(country, function(x) x=NA), country))

# names(SEER_countries)[254] <-  GeorgiaUSA 

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# grepl(pattern =  China , x = SEER_countries$Affiliations)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# deneme1 <- grepl(pattern = country[44], x = SEER_countries$Affiliations)
    
# deneme2 <- sapply(country, function(x) grepl(x, SEER_countries$Affiliations))

# sum(deneme1 != deneme2[,44])
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# deneme2 <- as.data.frame(deneme2)

# sum(deneme2$Turkey)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
SEER_countries <- cbind(SEER_countries, sapply(country, function(x) grepl(x, SEER_countries$Affiliations)))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dim(SEER_countries)[1]
\end{verbatim}

At the time of the research the number of articles with `SEER Program'{[}Mesh{]} formula is r dim(SEER\_countries){[}1{]} .

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# deneme <- colSums(SEER_countries[,-(1:3)])

# deneme <- as.data.frame(deneme)

# deneme <- rownames_to_column(deneme, var =  countries )

# names(deneme) <- c( countries ,  number )

# deneme %>% arrange(desc(number))

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
SEER_countries[SEER_countries == FALSE] <- 0

SEER_countries[SEER_countries == TRUE] <- 1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
countryTotals <- SEER_countries %>% 
  select(-c(1:3)) %>% 
  summarise_all(funs(sum)) 

countryTotals[which(countryTotals>0)]

publisherCountries <- names(countryTotals[which(countryTotals>0)])

SEER_countries <- SEER_countries %>% 
  select(c(1:3, publisherCountries))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
deneme <- SEER_countries %>% 
  gather(key =  Country , value =  Number , -c(1:3)) %>% 
  group_by(Country, year) %>% 
  summarise(total = sum(Number))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
deneme %>% 
  filter(year !=  na ) %>%
  filter(year !=  2017 ) %>% 
  filter(year !=  2018 ) %>% 
ggplot() +
  aes(y = total, x = year, group = Country, color = Country) +
  geom_line() + 
  guides(fill=FALSE, color=FALSE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
USAnames <- names(SEER_countries) %in% state.name

Others <- setdiff(names(SEER_countries[-c(1:3)]), c(USAnames, United States ,  China ))


deneme2 <- SEER_countries %>% 
  mutate(
    sumUSA = rowSums(
      select(., one_of(USAnames), `United States`)
      )
    ) %>% 
mutate(
    sumOthers = rowSums(
      select(., one_of(Others))
      )
    ) %>% 
  select(PMID, year, China, USA = sumUSA, Others = sumOthers)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
deneme3 <- deneme2 %>% 
  gather(key =  Country , value =  Number , -c(1:2)) %>% 
  group_by(PMID, Country, year) %>% 
  summarise(total = sum(Number)) %>% 
  filter(year !=  na ) %>%
  filter(year !=  2017 ) %>% 
  filter(year !=  2018 ) %>% 
  filter(total !=  0 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# which(duplicated(deneme3$PMID))
# which(duplicated(deneme3$PMID))-1

# deneme3[which(duplicated(deneme3$PMID)),]

together <- bind_cols(
First = deneme3$Country[which(duplicated(deneme3$PMID))],
Second = deneme3$Country[which(duplicated(deneme3$PMID))-1]
)

table(together$First, together$Second) %>% addmargins()
bind_cols(
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
deneme4 <- deneme2 %>% 
  gather(key =  Country , value =  Number , -c(1:2)) %>% 
  group_by(Country, year) %>% 
  summarise(total = sum(Number)) %>% 
  filter(year !=  na ) %>%
  filter(year !=  2017 ) %>% 
  filter(year !=  2018 ) %>% 
  filter(total !=  0 )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
deneme4 %>% 
ggplot() +
  aes(y = total, x = year, group = Country, color = Country) +
  geom_line() + 
  # guides(fill=FALSE, color=FALSE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
\end{verbatim}

While helping the preparation of \#PBPath Journal Watch (https://t.co/WiBsJixzlc) I thought that many SEER \citet{NCICancerStats} studies are from China. So using edirect \citet{NCBI} and \#RStats I draw the attached graph. What do you think? Do Chinese do research on SEER that much? pic.twitter.com/3Op5r9ofbK

--- Serdar Balcƒ± (\citet{serdarbalci}) October 6, 2018

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
p <- deneme4 %>% 
ggplot() +
  aes(y = total, x = year, group = Country, color = Country) +
  geom_line() + 
  # guides(fill=FALSE, color=FALSE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

\end{verbatim}

\hypertarget{eurostat}{%
\chapter{Eurostat}\label{eurostat}}

\begin{itemize}
\tightlist
\item
  eurostat
\end{itemize}

\url{http://ec.europa.eu/eurostat}

\url{http://ec.europa.eu/eurostat/data/database}

\begin{itemize}
\tightlist
\item
  eurostat R package
\end{itemize}

\url{http://ropengov.github.io/eurostat/}

\begin{itemize}
\tightlist
\item
  Retrieval and Analysis of Eurostat Open Data with the eurostat Package
\end{itemize}

\url{https://journal.r-project.org/archive/2017/RJ-2017-019/index.html}

\begin{itemize}
\tightlist
\item
  CheatSheet
\end{itemize}

\url{https://github.com/rOpenGov/eurostat/blob/master/vignettes/cheatsheet/eurostat_cheatsheet.pdf}

\url{https://github.com/rstudio/cheatsheets/raw/master/eurostat.pdf}

\begin{itemize}
\tightlist
\item
  Searching, downloading and manipulating Eurostat data with R
\end{itemize}

\url{http://ropengov.github.io/r/2015/05/01/eurostat-package-examples/}

\begin{itemize}
\tightlist
\item
  Mapping Eurostat information
\end{itemize}

\url{https://www.mytinyshinys.com/2017/07/11/eurostat/}

\begin{itemize}
\tightlist
\item
  eurostat-package published
\end{itemize}

\url{https://rpubs.com/muuankarski/27120}

\begin{itemize}
\tightlist
\item
  Tutorial (vignette) for the eurostat R package
\end{itemize}

\url{http://ropengov.github.io/eurostat/articles/eurostat_tutorial.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( eurostat )
library(eurostat)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
TOC <- get_eurostat_toc()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
TOC
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
query <- search_eurostat( road accidents , type =  table )

query
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
query$code[[1]]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
  query$title[[1]]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dat <- get_eurostat(id =  sdg_11_40 , time_format =  num )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dat
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
countries <- c( UK ,  SK ,  FR ,  PL ,  ES ,  PT ,  TR )
t1 <- get_eurostat( sdg_11_40 , filters = list(geo = countries))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
t1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
t2 <- get_eurostat(id =  sdg_11_40 , time_format =  num )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(t2$geo)
\end{verbatim}

\hypertarget{evidence-synthesis-projects}{%
\chapter{Evidence Synthesis Projects}\label{evidence-synthesis-projects}}

\hypertarget{revtools}{%
\chapter{revtools}\label{revtools}}

revtools: Tools to Support Evidence Synthesis

\url{https://cran.r-project.org/package=revtools}

\url{https://revtools.net/}

\url{https://revtools.net/user_manual/1_introduction.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( revtools )
# devtools:: install_github( mjwestgate/revtools )
library(revtools)
\end{verbatim}

\begin{verbatim}
data1 <- read_bibliography( my_data.ris )
data2 <- read_bibliography( my_data.bib )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# data1 <- read_bibliography(file.choose())

data1 <- read_bibliography( data/citations.nbib )

\end{verbatim}

\begin{verbatim}
# If the files are in the working directory:
file_names <- list.files()

# Or if they are in a subdirectory:
file_names <- paste0(
   ./raw_data/ ,
  list.files(path =  ./raw_data/ )
)

# Then import to a list
data_list <- lapply(
  file_names,
  function(x){read_bibliography(x)}
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data2 <- read_bibliography(
   data/citations.nbib ,
  return_df = FALSE
)

class(data2)

class(data2[[1]])

names(data2[[1]])
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
write_bibliography(data2,  data/denemeRIS , format =  ris )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# revtools::format_citation()
\end{verbatim}

\begin{verbatim}
data <- read_bibliography( my_data.ris )

matches <- find_duplicates(
  data = data,
  match_variable =  title ,
  group_variable = NULL,
  match_function =  fuzzdist ,
  method =  fuzz_partial_ratio ,
  threshold = 0
)
\end{verbatim}

\begin{verbatim}
data_unique <- extract_unique_references(data, matches)
\end{verbatim}

\hypertarget{screen_duplicates}{%
\chapter{screen\_duplicates}\label{screen_duplicates}}

\url{https://revtools.net/user_manual/4_removing_duplicates.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
screen_duplicates(data1)
\end{verbatim}

\begin{verbatim}
# 1. standalone; load in data in the app
screen_titles()

# 2. the same, but save back to workspace on exit
result <- screen_titles() # ditto,

data <- read_bibliography( my_data.ris ) # load in data

# 3. launch the app using data from the workspace
screen_titles(data)  

# 4. specify an object to return data to
result <- screen_titles(data)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
screen_titles(data1)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
screen_abstracts(data1)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
screen_topics(data1)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(revtools)
data <- read_bibliography( data/deneme2.ris )
dtm <- make_DTM(data)
model <- topicmodels::LDA(
  dtm,
  k = 15,
  LDA.control = list(
    burnin = 1000,
    iter = 6000,
    keep = 100
  )
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
articles <- as.data.frame(data)
articles$topic <- topics(model)

# cross-tabulate to show number of articles per topic per year
popularity <- as.data.frame(
  xtabs(
    ~ year + topic,
    data = articles,
    drop.unused.levels = FALSE
  ),
stringsAsFactors = FALSE
)
popularity$year <- scale(
  as.numeric(popularity$year)
)
popularity$topic <- as.factor(popularity$topic)

# create a mixed model
library(lme4)
popularity_model <- glmer(Freq ~ 1 + (1 | topic) + (year -1 | topic),
    family = poisson(link =  log ),
    data = popularity
)

# export the results of this model
popularity_results <- ranef(popularity_model)$topic
colnames(popularity_results) <- c( intercept ,  slope )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
p <- ggplot(popularity_results,
  aes(x = intercept, y = slope)
) +
geom_point()
p
\end{verbatim}

\hypertarget{refmanager}{%
\chapter{RefManageR}\label{refmanager}}

RefManageR: Straightforward `BibTeX' and `BibLaTeX' Bibliography Management

\url{https://cran.r-project.org/web/packages/RefManageR/index.html}

\hypertarget{bibtex}{%
\chapter{bibtex}\label{bibtex}}

bibtex: Bibtex Parser

\url{https://cran.r-project.org/web/packages/bibtex/index.html}

\hypertarget{explatory-data-analysis-summary-statistics}{%
\chapter{Explatory Data Analysis \& Summary Statistics}\label{explatory-data-analysis-summary-statistics}}

\hypertarget{dataexplorer-1}{%
\chapter{DataExplorer}\label{dataexplorer-1}}

\url{https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html}

\url{https://boxuancui.github.io/DataExplorer/}

\hypertarget{my-r-codes-for-data-analysis-5}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-5}}

\hypertarget{file-organization-best-practices-1}{%
\section{File organization best practices}\label{file-organization-best-practices-1}}

This page summarises how to organize files and analysis before everything gets jumbled up:
\href{https://andrewbtran.github.io/NICAR/2018/workflow/docs/01-workflow_intro.html}{Setting up a reproducible data analysis workflow in R}

Basically they suggest:
- using a project and project folder in RStudio for each analysis
- using \texttt{packrat} as much as possible

\texttt{setwd()} and \texttt{getwd()} is not necesary when you use projects.

\begin{itemize}
\tightlist
\item
  \textbf{Why should I use the here package when I'm already using projects?}
\end{itemize}

\url{https://malco.io/2018/11/05/why-should-i-use-the-here-package/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(here)
here()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dr_here()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
here( figure ,  figure.png )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
file.path( figure ,  figure.png )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
read_csv(here( data ,  mtcars.csv ))
\end{verbatim}

\hypertarget{all-tables-examples}{%
\chapter{All tables examples}\label{all-tables-examples}}

author: Ewen Harrison

\begin{verbatim}
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{All tables examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
\end{verbatim}

\hypertarget{cross-tables}{%
\section{1 Cross tables}\label{cross-tables}}

Two-way tables are used extensively in healthcare research, e.g.~a 2x2 table comparing two factors with two levels each, or table 1 from a typical clinical study or trial

The main functions all take a \texttt{dependent} variable - the outcome (maximum of 5 levels) - and \texttt{explanatory} variables - predictors or exposures (any number categorical or continuous variables).

\hypertarget{default}{%
\subsection{1.01 Default}\label{default}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
  summary_factorlist(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ))
\end{verbatim}

Note, chi-squared warnings will be generated when the expected count in any cell is less than 5. Fisher's exact test can be used as below, or go straight to a univariable logistic regression, e.g.~\texttt{colon\_s\ \%\textgreater{}\%\ finalfit(dependent,\ explanatory)}

\hypertarget{add-or-edit-variable-labels}{%
\subsection{1.02 Add or edit variable labels}\label{add-or-edit-variable-labels}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
library(dplyr)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    mutate(
        sex.factor = ff_label(sex.factor,  Gender )
    ) %>% 
  summary_factorlist(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ))
\end{verbatim}

\hypertarget{p-value-for-hypothesis-test}{%
\subsection{1.03 P-value for hypothesis test}\label{p-value-for-hypothesis-test}}

Chi-squared for categorical, Kruskal-Wallis/Mann-Whitney for continuous

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{with-fishers-exact-test}{%
\subsection{1.04 With Fisher's exact test}\label{with-fishers-exact-test}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
  summary_factorlist(dependent, explanatory, p = TRUE, catTest = catTestfisher) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ))
\end{verbatim}

\hypertarget{median-interquartile-range-instead-of-mean-standard-deviation}{%
\subsection{1.05 Median (interquartile range) instead of mean (standard deviation)}\label{median-interquartile-range-instead-of-mean-standard-deviation}}

\ldots{} for continuous variables.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{missing-values-for-the-explanatory-variables}{%
\subsection{1.06 Missing values for the explanatory variables}\label{missing-values-for-the-explanatory-variables}}

Always do this when describing your data.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{column-proportions-rather-than-row}{%
\subsection{1.07 Column proportions (rather than row)}\label{column-proportions-rather-than-row}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
                                         column = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{total-column}{%
\subsection{1.08 Total column}\label{total-column}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
                                         column = TRUE, total_col = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{order-a-variable-by-total}{%
\subsection{1.09 Order a variable by total}\label{order-a-variable-by-total}}

This is intended for when there is only one \texttt{explanatory} variable.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( extent.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
                                         column = TRUE, total_col = TRUE, orderbytotal = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{label-with-dependent-name}{%
\subsection{\texorpdfstring{1.10 Label with \texttt{dependent} name}{1.10 Label with dependent name}}\label{label-with-dependent-name}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
    summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
                                         column = TRUE, total_col = TRUE, add_dependent_label = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

The dependent name cannot be passed directly to the table intentionally. This is to avoid errors when code is copied and the name is not updated. Change the dependent label using the following. The prefix ( Dependent: ) and any suffix can be altered.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  perfor.factor 
colon_s %>%
  dplyr::mutate(
    perfor.factor = ff_label(perfor.factor,  Perforated cancer )
    ) %>% 
  summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
    column = TRUE, total_col = TRUE, add_dependent_label = TRUE, dependent_label_prefix =   ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{dependent-variable-with-any-number-of-factor-levels-supported}{%
\subsection{1.11 Dependent variable with any number of factor levels supported}\label{dependent-variable-with-any-number-of-factor-levels-supported}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( age ,  age.factor ,  sex.factor ,  obstruct.factor )
dependent =  extent.factor 
colon_s %>%
  dplyr::mutate(
    perfor.factor = ff_label(perfor.factor,  Perforated cancer )
  ) %>% 
  summary_factorlist(dependent, explanatory, p = TRUE, cont =  median , na_include = TRUE,
    column = TRUE, total_col = TRUE, add_dependent_label = TRUE, dependent_label_prefix =   ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{explanatory-variable-defaults-to-factor-when-5-distinct-values}{%
\subsection{1.12 Explanatory variable defaults to factor when ‚â§5 distinct values}\label{explanatory-variable-defaults-to-factor-when-5-distinct-values}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)

# Here, `extent` is a continuous variable with 4 distinct values. 
# Any continuous variable with 5 or fewer unique values is converted silently to factor 
# e.g.
explanatory = c( extent )
dependent =  mort_5yr 
colon_s %>%
  summary_factorlist(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{keep-as-continous-variable-when-5-distinct-values}{%
\subsection{1.13 Keep as continous variable when ‚â§5 distinct values}\label{keep-as-continous-variable-when-5-distinct-values}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(finalfit)
explanatory = c( extent )
dependent =  mort_5yr 
colon_s %>%
  summary_factorlist(dependent, explanatory, cont_cut = 3) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{stratified-crosstables}{%
\subsection{1.14 Stratified crosstables}\label{stratified-crosstables}}

I've been meaning to include support for table stratification for a while. I have delayed for a good reason. Perhaps the most straightforward way to implement stratificiation is with \texttt{dplyr::group\_by()}. However, the non-standard evaluation required for multiple strata may confuse as it is not implemented else where in the package (doesn't work with \texttt{group\_by\_}). This translates to whether variable names are passed in quotes or not. Finally,. \texttt{dplyr::do()} is planned for deprecation, but there is no good alternative at the moment. Anyway, here is a solution, which while not that pretty, is very effective.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE}
library(dplyr)
# Piped function to generate stratified crosstabs table
explanatory = c( age.factor ,  sex.factor )
dependent =  rx.factor 

# Pick option below
split =  rx.factor 
split = c( perfor.factor ,  node4.factor )

colon_s %>%
  group_by(!!! syms(split)) %>% #Looks awkward, but this keeps quoted var names (rather than unquoted)
  do(
    summary_factorlist(., dependent, explanatory, p = TRUE)
  ) %>%
  data.frame() %>%
  dependent_label(colon_s, dependent, prefix =   ) %>%
  colname2label(split) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  l ,  l ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{model-tables-with-finalfit}{%
\section{\texorpdfstring{2 Model tables with \texttt{finalfit()}}{2 Model tables with finalfit()}}\label{model-tables-with-finalfit}}

\hypertarget{default-1}{%
\subsection{2.01 Default}\label{default-1}}

Logistic regression first.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{hide-reference-levels}{%
\subsection{2.02 Hide reference levels}\label{hide-reference-levels}}

Most appropriate when all explanatory variables are continuous or well-known binary variables, such as sex.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age ,  sex.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, add_dependent_label = FALSE) %>% 
    ff_remove_ref() %>% 
    dependent_label(colon_s, dependent)-> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{model-metrics}{%
\subsection{2.03 Model metrics}\label{model-metrics}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, metrics = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t[[1]], row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
kable(t[[2]], row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ), col.names =   )
\end{verbatim}

\hypertarget{model-metrics-can-be-applied-to-all-supported-base-models}{%
\subsection{2.04 Model metrics can be applied to all supported base models}\label{model-metrics-can-be-applied-to-all-supported-base-models}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
glm(mort_5yr ~ age.factor + sex.factor + obstruct.factor + perfor.factor, data = colon_s, family =  binomial ) %>% 
    ff_metrics() -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ), col.names =   )
\end{verbatim}

\hypertarget{reduced-model}{%
\subsection{2.05 Reduced model}\label{reduced-model}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
explanatory_multi = c( age.factor ,  obstruct.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, explanatory_multi) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{include-all-models}{%
\subsection{2.06 Include all models}\label{include-all-models}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
explanatory_multi = c( age.factor ,  obstruct.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, explanatory_multi, metrics = TRUE, keep_models = TRUE) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t[[1]], row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
kable(t[[2]], row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ), col.names =   )
\end{verbatim}

\hypertarget{interactions}{%
\subsection{2.06 Interactions}\label{interactions}}

Interactions can be specified in the normal way. Formatting the output is trickier. At the moment, we have left the default model output. This can be adjusted as necessary.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor*sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{interactions-create-interaction-variable-with-two-factors}{%
\subsection{2.07 Interactions: create interaction variable with two factors}\label{interactions-create-interaction-variable-with-two-factors}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
#explanatory = c( age.factor*sex.factor ,  obstruct.factor ,  perfor.factor )
explanatory = c( obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    ff_interaction(age.factor, sex.factor) %>% 
    finalfit(dependent, c(explanatory,  age.factor__sex.factor )) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{dependent-name}{%
\subsection{2.08 Dependent name}\label{dependent-name}}

The dependent name cannot be specified directly intentionally. This is to prevent errors when copying code. Re-label using \texttt{ff\_label()}. The dependent prefix and suffix can also be altered.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    dplyr::mutate(
        mort_5yr = ff_label(mort_5yr,  5-year mortality )
    ) %>% 
    finalfit(dependent, explanatory, dependent_label_prefix =   ,
                     dependent_label_suffix =   (full model) ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{estimate-name}{%
\subsection{2.09 Estimate name}\label{estimate-name}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, estimate_name =  Odds ratio ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{digits-decimal-places}{%
\subsection{2.10 Digits / decimal places}\label{digits-decimal-places}}

Number of digits to round to regression results. (1) estimate, (2) confidence interval limits, (3) p-value. Default is c(2,2,3). Trailing zeros are preserved. Number of decimal places for counts and mean (sd) / median (IQR) not currently supported. Defaults are senisble :)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, digits = c(3,3,4)) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{confidence-interval-type}{%
\subsection{2.11 Confidence interval type}\label{confidence-interval-type}}

One of \texttt{c(\ profile\ ,\ \ default\ )} for GLM models (\texttt{confint.glm()}). Note, a little awkwardly, the `default' setting is \texttt{profile}, rather than \texttt{default}. Profile levels are probably a little more accurate. Only go to default if taking a significant length of time for profile, i.e.~data is greater than hundreds of thousands of lines.

For glmer/lmer models (\texttt{confint.merMod()}), \texttt{c(\ profile\ ,\ \ Wald\ ,\ \ boot\ )}. Not implemented for \texttt{lm()}, \texttt{coxph()} or \texttt{coxphlist}, which use default.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, confint_type =  default ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{confidence-interval-level}{%
\subsection{2.12 Confidence interval level}\label{confidence-interval-level}}

Probably never change this :) Note, the p-value is intentionally not included for confidence levels other than 95\% to avoid confusion.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, confint_level = 0.90) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{confidence-interval-separation}{%
\subsection{2.13 Confidence interval separation}\label{confidence-interval-separation}}

Some like to avoid the hyphen so as not to confuse with minus sign. Obviously not an issue in logistic regression.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
colon_s %>%
    finalfit(dependent, explanatory, confint_sep =   to  ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{mixed-effects-random-intercept-model}{%
\subsection{2.14 Mixed effects random-intercept model}\label{mixed-effects-random-intercept-model}}

At its simplest, a random-intercept model can be specified using a single quoted variable. In this example, it is the equivalent of quoting \texttt{\{r\ \#\ andom\_effect\ =\ \ (1\ \textbar{}\ hospital)}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
random_effect =  hospital 
colon_s %>%
    finalfit(dependent, explanatory, random_effect = random_effect,
                     dependent_label_suffix =   (random intercept) ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{mixed-effects-random-slope-model}{%
\subsection{2.15 Mixed effects random-slope model}\label{mixed-effects-random-slope-model}}

In the example below, allow the effect of age on outcome to vary by hospital. Note, this specification must have parentheses included.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
random_effect =  (age.factor | hospital) 
colon_s %>%
    finalfit(dependent, explanatory, random_effect = random_effect,
                     dependent_label_suffix =   (random slope: age) ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{mixed-effects-random-slope-model-directly-from-lme4}{%
\subsection{\texorpdfstring{2.16 Mixed effects random-slope model directly from \texttt{lme4}}{2.16 Mixed effects random-slope model directly from lme4}}\label{mixed-effects-random-slope-model-directly-from-lme4}}

Clearly, as models get more complex, parameters such as random effect group variances may require to be extracted directly from model outputs.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
random_effect =  (age.factor | hospital) 
colon_s %>% 
    lme4::glmer(mort_5yr ~ age.factor + (age.factor | hospital), family =  binomial , data = .) %>% 
    broom::tidy() -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{exclude-all-missing-data-in-final-model-from-univariable-analyses}{%
\subsection{2.17 Exclude all missing data in final model from univariable analyses}\label{exclude-all-missing-data-in-final-model-from-univariable-analyses}}

This can be useful if you want the numbers in the final table to match the final multivariable model. However, be careful to include a full explanation of this in the methods and the reason for exluding the missing data.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent = 'mort_5yr'
colon_s %>%
    dplyr::select(explanatory, dependent) %>%
    na.omit() %>%
    finalfit(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{linear-regression}{%
\subsection{2.18 Linear regression}\label{linear-regression}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent = 'nodes'
colon_s %>%
    finalfit(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{mixed-effects-random-intercept-linear-regression}{%
\subsection{2.19 Mixed effects random-intercept linear regression}\label{mixed-effects-random-intercept-linear-regression}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  nodes 
random_effect =  hospital 
colon_s %>%
    finalfit(dependent, explanatory, random_effect = random_effect,
                     dependent_label_suffix =   (random intercept) ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{mixed-effects-random-slope-linear-regression}{%
\subsection{2.20 Mixed effects random-slope linear regression}\label{mixed-effects-random-slope-linear-regression}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  nodes 
random_effect =  (age.factor | hospital) 
colon_s %>%
    finalfit(dependent, explanatory, random_effect = random_effect,
                     dependent_label_suffix =   (random slope: age) ) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{cox-proportional-hazards-model-survival-time-to-event}{%
\subsection{2.21 Cox proportional hazards model (survival / time to event)}\label{cox-proportional-hazards-model-survival-time-to-event}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  Surv(time, status) 
colon_s %>%
    finalfit(dependent, explanatory) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{cox-proportional-hazards-model-change-dependent-label}{%
\subsection{2.22 Cox proportional hazards model: change dependent label}\label{cox-proportional-hazards-model-change-dependent-label}}

As above, the dependent label cannot be specfied directly in the model to avoid errors. However, in survival modelling the surivial object specification can be long or awkward. Therefore, here is the work around.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  Surv(time, status) 
colon_s %>%
    finalfit(dependent, explanatory, add_dependent_label = FALSE) %>% 
    dplyr::rename( Overall survival  = label) %>% 
    dplyr::rename(    = levels) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{model-tables-manually-using-ff_merge}{%
\section{\texorpdfstring{3 Model tables manually using \texttt{ff\_merge()}}{3 Model tables manually using ff\_merge()}}\label{model-tables-manually-using-ff_merge}}

\hypertarget{basic-table}{%
\subsection{3.1 Basic table}\label{basic-table}}

Note \texttt{summary\_factorlist()} needs argument, \texttt{fit\_id\ =\ TRUE}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 

## Crosstable
colon_s %>%
    summary_factorlist(dependent, explanatory, fit_id=TRUE) -> table_1

## Univariable
colon_s %>%
    glmuni(dependent, explanatory) %>%
    fit2df(estimate_suffix=  (univariable) ) -> table_2

## Merge

table_1 %>% 
    ff_merge(table_2) %>% 
    select(-c(fit_id, index)) %>% 
    dependent_label(colon_s, dependent)-> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{complex-table-all-in-single-pipe}{%
\subsection{3.2 Complex table (all in single pipe)}\label{complex-table-all-in-single-pipe}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
random_effect =  hospital 
dependent =  mort_5yr 

# All in one pipe

colon_s %>%
    ## Crosstable
    summary_factorlist(dependent, explanatory, fit_id=TRUE)  %>% 
    
    ## Add univariable
    ff_merge(
        glmuni(colon_s, dependent, explanatory) %>%
            fit2df(estimate_suffix=  (univariable) )
    ) %>% 
    
    ## Add multivariable
    ff_merge(
        glmmulti(colon_s, dependent, explanatory) %>%
            fit2df(estimate_suffix=  (multivariable) )
    ) %>% 
    
    ## Add mixed effects
    ff_merge(
        glmmixed(colon_s, dependent, explanatory, random_effect) %>%
            fit2df(estimate_suffix=  (multilevel) ) 
    ) %>% 
    select(-c(fit_id, index)) %>% 
    dependent_label(colon_s, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{other-glm-models}{%
\subsection{3.3 Other GLM models}\label{other-glm-models}}

\hypertarget{poisson}{%
\subsubsection{Poisson}\label{poisson}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)

## Dobson (1990) Page 93: Randomized Controlled Trial :
counts = c(18,17,15,20,10,20,25,13,12)
outcome = gl(3,1,9)
treatment = gl(3,3)
d.AD <- data.frame(treatment, outcome, counts)

dependent =  counts 
explanatory = c( outcome ,  treatment )

fit_uni = d.AD %>% 
    glmuni(dependent, explanatory, family = poisson) %>% 
    fit2df(estimate_name =  Rate ratio (univariable) )

fit_multi = d.AD %>% 
    glmmulti(dependent, explanatory, family = poisson) %>% 
    fit2df(estimate_name =  Rate ratio (multivariable) )

# All in one pipe
d.AD %>%
    ## Crosstable
    summary_factorlist(dependent, explanatory, cont =  median , fit_id=TRUE)  %>% 
    
    ## Add univariable
    ff_merge(fit_uni, estimate_name =  Rate ratio ) %>% 
    
    ## Add multivariable
    ff_merge(fit_multi, estimate_name =  Rate ratio ) %>% 
    
    select(-c(fit_id, index)) %>% 
    dependent_label(d.AD, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{gamma}{%
\subsubsection{Gamma}\label{gamma}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)

# A Gamma example, from McCullagh & Nelder (1989, pp. 300-2)
clotting <- data.frame(
    u = c(5,10,15,20,30,40,60,80,100),
    lot1 = c(118,58,42,35,27,25,21,19,18),
    lot2 = c(69,35,26,21,18,16,13,12,12))

dependent =  lot1 
explanatory =  log(u) 

fit_uni = clotting %>% 
    glmuni(dependent, explanatory, family = Gamma) %>% 
    fit2df(estimate_name =  Coefficient , exp = FALSE, digits = c(3,3,4))

# All in one pipe
clotting %>%
    ## Crosstable
    summary_factorlist(dependent, explanatory, cont =  median , fit_id=TRUE)  %>% 
    
    ## Add fit
    ff_merge(fit_uni) %>% 
    
    select(-c(fit_id, index)) %>% 
    dependent_label(colon_s, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{weighted-regression}{%
\subsection{3.4 Weighted regression}\label{weighted-regression}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 
weights = runif(dim(colon_s)[1]) # random just for example

# All in one pipe
colon_s %>%
    ## Crosstable
    summary_factorlist(dependent, explanatory, fit_id=TRUE)  %>% 
    
    ## Add univariable
    ff_merge(
        glmuni(colon_s, dependent, explanatory, weights = weights, family = quasibinomial) %>%
            fit2df(estimate_suffix=  (univariable) )
    ) %>% 
    
    ## Add multivariable
    ff_merge(
        glmmulti(colon_s, dependent, explanatory, weights = weights, family = quasibinomial) %>%
            fit2df(estimate_suffix=  (multivariable) )
    ) %>% 
    select(-c(fit_id, index)) %>% 
    dependent_label(colon_s, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{using-base-r-functions}{%
\subsection{3.5 Using base R functions}\label{using-base-r-functions}}

Note \texttt{ff\_formula()} convenience function to make multivariable formula (\texttt{y\ \textasciitilde{}\ x1\ +\ x2\ +\ x3} etc.) from a \texttt{dependent} and \texttt{explanatory} vector of names.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)
explanatory = c( age.factor ,  sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 

# All in one pipe

colon_s %>%
    ## Crosstable
    summary_factorlist(dependent, explanatory, fit_id=TRUE)  %>% 
    
    ## Add univariable
    ff_merge(
        glmuni(colon_s, dependent, explanatory) %>%
            fit2df(estimate_suffix=  (univariable) )
    ) %>% 
    
    ## Add multivariable
    ff_merge(
        glm(
            ff_formula(dependent, explanatory), data = colon_s, family =  binomial , weights = NULL
        ) %>%
            fit2df(estimate_suffix=  (multivariable) )
    ) %>% 
    
    select(-c(fit_id, index)) %>% 
    dependent_label(colon_s, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{edit-table-rows}{%
\subsection{3.6 Edit table rows}\label{edit-table-rows}}

This can be done as any dataframe would be edited.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)
explanatory = c( age.factor*sex.factor ,  obstruct.factor ,  perfor.factor )
dependent =  mort_5yr 

# Run model for term test
fit <- glm(
    ff_formula(dependent, explanatory), 
    data=colon_s, family = binomial
)

# Not run
#term_test <- survey::regTermTest(fit,  age.factor:sex.factor )

# Run final table with results of term test
colon_s %>%
    finalfit(dependent, explanatory) %>%
    rbind(c(
         age.factor:sex.factor (overall) ,
         Interaction ,
         - ,
         - ,
         - ,
        paste0( p = 0.775 )
    ))-> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{base-model-individual-explanatory-variables}{%
\subsection{3.7 Base model + individual explanatory variables}\label{base-model-individual-explanatory-variables}}

This was an email enquiry about how to build on a base model. The example request was in a survival context.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(finalfit)
library(dplyr)

mydata = colon_s
base_explanatory = c( age.factor ,  sex.factor )
explanatory = c( obstruct.factor ,  perfor.factor ,  node4.factor )
dependent =  Surv(time, status) 

mydata %>%
    # Counts
    summary_factorlist(dependent, c(base_explanatory,
                                                                    explanatory),
                                         column = TRUE,
                                         fit_id = TRUE) %>% 
    
    # Univariable
    ff_merge(
        coxphuni(mydata, dependent, c(base_explanatory, explanatory)) %>% 
            fit2df(estimate_suffix =   (Univariable) )
    ) %>% 
    
    # Base
    ff_merge(
        coxphmulti(mydata, dependent, base_explanatory) %>% 
            fit2df(estimate_suffix =   (Base model) )
    ) %>% 
    
    # Model 1
    ff_merge(
        coxphmulti(mydata, dependent, c(base_explanatory, explanatory[1])) %>% 
            fit2df(estimate_suffix =   (Model 1) )
    ) %>% 
    
    # Model 2
    ff_merge(
        coxphmulti(mydata, dependent, c(base_explanatory, explanatory[2])) %>% 
            fit2df(estimate_suffix =   (Model 2) )
    ) %>% 
    
    # Model 3
    ff_merge(
        coxphmulti(mydata, dependent, c(base_explanatory, explanatory[3])) %>% 
            fit2df(estimate_suffix =   (Model 3) )
    ) %>% 
    
    # Full
    ff_merge(
        coxphmulti(mydata, dependent, c(base_explanatory, explanatory)) %>% 
            fit2df(estimate_suffix =   (Full) )
    ) %>% 
    
    # Tidy-up
    select(-c(fit_id, index)) %>% 
    rename( Overall survival  = label) %>% 
    rename(    = levels) %>% 
    rename(`n (%)` = all) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{support-for-complex-survey-structures-via-librarysurvey}{%
\section{\texorpdfstring{4 Support for complex survey structures via \texttt{library(survey)}}{4 Support for complex survey structures via library(survey)}}\label{support-for-complex-survey-structures-via-librarysurvey}}

\hypertarget{linear-regression-1}{%
\subsection{4.1 Linear regression}\label{linear-regression-1}}

Examples taken from \texttt{survey::svyglm()} help page.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(survey)
library(dplyr)

data(api)
dependent =  api00 
explanatory = c( ell ,  meals ,  mobility )

# Label data frame
apistrat = apistrat %>%
  mutate(
  api00 = ff_label(api00,  API in 2000 (api00) ),
  ell = ff_label(ell,  English language learners (percent)(ell) ),
  meals = ff_label(meals,  Meals eligible (percent)(meals) ),
  mobility = ff_label(mobility,  First year at the school (percent)(mobility) ),
  sch.wide = ff_label(sch.wide,  School-wide target met (sch.wide) )
  )

# Linear example
dependent =  api00 
explanatory = c( ell ,  meals ,  mobility )

# Stratified design
dstrat = svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)

# Univariable fit
fit_uni = dstrat %>%
  svyglmuni(dependent, explanatory) %>%
  fit2df(estimate_suffix =   (univariable) )

# Multivariable fit
fit_multi = dstrat %>%
  svyglmmulti(dependent, explanatory) %>%
  fit2df(estimate_suffix =   (multivariable) )

# Pipe together
apistrat %>%
  summary_factorlist(dependent, explanatory, fit_id = TRUE) %>%
  ff_merge(fit_uni) %>%
  ff_merge(fit_multi) %>%
  select(-fit_id, -index) %>%
  dependent_label(apistrat, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{binomial-example}{%
\subsection{4.2 Binomial example}\label{binomial-example}}

Note model family needs specified and exponentiation set to \texttt{TRUE} if desired.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
library(survey)
library(dplyr)

data(api)
dependent =  sch.wide 
explanatory = c( ell ,  meals ,  mobility )

# Label data frame
apistrat = apistrat %>%
  mutate(
  api00 = ff_label(api00,  API in 2000 (api00) ),
  ell = ff_label(ell,  English language learners (percent)(ell) ),
  meals = ff_label(meals,  Meals eligible (percent)(meals) ),
  mobility = ff_label(mobility,  First year at the school (percent)(mobility) ),
  sch.wide = ff_label(sch.wide,  School-wide target met (sch.wide) )
  )
  
# Univariable fit
fit_uni = dstrat %>%
  svyglmuni(dependent, explanatory, family =  quasibinomial ) %>%
  fit2df(exp = TRUE, estimate_name =  OR , estimate_suffix =   (univariable) )

# Multivariable fit
fit_multi = dstrat %>%
  svyglmmulti(dependent, explanatory, family =  quasibinomial ) %>%
  fit2df(exp = TRUE, estimate_name =  OR , estimate_suffix =   (multivariable) )

# Pipe together
apistrat %>%
  summary_factorlist(dependent, explanatory, fit_id = TRUE) %>%
  ff_merge(fit_uni) %>%
  ff_merge(fit_multi) %>%
  select(-fit_id, -index) %>%
  dependent_label(apistrat, dependent) -> t
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
kable(t, row.names=FALSE, align = c( l ,  l ,  r ,  r ,  r ,  r ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{finalfit}{%
\chapter{finalfit}\label{finalfit}}

\begin{verbatim}
devtools::install_github( ewenharrison/finalfit )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
library(dplyr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dependent <-  differ.factor 

# Specify explanatory variables of interest
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  obstruct.factor , 
   nodes )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# colon_s %>%
#   select(age, sex.factor, 
#   extent.factor, obstruct.factor, nodes) %>% 
#   names() -> explanatory
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Hmisc::label(colon_s$nodes) <-  Lymph nodes involved 
explanatory = c( age ,  sex.factor , 
   extent.factor ,  nodes )

colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE, 
  add_dependent_label=TRUE) -> table1

table1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  nodes , 
   differ.factor )
dependent <-  mort_5yr 

colon_s %>% 
  finalfit(dependent = dependent, explanatory = explanatory, fit_id=TRUE, 
  dependent_label_prefix =   ) -> table2

kableExtra::kable(table2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  or_plot(dependent, explanatory, 
  breaks = c(0.5, 1, 5, 10, 20, 30))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Save objects for knitr/markdown
save(table1, table2, dependent, explanatory, file =  out.rda )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load data into global environment. 
library(finalfit)
library(dplyr)
library(knitr)
load( out.rda )
\end{verbatim}

\hypertarget{table-1---demographics}{%
\section{Table 1 - Demographics}\label{table-1---demographics}}

\begin{verbatim}
{r table1x, echo = TRUE, results='asis'}
kable(table1, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{table-2---association-between-tumour-factors-and-5-year-mortality}{%
\section{Table 2 - Association between tumour factors and 5 year mortality}\label{table-2---association-between-tumour-factors-and-5-year-mortality}}

\begin{verbatim}
{r table2x, echo = TRUE, results='asis'}
kable(table2, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{figure-1---association-between-tumour-factors-and-5-year-mortality}{%
\section{Figure 1 - Association between tumour factors and 5 year mortality}\label{figure-1---association-between-tumour-factors-and-5-year-mortality}}

\begin{verbatim}
{r figure1x, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
colon_s %>% 
  or_plot(dependent, explanatory)
\end{verbatim}

\hypertarget{finalfit-1}{%
\chapter{finalfit}\label{finalfit-1}}

\begin{verbatim}
devtools::install_github( ewenharrison/finalfit )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
library(dplyr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dependent <-  differ.factor 

# Specify explanatory variables of interest
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  obstruct.factor , 
   nodes )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# colon_s %>%
#   select(age, sex.factor, 
#   extent.factor, obstruct.factor, nodes) %>% 
#   names() -> explanatory
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Hmisc::label(colon_s$nodes) <-  Lymph nodes involved 
explanatory = c( age ,  sex.factor , 
   extent.factor ,  nodes )

colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE, 
  add_dependent_label=TRUE) -> table1

table1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  nodes , 
   differ.factor )
dependent <-  mort_5yr 

colon_s %>% 
  finalfit(dependent = dependent, explanatory = explanatory, fit_id=TRUE, 
  dependent_label_prefix =   ) -> table2

kableExtra::kable(table2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  or_plot(dependent, explanatory, 
  breaks = c(0.5, 1, 5, 10, 20, 30))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Save objects for knitr/markdown
save(table1, table2, dependent, explanatory, file =  out.rda )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load data into global environment. 
library(finalfit)
library(dplyr)
library(knitr)
load( out.rda )
\end{verbatim}

\hypertarget{table-1---demographics-1}{%
\section{Table 1 - Demographics}\label{table-1---demographics-1}}

\begin{verbatim}
{r table1 4, echo = TRUE, results='asis'}
kable(table1, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{table-2---association-between-tumour-factors-and-5-year-mortality-1}{%
\section{Table 2 - Association between tumour factors and 5 year mortality}\label{table-2---association-between-tumour-factors-and-5-year-mortality-1}}

\begin{verbatim}
{r table2 4, echo = TRUE, results='asis'}
kable(table2, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{figure-1---association-between-tumour-factors-and-5-year-mortality-1}{%
\section{Figure 1 - Association between tumour factors and 5 year mortality}\label{figure-1---association-between-tumour-factors-and-5-year-mortality-1}}

\begin{verbatim}
{r figure1 4, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
colon_s %>% 
  or_plot(dependent, explanatory)
\end{verbatim}

\hypertarget{example-knitrr-markdown-document}{%
\chapter{Example knitr/R Markdown document}\label{example-knitrr-markdown-document}}

author: Ewen Harrison
date: 21/5/2018
output:
pdf\_document: default
geometry: margin=0.75in

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load data into global environment. 
library(finalfit)
library(dplyr)
library(knitr)
library(kableExtra)
load( out.rda )
\end{verbatim}

\hypertarget{table-1---demographics-2}{%
\section{Table 1 - Demographics}\label{table-1---demographics-2}}

\begin{verbatim}
{r table1 3, echo = TRUE, results='asis'}
kable(table1, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ),
                        booktabs=TRUE)
\end{verbatim}

\hypertarget{table-2---association-between-tumour-factors-and-5-year-mortality-2}{%
\section{Table 2 - Association between tumour factors and 5 year mortality}\label{table-2---association-between-tumour-factors-and-5-year-mortality-2}}

\begin{verbatim}
{r table2 3, eval=FALSE, include=FALSE, results='asis'}
kable(table2, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ),
            booktabs=TRUE) %>% 
    kable_styling(font_size=8)
\end{verbatim}

\hypertarget{figure-1---association-between-tumour-factors-and-5-year-mortality-2}{%
\section{Figure 1 - Association between tumour factors and 5 year mortality}\label{figure-1---association-between-tumour-factors-and-5-year-mortality-2}}

\begin{verbatim}
{r figure1-, warning=FALSE, message=FALSE, fig.width=10, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
colon_s %>% 
  or_plot(dependent, explanatory)
\end{verbatim}

\hypertarget{finalfit-2}{%
\chapter{finalfit}\label{finalfit-2}}

\begin{verbatim}
devtools::install_github( ewenharrison/finalfit )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
library(dplyr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dependent <-  differ.factor 

# Specify explanatory variables of interest
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  obstruct.factor , 
   nodes )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# colon_s %>%
#   select(age, sex.factor, 
#   extent.factor, obstruct.factor, nodes) %>% 
#   names() -> explanatory
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Hmisc::label(colon_s$nodes) <-  Lymph nodes involved 
explanatory = c( age ,  sex.factor , 
   extent.factor ,  nodes )

colon_s %>% 
  summary_factorlist(dependent, explanatory, 
  p=TRUE, na_include=FALSE, 
  add_dependent_label=TRUE) -> table1

table1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory <- c( age ,  sex.factor , 
   extent.factor ,  nodes , 
   differ.factor )
dependent <-  mort_5yr 

colon_s %>% 
  finalfit(dependent = dependent, explanatory = explanatory, fit_id=TRUE, 
  dependent_label_prefix =   ) -> table2

kableExtra::kable(table2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon_s %>% 
  or_plot(dependent, explanatory, 
  breaks = c(0.5, 1, 5, 10, 20, 30))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Save objects for knitr/markdown
save(table1, table2, dependent, explanatory, file =  out.rda )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load data into global environment. 
library(finalfit)
library(dplyr)
library(knitr)
load( out.rda )
\end{verbatim}

\hypertarget{table-1---demographics-3}{%
\section{Table 1 - Demographics}\label{table-1---demographics-3}}

\begin{verbatim}
{r table1y 2, echo = TRUE, results='asis'}
kable(table1, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{table-2---association-between-tumour-factors-and-5-year-mortality-3}{%
\section{Table 2 - Association between tumour factors and 5 year mortality}\label{table-2---association-between-tumour-factors-and-5-year-mortality-3}}

\begin{verbatim}
{r table2 2, echo = TRUE, results='asis'}
kable(table2, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{figure-1---association-between-tumour-factors-and-5-year-mortality-3}{%
\section{Figure 1 - Association between tumour factors and 5 year mortality}\label{figure-1---association-between-tumour-factors-and-5-year-mortality-3}}

\begin{verbatim}
{r figure1, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
colon_s %>% 
  or_plot(dependent, explanatory)
\end{verbatim}

\hypertarget{r-notebook}{%
\chapter{R Notebook}\label{r-notebook}}

\hypertarget{flipping-coin-1}{%
\section{Flipping Coin}\label{flipping-coin-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rbinom(n = 1, size = 1, prob = 0.5)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rbinom(n = 10, size = 1, prob = 0.5)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rbinom(n = 1, size = 10, prob = 0.5)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rbinom(n = 100, size = 100, prob = 0.5)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rbinom(n = 10, size = 10, prob = 0.3)
\end{verbatim}

\hypertarget{formattable}{%
\chapter{formattable}\label{formattable}}

\url{https://www.littlemissdata.com/blog/prettytables}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(data.table)
library(dplyr)
library(formattable)
library(tidyr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#Set a few color variables to make our table more visually appealing
customGreen0 =  #DeF7E9 
customGreen =  #71CA97 
customRed =  #ff7f7f 
\end{verbatim}

\hypertarget{general-linear-models-1}{%
\chapter{General Linear Models}\label{general-linear-models-1}}

\hypertarget{alternatives-to-the-default-r-outputs-for-glms-and-linear-models}{%
\chapter{5 Alternatives to the Default R Outputs for GLMs and Linear Models}\label{alternatives-to-the-default-r-outputs-for-glms-and-linear-models}}

\url{https://www.displayr.com/5-alternatives-to-the-default-r-outputs-for-glms-and-linear-models/?utm_medium=Feed\&utm_source=Syndication}

\hypertarget{classic-output}{%
\section{Classic Output}\label{classic-output}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
churn <- read.csv( https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv )
my.glm <- glm(Churn ~ SeniorCitizen + tenure + InternetService + MonthlyCharges,
             data = churn, 
             family = binomial(logit))
summary(my.glm)
\end{verbatim}

\hypertarget{stargazer}{%
\section{stargazer}\label{stargazer}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
write(stargazer::stargazer(my.glm, type =  html ),  stargazer.html )
\end{verbatim}

\hypertarget{formattable-1}{%
\section{formattable}\label{formattable-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(formattable)
my.glm
\end{verbatim}

\hypertarget{flipregression}{%
\section{flipRegression}\label{flipregression}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( Displayr/flipPlots )
# devtools::install_github( Displayr/flipRegression )
library(flipPlots)
library(flipRegression)
my.regression <- Regression(Churn ~ SeniorCitizen + tenure + InternetService + MonthlyCharges,
                           data = churn,
                           show.labels = TRUE,
                           type = Binary Logit )

my.regression
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(flipRegression)
Regression(Churn ~ SeniorCitizen + tenure + InternetService + MonthlyCharges,
           data = churn,
           show.labels = TRUE,
           output =  Relative Importance Analysis ,
           type = Binary Logit )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(effects)
my.glm = glm(Churn ~ SeniorCitizen + tenure + InternetService + MonthlyCharges,
             data = churn, 
             family = binomial(logit))
effects = allEffects(my.glm)
plot(effects,
     col = 2,
     ylab =  Probability(Churn) , 
     ylim = c(0, .6),  
     type =  response )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(httr)
# GET( https://docs.displayr.com/images/f/f0/Churn.xlsx , 
    # write_disk(tf <- tempfile(fileext =  .xlsx )))
# df <- readxl::read_excel(tf, 1L)
library(mgcv)
my.gam <- gam(Churn ~ SeniorCitizen + s(tenure) + InternetService + s(MonthlyCharges), 
                data = churn, 
                family = binomial(logit))


my.gam
\end{verbatim}

\hypertarget{building-online-interactive-simulators-for-predictive-models-in-r}{%
\subsection{Building Online Interactive Simulators for Predictive Models in R}\label{building-online-interactive-simulators-for-predictive-models-in-r}}

\url{https://www.displayr.com/building-online-interactive-simulators-for-predictive-models-in-r/}

\hypertarget{general-resources-1}{%
\chapter{General Resources}\label{general-resources-1}}

\hypertarget{data-science-live-book-1}{%
\chapter{Data Science Live Book}\label{data-science-live-book-1}}

\url{https://livebook.datascienceheroes.com/}

\url{https://toolbox.google.com/datasetsearch}

\url{http://archive.ics.uci.edu/ml/index.php}

\url{http://asdfree.com/}

\url{https://rstudio-education.github.io/hopr/}

\begin{itemize}
\tightlist
\item
  \textbf{What I Wish I Knew When I Started R}
\end{itemize}

\url{https://www.williamrchase.com/slides/intro_r_anthropology_2018}

\url{https://sbalci.gitbooks.io/pathology-notes/content/pathology-residents/computational-pathology.html}

\url{http://web.stanford.edu/class/bios221/book/}

\url{https://kbroman.org/minimal_make/}

\url{https://www.gnu.org/software/make/}

\url{https://kbroman.org/minimal_make/}

\url{https://www}..com/community/tutorials/shell-commands-data-scientist

\url{https://moderndive.com/3-viz.html}

\url{https://www.causeweb.org/cause/ecots/ecots18/breakouts/7}

\url{https://plotly-book.cpsievert.me/}

\url{http://r-bio.github.io/01-intro-R/}

\url{https://www.rdatagen.net/post/by-vs-within/?platform=hootsuite}

\url{http://www.biomart.org/download.html}

\url{https://ropensci.org/blog/2018/07/24/educollab-challenges/}

\url{https://www}..com/community/tutorials/data-science-pitfalls

\url{https://serialmentor.com/dataviz/preface.html}

\begin{itemize}
\item
  \url{https://news.codecademy.com/errors-in-code-think-differently/?utm_source=customer.io\&utm_medium=email\&utm_campaign=fortnightly_8-1-18\&utm_content=ErrorFortnightly}
\item
  Data Science Live Book
\end{itemize}

\url{https://livebook.datascienceheroes.com/}

\begin{itemize}
\item
  School of Psychology at the University of New South Wales \url{http://www.compcogscisydney.org/teaching/}

  \begin{itemize}
  \item
    Of Minds and Machines
    \url{http://www.compcogscisydney.org/mm/}
  \item
    psyr: Using R in Psychological Science
    \url{http://www.compcogscisydney.org/psyr/}
  \item
    Perception and Cognition
    \url{http://www.compcogscisydney.org/psyc2071/}
  \item
    Learning Statistics with R
    \url{http://www.compcogscisydney.org/learning-statistics-with-r/}
  \item
    Computational Cognitive Science
    \url{http://www.compcogscisydney.org/ccs/}
  \end{itemize}
\item
  Advanced R
\end{itemize}

\url{https://adv-r.hadley.nz/}

\begin{itemize}
\tightlist
\item
  One Page R
\end{itemize}

\url{https://togaware.com/onepager/}

\begin{itemize}
\tightlist
\item
  htmlwidgets for R
\end{itemize}

\url{http://www.htmlwidgets.org/}

\url{http://gallery.htmlwidgets.org/}

\begin{itemize}
\tightlist
\item
  Learning R for Clinical Epidemiologists
\end{itemize}

\url{http://rpubs.com/michaelmarks/R-Clin-Epi}

\begin{itemize}
\tightlist
\item
  r-tutor
\end{itemize}

\url{http://www.r-tutor.com/}

\begin{itemize}
\tightlist
\item
  Statistics Meets Big Data
\end{itemize}

\url{http://www.statsoft.org/}

\begin{itemize}
\tightlist
\item
  ModernDive
\end{itemize}

\url{https://moderndive.com/}

\begin{itemize}
\tightlist
\item
  Laerd Statistics
\end{itemize}

\url{https://statistics.laerd.com/}

\begin{itemize}
\tightlist
\item
  statpages
\end{itemize}

\url{http://statpages.info/index.html}

\begin{itemize}
\tightlist
\item
  The R class R programming for biologists
\end{itemize}

\url{http://r-bio.github.io/}

\begin{itemize}
\tightlist
\item
  Sosyal Bilimler Ara≈ütƒ±rmalarƒ± ƒ∞√ßin R
\end{itemize}

\url{https://bookdown.org/connect/\#/apps/1531/access}

\begin{itemize}
\tightlist
\item
  R for Psychological Science An introductory resource
\end{itemize}

\url{http://compcogscisydney.org/psyr/}

\begin{itemize}
\tightlist
\item
  Jamovi tutorial
\end{itemize}

\url{https://datalab.cc/tools/jamovi}

\url{https://www.youtube.com/playlist?list=PLkk92zzyru5OAtc_ItUubaSSq6S_TGfRn}

\hypertarget{master-course-links}{%
\section{master course links}\label{master-course-links}}

\hypertarget{do-more-with-r}{%
\chapter{Do More with R}\label{do-more-with-r}}

\url{https://www.infoworld.com/video/series/8563/do-more-with-r}

\hypertarget{my-r-codes-for-data-analysis-6}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-6}}

\hypertarget{getting-data-into-r-veriyi-ra-yuxfckleme-1}{%
\chapter{Getting Data into R / Veriyi R'a y√ºkleme}\label{getting-data-into-r-veriyi-ra-yuxfckleme-1}}

\hypertarget{import-data}{%
\section{Import Data}\label{import-data}}

\hypertarget{import-using-rstudio}{%
\subsection{Import using RStudio}\label{import-using-rstudio}}

\hypertarget{import-csv-file}{%
\subsection{Import CSV File}\label{import-csv-file}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
scabies <- read.csv(file =  http://datacompass.lshtm.ac.uk/607/2/S1-Dataset_CSV.csv , header = TRUE, sep =  , )
scabies
\end{verbatim}

\hypertarget{how-to-import-multiple-.csv-files-at-once}{%
\subsubsection{How to import multiple .csv files at once?}\label{how-to-import-multiple-.csv-files-at-once}}

\url{https://stackoverflow.com/questions/11433432/how-to-import-multiple-csv-files-at-once}

\begin{verbatim}
temp = list.files(pattern= *.csv )
myfiles = lapply(temp, read.delim)

temp = list.files(pattern= *.csv )
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))

temp = list.files(pattern= *.csv )
list2env(
  lapply(setNames(temp, make.names(gsub( *.csv$ ,   , temp))), 
         read.csv), envir = .GlobalEnv)
\end{verbatim}

\begin{verbatim}
# Get the files names
files = list.files(pattern= *.csv )
# First apply read.csv, then rbind
myfiles = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
\end{verbatim}

\begin{verbatim}
library(data.table)
DT = do.call(rbind, lapply(files, fread))
# The same using `{r # bindlist`
DT = rbindlist(lapply(files, fread))
\end{verbatim}

\begin{verbatim}
library(readr)
library(dplyr)
tbl = lapply(files, read_csv) %>% bind_rows()
\end{verbatim}

\begin{verbatim}
data <- read.csv(
  switch(animal, 
          dog  =  dogdata.csv , 
          cat  =  catdata.csv ,
          rabbit  =  rabbitdata.csv )
)
\end{verbatim}

\hypertarget{import-txt-file}{%
\subsection{Import TXT File}\label{import-txt-file}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ebola <- read.csv(file =  http://datacompass.lshtm.ac.uk/608/1/mmc1.txt , header = TRUE, sep =  , )
ebola
\end{verbatim}

\hypertarget{import-excel-file}{%
\subsection{Import Excel File}\label{import-excel-file}}

\begin{verbatim}
my_data <- read_excel(file.choose())


files <- list.files(pattern =  .xlsx )

data_xlsx_df <- map_df(set_names(files), function(file) {
  file %>% 
    excel_sheets() %>% 
    set_names() %>% 
    map_df(
      ~ read_xlsx(path = file, sheet = .x, range =  H3 ),
      .id =  sheet )
}, .id =  file )
\end{verbatim}

\hypertarget{import-sheets}{%
\subsubsection{Import Sheets}\label{import-sheets}}

\hypertarget{import-spss-file}{%
\subsection{Import SPSS File}\label{import-spss-file}}

\hypertarget{keep-spss-labels}{%
\subsection{Keep SPSS labels}\label{keep-spss-labels}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(foreign) # foreign paketi y√ºkleniyor
\end{verbatim}

read.spss komutu ile deƒüer etiketlerini almasƒ±nƒ± ve bunu liste olarak deƒüil de data.frame olarak kaydetmesini istiyoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mydata <- read.spss( mydata.sav , use.value.labels = TRUE, to.data.frame = TRUE)
\end{verbatim}

aktardƒ±ƒüƒ±mƒ±z data.frame'in √∂zellikleri (attr) i√ßinde deƒüi≈ükenlerin etiketleri var, bunlarƒ± dƒ±≈üarƒ± √ßƒ±kartƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels <- as.data.frame(attr(mydata,  variable.labels ))
\end{verbatim}

elde ettiƒüimiz data.frame'deki satƒ±r isimleri deƒüi≈ükenlerin isimleri oluyor, kar≈üƒ±larƒ±nda da deƒüi≈üken etiketleri var
satƒ±r isimlerini de dƒ±≈üarƒ± √ßƒ±kartƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels$original <- rownames(VariableLabels)
\end{verbatim}

Deƒüi≈üken etiketi olanlarƒ± etiketleri ile diƒüerlerini olduƒüu gibi saklƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels$label[VariableLabels$label ==  ] <- NA 
VariableLabels$colname <- VariableLabels$original
VariableLabels$colname[!is.na(VariableLabels$label)] <- as.vector(VariableLabels$label[!is.na(VariableLabels$label)])
\end{verbatim}

son olarak da data.frame'deki s√ºtun isimlerini deƒüi≈ütiriyoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
names(mydata) <- VariableLabels$colname
\end{verbatim}

\hypertarget{export-data}{%
\chapter{Export Data}\label{export-data}}

\hypertarget{export-to-spss-while-keeping-labels}{%
\subsection{Export to SPSS, while keeping labels}\label{export-to-spss-while-keeping-labels}}

R'da \texttt{factor} olan label verdiƒüiniz deƒüi≈ükenleri \texttt{SPSS} ya da diƒüer istatistik programlarƒ±na aktardƒ±ƒüƒ±nƒ±zda bu tanƒ±mlamalarƒ± korumak i≈üimize yarar. Bunun i√ßin \texttt{foreign} paketi ile bir \texttt{txt} dosyasƒ± ve bir \texttt{sps} dosyasƒ± olu≈üturuyoruz. SPSS'te \texttt{sps} dosyasƒ±nƒ± a√ßƒ±p kodu √ßalƒ±≈ütƒ±rarak tekrar atanan deƒüerler geri y√ºkleniyor.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(foreign)
write.foreign(mydata,  mydata.txt ,  mydata.sps ,   package =  SPSS )
\end{verbatim}

\url{https://twitter.com/WeAreRLadies/status/1034817323922804737}

\begin{verbatim}
f <- list.files(  my_folder , pattern =  *.csv , full.names = TRUE)
d <- purrr::map_df(f, readr::read_csv, .id =  id )
\end{verbatim}

\begin{verbatim}
m <- lm(mpg ~ qsec + wt, data = mtcars)
broom::tidy(m)
\end{verbatim}

Import a Directory of CSV Files at Once Using \{purrr\} and \{readr\}

\url{https://www.gerkelab.com/blog/2018/09/import-directory-csv-purrr-readr/}

\begin{verbatim}
data_dir %>% 
  dir_ls(regexp =  \\.csv$ ) %>% 
  map_dfr(read_csv, .id =  source ) %>% 
  mutate(Month_Year = myd(Month_Year, truncated = 1))
\end{verbatim}

\url{https://suatatan.wordpress.com/2017/10/07/bulk-replacing-turkish-characters-in-r/}

Turkish character sometimes became the menace for the data scientist. To avoid the risks you may want to change it with safe characters. To do that you can use this code:

\begin{verbatim}
#turkce karakter donusumu
to.plain <- function(s) {

# 1 character substitutions
old1 <- ‚Äú√ßƒü≈üƒ±√º√∂√áƒû≈ûƒ∞√ñ√ú‚Äù
new1 <- ‚Äúcgsiuocgsiou‚Äù
s1 <- chartr(old1, new1, s)

# 2 character substitutions
old2 <- c(‚Äú≈ì‚Äù, ‚Äú√ü‚Äù, ‚Äú√¶‚Äù, ‚Äú√∏‚Äù)
new2 <- c(‚Äúoe‚Äù, ‚Äúss‚Äù, ‚Äúae‚Äù, ‚Äúoe‚Äù)
s2 <- s1
for(i in seq_along(old2)) s2 <- gsub(old2[i], new2[i], s2, fixed = TRUE)

s2
}
df$source=as.vector(sapply(df$source,to.plain))


to.plain(make.names(tolower(names(df))))
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Remove all special characters from a string in R?
\end{itemize}

\url{https://stackoverflow.com/questions/10294284/remove-all-special-characters-from-a-string-in-r}

\begin{verbatim}
x <-  a1~!@#$%^&*(){}_+:\ <>?,./;'[]-= 
stringr::str_replace_all(x,  [[:punct:]] ,    )
stringr::str_replace_all(x,  [^[:alnum:]] ,    )
\end{verbatim}

\begin{verbatim}
astr <-  √Åbcd√™√£√ßo√†√∫√º 
iconv(astr, from = 'UTF-8', to = 'ASCII//TRANSLIT')
\end{verbatim}

\begin{verbatim}
Data  <- gsub( [^0-9A-Za-z///' ] , '  , Data ,ignore.case = TRUE)

Data <- gsub( '' ,   , Data ,ignore.case = TRUE)
\end{verbatim}

\hypertarget{pdftables}{%
\chapter{pdftables}\label{pdftables}}

\url{https://cran.r-project.org/web/packages/pdftables/vignettes/convert_pdf_tables.html}

\hypertarget{tabulizer}{%
\chapter{tabulizer}\label{tabulizer}}

Extract Tables from PDFs

\url{https://github.com/ropensci/tabulizer}

\hypertarget{rio}{%
\chapter{rio}\label{rio}}

Import, Export, and Convert Data Files

\url{https://thomasleeper.com/rio/index.html}

\url{https://cran.r-project.org/web/packages/rio/vignettes/rio.html}

\hypertarget{read-with-purrr}{%
\chapter{read with purrr}\label{read-with-purrr}}

R tip: Iterate with purrr's map\_df function

\url{https://www.infoworld.com/video/89075/r-tip-iterate-with-purrrs-map-df-function}

\hypertarget{the-janitor-package}{%
\chapter{The janitor package}\label{the-janitor-package}}

\url{https://garthtarr.github.io/meatR/janitor.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( janitor )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
library(janitor)
library(xlsx)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# mymsa <-  data.table::fread( https://garthtarr.com/data/mymsa.xlsx , fill = TRUE)
mymsa <-  read_excel( data/mymsa.xlsx )
mymsa$√ßƒü≈ü√º√∂ <- 2
x <-  janitor::clean_names(mymsa)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data.frame(mymsa = colnames(mymsa), x = colnames(x))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tabyl(x, meat_colour) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(x$meat_colour)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load dplyr for the %>% pipe 
library(dplyr)
x %>% tabyl(meat_colour) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% 
  tabyl(meat_colour) %>% 
  adorn_pct_formatting(digits = 0, affix_sign = TRUE) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% tabyl(spare)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x = remove_empty(x, which = c( rows , cols ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x = read_excel( data/mymsa.xlsx ) %>% 
  clean_names() %>% remove_empty()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% tabyl(meat_colour, plant) %>%
  knitr::kable()

# can also make 3 way tables
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# row totals
x %>% 
  tabyl(meat_colour, plant) %>% 
  adorn_totals(where =  row ) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# column totals
x %>% 
  tabyl(meat_colour, plant) %>% 
  adorn_totals(where =  col ) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# row and column totals
x %>% 
  tabyl(meat_colour, plant) %>% 
  adorn_totals(where = c( row , col ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% 
  tabyl(meat_colour, plant) %>% 
  adorn_totals(where = c( row , col )) %>% 
  adorn_percentages(denominator =  col ) %>% 
  adorn_pct_formatting(digits = 0) 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% 
  tabyl(meat_colour, plant) %>% 
  adorn_totals(where = c( row , col )) %>% 
  adorn_percentages(denominator =  col ) %>% 
  adorn_pct_formatting(digits = 0) %>% 
  adorn_ns(position =  front )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
adorn_cumulative <- function(dat, colname, dir =  down ){

  if(!missing(colname)){
    colname <- rlang::enquo(colname)
  } else if( valid_percent  %in% names(dat)) {
  colname <- rlang::sym( valid_percent )
  } else if( percent  %in% names(dat)){
    colname <- rlang::sym( percent )
  } else {
    stop( \ colname\  not specified and default columns valid_percent and percent are not present in data.frame dat )
  }

  target <- dplyr::pull(dat, !! colname)

  if(dir ==  up ){
    target <- rev(target)
  }
  dat$cumulative <- cumsum(ifelse(is.na(target), 0, target)) + target*0 # an na.rm version of cumsum, from https://stackoverflow.com/a/25576972
  if(dir ==  up ){
    dat$cumulative <- rev(dat$cumulative)
    names(dat)[names(dat) %in%  cumulative ] <-  cumulative_up 
  }
  dat
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x %>% get_dupes(rfid)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x1 = x %>% slice(1:3)
x2 = bind_rows(x1,x)
x2 %>% get_dupes(rfid)
\end{verbatim}

\hypertarget{convert-excel-number-into-date}{%
\section{convert excel number into date}\label{convert-excel-number-into-date}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
janitor::excel_numeric_to_date(41103)
\end{verbatim}

\begin{verbatim}
output:
  pdf_document: default
  html_document: default
header-includes:
- \usepackage{pdflscape}
- \usepackage{xcolor}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
\end{verbatim}

\hypertarget{ggplot2--}{%
\chapter{ggplot2 -}\label{ggplot2--}}

mpg

\begin{verbatim}
{r, background='#fff5e6'}
library( tidyverse )
ggplot(mpg) + 
    geom_point(aes(x = displ, y = hwy))
\end{verbatim}

ggplot(mpg, aes(model, manufacturer)) + geom\_point()

ggplot(mpg, aes(displ, cty, colour = year)) +
geom\_point()

ggplot(mpg, aes(displ, hwy)) +
geom\_point(aes(shape = year))

ggplot(mpg, aes(displ, hwy)) +
geom\_point() +
geom\_smooth(span = 0.2)

ggplot(mpg, aes(hwy)) +
geom\_histogram() +
geom\_freqpoly()

ggplot(mpg, aes(cty, hwy)) +
geom\_point() +
geom\_smooth()

ggplot(mpg, aes(class, hwy)) + geom\_boxplot()
ggplot(mpg, aes(reorder(class, hwy), hwy)) + geom\_boxplot()

\hypertarget{gganimate--}{%
\chapter{gganimate -}\label{gganimate--}}

library(gganimate)

p \textless- ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) +
geom\_point()

plot(p)

anim \textless- p +
transition\_states(Species,
transition\_length = 2,
state\_length = 1)

anim

p +
enter\_appear()

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
sometext <-strsplit(
    paste0( You can even try to make some crazy things like this paragraph.  , It may seem like a useless feature right now but it's so cool  , and nobody can resist. ;) ),    )[[1]]

text_formatted <-paste(
    kableExtra::text_spec(sometext,
               latex ,
              color = kableExtra::spec_color(1:length(sometext), end = 0.9),
              font_size =kableExtra::spec_font_size(1:length(sometext), begin = 5, end = 20)),collapse =    )

mytext <-  kableExtra::text_spec( Serdar , color =  blue , background =  black )
\end{verbatim}

\texttt{\{r\ \#\ \ mytext}

To display the text, type \texttt{\{r\ \#\ \ text\_formatted} outside of the chunk

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

library(kableExtra)

my_text <- paste0( ƒ∞statistik Metod: ,
 S√ºrekli verilerin ortalama, standart sapma, median, minimum ve maksimum deƒüerleri verildi. ,

 R Core Team (2019). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/. ,
  
 Therneau T (2015). A Package for Survival Analysis in S. version 2.38, URL:https://CRAN.R-project.org/package=survival ,

 Terry M. Therneau, Patricia M. Grambsch (2000). Modeling Survival Data: Extending the Cox Model. Springer, New York. ISBN 0-387-98784-3. ,

 Ewen Harrison, Tom Drake and Riinu Ots (2019). finalfit: Quickly Create Elegant Regression Results Tables and Plots when Modelling. R package version 0.9.6. https://github.com/ewenharrison/finalfit ,

sep =  \n 
)

my_text <- paste0(
   You can even try to make some crazy things like this paragraph.  ,
   It may seem like a useless feature right now but it's so cool  ,
   and nobody can resist. ;) )


my_text_html <- paste(
  text_spec(
    my_text,
     html ,
    color =  red ,
    background =  yellow 
    ),
  collapse =    )



sometext <-strsplit(my_text,    )[[1]]

my_text_latex <- paste(
  text_spec(
    sometext,
     latex ,
    color =  red ,
    background =  yellow 
    ),
  collapse =    )

\end{verbatim}

\hypertarget{ggpubr}{%
\chapter{ggpubr}\label{ggpubr}}

\hypertarget{ggpubr-1}{%
\chapter{ggpubr}\label{ggpubr-1}}

\begin{verbatim}
https://rpkgs.datanovia.com/ggpubr



if(!require(devtools)) install.packages( devtools )
devtools::install_github( kassambara/ggpubr )
Distribution
library(ggpubr)


set.seed(1234)
wdata = data.frame(
   sex = factor(rep(c( F ,  M ), each=200)),
   weight = c(rnorm(200, 55), rnorm(200, 58)))
head(wdata, 4)




ggdensity(wdata, x =  weight ,
   add =  mean , rug = TRUE,
   color =  sex , fill =  sex ,
   palette = c( #00AFBB ,  #E7B800 ))



gghistogram(wdata, x =  weight ,
   add =  mean , rug = TRUE,
   color =  sex , fill =  sex ,
   palette = c( #00AFBB ,  #E7B800 ))




data( ToothGrowth )
df <- ToothGrowth
head(df, 4)


 p <- ggboxplot(df, x =  dose , y =  len ,
                color =  dose , palette =c( #00AFBB ,  #E7B800 ,  #FC4E07 ),
                add =  jitter , shape =  dose )
 p


 
 # Add p-values comparing groups
 # Specify the comparisons you want
my_comparisons <- list( c( 0.5 ,  1 ), c( 1 ,  2 ), c( 0.5 ,  2 ) )
p + stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 50)                   # Add global p-value



ggviolin(df, x =  dose , y =  len , fill =  dose ,
         palette = c( #00AFBB ,  #E7B800 ,  #FC4E07 ),
         add =  boxplot , add.params = list(fill =  white ))+
  stat_compare_means(comparisons = my_comparisons, label =  p.signif )+ # Add significance levels
  stat_compare_means(label.y = 50)                                      # Add global the p-value 




data( mtcars )
dfm <- mtcars

dfm$cyl <- as.factor(dfm$cyl)

dfm$name <- rownames(dfm)

head(dfm[, c( name ,  wt ,  mpg ,  cyl )])


ggbarplot(dfm, x =  name , y =  mpg ,
          fill =  cyl ,               # change fill color by cyl
          color =  white ,            # Set bar border colors to white
          palette =  jco ,            # jco journal color palett. see ?ggpar
          sort.val =  desc ,          # Sort the value in dscending order
          sort.by.groups = FALSE,     # Don't sort inside each group
          x.text.angle = 90           # Rotate vertically x axis texts
          )




ggbarplot(dfm, x =  name , y =  mpg ,
          fill =  cyl ,               # change fill color by cyl
          color =  white ,            # Set bar border colors to white
          palette =  jco ,            # jco journal color palett. see ?ggpar
          sort.val =  asc ,           # Sort the value in dscending order
          sort.by.groups = TRUE,      # Sort inside each group
          x.text.angle = 90           # Rotate vertically x axis texts
          )




dfm$mpg_z <- (dfm$mpg -mean(dfm$mpg))/sd(dfm$mpg)
dfm$mpg_grp <- factor(ifelse(dfm$mpg_z < 0,  low ,  high ), 
                     levels = c( low ,  high ))

head(dfm[, c( name ,  wt ,  mpg ,  mpg_z ,  mpg_grp ,  cyl )])


ggbarplot(dfm, x =  name , y =  mpg_z ,
          fill =  mpg_grp ,           # change fill color by mpg_level
          color =  white ,            # Set bar border colors to white
          palette =  jco ,            # jco journal color palett. see ?ggpar
          sort.val =  asc ,           # Sort the value in ascending order
          sort.by.groups = FALSE,     # Don't sort inside each group
          x.text.angle = 90,          # Rotate vertically x axis texts
          ylab =  MPG z-score ,
          xlab = FALSE,
          legend.title =  MPG Group 
          )



ggbarplot(dfm, x =  name , y =  mpg_z ,
          fill =  mpg_grp ,           # change fill color by mpg_level
          color =  white ,            # Set bar border colors to white
          palette =  jco ,            # jco journal color palett. see ?ggpar
          sort.val =  desc ,          # Sort the value in descending order
          sort.by.groups = FALSE,     # Don't sort inside each group
          x.text.angle = 90,          # Rotate vertically x axis texts
          ylab =  MPG z-score ,
          legend.title =  MPG Group ,
          rotate = TRUE,
          ggtheme = theme_minimal()
          )



ggdotchart(dfm, x =  name , y =  mpg ,
           color =  cyl ,                                # Color by groups
           palette = c( #00AFBB ,  #E7B800 ,  #FC4E07 ), # Custom color palette
           sorting =  ascending ,                        # Sort value in descending order
           add =  segments ,                             # Add segments from y = 0 to dots
           ggtheme = theme_pubr()                        # ggplot2 theme
           )




ggdotchart(dfm, x =  name , y =  mpg ,
           color =  cyl ,                                # Color by groups
           palette = c( #00AFBB ,  #E7B800 ,  #FC4E07 ), # Custom color palette
           sorting =  descending ,                       # Sort value in descending order
           add =  segments ,                             # Add segments from y = 0 to dots
           rotate = TRUE,                                # Rotate vertically
           group =  cyl ,                                # Order by groups
           dot.size = 6,                                 # Large dot size
           label = round(dfm$mpg),                        # Add mpg values as dot labels
           font.label = list(color =  white , size = 9, 
                             vjust = 0.5),               # Adjust label parameters
           ggtheme = theme_pubr()                        # ggplot2 theme
           )




ggdotchart(dfm, x =  name , y =  mpg_z ,
           color =  cyl ,                                # Color by groups
           palette = c( #00AFBB ,  #E7B800 ,  #FC4E07 ), # Custom color palette
           sorting =  descending ,                       # Sort value in descending order
           add =  segments ,                             # Add segments from y = 0 to dots
           add.params = list(color =  lightgray , size = 2), # Change segment color and size
           group =  cyl ,                                # Order by groups
           dot.size = 6,                                 # Large dot size
           label = round(dfm$mpg_z,1),                        # Add mpg values as dot labels
           font.label = list(color =  white , size = 9, 
                             vjust = 0.5),               # Adjust label parameters
           ggtheme = theme_pubr()                        # ggplot2 theme
           )+
  geom_hline(yintercept = 0, linetype = 2, color =  lightgray )




ggdotchart(dfm, x =  name , y =  mpg ,
           color =  cyl ,                                # Color by groups
           palette = c( #00AFBB ,  #E7B800 ,  #FC4E07 ), # Custom color palette
           sorting =  descending ,                       # Sort value in descending order
           rotate = TRUE,                                # Rotate vertically
           dot.size = 2,                                 # Large dot size
           y.text.col = TRUE,                            # Color y text by groups
           ggtheme = theme_pubr()                        # ggplot2 theme
           )+
  theme_cleveland()                                      # Add dashed grids
\end{verbatim}

\hypertarget{r-notebook-1}{%
\chapter{R Notebook}\label{r-notebook-1}}

\begin{verbatim}
print(paste0( Git Update Started at:  , Sys.time()))
CommitMessage <- paste( updated on:  , Sys.time(), sep =   )
wd <-  ~/serdarbalci 
setorigin <-  git remote set-url origin git@github.com:sbalci/MyJournalWatch.git \n 
gitCommand <- paste( cd  , wd,   \n git add . \n git commit --message ' , CommitMessage,  ' \n , setorigin,  git push origin master \n ,  sep =   )
system(command = paste(gitCommand,  \n ) , intern = TRUE, wait = TRUE)
Sys.sleep(5)
print(paste0( Git Update Ended at:  , Sys.time()))
\end{verbatim}

\hypertarget{happy-git-and-github-for-the-user}{%
\chapter{Happy Git and GitHub for the useR}\label{happy-git-and-github-for-the-user}}

\url{https://happygitwithr.com}

\begin{itemize}
\tightlist
\item
  An introduction to Git and how to use it with RStudio
\end{itemize}

\url{http://r-bio.github.io/intro-git-rstudio/}

\url{https://andrewbtran.github.io/NICAR/2018/workflow/docs/03-integrating_github.html}

\url{https://aberdeenstudygroup.github.io/studyGroup/lessons/SG-T1-GitHubVersionControl/VersionControl/}

\url{http://r-bio.github.io/intro-git-rstudio/}

\url{https://stackoverflow.com/questions/41688164/using-rstudio-to-make-pull-requests-in-git}

\url{https://bookdown.org/rdpeng/RProgDA/version-control-and-github.html}

\url{https://www.r-bloggers.com/rstudio-and-github/}

\url{http://happygitwithr.com/fork.html}

\url{https://kbroman.org/github_tutorial/}

\url{https://kbroman.org/simple_site/}

\begin{itemize}
\tightlist
\item
  Helping you make your first pull request!
\end{itemize}

\url{https://github.com/thisisnic/first-contributions}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
require(rstudioapi)
CommitMessage <- paste( updated on  , Sys.time(), sep =   )
wd <- getwd()
gitCommand <- paste( cd , wd,   \n git add . \n git commit --message ' , CommitMessage,  ' \n git push origin master \n , sep =   )
Sys.sleep(time = 1)
gitTerm <- rstudioapi::terminalCreate(show = FALSE)
Sys.sleep(time = 1)
rstudioapi::terminalSend(gitTerm, gitCommand)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
CommitMessage <- paste( updated on  , Sys.time(), sep =   )
wd <- getwd()
gitCommand <- paste( cd  , wd,   \n git add . \n git commit --message ' , CommitMessage,  ' \n git push origin master \n , sep =   )
system(command = gitCommand, intern = TRUE)
\end{verbatim}

\hypertarget{r-notebook-2}{%
\chapter{R Notebook}\label{r-notebook-2}}

\hypertarget{scholar-1}{%
\subsection{scholar}\label{scholar-1}}

Analyse citation data from Google Scholar: \url{https://github.com/jkeirstead/scholar/}

\hypertarget{coauthornetwork}{%
\subsection{coauthornetwork}\label{coauthornetwork}}

Exploring Google Scholar coauthorship: \url{https://cimentadaj.github.io/blog/2018-06-19-exploring-google-scholar-coauthorship/exploring-google-scholar-coauthorship/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( cimentadaj/coauthornetwork )
library(coauthornetwork)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
network <- grab_network( citations?user=q40DcqYAAAAJ&hl=en )
network
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot_coauthors(grab_network( citations?user=q40DcqYAAAAJ&hl=en , n_coauthors = 15), size_labels = 2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot_coauthors(grab_network( citations?user=RJNKLHgAAAAJ&hl=en , n_coauthors = 15), size_labels = 2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, fig.height=5, fig.width=6, include=FALSE}
plot_coauthors(grab_network( citations?user=VYE2H0wAAAAJ&hl=en , n_coauthors = 15), size_labels = 3)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot_coauthors(grab_network( citations?user=joN_UxsAAAAJ&hl=en , n_coauthors = 15), size_labels = 1)
\end{verbatim}

\hypertarget{scholar.shiny}{%
\section{scholar.shiny}\label{scholar.shiny}}

A shiny application that interacts with Google Scholar

\url{https://github.com/agbarnett/scholar.shiny}

\hypertarget{graphs}{%
\chapter{Graphs}\label{graphs}}

\hypertarget{flatly}{%
\chapter{flatly}\label{flatly}}

Texas Housing Prices: flatly theme

\url{https://elastic-lovelace-155848.netlify.com/gallery/themes/flatly.html}

\hypertarget{easyalluvial}{%
\chapter{easyalluvial}\label{easyalluvial}}

\url{https://github.com/erblast/easyalluvial}

\url{https://www.datisticsblog.com/2018/10/intro_easyalluvial/\#features}

\url{https://cran.r-project.org/web/packages/easyalluvial/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages('easyalluvial')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
suppressPackageStartupMessages(require(tidyverse))
suppressPackageStartupMessages(require(easyalluvial))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## mtcars2 is included in the current development version

# mtcars2 <- within(mtcars, {
#   vs <- factor(vs, labels = c( V ,  S ))
#   am <- factor(am, labels = c( automatic ,  manual ))
#   cyl  <- ordered(cyl)
#   gear <- ordered(gear)
#   carb <- ordered(carb)
# })
# 
# mtcars2$id = row.names(mtcars)
# 
# mtcars2 = dplyr::as_tibble(mtcars2)

knitr::kable(head(mtcars2))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(easyalluvial)
alluvial_wide(data = mtcars2
                , max_variables = 5
                , fill_by = 'first_variable' )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable( head(quarterly_flights) )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
alluvial_long( quarterly_flights
               , key = qu
               , value = mean_arr_delay
               , id = tailnum
               , fill = carrier )
\end{verbatim}

\hypertarget{rcolorbrewer}{%
\chapter{RColorBrewer}\label{rcolorbrewer}}

How to expand color palette with ggplot and RColorBrewer

\url{https://www.r-bloggers.com/how-to-expand-color-palette-with-ggplot-and-rcolorbrewer/}

\hypertarget{highcharter}{%
\chapter{highcharter}\label{highcharter}}

\url{http://jkunst.com/highcharter/}

\url{https://github.com/jbkunst/highcharter}

\url{http://www.htmlwidgets.org/index.html}

\url{https://cran.r-project.org/web/packages/highcharter/index.html}

\url{https://www}..com/community/tutorials/data-visualization-highcharter-r

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
library(highcharter)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data( pokemon )
# glimpse(pokemon)
\end{verbatim}

\begin{verbatim}
hchart works like ggplot2's qplot.
hc_add_series works like ggplot2's geom_S.
hcaes works like ggplot2's aes.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pokemon %>%
  count(type_1) %>%
  arrange(n) %>%
  hchart(type =  bar , hcaes(x =  type_1 , y =  n ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pokemon %>%
  count(type_1) %>%
  arrange(n) %>%
  hchart(type =  column , hcaes(x =  type_1 , y =  n ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pokemon %>%
  count(type_1) %>%
  arrange(n) %>%
  hchart(type =  treemap , hcaes(x =  type_1 , value =  n , color =  n ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
highchart() %>%
  hc_add_series(pokemon,  scatter , hcaes(x =  height , y =  weight ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(diamonds, package =  ggplot2 )

set.seed(123)
data <- sample_n(diamonds, 300)

modlss <- loess(price ~ carat, data = data)
fit <- arrange(broom::augment(modlss), carat)

highchart() %>%
  hc_add_series(data, type =  scatter ,
                hcaes(x =  carat , y =  price , size =  depth , group =  cut )) %>%
  hc_add_series(fit, type =  line , hcaes(x =  carat , y =  .fitted ),
                name =  Fit , id =  fit ) %>%
  hc_add_series(fit, type =  arearange ,
                hcaes(x =  carat , low =  .fitted - 2*.se.fit ,
                      high =  .fitted + 2*.se.fit ),
                linkedTo =  fit )

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
highchart() %>%
  hc_chart(type =  area ) %>%
  hc_title(text =  Historic and Estimated Worldwide Population Distribution by Region ) %>%
  hc_subtitle(text =  Source: Wikipedia.org ) %>%
  hc_xAxis(categories = c( 1750 ,  1800 ,  1850 ,  1900 ,  1950 ,  1999 ,  2050 ),
           tickmarkPlacement =  on ,
           title = list(enabled = FALSE)) %>%
  hc_yAxis(title = list(text =  Percent )) %>%
  hc_tooltip(pointFormat =  <span style=\ color:{series.color}\ >{series.name}</span>:
             <b>{point.percentage:.1f}%</b> ({point.y:,.0f} millions)<br/> ,
             shared = TRUE) %>%
  hc_plotOptions(area = list(
     stacking =  percent ,
     lineColor =  #ffffff ,
     lineWidth = 1,
     marker = list(
       lineWidth = 1,
       lineColor =  #ffffff 
       ))
     ) %>%
  hc_add_series(name =  Asia , data = c(502, 635, 809, 947, 1402, 3634, 5268)) %>%
  hc_add_series(name =  Africa , data = c(106, 107, 111, 133, 221, 767, 1766)) %>%
  hc_add_series(name =  Europe , data = c(163, 203, 276, 408, 547, 729, 628)) %>%
  hc_add_series(name =  America , data = c(18, 31, 54, 156, 339, 818, 1201)) %>%
  hc_add_series(name =  Oceania , data = c(2, 2, 2, 6, 13, 30, 46))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
x <- quantmod::getSymbols( GOOG , auto.assign = FALSE)

hchart(x)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
y <- quantmod::getSymbols( AMZN , auto.assign = FALSE)

highchart(type =  stock ) %>%
  hc_add_series(x) %>%
  hc_add_series(y, type =  ohlc )
\end{verbatim}

Highmaps - Map Collection\\
\url{https://code.highcharts.com/mapdata/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
hcmap( https://code.highcharts.com/mapdata/countries/in/in-all.js )%>%
  hc_title(text =  India )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
hcmap( https://code.highcharts.com/mapdata/countries/tr/tr-all.js )%>%
  hc_title(text =  Turkey )
\end{verbatim}

\begin{verbatim}
download_map_data: Download the geojson data from the highcharts collection.
get_data_from_map: Get the properties for each region in the map, as the keys from the map data.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mapdata <- get_data_from_map(download_map_data( https://code.highcharts.com/mapdata/countries/in/in-all.js ))
# glimpse(mapdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

#population state wise
pop <-  as.data.frame(c(84673556, 1382611, 31169272, 103804637, 1055450, 25540196, 342853, 242911, 18980000, 1457723, 60383628, 25353081, 6864602,
12548926, 32966238, 61130704, 33387677, 64429, 72597565, 112372972, 2721756, 2964007, 1091014, 1980602, 41947358, 1244464,
27704236, 68621012, 607688, 72138958, 3671032, 207281477, 10116752,91347736))

state <-  mapdata%>%
  select(`hc-a2`)%>%
  arrange(`hc-a2`)

State_pop <-  as.data.frame(c(state, pop))
names(State_pop)= c( State ,  Population )

hcmap( https://code.highcharts.com/mapdata/countries/in/in-all.js , data = State_pop, value =  Population ,
      joinBy = c( hc-a2 ,  State ), name =  Fake data ,
      dataLabels = list(enabled = TRUE, format = '{point.name}'),
      borderColor =  #FAFAFA , borderWidth = 0.1,
      tooltip = list(valueDecimals = 0))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(mpg, package =  ggplot2 )

mpgg <- mpg %>%
  filter(class %in% c( suv ,  compact ,  midsize )) %>%
  group_by(class, manufacturer) %>%
  summarize(count = n())

categories_grouped <- mpgg %>%
  group_by(name = class) %>%
  do(categories = .$manufacturer) %>%
  list_parse()

highchart() %>%
  hc_xAxis(categories = categories_grouped) %>%
  hc_add_series(data = mpgg, type =  bar , hcaes(y =  count , color =  manufacturer ),
                showInLegend = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df <- data_frame(
  name = c( Animals ,  Fruits ,  Cars ),
  y = c(5, 2, 4),
  drilldown = tolower(name)
)


ds <- list_parse(df)
names(ds) <- NULL


hc <- highchart() %>%
  hc_chart(type =  column ) %>%
  hc_title(text =  Basic drilldown ) %>%
  hc_xAxis(type =  category ) %>%
  hc_legend(enabled = FALSE) %>%
  hc_plotOptions(
    series = list(
      boderWidth = 0,
      dataLabels = list(enabled = TRUE)
    )
  ) %>%
  hc_add_series(
    name =  Things ,
    colorByPoint = TRUE,
    data = ds
  )

dfan <- data_frame(
  name = c( Cats ,  Dogs ,  Cows ,  Sheep ,  Pigs ),
  value = c(4, 3, 1, 2, 1)
)

dffru <- data_frame(
  name = c( Apple ,  Organes ),
  value = c(4, 2)
)

dfcar <- data_frame(
  name = c( Toyota ,  Opel ,  Volkswage ),
  value = c(4, 2, 2)
)

second_el_to_numeric <- function(ls){

  map(ls, function(x){
    x[[2]] <- as.numeric(x[[2]])
    x
  })

}

dsan <- second_el_to_numeric(list_parse2(dfan))

dsfru <- second_el_to_numeric(list_parse2(dffru))

dscar <- second_el_to_numeric(list_parse2(dfcar))

hc %>%
  hc_drilldown(
    allowPointDrilldown = TRUE,
    series = list(
      list(
        id =  animals ,
        data = dsan
      ),
      list(
        id =  fruits ,
        data = dsfru
      ),
      list(
        id =  cars ,
        data = dscar
      )
    )
  )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tm <- pokemon %>%
  mutate(type_2 = ifelse(is.na(type_2), paste( only , type_1), type_2),
         type_1 = type_1) %>%
  group_by(type_1, type_2) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  treemap::treemap(index = c( type_1 ,  type_2 ),
                   vSize =  n , vColor =  type_1 )

tm$tm <- tm$tm %>%
  tbl_df() %>%
  left_join(pokemon %>% select(type_1, type_2, color_f) %>% distinct(), by = c( type_1 ,  type_2 )) %>%
  left_join(pokemon %>% select(type_1, color_1) %>% distinct(), by = c( type_1 )) %>%
  mutate(type_1 = paste0( Main  , type_1),
         color = ifelse(is.na(color_f), color_1, color_f))

highchart() %>%
  hc_add_series_treemap(tm, allowDrillToNode = TRUE,
                        layoutAlgorithm =  squarified )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pokemon%>%
  count(type_1)%>%
  arrange(n)%>%
  hchart(type =  bar , hcaes(x =  type_1 , y =  n , color =  type_1 ))%>%
  hc_exporting(enabled = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pokemon%>%
  count(type_1)%>%
  arrange(n)%>%
  hchart(type =  bar , hcaes(x =  type_1 , y =  n , color =  type_1 ))%>%
  hc_exporting(enabled = TRUE)%>%
hc_add_theme(hc_theme_chalk())
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data( weather )

x <- c( Min ,  Mean ,  Max )
y <- sprintf( {point.%s} , c( min_temperaturec ,  mean_temperaturec ,  max_temperaturec ))
tltip <- tooltip_table(x, y)

hchart(weather, type =  columnrange ,
       hcaes(x =  date , low =  min_temperaturec , high =  max_temperaturec ,
             color =  mean_temperaturec )) %>%
  hc_chart(polar = TRUE) %>%
  hc_yAxis( max = 30, min = -10, labels = list(format =  {value} C ),
            showFirstLabel = FALSE) %>%
  hc_xAxis(
    title = list(text =   ), gridLineWidth = 0.5,
    labels = list(format =  {value: %b} )) %>%
  hc_tooltip(useHTML = TRUE, pointFormat = tltip,
             headerFormat = as.character(tags$small( {point.x:%d %B, %Y} )))
\end{verbatim}

\hypertarget{taucharts}{%
\chapter{taucharts}\label{taucharts}}

\url{https://www.infoworld.com/video/87337/r-tip-how-to-create-easy-interactive-scatter-plots-with-taucharts}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
devtools::install_github( hrbrmstr/taucharts )
# githubinstall::githubinstall( taucharts )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
library(taucharts)
data( mtcars )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mtcars2 <- mtcars %>% 
  select(wt, mpg) %>% 
  mutate(model = row.names(mtcars))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
taucharts::tauchart(mtcars2) %>% 
  tau_point(x =  wt , y =  mpg ) %>% 
  tau_tooltip() %>% 
  tau_trendline()
\end{verbatim}

\hypertarget{gganimate}{%
\chapter{gganimate}\label{gganimate}}

\url{https://www.infoworld.com/video/89987/r-tip-animations-in-r}

\hypertarget{ggplot2}{%
\chapter{ggplot2}\label{ggplot2}}

\url{http://r-statistics.co/ggplot2-Tutorial-With-R.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
diamonds
ggplot(diamonds)  # if only the dataset is known.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds, aes(x=carat))  # if only X-axis is known. The Y-axis can be specified in respective geoms.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds, aes(x=carat, y=price))  # if both X and Y axes are fixed for all layers.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds, aes(x=carat, color=cut))  # Each category of the 'cut' variable will now have a distinct  color, once a geom is added.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds, aes(x=carat), color= steelblue )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \url{https://ggplot2.tidyverse.org/reference/}
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds, aes(x=carat, y=price, color=cut)) + 
  geom_point() + 
  geom_smooth()
# Adding scatterplot geom (layer1) and smoothing geom (layer2).
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(diamonds) + 
  geom_point(aes(x=carat, y=price, color=cut)) + 
  geom_smooth(aes(x=carat, y=price, color=cut))
# Same as above but specifying the aesthetics inside the geoms.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(ggplot2)
ggplot(diamonds) + 
  geom_point(aes(x=carat, y=price, color=cut)) + 
  geom_smooth(aes(x=carat, y=price)) # Remove color from geom_smooth
ggplot(diamonds, aes(x=carat, y=price)) + 
  geom_point(aes(color=cut)) + 
  geom_smooth()  # same but simpler
\end{verbatim}

continue from here
\url{http://r-statistics.co/ggplot2-Tutorial-With-R.html}

\hypertarget{gganimate-1}{%
\chapter{gganimate}\label{gganimate-1}}

\url{https://cran.r-project.org/web/packages/gganimate/vignettes/gganimate.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(gganimate)
#> Loading required package: ggplot2

# We'll start with a static plot
p <- ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) + 
  geom_point()

plot(p)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
anim <- p + 
  transition_states(Species,
                    transition_length = 2,
                    state_length = 1)

anim
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
anim + 
  ease_aes('cubic-in-out') # Slow start and end for a smoother look
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
anim + 
  ease_aes('cubic-in-out',
           y = 'bounce-out') # Sets special ease for y aesthetic
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
anim + 
  ggtitle('Now showing {closest_state}',
          subtitle = 'Frame {frame} of {nframes}')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) + 
  geom_line(aes(group = rep(1:50, 3)), colour = 'grey') + 
  geom_point()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) + 
  geom_point(aes(colour = Species)) + 
  transition_states(Species,
                    transition_length = 2,
                    state_length = 1)
\end{verbatim}

\hypertarget{ggforce}{%
\chapter{ggforce}\label{ggforce}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( ggforce )
library(ggforce)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Titanic
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
titanic <- reshape2::melt(Titanic)

head(titanic)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
titanic <- gather_set_data(titanic, 1:4)
head(titanic)
# View(titanic)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(titanic, aes(x, id = id, split = y, value = value)) +
  geom_parallel_sets(aes(fill = Sex), alpha = 0.3, axis.width = 0.1) +
  geom_parallel_sets_axes(axis.width = 0.1) +
  geom_parallel_sets_labels(colour = 'white')

\end{verbatim}

\hypertarget{g2r}{%
\chapter{g2r}\label{g2r}}

\begin{verbatim}
remotes::install_github( JohnCoene/g2r )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(g2r)

g2(iris, asp(Petal.Length, Petal.Width, color = Species)) %>% 
  fig_point() %>%
  plane_wrap(planes(Species))
\end{verbatim}

\hypertarget{h2o}{%
\chapter{h2o}\label{h2o}}

\url{http://h2o-release.s3.amazonaws.com/h2o/rel-wright/10/docs-website/h2o-r/docs/articles/getting_started.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if ( package:h2o  %in% search()) { detach( package:h2o , unload=TRUE) }
if ( h2o  %in% rownames(installed.packages())) { remove.packages( h2o ) }

# Next, download packages that H2O depends on.

pkgs <- c( RCurl , jsonlite )
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

# Download and install the latest H2O package for R.

install.packages( h2o , type= source , repos=(c( http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R )))

# Initialize H2O and run a demo to see H2O at work.

library(h2o)
h2o.init()
demo(h2o.kmeans)
\end{verbatim}

\hypertarget{hierarchical-clustering-1}{%
\chapter{Hierarchical Clustering}\label{hierarchical-clustering-1}}

\url{https://datascienceplus.com/hierarchical-clustering-in-r/}

\hypertarget{how-to-prepare-data-for-histopathology-research}{%
\chapter{How to Prepare Data for Histopathology Research?}\label{how-to-prepare-data-for-histopathology-research}}

\begin{verbatim}
author: '[Serdar Balcƒ±, MD, Pathologist](https://sbalci.github.io/)'
date:  `{r #  format(Sys.Date())` 
output:
  revealjs::revealjs_presentation:
    incremental: yes
    theme: sky
    highlight: pygments
    center: no
    smart: yes
    transition: fade
    self_contained: yes
    ig_width: 7
    fig_height: 6
    fig_caption: yes
    reveal_options:
      slideNumber: yes
      previewLinks: yes
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
  rmdshower::shower_presentation: null
  beamer_presentation:
    incremental: yes
    highlight: tango
  html_notebook:
    fig_caption: yes
    highlight: kate
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
    toc_float: yes
  slidy_presentation: null
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    fig_caption: yes
    keep_md: yes
    toc: yes
    toc_depth: 5
    toc_float: yes
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      beforeInit:
      - macros.js
      - https://platform.twitter.com/widgets.js
      highlightStyle: github
      highlightLines: yes
      countIncrementalSlides: no
    self_contained: yes
  ioslides_presentation:
    incremental: yes
    highlight: github
institute: '[serdarbalci.com](https://www.serdarbalci.com)'
editor_options:
  chunk_output_type: inline
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.path = 'Figs/', echo = TRUE, warning = FALSE, message = FALSE, error = FALSE, eval = TRUE, tidy = TRUE, comment = NA, cache = TRUE)
\end{verbatim}

\begin{verbatim}
{r strings , include=FALSE}
PubMedString <-  PubMed: https://www.ncbi.nlm.nih.gov/pubmed/?term= 

doiString <-  doi: https://doi.org/ 

dimensionString1 <-  <script async='' charset='utf-8' src='https://badge.dimensions.ai/badge.js'></script> <span class='__dimensions_badge_embed__' data-doi=' 

dimensionString2 <-  ' data-style='small_circle' data-hide-zero-citations='true' data-legend='always'></span> 

altmetricString1 <- <script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script> <span class='altmetric-embed' data-link-target='_blank' data-badge-details='right' data-badge-type='donut' data-doi=' 

altmetricString2 <-  ' data-hide-no-mentions='true'></span> 

addthis_String1 <-  <div class='addthis_inline_share_toolbox' data-url='pbpath.org/current-journal-watch/' data-title='See this abstract on #PBPath #JournalWatch :  

addthis_String2 <-  '></div> 
\end{verbatim}

\begin{verbatim}
{r run xaringan, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# xaringan::inf_mr()
# servr::daemon_stop(1)
\end{verbatim}

\hypertarget{how-to-prepare-data-for-histopathology-research-1}{%
\chapter{How to Prepare Data for Histopathology Research?}\label{how-to-prepare-data-for-histopathology-research-1}}

\textbf{Outline}

\begin{itemize}
\tightlist
\item
  Why is Data Preparation Important?
\item
  Do I need a specific Software?
\item
  What are the Golden Rules?
\item
  What do I do with Data after analysis?
\item
  I got all the tables from the biostatistician, is it enough?
\item
  What is a Good (Clean/Ideal/Tidy) Data?
\item
  What is a Bad (Dirty/Common/Untidy) Data?
\item
  Do I need to know statistics before collecting Data?
\item
  Do I need to have a hypothesis before collecting Data?
\item
  Do I need a research question before collecting Data?
\end{itemize}

\hypertarget{how-to-prepare-data-for-histopathology-research-2}{%
\chapter{How to Prepare Data for Histopathology Research?}\label{how-to-prepare-data-for-histopathology-research-2}}

\textbf{We Should Collect the Data Related to What We will Report}

\begin{itemize}
\tightlist
\item
  Recommendations for reporting histopathology studies: a proposal
\end{itemize}

\begin{verbatim}
{r 25846513, include=FALSE}

PMID_25846513 <- RefManageR::ReadPubMed('25846513', database = 'PubMed')

citation_25846513 <- paste0(PMID_25846513$journal,' ', PMID_25846513$year, ' ', PMID_25846513$month,';', PMID_25846513$volume,'(', PMID_25846513$number,'):', PMID_25846513$pages)

PubMed_25846513 <- paste0(PubMedString, PMID_25846513$eprint)

doi_25846513 <- paste0(doiString, PMID_25846513$doi)

dimensionBadge_25846513 <- paste0(dimensionString1, PMID_25846513$doi,dimensionString2)

altmetricBadge_25846513 <- paste0(altmetricString1, PMID_25846513$doi, altmetricString2 )

addthis_inline_25846513 <- paste0(addthis_String1, PMID_25846513$title ,   PMID: 25846513  , addthis_String2)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{\{r\ \#\ \ PMID\_25846513\$title}}
\end{itemize}

\emph{\texttt{\{r\ \#\ \ citation\_25846513}}

\texttt{\{r\ \#\ \ PubMed\_25846513}

\texttt{\{r\ \#\ \ addthis\_inline\_25846513}

\texttt{\{r\ \#\ \ PMID\_25846513\$abstract}

\texttt{\{r\ \#\ \ doi\_25846513}

\texttt{\{r\ \#\ \ dimensionBadge\_25846513}

\texttt{\{r\ \#\ \ altmetricBadge\_25846513}

\hypertarget{tables-and-graphs-to-be-formed}{%
\chapter{Tables and Graphs to be Formed}\label{tables-and-graphs-to-be-formed}}

\begin{itemize}
\item
  Table One: Clinical Features Related to this disease and Histopathological Features (like a CAP synoptic)
\item
  Cross Tables
\item
  IHC Tables
\item
  Survival Tables and Graphs
\end{itemize}

\hypertarget{age}{%
\chapter{Age}\label{age}}

\hypertarget{gender}{%
\chapter{Gender}\label{gender}}

\begin{itemize}
\tightlist
\item
  Male
\item
  Female
\item
  Non-binary (based on research)
\end{itemize}

For missing values:

\{gender\} üì¶

\url{https://lincolnmullen.com/software/gender/}

\url{https://github.com/ropensci/gender}

\hypertarget{surgery-type}{%
\chapter{Surgery Type}\label{surgery-type}}

\hypertarget{histopatoloji-uxe7alux131ux15fmalarux131nda-istatistik-analizi-iuxe7in-nasux131l-veri-hazux131rlanux131r}{%
\chapter{Histopatoloji √ßalƒ±≈ümalarƒ±nda istatistik analizi i√ßin nasƒ±l veri hazƒ±rlanƒ±r?}\label{histopatoloji-uxe7alux131ux15fmalarux131nda-istatistik-analizi-iuxe7in-nasux131l-veri-hazux131rlanux131r}}

ƒ∞statistik analizlerinde en √ßok vakit alan kƒ±sƒ±m verilerin d√ºzenlenmesi ve analize hazƒ±r hale getirilmesidir. Bu durum o kadar belirgindir ki veri analizi ile ilgili eƒüitimlerin de √∂zel bir kƒ±smƒ±nƒ± veri temizleme dersleri olu≈üturmaktadƒ±r \(Coursera\). Analize hazƒ±r haldeki veri temiz veri olarak adlandƒ±rƒ±lƒ±r \(Tidy Data, H.Wickham\). ƒ∞statistik√ßilerin kƒ±sƒ±tlƒ± vakti olduƒüunu d√º≈ü√ºn√ºld√ºƒü√ºnde verinin temiz olarak teslim edilmesi onlarƒ±n veriyi rahat anlamalarƒ±na ve veri temizleme i√ßin ayƒ±racaklarƒ± vakit yerine sizin ara≈ütƒ±rmanƒ±zdaki ilgin√ß noktalara odaklanmalarƒ±na yardƒ±mcƒ± olacaktƒ±r. Ayrƒ±ca temiz veri ile √ßalƒ±≈ümanƒ±n istatistik√ßileri daha mutlu ettiƒüini ve √∂zen g√∂sterilmi≈ü bir veride onlarƒ±n da daha √∂zenli √ßalƒ±≈ütƒ±ƒüƒ±nƒ± g√∂zlemlediƒüimi belirtmek isterim.

Bu yazƒ±da hipotetik bir histopatoloji √ßalƒ±≈ümasƒ± i√ßin basamak basamak veri hazƒ±rlanma s√ºreci anlatƒ±lacaktƒ±r.

Histopatolojik makalelerde bulunmasƒ± gereken minimum bilgiler

Bu yazƒ±da kendi kar≈üƒ±la≈ütƒ±ƒüƒ±m problemleri ve literat√ºrdeki √∂nerileri \(Virchows Arch \(2015\) 466:611--615) derlemeye √ßalƒ±≈ütƒ±m.

Statistical Problems to Document and to Avoid Manuscript Checklist for Authors

\url{http://biostat.mc.vanderbilt.edu/wiki/Main/ManuscriptChecklist}

Aslƒ±nda bir eski t√ºm√∂re yeni boya olarak adlandƒ±rƒ±lan ve sƒ±k yapƒ±lan bir √ßalƒ±≈üma t√ºr√ºn√º inceleyeceƒüiz. Bunun i√ßin yapƒ±lacak ilk i≈ü √ßalƒ±≈üƒ±lacak t√ºm√∂rle ilgili CAP protokol√ºn√º dikkatlice okumaktƒ±r. CAP protokollerinin √∂zellikle not ve a√ßƒ±klama kƒ±sƒ±mlarƒ±ndaki detaylar √ßok faydalƒ± olacaktƒ±r. Bundan sonra bir bo≈ü kaƒüƒ±t alƒ±p CAP protokol√ºnde raporda belirtilmesi gereken konular maddeler halinde sƒ±ralanmalƒ±dƒ±r. Bu maddeler √ßalƒ±≈ümanƒ±n tasarlamasƒ±ndan, analizine, yorumuna ve tartƒ±≈ümasƒ±na √ßok yardƒ±mcƒ± olacaktƒ±r.

\begin{itemize}
\item ~
  \hypertarget{temiz-veri-iuxe7in-dikkat-edilmesi-gereken-kurallar}{%
  \chapter{Temiz veri i√ßin dikkat edilmesi gereken kurallar:}\label{temiz-veri-iuxe7in-dikkat-edilmesi-gereken-kurallar}}
\item
  Her satƒ±r tek hasta
\item
  Her s√ºtun tek bilgi
\item
  Her bilgi tek bir ≈üekilde ifade edilecek
\item ~
  \hypertarget{verinin-girileceux11fi-bilgisayar-programux131}{%
  \chapter{Verinin girileceƒüi bilgisayar programƒ±}\label{verinin-girileceux11fi-bilgisayar-programux131}}
\end{itemize}

Aynƒ± deƒüerin farklƒ± ≈üekilde yazƒ±lmasƒ±

Veri hazƒ±rlamak i√ßin excel ya da filemaker kullanƒ±lmasƒ±nƒ± √∂neririm.

\begin{itemize}
\item ~
  \hypertarget{vaka-numarasux131}{%
  \chapter{Vaka numarasƒ±}\label{vaka-numarasux131}}
\end{itemize}

√áalƒ±≈ümaya ka√ß vaka alƒ±nacak?

Her deƒüi≈üken i√ßin 10 vaka?

Vakalarƒ±n se√ßilme ≈üekli: Geli≈üig√ºzel? Randomize? Birbirini takip eden \(consequative\)

\begin{itemize}
\item ~
  \hypertarget{yux131l}{%
  \chapter{Yƒ±l}\label{yux131l}}
\end{itemize}

Hangi yƒ±l aralƒ±ƒüƒ± tercih edilmeli?

Yƒ±l aralƒ±ƒüƒ±nƒ±nƒ±n belirtilmesi nadir vakalarda vaka sayƒ±sƒ± ile ilgili bilgi verebilir. Bu nedenle klinikteki toplam vaka sayƒ±sƒ± ile kar≈üƒ±la≈ütƒ±rma yapƒ±lmasƒ±

Bir klinikten √ßƒ±kan vaka sayƒ±sƒ± da o klinikte bu i≈üin ne kadar ciddi yapƒ±ldƒ±ƒüƒ±nƒ±n ve tecr√ºbenin g√∂stergesi. Kabul ≈üansƒ±nƒ± arttƒ±ran fakt√∂r.

ƒ∞mm√ºnohistokimya i√ßin eski vakalar mƒ± tercih edilecek yeni vakalar mƒ±?

\begin{itemize}
\item ~
  \hypertarget{biyopsi-no}{%
  \chapter{Biyopsi No}\label{biyopsi-no}}
\item ~
  \hypertarget{tc-kimlik-hasta-no-ad-soyad}{%
  \chapter{TC Kimlik, Hasta No, Ad Soyad}\label{tc-kimlik-hasta-no-ad-soyad}}

  \begin{itemize}
  \item
    hasta bazlƒ± √ßalƒ±≈üma vs √∂rnek bazlƒ± √ßalƒ±≈üma
  \item
    HIPAA kurallarƒ±
  \item
  \end{itemize}
\item ~
  \hypertarget{yaux15f}{%
  \chapter{Ya≈ü}\label{yaux15f}}
\end{itemize}

Yƒ±l, ay

Eƒüer t√ºm√∂r belli bir ya≈ü aralƒ±ƒüƒ±nda g√∂r√ºl√ºyor, ya da bimodal daƒüƒ±lƒ±m g√∂steriyorsa \(osteosarkom gibi\) bu durumu

\begin{itemize}
\item ~
  \hypertarget{doux11fum-tarihi}{%
  \chapter{Doƒüum Tarihi}\label{doux11fum-tarihi}}
\item ~
  \hypertarget{cinsiyet}{%
  \chapter{Cinsiyet}\label{cinsiyet}}
\item
\item ~
  \hypertarget{tuxfcmuxf6r-uxe7apux131}{%
  \chapter{T√ºm√∂r √ßapƒ±}\label{tuxfcmuxf6r-uxe7apux131}}
\item ~
  \hypertarget{t-evresi}{%
  \chapter{T evresi}\label{t-evresi}}
\item ~
  \hypertarget{n-evresi}{%
  \chapter{N evresi}\label{n-evresi}}

  \begin{itemize}
  \tightlist
  \item
    \textbf{Lenf nodu}
    Direk invazyon
  \end{itemize}
\item ~
  \hypertarget{m-evresi}{%
  \chapter{M evresi}\label{m-evresi}}
\item ~
  \hypertarget{tnmajcc-evresi}{%
  \chapter{TNM/AJCC evresi}\label{tnmajcc-evresi}}
\item ~
  \hypertarget{histopatolojik-tip}{%
  \chapter{Histopatolojik tip}\label{histopatolojik-tip}}
\item
\item ~
  \hypertarget{lenfovaskuxfcler-invazyon-lvi}{%
  \chapter{\texorpdfstring{\textbf{Lenfovask√ºler ƒ∞nvazyon \(LVI\)}}{Lenfovask√ºler ƒ∞nvazyon LVI}}\label{lenfovaskuxfcler-invazyon-lvi}}
\end{itemize}

Lenfovask√ºler invazyon √ßoƒüu t√ºm√∂r raporlarƒ±nda belirtilmesi gereken bir √∂zelliktir.

√ñnerilen kodlama ≈üekli var ise 1, yok ise 0 ≈üeklindedir.

Lenfatik ve vask√ºler invazyon ayrƒ± ayrƒ± da kodlanabilir. Mesela kolon t√ºm√∂rlerinde ekstramural ven√∂z invazyonun belirtilmesi gibi.

CAP protokollerinde equivocal olarak belirtilen ≈ü√ºpheli durumlardan m√ºmk√ºn olduk√ßa ka√ßƒ±nmak analizlerin daha rahat yapƒ±labilmesi i√ßin gereklidir.

Extensive retraction artefact gibi √∂zellikli durumlar √ßalƒ±≈ümƒ±yorsa imm√ºnohistokimyasal √ßalƒ±≈ümalara gerek olmadan rutin H\&E deƒüerlendirme yeterlidir.

Raporlardan elde edilen bulgular da analiz i√ßin kullanƒ±labilir. √ñzellikle rutin rapora g√∂re tedavi planlanan durumlarda, doƒüal seyri seyretmek istediƒüiniz √ßalƒ±≈ümalarda bunu yapabilirsiniz.

Patologlarƒ±n ise yaptƒ±klarƒ± √ßalƒ±≈ümalarda mutlaka t√ºm vakalara yeniden bakmalarƒ± √∂nerilir. Bazen ara≈ütƒ±rmacƒ±lar sadece negatif olarak raporlanan vakalara bakƒ±p, bunlarda atlanan lenfovask√ºler invazyonu yakalamaya √ßalƒ±≈üƒ±rlar. Bu durumda lenfovask√ºler invazyon y√ºzdeniz literat√ºrden y√ºksek √ßƒ±kacaktƒ±r \(Yanlƒ±≈ü negatifler azalacaktƒ±r\). Pozitif olan olgulara da bakƒ±lmalƒ±, pozitif olarak raporlanan ve aslƒ±nda lenfovask√ºler invazyonu olmayan vakalar \(yanlƒ±≈ü pozitif\) ise negatif olarak analize alƒ±nmalƒ±dƒ±r.

Lenf nodunda metastaz olan olgularda lenfovask√ºler invazyonu pozitif olarak kabul etmek uygun deƒüildir. Lenf noduna metastaz yapmanƒ±n ayrƒ± perit√ºm√∂ral lenfovask√ºler invazyon tespit edilmesinin ayrƒ± t√ºm√∂r geli≈üim basamaklarƒ± olduƒüu d√º≈ü√ºn√ºlmelidir.

\begin{itemize}
\item ~
  \hypertarget{perinuxf6ral-perinuxf6ryal-invazyon}{%
  \chapter{\texorpdfstring{\textbf{Perin√∂ral \(perin√∂ryal\) invazyon}}{Perin√∂ral perin√∂ryal invazyon}}\label{perinuxf6ral-perinuxf6ryal-invazyon}}
\item ~
  \hypertarget{cerrahi-sux131nux131r}{%
  \chapter{Cerrahi sƒ±nƒ±r}\label{cerrahi-sux131nux131r}}
\item ~
  \hypertarget{ek-hastalux131k}{%
  \chapter{Ek hastalƒ±k}\label{ek-hastalux131k}}
\item ~
  \hypertarget{ikinci-primer}{%
  \chapter{ƒ∞kinci primer}\label{ikinci-primer}}
\end{itemize}

Birden fazla t√ºm√∂r√º olan olgularda klinik gidi≈üi ve saƒükalƒ±mƒ± diƒüer t√ºm√∂r etkiliyor olabilir. Sistoprostatektomilerde √ºrotelyal karsinom saƒükalƒ±ma, prostat t√ºm√∂rlerinden daha fazla etki edecektir.

Bu vakalarƒ±n √ßƒ±kartƒ±lmasƒ± da insidansƒ± etkileyebilir. Bu nedenle √ßalƒ±≈ümanƒ±n tasarƒ±mƒ±na g√∂re bu vakalarƒ± eklemek ya da √ßƒ±akrtmak gerekecektir.

\begin{itemize}
\item ~
  \hypertarget{immuxfcnohistokimya}{%
  \chapter{\texorpdfstring{\textbf{ƒ∞mm√ºnohistokimya}}{ƒ∞mm√ºnohistokimya}}\label{immuxfcnohistokimya}}

  \begin{itemize}
  \item
    Pozitif, negatif
  \item
    Kayƒ±p, korunmu≈ü
  \item
    ≈ûiddet
  \item
    Yaygƒ±nlƒ±k
  \item
    H-skor, Allred score, Quick score
  \item
    Hangi h√ºcre pozitif
  \item
    Hangi komponent pozitif \(n√ºkleer, sitoplazmik, membran√∂z\)
  \item
    Y√ºzde
  \item
    Sonu√ßlarƒ± gruplama
  \item
    Uygun antikor klonunu se√ßmek ayrƒ± bir yazƒ± konusu olmalƒ±.
  \end{itemize}
\item ~
  \hypertarget{ameliyat-ux15fekli}{%
  \chapter{\texorpdfstring{\textbf{Ameliyat ≈üekli}}{Ameliyat ≈üekli}}\label{ameliyat-ux15fekli}}
\item ~
  \hypertarget{saux11fkalux131m}{%
  \chapter{Saƒükalƒ±m}\label{saux11fkalux131m}}
\end{itemize}

Saƒükalƒ±m verisi de hassas bilgilerdendir.

√ñl√ºm bildirim sistemi

Tarihler

Tanƒ± tarihi

Son tarih

Tarih girerken neye dikkat edelim \(ƒ∞ngilizce ve T√ºrk√ße farklƒ± tarih formatlarƒ±\)

\begin{itemize}
\item ~
  \hypertarget{overall-survival}{%
  \chapter{Overall survival}\label{overall-survival}}
\item ~
  \hypertarget{disease-free-survival}{%
  \chapter{Disease Free Survival}\label{disease-free-survival}}
\item ~
  \hypertarget{vertikal-tarama}{%
  \chapter{Vertikal tarama}\label{vertikal-tarama}}
\item ~
  \hypertarget{bilinmeyen-veriler-eksik-veriler-missing-values}{%
  \chapter{Bilinmeyen veriler, Eksik veriler, Missing values}\label{bilinmeyen-veriler-eksik-veriler-missing-values}}
\end{itemize}

Her eksik h√ºcre, √ßok deƒüi≈ükenli analizden o vakanƒ±n d√º≈ümesine neden olacaktƒ±r.

Eksik camlar

Eksik verileri excelde kontrol etme

\begin{itemize}
\item ~
  \hypertarget{tek-merkez-uxe7ok-merkezli-uxe7alux131ux15fma}{%
  \chapter{Tek merkez, √ßok merkezli √ßalƒ±≈üma}\label{tek-merkez-uxe7ok-merkezli-uxe7alux131ux15fma}}
\item ~
  \hypertarget{istatistikuxe7iye-sorulmasux131-gereken-sorular}{%
  \chapter{ƒ∞statistik√ßiye sorulmasƒ± gereken sorular}\label{istatistikuxe7iye-sorulmasux131-gereken-sorular}}
\end{itemize}

√áalƒ±≈ümaya ba≈ülamadan √∂nce, hangi sorularƒ± soracaƒüƒ±nƒ±zƒ± zaten planlamƒ±≈ü olmanƒ±z ve buna g√∂re verilerinizi d√ºzenlemi≈ü olmanƒ±z gerekir. Yine de √ßalƒ±≈üma s√ºrerken ve √ßalƒ±≈ümanƒ±n sonunda yeni sorular ve d√º≈ü√ºnceler ortaya √ßƒ±kabilir. Sorulacak sorular ve yapƒ±lacak analizler i√ßin bir √∂n hazƒ±rlƒ±k yapmak ve bunlarƒ± d√ºzg√ºn c√ºmleler halinde kaydetmek √∂nemlidir. Mesela t√ºm√∂r tipleri ile X protein ekspresyonunu kar≈üƒ±la≈ütƒ±rmak istiyorum bir soru olabilir. Ama daha iyisi X proteininin ekspresyonunun A t√ºm√∂r√ºnde B t√ºm√∂r√ºne g√∂re daha fazla olduƒüunu d√º≈ü√ºn√ºyorum, bunun √∂yle olup olmadƒ±ƒüƒ±nƒ± analiz etmenizi istiyorum daha da anla≈üƒ±lƒ±r bir soru olacaktƒ±r.

\begin{itemize}
\item ~
  \hypertarget{bana-p-deux11feri-ver}{%
  \chapter{Bana p deƒüeri ver}\label{bana-p-deux11feri-ver}}
\item ~
  \hypertarget{hangi-istatistik-yuxf6ntemlerini-bilmem-lazux131m}{%
  \chapter{Hangi istatistik y√∂ntemlerini bilmem lazƒ±m}\label{hangi-istatistik-yuxf6ntemlerini-bilmem-lazux131m}}
\end{itemize}

Tƒ±p fak√ºltesinin ilk yƒ±llarƒ±nda √∂ƒürenilen istatistikle ilgili kavramlar yƒ±llar i√ßinde unutuluyor. Elbette herkesin detaylƒ± olarak istatistik metodlarƒ±nƒ± bilmesine gerek yok. Ancak yine de bir istatistik okuryazarlƒ±ƒüƒ±nƒ±n \(statistical literacy\) olmasƒ±nda fayda var.

\begin{itemize}
\item
  \begin{itemize}
  \tightlist
  \item
    ANOVA testi
  \end{itemize}
\end{itemize}

30 vaka sayƒ±lƒ±, tercihen verilerin normal daƒüƒ±ldƒ±ƒüƒ± durumlarda ve veriler √∂l√ß√ºlebilir ve s√ºrekli nitelikte ise kullanƒ±lƒ±r. Mesela ya≈ü, √∂zefagus l√ºmeninin, √∂zefagus duvarƒ±na oranƒ± gibi durumlarda kullanƒ±labilir.

Ancak histopatolojik dercelendirme ya da evreleme gibi kesikli deƒüi≈ükenlerin olduƒüu durumlarda parametrik test olan ANOVA √∂nerilmez. Grade 1 ila grade 2 arasƒ±ndaki fark ile grade 2 ila grade 3 arasƒ±ndaki fark matematiksel olarak e≈üit deƒüildir. Grade 2, grade 1 den 2 kat k√∂t√º, grade 3 ise grade 1'den 3 kat k√∂t√ºd√ºr gibi bir yorum yapƒ±lmaz.

Hastalarƒ±n kanser evresinin ortalama 2,5 , ya da t√ºm√∂r grade'inin ortalama 1,2 olarak verilmesi √∂nerilmez. Bunun yerine ortanca ve √ßeyrekler arasƒ± fark \(median, interquartile range\) kullanƒ±lmasƒ± daha uygun olur. Bu nedenle yapƒ±lacak test de ANOVA'nƒ±n nonparametrik kar≈üƒ±lƒ±ƒüƒ± olan Kruskal Wallis testidir.

√ñl√ß√ºm ≈üeklinde olan, s√ºrekli deƒüi≈ükenlerde bile vaka sayƒ±sƒ±nƒ±n 30'dan az ise ya da veriler normal daƒüƒ±lmƒ±yorsa birden fazla grubun kar≈üƒ±la≈ütƒ±rmasƒ±nda da Kruskal Wallis testi kullanƒ±lƒ±r.

ƒ∞statistik dƒ±≈üƒ± bakƒ±≈ü a√ßƒ±sƒ± ile; Kanser evreleme √ßalƒ±≈ümalarƒ±nda \(lenf nodu sayƒ±sƒ±nda\) logaritmik d√∂n√º≈ü√ºm √ßok kullanƒ±lƒ±yor. Ve hemen t√ºm √ßalƒ±≈ümalarda i≈üe yarƒ±yor. √ñrnek \url{https://www.ncbi.nlm.nih.gov/pubmed/28094085} Ama klinikte bilgisayar destekli bir karar sistemi kullanƒ±lmadƒ±ƒüƒ± zaman bu logaritmik deƒüerler √ßok afaki kalabiliyor. Model anlamlƒ± olsa da pratikte anlamasƒ± zor oluyor. Normallik yoksa nonparametrik testleri bir kademe daha rahat anlayabiliyorum.

\hypertarget{top-ten-errors-of-statistical-analysis-in-observational-studies-for-cancer-research}{%
\chapter{Top ten errors of statistical analysis in observational studies for cancer research}\label{top-ten-errors-of-statistical-analysis-in-observational-studies-for-cancer-research}}

\url{https://rd.springer.com/article/10.1007\%2Fs12094-017-1817-9}

\hypertarget{tweets}{%
\chapter{Tweets}\label{tweets}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)

how_to_prepare_data_tweet_1 <- paste0(
   1/n
  
  
   
  )

post_tweet(how_to_prepare_data_tweet_1)
\end{verbatim}

title: R ile analize ba≈ülarken\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara referans
  vermeye √ßalƒ±≈ütƒ±m.}

\begin{verbatim}
author:  Derleyen [Serdar Balcƒ±, MD, Pathologist](https://sbalci.github.io/) 
date:  `{r #  format(Sys.Date())` 
output:
  rmdformats::html_clean:
    highlight: kate
  html_notebook:
    fig_caption: yes
    highlight: kate
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document: 
    fig_caption: yes
    keep_md: yes
    toc: yes
    toc_depth: 5
    toc_float: yes
\end{verbatim}

\begin{verbatim}
{r , echo=TRUE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print= 75 )
opts_chunk$set(echo=TRUE,
                 cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  R generation
\end{itemize}

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\hypertarget{r-yuxfckleme}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\href{http://www.youtube.com/watch?v=XcBLEVknqvY}{\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}}

\hypertarget{r-project}{%
\section{R-project}\label{r-project}}

\url{https://cran.r-project.org/}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#6}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}}

\hypertarget{rstudio}{%
\section{RStudio}\label{rstudio}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\hypertarget{rstudio-eklentileri}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{x11}{%
\section{X11}\label{x11}}

\url{https://www.xquartz.org/}

\hypertarget{java-os}{%
\section{Java OS}\label{java-os}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\hypertarget{r-paketleri}{%
\chapter{R paketleri}\label{r-paketleri}}

\hypertarget{neden-paketler-var}{%
\section{Neden paketler var}\label{neden-paketler-var}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\url{https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/}

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-iuxe7in-yardux131m-bulma}{%
\section{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma}}

\begin{verbatim}
# ?mean
# ??efetch
# help(merge)
# example(merge)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\includegraphics{figures/vignette.png}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Reproducible Examples
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\hypertarget{r-paket-yuxfckleme}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme}}

\begin{verbatim}
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r}
# install.packages( tidyverse , dependencies = TRUE)
# install.packages( jmv , dependencies = TRUE)
# install.packages( questionr , dependencies = TRUE)
# install.packages( Rcmdr , dependencies = TRUE)
# install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r, error=FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE}
# require(tidyverse)
# require(jmv)
# require(questionr)
# library(summarytools)
# library(gganimate)
\end{verbatim}

\hypertarget{r-studio-ile-proje-oluux15fturma}{%
\chapter{R studio ile proje olu≈üturma}\label{r-studio-ile-proje-oluux15fturma}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel}{%
\section{Excel}\label{excel}}

\hypertarget{spss}{%
\section{SPSS}\label{spss}}

\hypertarget{csv}{%
\section{csv}\label{csv}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\begin{verbatim}
{r, results= markup }
# library(nycflights13)
# summary(flights)
\end{verbatim}

\begin{verbatim}
View(data)
\end{verbatim}

\begin{verbatim}
data
\end{verbatim}

\begin{verbatim}
head
\end{verbatim}

\begin{verbatim}
tail
\end{verbatim}

\begin{verbatim}
glimpse
\end{verbatim}

\begin{verbatim}
str
\end{verbatim}

\begin{verbatim}
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme}}

\includegraphics{figures/change_data.png}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode}}

\emph{questionr} paketi kullanƒ±lacak

\includegraphics{figures/level_recode.png}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include = TRUE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )

scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools}{%
\section{summarytools}\label{summarytools}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\includegraphics{figures/dfsummary.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}

# First save the results

iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:

view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)

# view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

\hypertarget{skimr-1}{%
\section{skimr}\label{skimr-1}}

\begin{verbatim}
library(skimr)
skim(df)
\end{verbatim}

\hypertarget{dataexplorer-2}{%
\section{DataExplorer}\label{dataexplorer-2}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{grafikler}{%
\section{Grafikler}\label{grafikler}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{rcmdr}{%
\chapter{Rcmdr}\label{rcmdr}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi}{%
\chapter{jamovi}\label{jamovi}}

\url{https://www.jamovi.org/}

\begin{figure}
\centering
\includegraphics{https://www.jamovi.org/}
\caption{\includegraphics{https://www.jamovi.org/assets/main-screenshot.png}}
\end{figure}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\begin{figure}
\centering
\includegraphics{https://blog.jamovi.org/2018/07/30/rj.html}
\caption{\includegraphics{https://blog.jamovi.org/assets/images/rj.png}}
\end{figure}

\hypertarget{sonraki-konular}{%
\chapter{Sonraki Konular}\label{sonraki-konular}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub
\item
  Hipotez testleri
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\end{itemize}

\hypertarget{diux11fer-kodlar}{%
\chapter{Diƒüer kodlar}\label{diux11fer-kodlar}}

\begin{itemize}
\tightlist
\item
  Diƒüer kodlar i√ßin bakƒ±nƒ±z: \url{https://sbalci.github.io/}
\end{itemize}

\hypertarget{geri-bildirim}{%
\chapter{Geri Bildirim}\label{geri-bildirim}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

title: R ile analize ba≈ülarken\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara referans
  vermeye √ßalƒ±≈ütƒ±m.}

\begin{verbatim}
author:  Derleyen [Serdar Balcƒ±, MD, Pathologist](https://sbalci.github.io/) 
date:  `{r #  format(Sys.Date())` 
output:
  rmdformats::html_clean:
    highlight: kate
  html_notebook:
    fig_caption: yes
    highlight: kate
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document: 
    fig_caption: yes
    keep_md: yes
    toc: yes
    toc_depth: 5
    toc_float: yes
\end{verbatim}

\begin{verbatim}
{r , eval=FALSE, cache=FALSE, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print= 75 )
opts_chunk$set(echo=TRUE,
                 cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  R generation
\end{itemize}

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\hypertarget{r-yuxfckleme-1}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme-1}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\href{http://www.youtube.com/watch?v=XcBLEVknqvY}{\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}}

\hypertarget{r-project-1}{%
\section{R-project}\label{r-project-1}}

\url{https://cran.r-project.org/}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#6}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}}

\hypertarget{rstudio-1}{%
\section{RStudio}\label{rstudio-1}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\hypertarget{rstudio-eklentileri-1}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri-1}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{x11-1}{%
\section{X11}\label{x11-1}}

\url{https://www.xquartz.org/}

\hypertarget{java-os-1}{%
\section{Java OS}\label{java-os-1}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-1}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-1}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\hypertarget{r-paketleri-1}{%
\chapter{R paketleri}\label{r-paketleri-1}}

\hypertarget{neden-paketler-var-1}{%
\section{Neden paketler var}\label{neden-paketler-var-1}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\url{https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/}

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz-1}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz-1}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur-1}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur-1}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-iuxe7in-yardux131m-bulma-1}{%
\section{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma-1}}

\begin{verbatim}
# ?mean
# ??efetch
# help(merge)
# example(merge)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\includegraphics{figures/vignette.png}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Reproducible Examples
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\hypertarget{r-paket-yuxfckleme-1}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme-1}}

\begin{verbatim}
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r}
# install.packages( tidyverse , dependencies = TRUE)
# install.packages( jmv , dependencies = TRUE)
# install.packages( questionr , dependencies = TRUE)
# install.packages( Rcmdr , dependencies = TRUE)
# install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r, error=FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE}
# require(tidyverse)
# require(jmv)
# require(questionr)
# library(summarytools)
# library(gganimate)
\end{verbatim}

\hypertarget{r-studio-ile-proje-oluux15fturma-1}{%
\chapter{R studio ile proje olu≈üturma}\label{r-studio-ile-proje-oluux15fturma-1}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme-1}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme-1}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel-1}{%
\section{Excel}\label{excel-1}}

\hypertarget{spss-1}{%
\section{SPSS}\label{spss-1}}

\hypertarget{csv-1}{%
\section{csv}\label{csv-1}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-1}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-1}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\begin{verbatim}
{r, results= markup }
# library(nycflights13)
# summary(flights)
\end{verbatim}

\begin{verbatim}
View(data)
\end{verbatim}

\begin{verbatim}
data
\end{verbatim}

\begin{verbatim}
head
\end{verbatim}

\begin{verbatim}
tail
\end{verbatim}

\begin{verbatim}
glimpse
\end{verbatim}

\begin{verbatim}
str
\end{verbatim}

\begin{verbatim}
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme-1}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme-1}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim-1}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim-1}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme-1}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme-1}}

\includegraphics{figures/change_data.png}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode-1}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode-1}}

\emph{questionr} paketi kullanƒ±lacak

\includegraphics{figures/level_recode.png}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler-1}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler-1}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, eval=FALSE, include=FALSE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )

scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools-1}{%
\section{summarytools}\label{summarytools-1}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\includegraphics{figures/dfsummary.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}

# First save the results

iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:

view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)

# view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

\hypertarget{skimr-2}{%
\section{skimr}\label{skimr-2}}

\begin{verbatim}
library(skimr)
skim(df)
\end{verbatim}

\hypertarget{dataexplorer-3}{%
\section{DataExplorer}\label{dataexplorer-3}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{grafikler-1}{%
\section{Grafikler}\label{grafikler-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{rcmdr-1}{%
\chapter{Rcmdr}\label{rcmdr-1}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi-1}{%
\chapter{jamovi}\label{jamovi-1}}

\url{https://www.jamovi.org/}

\begin{figure}
\centering
\includegraphics{https://www.jamovi.org/}
\caption{\includegraphics{https://www.jamovi.org/assets/main-screenshot.png}}
\end{figure}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\begin{figure}
\centering
\includegraphics{https://blog.jamovi.org/2018/07/30/rj.html}
\caption{\includegraphics{https://blog.jamovi.org/assets/images/rj.png}}
\end{figure}

\hypertarget{sonraki-konular-1}{%
\chapter{Sonraki Konular}\label{sonraki-konular-1}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub
\item
  Hipotez testleri
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\end{itemize}

\hypertarget{diux11fer-kodlar-1}{%
\chapter{Diƒüer kodlar}\label{diux11fer-kodlar-1}}

\begin{itemize}
\tightlist
\item
  Diƒüer kodlar i√ßin bakƒ±nƒ±z: \url{https://sbalci.github.io/}
\end{itemize}

\hypertarget{geri-bildirim-1}{%
\chapter{Geri Bildirim}\label{geri-bildirim-1}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\begin{verbatim}
{r , echo=TRUE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print= 75 )
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
\end{verbatim}

\href{https://www..com/community/tutorials/data-science-pitfalls}{\includegraphics{http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530113077/Image_2_vfy48b.png}}

\begin{itemize}
\tightlist
\item
  R generation
\end{itemize}

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\hypertarget{r-yuxfckleme-2}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme-2}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\href{http://www.youtube.com/watch?v=XcBLEVknqvY}{\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}}

\hypertarget{r-project-2}{%
\section{R-project}\label{r-project-2}}

\url{https://cran.r-project.org/}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#6}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}}

\hypertarget{rstudio-2}{%
\section{RStudio}\label{rstudio-2}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\href{https://buzzrbeeline.blog/2018/07/04/rstudio-anatomy/}{\includegraphics{http://www-users.york.ac.uk/~er13/RStudio\%20Anatomy.svg}}

\hypertarget{rstudio-eklentileri-2}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri-2}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{x11-2}{%
\section{X11}\label{x11-2}}

\url{https://www.xquartz.org/}

\hypertarget{java-os-2}{%
\section{Java OS}\label{java-os-2}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-2}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-2}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\hypertarget{r-paketleri-2}{%
\chapter{R paketleri}\label{r-paketleri-2}}

\hypertarget{neden-paketler-var-2}{%
\section{Neden paketler var}\label{neden-paketler-var-2}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\url{https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/}

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz-2}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz-2}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur-2}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur-2}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-iuxe7in-yardux131m-bulma-2}{%
\section{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma-2}}

\begin{verbatim}
# ?mean
# ??efetch
# help(merge)
# example(merge)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\includegraphics{figures/vignette.png}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Reproducible Examples
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\hypertarget{r-paket-yuxfckleme-2}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme-2}}

\begin{verbatim}
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r}
# install.packages( tidyverse , dependencies = TRUE)
# install.packages( jmv , dependencies = TRUE)
# install.packages( questionr , dependencies = TRUE)
# install.packages( Rcmdr , dependencies = TRUE)
# install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r, error=FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE}
# require(tidyverse)
# require(jmv)
# require(questionr)
# library(summarytools)
# library(gganimate)
\end{verbatim}

\hypertarget{r-studio-ile-proje-oluux15fturma-2}{%
\chapter{R studio ile proje olu≈üturma}\label{r-studio-ile-proje-oluux15fturma-2}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme-2}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme-2}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel-2}{%
\section{Excel}\label{excel-2}}

\hypertarget{spss-2}{%
\section{SPSS}\label{spss-2}}

\hypertarget{csv-2}{%
\section{csv}\label{csv-2}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-2}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-2}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\begin{verbatim}
{r, results= markup }
# library(nycflights13)
# summary(flights)
\end{verbatim}

\begin{verbatim}
View(data)
\end{verbatim}

\begin{verbatim}
data
\end{verbatim}

\begin{verbatim}
head
\end{verbatim}

\begin{verbatim}
tail
\end{verbatim}

\begin{verbatim}
glimpse
\end{verbatim}

\begin{verbatim}
str
\end{verbatim}

\begin{verbatim}
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme-2}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme-2}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim-2}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim-2}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme-2}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme-2}}

\includegraphics{figures/change_data.png}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode-2}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode-2}}

\emph{questionr} paketi kullanƒ±lacak

\includegraphics{figures/level_recode.png}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler-2}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler-2}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include = TRUE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )

scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools-2}{%
\section{summarytools}\label{summarytools-2}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}

# First save the results

iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:

view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)

# view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

\hypertarget{skimr-3}{%
\section{skimr}\label{skimr-3}}

\begin{verbatim}
library(skimr)
skim(df)
\end{verbatim}

\hypertarget{dataexplorer-4}{%
\section{DataExplorer}\label{dataexplorer-4}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{grafikler-2}{%
\section{Grafikler}\label{grafikler-2}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{rcmdr-2}{%
\chapter{Rcmdr}\label{rcmdr-2}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi-2}{%
\chapter{jamovi}\label{jamovi-2}}

\url{https://www.jamovi.org/}

\begin{figure}
\centering
\includegraphics{https://www.jamovi.org/}
\caption{\includegraphics{https://www.jamovi.org/assets/main-screenshot.png}}
\end{figure}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\begin{figure}
\centering
\includegraphics{https://blog.jamovi.org/2018/07/30/rj.html}
\caption{\includegraphics{https://blog.jamovi.org/assets/images/rj.png}}
\end{figure}

\hypertarget{sonraki-konular-2}{%
\chapter{Sonraki Konular}\label{sonraki-konular-2}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub
\item
  Hipotez testleri
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\end{itemize}

\hypertarget{diux11fer-kodlar-2}{%
\chapter{Diƒüer kodlar}\label{diux11fer-kodlar-2}}

\begin{itemize}
\tightlist
\item
  Diƒüer kodlar i√ßin bakƒ±nƒ±z: \url{https://sbalci.github.io/}
\end{itemize}

\hypertarget{geri-bildirim-2}{%
\chapter{Geri Bildirim}\label{geri-bildirim-2}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\begin{verbatim}
{r , echo = TRUE, warning = FALSE, message = FALSE}

library(knitr)
library(dplyr)
library(huxtable)
options(huxtable.knit_print_df = FALSE)

is_latex <- guess_knitr_output_format() == 'latex'
# is_latex <- TRUE
knitr::knit_hooks$set(
  barrier = function(before, options, envir) {
    if (! before && is_latex) knitr::asis_output('\\FloatBarrier')
  }
)

if (is_latex) knitr::opts_chunk$set(barrier = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo = TRUE}
huxtable::hux_logo(latex = is_latex)
\end{verbatim}

\begin{verbatim}
{r, eval = FALSE, echo = TRUE}
# PLAN
# Make single document work in notebook format (maybe with minimal changes)
# Installation
# Dplyr examples
# Examples with where and friends
# Different kinds of output
# Cookbook?
# Limitations
\end{verbatim}

\hypertarget{introduction-1}{%
\chapter{Introduction}\label{introduction-1}}

\hypertarget{about-this-document}{%
\section{About this document}\label{about-this-document}}

This is the introductory vignette for the R package `huxtable', version \texttt{\{r\ \#\ \ packageVersion(\textquotesingle{}huxtable\textquotesingle{})}. A current
version is available on the web in \href{https://hughjonesd.github.io/huxtable/huxtable.html}{HTML} or
\href{https://hughjonesd.github.io/huxtable/huxtable.pdf}{PDF} format.

\hypertarget{huxtable}{%
\section{Huxtable}\label{huxtable}}

Huxtable is a package for creating \emph{text tables}. It is powerful, but easy to use. It is meant to be a
replacement for packages like xtable, which is useful but not always very user-friendly. Huxtable's features
include:

\begin{itemize}
\tightlist
\item
  Export to LaTeX, HTML, Word and Markdown
\item
  Easy integration with knitr and rmarkdown documents
\item
  Multirow and multicolumn cells
\item
  Fine-grained control over cell background, spacing, alignment, size and borders
\item
  Control over text font, style, size, colour, alignment, number format and rotation
\item
  Table manipulation using standard R subsetting, or dplyr functions like \texttt{filter} and \texttt{select}
\item
  Easy conditional formatting based on table contents
\item
  Quick table themes
\item
  Automatic creation of regression output tables with the \texttt{huxreg} function
\end{itemize}

We will cover all of these features below.

\hypertarget{installation}{%
\section{Installation}\label{installation}}

If you haven't already installed huxtable, you can do so from the R command line:

\begin{verbatim}
{r, eval = FALSE}
install.packages('huxtable')
\end{verbatim}

\hypertarget{getting-started}{%
\section{Getting started}\label{getting-started}}

A huxtable is a way of representing a table of text data in R. You already know that R can represent a
table of data in a data frame. For example, if \texttt{mydata} is a data frame, then \texttt{mydata{[}1,\ 2{]}} represents the
the data in row 1, column 2, and \texttt{mydata\$start\_time} is all the data in the column called \texttt{start\_time}.

A huxtable is just a data frame with some extra properties. So, if \texttt{myhux} is a huxtable, then \texttt{myhux{[}1,\ 2{]}}
represents the data in row 1 column 2, as before. But this cell will also have some other properties - for
example, the font size of the text, or the colour of the cell border.

To create a table with huxtable, use the function \texttt{huxtable}, or \texttt{hux} for short. This works very much like
\texttt{data.frame}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(huxtable)
ht <- hux(
        Employee     = c('John Smith', 'Jane Doe', 'David Hugh-Jones'), 
        Salary       = c(50000, 50000, 40000),
        add_colnames = TRUE
      )
\end{verbatim}

If you already have your data in a data frame, you can convert it to a huxtable with \texttt{as\_hux}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(mtcars)
car_ht <- as_hux(mtcars)
\end{verbatim}

If you look at a huxtable in R, it will print out a simple representation of the data. Notice that we've added the
column names to the data frame itself, using the \texttt{add\_colnames} argument to \texttt{hux}. We're going to print them out, so they need to be part of the actual table. \textbf{NB:} This means that row 1 of your data will be row 2 of the huxtable, and the
column names of your data will be the new row 1.

\begin{verbatim}
{r eval=FALSE, include=FALSE, results='markup'}
print_screen(ht)     # on the R command line, you can just type  ht 
\end{verbatim}

To print a huxtable out using LaTeX or HTML, just call \texttt{print\_latex} or \texttt{print\_html}. In knitr
documents, like this one, you can simply evaluate the hux. It will know what format to print itself
in.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ht
\end{verbatim}

\hypertarget{changing-the-look-and-feel}{%
\chapter{Changing the look and feel}\label{changing-the-look-and-feel}}

\hypertarget{huxtable-properties}{%
\section{Huxtable properties}\label{huxtable-properties}}

The default output is a very plain table. Let's make it a bit smarter. We'll make the table headings
bold, draw a line under the header row, and add some horizontal space to the cells. We also need to
change that default number formatting to look less scientific.

To do this, we need to set cell level properties. You set properties by assigning to the property name, just as you assign \texttt{names(x)\ \textless{}-\ new\_names} in base R. The following commands assign the value
10 to the \texttt{\{r\ \#\ ight\_padding} and \texttt{left\_padding} properties, for all cells in \texttt{ht}:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
right_padding(ht) <- 10
left_padding(ht)  <- 10
\end{verbatim}

Similarly, we can set the \texttt{number\_format} property to change how numbers are displayed in
cells:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
number_format(ht) <- 2    # 2 decimal places
\end{verbatim}

To assign properties to just some cells, you use subsetting, just as in base R. So, to make the
first row of the table \textbf{bold} and give it a bottom border, we do:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
bold(ht)[1, ]          <- TRUE
bottom_border(ht)[1, ] <- 1
\end{verbatim}

After these changes, our table looks smarter:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ht
\end{verbatim}

So far, all these properties have been set at cell level. Different cells can have different
alignment, text formatting and so on. By contrast, \texttt{caption} is a table-level property. It only
takes one value, which sets a table caption.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

caption(ht) <- 'Employee table'
ht
\end{verbatim}

As well as cell properties and table properties, there is also one row property, row heights, and
one column property, column widths.

The table below shows a complete list of properties. Most properties work the same for LaTeX and
HTML, though there are some exceptions.

\begin{verbatim}
{r, echo = TRUE}
sides <- c('left_', 'right_', 'top_', 'bottom_')
props <- list()
props[['Cell_Text']] <- sort(c('font', 'text_color', 'wrap', 'bold', 'italic', 'font', 'font_size', 'na_string', 'escape_contents', 'number_format', 'rotation'))

props[['Cell']] <- sort(c('align', 'valign', 'rowspan', 'colspan', 'background_color', paste0(sides, 'border'),
      paste0(sides, 'border_color'), paste0(sides, 'padding')))
props[['Row']]    <- 'row_height'
props[['Column']] <- 'col_width'
props[['Table']]  <- sort(c('width', 'height', 'position', 'caption', 'caption_pos', 'tabular_environment', 'label', 'latex_float'))

maxl <- max(sapply(props, length))
props <- lapply(props, function(x) c(x, rep('', maxl - length(x))))

ss_font <- if (guess_knitr_output_format() == 'latex') 'cmtt' else 'courier'

prop_hux <- hux(as.data.frame(props))                     %>% 
      add_colnames                                        %>% 
      {foo <- .; foo[1,] <- gsub('_', ' ', foo[1,]); foo} %>% 
      set_font(-1, everywhere, ss_font)                   %>% 
      set_bold(1, everywhere, TRUE)                       %>% 
      set_width(0.9)                                      %>% 
      set_background_color(everywhere, evens, grey(.9))   %>% 
      set_left_border(everywhere, 1, 1)                   %>% 
      set_right_border(everywhere, final(), 1)            %>% 
      set_top_border(1, everywhere, 1)                    %>% 
      set_bottom_border(1, everywhere, 1)                 %>% 
      set_bottom_border(final(), everywhere, 1)           %>% 
      set_top_padding(2)                                  %>% 
      set_bottom_padding(4)                               %>% 
      set_caption('Huxtable properties')                  %>% 
      set_position('left') %>% 
      set_col_width(c(.2, .25, .15, .15, .25))

prop_hux
\end{verbatim}

\hypertarget{tidyverse-syntax}{%
\section{Tidyverse syntax}\label{tidyverse-syntax}}

If you prefer a tidyverse style of code, using the pipe operator \texttt{\%\textgreater{}\%}, then you can use \texttt{set\_*}
functions. These have the same name as the property, with \texttt{set\_} prepended. For example, to set
the \texttt{bold} property, you use the \texttt{set\_bold} function.

\texttt{set\_*} functions return the modified huxtable, so you can chain them together like this:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

library(dplyr)
hux(
        Employee     = c('John Smith', 'Jane Doe', 'David Hugh-Jones'), 
        Salary       = c(50000, 50000, 40000),
        add_colnames = TRUE
      )                               %>% 
      set_bold(1, 1:2, TRUE)          %>% 
      set_bottom_border(1, 1:2, 1)    %>%
      set_align(1:4, 2, 'right')      %>%
      set_right_padding(10)           %>%
      set_left_padding(10)            %>% 
      set_caption('Employee table')
  
\end{verbatim}

\texttt{set\_*} functions for cell properties are called like this: \texttt{set\_xxx(ht,\ row,\ col,\ value)} or like
this: \texttt{set\_xxx(ht,\ value)}. If you use the second form, then the value is set for all cells. \texttt{set\_*}
functions for table properties are always called like \texttt{set\_xxx(ht,\ value)}. We'll learn more about
this interface in a moment.

There are also four useful convenience functions:

\begin{itemize}
\tightlist
\item
  \texttt{set\_all\_borders} sets left, right, top and bottom borders for selected cells;
\item
  \texttt{set\_all\_border\_colors} sets left, right, top and bottom border colors;
\item
  \texttt{set\_all\_padding} sets left, right, top and bottom padding (the amount of space between the content and the border);
\item
  \texttt{set\_outer\_borders} sets an outer border around a rectangle of cells.
\end{itemize}

\hypertarget{getting-properties}{%
\section{Getting properties}\label{getting-properties}}

To get the current properties of a huxtable, just use the properties function without the left arrow:

\begin{verbatim}
{r, results = 'markup', eval=FALSE}
italic(ht)
position(ht)
\end{verbatim}

As before, you can use subsetting to get particular rows or columns:

\begin{verbatim}
{r, results = 'markup', eval=FALSE}
bottom_border(ht)[1:2,]
bold(ht)[,'Salary']
\end{verbatim}

\hypertarget{editing-content}{%
\chapter{Editing content}\label{editing-content}}

\hypertarget{standard-subsetting}{%
\section{Standard subsetting}\label{standard-subsetting}}

You can subset, sort and generally data-wrangle a huxtable just like a normal data frame. Cell and
table properties will be carried over into subsets.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Select columns by name:
cars_mpg <- car_ht[, c('mpg', 'cyl', 'am')] 
# Order by number of cylinders:
cars_mpg <- cars_mpg[order(cars_mpg$cyl),]

cars_mpg <- cars_mpg                          %>% 
      huxtable::add_rownames(colname = 'Car') %>% 
      huxtable::add_colnames()

cars_mpg[1:5,]
\end{verbatim}

\hypertarget{using-dplyr-with-huxtable}{%
\section{Using dplyr with huxtable}\label{using-dplyr-with-huxtable}}

You can also use \texttt{dplyr} functions to edit a huxtable:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
car_ht <- car_ht                                          %>%
      huxtable::add_rownames(colname = 'Car')             %>%
      slice(1:10)                                         %>% 
      select(Car, mpg, cyl, hp)                           %>% 
      arrange(hp)                                         %>% 
      filter(cyl > 4)                                     %>% 
      rename(MPG = mpg, Cylinders = cyl, Horsepower = hp) %>% 
      mutate(kml = MPG/2.82)                               


car_ht <- car_ht                               %>% 
      set_number_format(1:7, 'kml', 2)         %>% 
      set_col_width(c(.35, .15, .15, .15, .2)) %>% 
      set_width(.6)                            %>% 
      huxtable::add_colnames() 

car_ht
\end{verbatim}

In general it is a good idea to prepare your data first, before styling it. For example, it was easier to sort the \texttt{cars\_mpg} data by cylinder, before adding column names to the data frame itself.

\hypertarget{functions-to-insert-rows-columns-and-footnotes}{%
\section{Functions to insert rows, columns and footnotes}\label{functions-to-insert-rows-columns-and-footnotes}}

Huxtable has three convenience functions for adding a row or column to your table: \texttt{insert\_row},
\texttt{insert\_column} and \texttt{add\_footnote}.
\texttt{insert\_row} and \texttt{insert\_column} let you add a single row or column. The \texttt{after} parameter specifies
where in the table to do the insertion, i.e.~after what row or column number.
\texttt{add\_footnote} adds a single cell in a new row at the bottom. The cell spans the whole table row,
and has a border above.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ht <- insert_row(ht, 'Hadley Wickham', '100000', after = 3)
ht <- add_footnote(ht, 'DHJ deserves a pay rise')
ht
\end{verbatim}

\hypertarget{more-formatting}{%
\chapter{More formatting}\label{more-formatting}}

\hypertarget{number-format}{%
\section{Number format}\label{number-format}}

You can change how huxtable formats numbers using \texttt{number\_format}. Set \texttt{number\_format} to a number of decimal places
(for more advanced options, see the help files). This affects all numbers, or number-like substrings within your cells.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pointy_ht <- hux(c('Do not pad this.', 11.003, 300, 12.02, '12.1 **')) %>% set_all_borders(1)

number_format(pointy_ht) <- 3
pointy_ht
\end{verbatim}

You can also align columns by decimal places. If you want to do this for a cell, just set the \texttt{align} property
to `.' (or whatever you use for a decimal point).

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
align(pointy_ht)[2:5, ] <- '.' # not the first row
pointy_ht
\end{verbatim}

There is currently no true way to align cells by the decimal point in HTML, and only limited possibilities in TeX, so this works by right-padding cells with spaces. The output may look better
if you use a fixed width font.

\hypertarget{automatic-formatting}{%
\section{Automatic formatting}\label{automatic-formatting}}

By default, when you create a huxtable using \texttt{huxtable} or \texttt{as\_huxtable}, the package will guess
defaults for number formatting and alignment, based on the type of data in your columns. Numeric
data will be right-aligned or aligned on the decimal point; character data will be left aligned;
and the package will try to set sensible defaults for number formatting. If you want to, you can
turn this off with \texttt{autoformat\ =\ FALSE}:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

my_data <- data.frame(
        Employee           = c('John Smith', 'Jane Doe', 'David Hugh-Jones'), 
        Salary             = c(50000L, 50000L, 40000L),
        Performance_rating = c(8.9, 9.2, 7.8)  
      )
as_huxtable(my_data, add_colnames = TRUE) # with automatic formatting

as_huxtable(my_data, add_colnames = TRUE, autoformat = FALSE) # no automatic formatting
\end{verbatim}

\hypertarget{escaping-html-or-latex}{%
\section{Escaping HTML or LaTeX}\label{escaping-html-or-latex}}

By default, HTML or LaTeX code will be escaped:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
code_ht <- if (is_latex) hux(c('Some maths', '$a^b$')) else 
      hux(c('Copyright symbol', '&copy;'))
code_ht
\end{verbatim}

To avoid this, set the \texttt{escape\_contents} property to \texttt{FALSE}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
escape_contents(code_ht)[2, 1] <- FALSE
code_ht
\end{verbatim}

\hypertarget{width-and-cell-wrapping}{%
\section{Width and cell wrapping}\label{width-and-cell-wrapping}}

You can set table widths using the \texttt{width} property, and column widths using the \texttt{col\_width} property. If you use
numbers for these, they will be interpreted as proportions of the table width (or for \texttt{width}, a proportion of the
width of the surrounding text). If you use character vectors, they must be valid CSS or LaTeX widths. The only
unit both systems have in common is \texttt{pt} for points.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
width(ht) <- 0.35
col_width(ht) <- c(.7, .3)
ht
\end{verbatim}

It is best to set table width explicitly, then set column widths as proportions.

By default, if a cell contains long contents, it will be stretched. Use the \texttt{wrap} property to allow cell contents
to wrap over multiple lines:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ht_wrapped <- ht
ht_wrapped[5, 1] <- 'David Arthur Shrimpton Hugh-Jones'
wrap(ht_wrapped) <- TRUE
ht_wrapped
\end{verbatim}

\hypertarget{adding-row-and-column-names}{%
\section{Adding row and column names}\label{adding-row-and-column-names}}

Just like data frames, huxtables can have row and column names. Often, we want to add these to the final table.
You can do this using either the \texttt{add\_colnames}/\texttt{add\_rownames} arguments to \texttt{as\_huxtable}, or the
\texttt{add\_colnames()}/\texttt{add\_rownames()} functions. (Note that earlier versions of \texttt{dplyr} used to have functions with the
same name.)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
as_hux(mtcars[1:4, 1:4])                           %>% 
      huxtable::add_rownames(colname = 'Car name') %>% 
      huxtable::add_colnames()
\end{verbatim}

\hypertarget{column-and-row-spans}{%
\section{Column and row spans}\label{column-and-row-spans}}

Huxtable cells can span multiple rows or columns, using the \texttt{colspan} and \texttt{\{r\ \#\ owspan} properties.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cars_mpg <- cbind(car_type = rep(  , nrow(cars_mpg)), cars_mpg)
cars_mpg$car_type[1] <- 'Four cylinders'
cars_mpg$car_type[13] <- 'Six cylinders'
cars_mpg$car_type[20] <- 'Eight cylinders'
rowspan(cars_mpg)[1, 1] <- 12
rowspan(cars_mpg)[13, 1] <- 7
rowspan(cars_mpg)[20, 1] <- 14

cars_mpg <- rbind(c('', 'List of cars', '', '', ''), cars_mpg)
colspan(cars_mpg)[1, 2] <- 4
align(cars_mpg)[1, 2] <- 'center'

# a little more formatting:

cars_mpg <- set_all_padding(cars_mpg, 2)
cars_mpg <- set_all_borders(cars_mpg, 1)
valign(cars_mpg)[1,] <- 'top'
col_width(cars_mpg) <- c(.4 , .3 , .1, .1, .1)
number_format(cars_mpg)[, 4:5] <- 0
bold(cars_mpg)[1:2, ] <- TRUE
bold(cars_mpg)[, 1] <- TRUE
if (is_latex) font_size(cars_mpg) <- 10
cars_mpg
\end{verbatim}

\hypertarget{quick-themes}{%
\section{Quick themes}\label{quick-themes}}

Huxtable comes with some predefined themes for formatting.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
theme_striped(cars_mpg[14:20,], stripe = 'bisque1', header_col = FALSE, header_row = FALSE)
\end{verbatim}

\hypertarget{selecting-rows-columns-and-cells}{%
\chapter{Selecting rows, columns and cells}\label{selecting-rows-columns-and-cells}}

\hypertarget{row-and-column-functions}{%
\section{Row and column functions}\label{row-and-column-functions}}

If you use the \texttt{set\_*} style functions, huxtable has some convenience functions for selecting rows and columns.

To select all rows, or all columns, use \texttt{everywhere} in the row or column specification. To select just even or odd-numbered rows or columns, use \texttt{evens} or \texttt{odds}. To select the last \texttt{n} rows or columns, use \texttt{final(n)}.
To select every \emph{n}th row, use \texttt{every(n)} and to do this starting from row \emph{m} use \texttt{every(n,\ from\ =\ m)}.

With these functions it is easy to add striped backgrounds to tables:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
car_ht                                                 %>% 
      set_background_color(evens, everywhere, 'wheat') %>% 
      set_background_color(odds, everywhere, grey(.9)) %>% 
      set_bold(1, everywhere, TRUE)
\end{verbatim}

Of course you could also just do \texttt{1:nrow(car\_ht)}, but, in the middle of a dplyr pipe, you may not know exactly
how many rows or columns you have. Also, these functions make your code easy to read.

You can also use \texttt{dplyr} functions like \texttt{starts\_with()}, \texttt{contains()}, and \texttt{matches()} to specify columns by column
name. For a full list of these functions, see \texttt{?select\_helpers}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
car_ht %>% set_background_color(everywhere, starts_with('C'), 'orange')
car_ht %>% set_italic(everywhere, matches('[aeiou]'), TRUE)
\end{verbatim}

Note that unlike in \texttt{dplyr}'s \texttt{select} function, you have to specify rows as well as columns.

Lastly, remember that you can set a property for every cell by simply omitting the \texttt{\{r\ \#\ ow} and \texttt{col} arguments, like this:
\texttt{set\_background\_color(ht,\ \textquotesingle{}orange\textquotesingle{})}.

\hypertarget{conditional-formatting}{%
\section{Conditional formatting}\label{conditional-formatting}}

You may want to apply conditional formatting to cells, based on their contents. Suppose we want to display a table of correlations, and to highlight ones which are significant. We can use the \texttt{where()} function to select those cells.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(psych)
data(attitude)
att_corr <- corr.test(as.matrix(attitude))

att_hux <- as_hux(att_corr$r)                                           %>% 
      # selects cells with p < 0.05:
      set_background_color(where(att_corr$p < 0.05), 'yellow')          %>% 
      # selects cells with p < 0.01:
      set_background_color(where(att_corr$p < 0.01), 'orange')          %>% 
      set_text_color(where(row(att_corr$r) == col(att_corr$r)), 'grey') 


att_hux <- att_hux                                                      %>% 
      huxtable::add_rownames()                                          %>% 
      huxtable::add_colnames()                                          %>%
      set_caption('Correlations in attitudes among 30 departments')     %>% 
      set_bold(1, everywhere, TRUE)                                     %>% 
      set_bold(everywhere, 1, TRUE)                                     %>% 
      set_all_borders(1)                                                %>%
      set_number_format(2)                                              %>% 
      set_position('left')

att_hux
\end{verbatim}

We have now seen three ways to call \texttt{set\_*} functions in huxtable:

\begin{itemize}
\tightlist
\item
  With four arguments, like \texttt{set\_property(hux\_object,\ rows,\ cols,\ value)};
\item
  With two arguments, like \texttt{set\_property(hux\_object,\ value)} to set a property everywhere;
\item
  With three arguments, like \texttt{set\_property(hux\_object,\ where(condition),\ value)} to set a property for specific cells.
\end{itemize}

The second argument of the three-argument version must return a 2-column matrix. Each row of the matrix gives one cell.
\texttt{where()} does this for you: it takes a logical matrix argument and returns the rows and columns where a condition is
\texttt{TRUE}. It's easiest to show this with an example:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
m <- matrix(c('dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog'), 4, 2)
m
where(m == 'dog') # m is equal to 'dog' in cells (1, 1), (3, 1), (4, 1) and (4, 2):
\end{verbatim}

\texttt{set\_*} functions have one more optional argument, the \texttt{byrow} argument, which is \texttt{FALSE} by default. If you set a
single pattern for many cells, you may want the pattern to fill the matrix by column or by row. The default fills the
pattern in going down columns. If you set \texttt{byrow\ =\ TRUE}, the pattern goes across rows instead. (This is a bit
confusing: typically, \texttt{byrow\ =\ TRUE} means that the \emph{columns} will all look the same. But it works the same way as the
\texttt{byrow} argument to \texttt{matrix()}.)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

color_demo <- matrix('text', 7, 7)
rainbow <- c('red', 'orange', 'yellow', 'green', 'blue', 'turquoise', 'violet')
color_demo <- as_hux(color_demo)                  %>% 
      set_text_color(rainbow)                     %>% # text rainbow down columns
      set_background_color(rainbow, byrow = TRUE) %>% # background color rainbow along rows
      set_all_borders(1)                          %>% 
      set_all_border_colors('white')
color_demo
\end{verbatim}

\hypertarget{creating-a-regression-table}{%
\chapter{Creating a regression table}\label{creating-a-regression-table}}

A common task for scientists is to create a table of regressions. The function \texttt{huxreg} does this for you. Here's a quick example:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(diamonds, package = 'ggplot2')

lm1 <- lm(price ~ carat, diamonds)
lm2 <- lm(price ~ depth, diamonds)
lm3 <- lm(price ~ carat + depth, diamonds)

huxreg(lm1, lm2, lm3)
\end{verbatim}

For more information see the \texttt{huxreg} vignette, available online in
\href{https://hughjonesd.github.io/huxtable/huxreg.html}{HTML} or \href{https://hughjonesd.github.io/huxtable/huxreg.pdf}{PDF} or
in R via \texttt{vignette(\textquotesingle{}huxreg\textquotesingle{})}.

\hypertarget{output-to-different-formats}{%
\chapter{Output to different formats}\label{output-to-different-formats}}

\hypertarget{automatic-pretty-printing-of-data-frames}{%
\section{Automatic pretty-printing of data frames}\label{automatic-pretty-printing-of-data-frames}}

If you load huxtable within a knitr document, it will automatically format data frames for you by
installing a \texttt{knit\_print.data\_frame} command.

\begin{verbatim}
{r, echo = TRUE, eval=FALSE}
options(huxtable.knit_print_df = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
head(mtcars)
\end{verbatim}

If you don't want this (e.g.~if you want to use \texttt{knitr::kable} or the \href{https://cran.r-project.org/web/packages/printr/vignettes/printr.html}{printr package}, then you can
turn it off like this:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
options(huxtable.knit_print_df = FALSE)

head(mtcars) # back to normal
\end{verbatim}

\hypertarget{using-huxtables-in-knitr-and-rmarkdown}{%
\section{Using huxtables in knitr and rmarkdown}\label{using-huxtables-in-knitr-and-rmarkdown}}

If you use knitr and rmarkdown in RStudio, huxtable objects should automatically display in the
appropriate format (HTML or LaTeX). You need to have some LaTeX packages installed for huxtable to
work. To find out what these are, you can call \texttt{\{r\ \#\ eport\_latex\_dependencies()}. This will print out
and/or return a set of \texttt{usepackage\{...\}} statements. If you use Sweave or knitr without rmarkdown,
you can use this function in your LaTeX preamble to load the packages you need.

Rmarkdown exports to Word via Markdown. You can use huxtable to do this, but since Markdown tables
are rather basic, a lot of formatting will be lost. If you want to create Word or Powerpoint
documents directly, install the \href{https://cran.r-project.org/package=flextable}{flextable package}
from CRAN. You can then convert your huxtable objects to \texttt{flextable} objects and include them in
Word or Powerpoint documents. Almost all formatting should work. See the \texttt{flextable} and \texttt{officer}
documentation and \texttt{?as\_flextable} for more details.

Similarly, to create formatted reports in Excel, install the \href{https://cran.r-project.org/package=openxlsx}{openxlsx
package}. You can then use \texttt{as\_Workbook} to convert
your huxtables to Workbook objects, and save them using \texttt{openxlsx::saveWorkbook}.

Sometimes you may want to select how huxtable objects are printed by default. For example, in an
RStudio notebook (a .Rmd document with \texttt{output\_format\ =\ html\_notebook}), huxtable can't
automatically work out what format to use, as of the time of writing. You can set it manually using
\texttt{options(huxtable.print\ =\ print\_notebook)} which prints out HTML in an appropriate format.

You can print a huxtable on screen using \texttt{print\_screen} (or just by typing its name at the command
line.) Borders, column and row spans and cell alignment are shown. If the
\href{https://cran.r-project.org/package=crayon}{crayon} package is installed, and your terminal or R IDE
supports it, border, text and background colours are also displayed.

\begin{verbatim}
{r, results = 'markup', eval=FALSE}
print_screen(ht)
\end{verbatim}

If you need to output to another format, file an
\href{https://github.com/hughjonesd/huxtable}{issue request} on Github.

\hypertarget{quick-output-commands}{%
\section{Quick output commands}\label{quick-output-commands}}

Sometimes you quickly want to get your data into a Word, HTML or PDF document. To do this you can
use the \texttt{quick\_docx}, \texttt{quick\_html}, \texttt{quick\_pdf} and \texttt{quick\_xlsx} functions. These are called with
one or more huxtable objects, or objects which can be turned into a huxtable such as data frames. A
new document of the appropriate type will be created. By default the file will be in the current
directory under the name e.g.~\texttt{huxtable-output.pdf}. If the file already exists, you'll be asked to
confirm the overwrite. For non-interactive use, you must specify a filename yourself explicitly --
this keeps you from accidentally trashing your files.

\begin{verbatim}
{r, eval = FALSE}
quick_pdf(mtcars) 
quick_pdf(mtcars, file = 'motorcars data.pdf')
\end{verbatim}

\hypertarget{end-matter}{%
\chapter{End matter}\label{end-matter}}

For more information, see the \href{https://hughjonesd.github.io/huxtable}{website} or
\href{https://github.com/hughjonesd/huxtable}{github}.

\hypertarget{hypothesis-testing-1}{%
\chapter{Hypothesis Testing}\label{hypothesis-testing-1}}

\hypertarget{glue}{%
\chapter{Glue}\label{glue}}

Glue strings to data in R. Small, fast, dependency free interpreted string literals.

\url{https://glue.tidyverse.org/}

\hypertarget{infer-package}{%
\chapter{infer package}\label{infer-package}}

Statistical Inference: A Tidy Approach
\url{https://ismayc.github.io/talks/ness-infer/slide_deck.html}

\url{https://infer.netlify.com/}

\url{https://moderndive.netlify.com/}

\url{https://cran.r-project.org/web/packages/infer/index.html}

\hypertarget{hypothesis-testing-2}{%
\chapter{Hypothesis Testing}\label{hypothesis-testing-2}}

\hypertarget{test-selection}{%
\section{Test Selection}\label{test-selection}}

\hypertarget{statkat}{%
\subsection{Statkat}\label{statkat}}

\url{https://statkat.com/}

\url{https://statkat.com/stattest_overview.php}

\hypertarget{jamovi-statkat-module}{%
\subsubsection{Jamovi Statkat module}\label{jamovi-statkat-module}}

\url{https://blog.jamovi.org/2018/06/25/statkat.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(jmv)
library(Statkat)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

Statkat::correlational(
    data = data,
    dep =  len ,
    independents =  supp )
\end{verbatim}

\hypertarget{infer-2}{%
\chapter{infer}\label{infer-2}}

Full infer pipeline examples using nycflights13 flights data

\url{https://cran.r-project.org/web/packages/infer/vignettes/observed_stat_examples.html}

Full infer pipeline examples using nycflights13 flights data
Chester Ismay
Updated on 2018-06-14
Data preparation
library(nycflights13)
library(dplyr)
library(ggplot2)
library(stringr)
library(infer)
set.seed(2017)
fli\_small \textless- flights \%\textgreater\%
na.omit() \%\textgreater\%
sample\_n(size = 500) \%\textgreater\%
mutate(season = case\_when(
month \%in\% c(10:12, 1:3) \textasciitilde{} winter ,
month \%in\% c(4:9) \textasciitilde{} summer
)) \%\textgreater\%
mutate(day\_hour = case\_when(
between(hour, 1, 12) \textasciitilde{} morning ,
between(hour, 13, 24) \textasciitilde{} not morning
)) \%\textgreater\%
select(arr\_delay, dep\_delay, season,
day\_hour, origin, carrier)
Two numeric - arr\_delay, dep\_delay
Two categories
season ( winter , summer ),
day\_hour ( morning , not morning )
Three categories - origin ( EWR , JFK , LGA )
Sixteen categories - carrier
Hypothesis tests
One numerical variable (mean)
Observed stat

( x\_bar \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
calculate(stat = mean ) )
stat
10.4
null\_distn \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
hypothesize(null = point , mu = 10) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = mean )
\#\# Setting \texttt{type\ =\ \ bootstrap} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = x\_bar, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = x\_bar, direction = two\_sided )
p\_value
0.794
One numerical variable (standardized mean t)
Observed stat

( t\_bar \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
calculate(stat = t ) )
stat
6.93
null\_distn \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
hypothesize(null = point , mu = 8) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = t )
\#\# Setting \texttt{type\ =\ \ bootstrap} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = t\_bar, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = t\_bar, direction = two\_sided )
p\_value
0
One numerical variable (median)
Observed stat

( x\_tilde \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
calculate(stat = median ) )
stat
-2
null\_distn \textless- fli\_small \%\textgreater\%
specify(response = dep\_delay) \%\textgreater\%
hypothesize(null = point , med = -1) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = median )
\#\# Setting \texttt{type\ =\ \ bootstrap} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = x\_tilde, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = x\_tilde, direction = two\_sided )
p\_value
0.15
One categorical (one proportion)
Observed stat

( p\_hat \textless- fli\_small \%\textgreater\%
specify(response = day\_hour, success = morning ) \%\textgreater\%
calculate(stat = prop ) )
stat
0.466
null\_distn \textless- fli\_small \%\textgreater\%
specify(response = day\_hour, success = morning ) \%\textgreater\%
hypothesize(null = point , p = .5) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = prop )
\#\# Setting \texttt{type\ =\ \ simulate} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = p\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = p\_hat, direction = two\_sided )
p\_value
0.11
Logical variables will be coerced to factors:

null\_distn \textless- fli\_small \%\textgreater\%
mutate(day\_hour\_logical = (day\_hour == morning )) \%\textgreater\%
specify(response = day\_hour\_logical, success = TRUE ) \%\textgreater\%
hypothesize(null = point , p = .5) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = prop )
\#\# Setting \texttt{type\ =\ \ simulate} in \texttt{generate()}.
One categorical variable (standardized proportion z)
Not yet implemented.

Two categorical (2 level) variables
Observed stat

( d\_hat \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
calculate(stat = diff in props , order = c( winter , summer )) )
stat
-0.0205
null\_distn \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = diff in props , order = c( winter , summer ))
\#\# Setting \texttt{type\ =\ \ permute} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = d\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = d\_hat, direction = two\_sided )
p\_value
0.708
Two categorical (2 level) variables (z)
Standardized observed stat

( z\_hat \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
calculate(stat = z , order = c( winter , summer )) )
stat
-0.4605
null\_distn \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000) \%\textgreater\%
calculate(stat = z , order = c( winter , summer ))
\#\# Setting \texttt{type\ =\ \ permute} in \texttt{generate()}.
visualize(null\_distn) +
shade\_p\_value(obs\_stat = z\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = z\_hat, direction = two\_sided )
p\_value
0.684
Note the similarities in this plot and the previous one.

One categorical (\textgreater2 level) - GoF
Observed stat

Note the need to add in the hypothesized values here to compute the observed statistic.

( Chisq\_hat \textless- fli\_small \%\textgreater\%
specify(response = origin) \%\textgreater\%
hypothesize(null = point ,
p = c( EWR = .33, JFK = .33, LGA = .34)) \%\textgreater\%
calculate(stat = Chisq ) )
stat
10.4
null\_distn \textless- fli\_small \%\textgreater\%
specify(response = origin) \%\textgreater\%
hypothesize(null = point ,
p = c( EWR = .33, JFK = .33, LGA = .34)) \%\textgreater\%
generate(reps = 1000, type = simulate ) \%\textgreater\%
calculate(stat = Chisq )

visualize(null\_distn) +
shade\_p\_value(obs\_stat = Chisq\_hat, direction = greater )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = Chisq\_hat, direction = greater )
p\_value
0.005
Two categorical (\textgreater2 level) variables
Observed stat

( Chisq\_hat \textless- fli\_small \%\textgreater\%
specify(formula = day\_hour \textasciitilde{} origin) \%\textgreater\%
calculate(stat = Chisq ) )
stat
9.027
null\_distn \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} origin) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = Chisq )

visualize(null\_distn) +
shade\_p\_value(obs\_stat = Chisq\_hat, direction = greater )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = Chisq\_hat, direction = greater )
p\_value
0.007
One numerical variable, one categorical (2 levels) (diff in means)
Observed stat

( d\_hat \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\%
calculate(stat = diff in means , order = c( summer , winter )) )
stat
2.266
null\_distn \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = diff in means , order = c( summer , winter ))

visualize(null\_distn) +
shade\_p\_value(obs\_stat = d\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = d\_hat, direction = two\_sided )
p\_value
0.488
One numerical variable, one categorical (2 levels) (t)
Standardized observed stat

( t\_hat \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\%
calculate(stat = t , order = c( summer , winter )) )
stat
0.7542
null\_distn \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = t , order = c( summer , winter ))

visualize(null\_distn) +
shade\_p\_value(obs\_stat = t\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = t\_hat, direction = two\_sided )
p\_value
0.49
Note the similarities in this plot and the previous one.

One numerical variable, one categorical (2 levels) (diff in medians)
Observed stat

( d\_hat \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\%
calculate(stat = diff in medians , order = c( summer , winter )) )
stat
2
null\_distn \textless- fli\_small \%\textgreater\%
specify(dep\_delay \textasciitilde{} season) \%\textgreater\% \# alt: response = dep\_delay,
\# explanatory = season
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = diff in medians , order = c( summer , winter ))

visualize(null\_distn) +
shade\_p\_value(obs\_stat = d\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = d\_hat, direction = two\_sided )
p\_value
0.084
One numerical, one categorical (\textgreater2 levels) - ANOVA
Observed stat

( F\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} origin) \%\textgreater\%
calculate(stat = F ) )
stat
1.084
null\_distn \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} origin) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = F )

visualize(null\_distn) +
shade\_p\_value(obs\_stat = F\_hat, direction = greater )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = F\_hat, direction = greater )
p\_value
0.353
Two numerical vars - SLR
Observed stat

( slope\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
calculate(stat = slope ) )
stat
1.017
null\_distn \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = slope )

visualize(null\_distn) +
shade\_p\_value(obs\_stat = slope\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = slope\_hat, direction = two\_sided )
p\_value
0
Two numerical vars - correlation
Observed stat

( correlation\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
calculate(stat = correlation ) )
stat
0.8943
null\_distn \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
hypothesize(null = independence ) \%\textgreater\%
generate(reps = 1000, type = permute ) \%\textgreater\%
calculate(stat = correlation )

visualize(null\_distn) +
shade\_p\_value(obs\_stat = correlation\_hat, direction = two\_sided )

null\_distn \%\textgreater\%
get\_p\_value(obs\_stat = correlation\_hat, direction = two\_sided )
p\_value
0
Two numerical vars - SLR (t)
Not currently implemented since t could refer to standardized slope or standardized correlation.

Confidence intervals
One numerical (one mean)
Point estimate

( x\_bar \textless- fli\_small \%\textgreater\%
specify(response = arr\_delay) \%\textgreater\%
calculate(stat = mean ) )
stat
4.572
boot \textless- fli\_small \%\textgreater\%
specify(response = arr\_delay) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = mean )
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
1.436 7.819
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = x\_bar) )
lower upper
1.267 7.877
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

One numerical (one mean - standardized)
Point estimate

( t\_hat \textless- fli\_small \%\textgreater\%
specify(response = arr\_delay) \%\textgreater\%
calculate(stat = t ) )
stat
2.679
boot \textless- fli\_small \%\textgreater\%
specify(response = arr\_delay) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = t )
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
0.9338 4.362
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = t\_hat) )
lower upper
0.9141 4.444
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

One categorical (one proportion)
Point estimate

( p\_hat \textless- fli\_small \%\textgreater\%
specify(response = day\_hour, success = morning ) \%\textgreater\%
calculate(stat = prop ) )
stat
0.466
boot \textless- fli\_small \%\textgreater\%
specify(response = day\_hour, success = morning ) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = prop )
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
0.42 0.508
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = p\_hat) )
lower upper
0.4218 0.5102
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

One categorical variable (standardized proportion z)
Not yet implemented.

One numerical variable, one categorical (2 levels) (diff in means)
Point estimate

( d\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} season) \%\textgreater\%
calculate(stat = diff in means , order = c( summer , winter )) )
stat
-0.7452
boot \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} season) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = diff in means , order = c( summer , winter ))
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
-7.167 6.079
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = d\_hat) )
lower upper
-7.296 5.806
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

One numerical variable, one categorical (2 levels) (t)
Standardized point estimate

( t\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} season) \%\textgreater\%
calculate(stat = t , order = c( summer , winter )) )
stat
-0.2182
boot \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} season) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = t , order = c( summer , winter ))
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
-2.236 1.718
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = t\_hat) )
lower upper
-2.183 1.746
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

Two categorical variables (diff in proportions)
Point estimate

( d\_hat \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
calculate(stat = diff in props , order = c( summer , winter )) )
stat
0.0205
boot \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = diff in props , order = c( summer , winter ))
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
-0.0648 0.1083
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = d\_hat) )
lower upper
-0.0676 0.1087
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

Two categorical variables (z)
Standardized point estimate

( z\_hat \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
calculate(stat = z , order = c( summer , winter )) )
stat
0.4605
boot \textless- fli\_small \%\textgreater\%
specify(day\_hour \textasciitilde{} season, success = morning ) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = z , order = c( summer , winter ))
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
-1.479 2.501
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = z\_hat) )
lower upper
-1.522 2.443
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

Two numerical vars - SLR
Point estimate

( slope\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
calculate(stat = slope ) )
stat
1.017
boot \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = slope )
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
0.9728 1.074
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se , point\_estimate = slope\_hat) )
lower upper
0.9653 1.069
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

Two numerical vars - correlation
Point estimate

( correlation\_hat \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
calculate(stat = correlation ) )
stat
0.8943
boot \textless- fli\_small \%\textgreater\%
specify(arr\_delay \textasciitilde{} dep\_delay) \%\textgreater\%
generate(reps = 1000, type = bootstrap ) \%\textgreater\%
calculate(stat = correlation )
( percentile\_ci \textless- get\_ci(boot) )
2.5\% 97.5\%
0.8502 0.9218
visualize(boot) +
shade\_confidence\_interval(endpoints = percentile\_ci)

( standard\_error\_ci \textless- get\_ci(boot, type = se ,
point\_estimate = correlation\_hat) )
lower upper
0.858 0.9306
visualize(boot) +
shade\_confidence\_interval(endpoints = standard\_error\_ci)

Two numerical vars - t
Not currently implemented since t could refer to standardized slope or standardized correlation.

\hypertarget{keras}{%
\chapter{Keras}\label{keras}}

\url{https://keras.io/}

\hypertarget{k-means-clustering-1}{%
\chapter{K Means Clustering}\label{k-means-clustering-1}}

\url{https://datascienceplus.com/k-means-clustering-in-r/}

\hypertarget{lessr}{%
\chapter{lessR}\label{lessr}}

lessRstats.com/lessR.r
tour of lessR functions for data analysis

Purpose: Provide basic statistical computations for the analyses presented in intro stat texts and more

Get R
\url{http://r-project.org}

one time only, to get the lessR functions onto your computer if asked to install into a personal library, say Yes

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( lessR )
\end{verbatim}

Begin each R session by loading the lessR functions

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(lessR)
\end{verbatim}

help

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Help()   # list the lessR help values by subject
Help(lessR) #  access to the full lessR manual and News items
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Help(Read)
\end{verbatim}

read data from one of many different formats into a data table called mydata with the same Read statement: csv, tab-delimited text, Excel, SPSS, and SAS

Categorical: Gender coded M, F; Dept coded ACCT, ADMN, FINC, MKTG, SALE Numeric: Salary and Years

\texttt{mydata\ \textless{}-\ Read()} or \texttt{\{r\ \#\ d()}, browse for text, Excel, SPSS, SAS, or R data file

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
head(mydata) #  R function, see variable names and first 6 rows of data
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mydata <- Read( http://lessRstats.com/data/employee.csv )   # read data from web
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mydata <- Read( http://lessRstats.com/data/employee.csv , row.names=1) # row names
\end{verbatim}

data included as part of lessR

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mydata <- rd( Employee , format= lessR )  # this example includes variable labels
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
details() #  provides full details of the data frame, defaults to mydata
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}




db()   brief version, same as provided by Read

 can also read a text file o fixed width formatted data
 example provided later

 distribution of a categorical variable
 
 all the same
BarChart(Dept)    or bc(Dept)
bc(Dept)    all function calls have a 2 or 3 digit abbreviation
BarChart(Dept, data=mydata)    mydata is the default data frame (table)
bc(Dept, fill= colors )   specify a more colorful display
bc(Dept, rotate.x=45, offset=1)   value labels rotated and offset
 other summaries
PieChart(Dept)    or pc(Dept), provides a doughnut or ring chart
PieChart(Dept, hole=0)    full pie chart
Plot(Dept)   or Plot(Dept), 1-categorical variable bubble plot
SummaryStats(Dept)   or ss(Dept), no graphics

 read Mach IV data, integer Likert responses from 0 to 5
mydata <- Read( Mach4 , format= lessR )   read a data file included with lessR
 form a Bubble Plot Frequency Matrix (BPFM) from a range of x-variables
 each line is a bubble plot of frequencies for a single variable
Plot(c(m06,m07,m09,m10))
 for each bubble, lighten fill color, make border black
Plot(m06:m12, trans=.8, coloe= gray50 )
 create BPFM for entire Mach IV scale and store as a pdf file
LikertCats <- c( Strongly Disagree ,  Disagree ,  Slightly Disagree ,
                      Slightly Agree ,  Agree ,  Strongly Agree )
Plot(m01:m20, value.labels=LikertCats, pdf.file= MachFreqs.pdf )
Plot(m06)   Integrated Violin/Box/Scatterplot (VBS plot)

 back to the Employee data
mydata <- rd( Employee , format= lessR )   includes variable labels


 distribution of a numeric (continuous) variable
 
Plot(Salary)    Integrated Violin/Box/Scatterplot (VBS plot)
Plot(Salary, by1=Gender)    Trellis VBS plots for Gender
Histogram(Salary)    or hs(Salary)
hs(Salary, bin.start=30000, bin.width=12000, bin.end=150000)   common options
Density(Salary)   or dn(Salary)
BoxPlot(Salary)   or bx(Salary), a call to Plot with vbs.plot= b 
SummaryStats(Salary)   or ss(Salary)
ss.brief(Salary)   brief output
hs(Salary, Rmd= Salary )   generate an R markdown file of all the methods
hs(Salry)    ERROR, misspelled variable name to show lessR error messages

 for ordered values, such as by time (just for illustration here)
LineChart(Salary)   or lc(Salary)
Plot(Salary, run=TRUE)
Plot(Salary, run=TRUE, center.line= off , show.runs=TRUE)
Plot(Salary, run=TRUE, lwd=0)   points only
Plot(Salary, run=TRUE, size=0)   line only
Plot(Salary, run=TRUE, area=TRUE)

 distributions for multiple variables (writes to pdf files)
 
 the corresponding standard R functions do not take multiple variables
 specify multiple variables with c function or :
Histogram(c(Salary, Years))   c is R combine function
BarChart(Gender:Satisfaction)   : indicates a range of variables in R
Histogram()  a histogram for each numeric variable in mydata data table
CountAll()   or ca(), a bar chart or histogram for each variable in mydata

 relationship of two variables
 
 two numeric variables yields traditional scatter plot
Plot(Years, Salary)    or Plot(Years, Salary)
Plot(Years, Salary, auto=TRUE)    or Plot(Years, Salary)
Plot(Years, Salary, ellipse=TRUE, fit= loess )    common options
Plot(Years, Salary, ellipse=c(.50,.75,.90))    3 data ellipses
Plot(Years, Salary, size=3)  bubbles

 classify by a 3rd variable, which is categorical
Plot(Years, Salary, by=Gender)
Plot(Years, Salary, by=Gender, color=c( green ,  brown ))
Plot(Years, Salary, by=Gender, color=c( darkgreen ,  brown ), shape=c( F , M ))
Plot(Years, Salary, by=Gender, color=c( darkgreen ,  brown ), fit= ls )

 categorical with a numeric variable, shows scatter about each group mean
Plot(Dept, Salary)   Dept is categorical, Salary is numeric
SummaryStats(Salary, by=Dept)    stats, for each level of a grouping variable
ss.brief(Salary, by=Dept)    brief output

 two categorical variables (factors)
BarChart(Gender, by=Dept)   text from ss.brief
bc(Gender, by=Dept, beside=TRUE, horiz=TRUE)   common options
Plot(Gender, Dept)   scatter (bubble) plot in place of traditional bar chart
SummaryStats(Gender, Dept)   4 cross-tab tables
bc(Dept, by=Gender, beside=TRUE)
 the proportion of data values by fill variable within each group
bc(Dept, by=Gender, proportion=TRUE)

Plot(Dept, Salary)
 Plot refers to what is plotted in the scatter plot as the values
 Plot default for values is  data 
Plot(Dept, Salary, values= mean )
Plot(c(Pre, Post), Salary)
Plot(c(Pre, Post), Salary, fit= ls )



 Cleveland dot plot test
Plot(Salary, row.names)
Plot(c(Pre, Post), row.names)
Plot(row.names, Salary, means=FALSE, rotate.x=60, offset=1, xlab=  )
Plot(Salary, row.names, fill= black , color= black , sort.y=TRUE)
style(panel.fill= off , grid.color= off )
Plot(Salary, row.names, sort.y=TRUE, segments.y=TRUE)
style()   return to default style


 set system values
 
 color themes
Help(theme)
style( orange , sub.theme= black )
hs(Salary)
Plot(Years, Salary, ellipse=TRUE, fit= loess )    common options
style( darkred )
hs(Salary)
style( gray )
hs(Salary)
Plot(Years, Salary, ellipse=TRUE, fit= loess )    common options

 more system settings, can also be set by individual function calls
style(brief=TRUE)   partial text output
style(quiet=TRUE)   no text output
style(n.cat=6)   treat integer variables with <=6 unique values as categorical
style(brief=FALSE)  back to default
style(quiet=FALSE)
style(n.cat=0)


 analysis of a mean
 
ttest(Salary)   or tt(Salary) for confidence interval
tt.brief(Salary, mu0=70000)   brief output, for CI and hypothesis test
tt.brief(n=37, m=63795.557, s=21799.533)   input summary stats instead of data
ttestPower(n=20, s=5)


 compare 2 groups, with graphics
 
ttest(Salary ~ Gender)    or tt(Salary ~ Gender), compare means for two groups
tt(Gender ~ Salary)    ERROR, do it wrong to illustrate lessR error messages
tt.brief(Salary ~ Gender)    brief output
tt(n1=18, n2=19, m1=71147.458, m2=56830.598, s1=23128.436, s2=18438.456)  from stats
ttestPower(n1=14, n2=27, s1=4, s2=6, msmd=.5)

 Pre and Post are variables that are two matched sets of data values
ttest(Pre, Post)   t-test to compare group means, data entered as two vectors
ttest(Pre, Post, paired=TRUE)   t-test of paired differences


 analysis of variance, compare 2 or more groups
 
 warpbreaks is a data set contained in R
ANOVA(breaks ~ tension, data=warpbreaks)   or av, one-way ANOVA

 two-factor between-groups ANOVA with replications and interaction
ANOVA(breaks ~ wool * tension, data=warpbreaks)

 randomized blocks design with the second term the blocking factor
ANOVA(breaks ~ wool + tension, data=warpbreaks)


 regression analysis
 
 single predictor variable regression
reg(Salary ~ Years)   or reg, or reg.brief, equivalent of Excel regression
reg.brief(Salary ~ Years)   reg.brief equivalent of Excel regression
reg(Salary ~ 1)   null model
reg.brief(Salary ~ 1)   null model

 multiple regression
reg(Salary ~ Years + Pre + Post)   multiple reg

 output to an object
r <- reg(Salary ~ Years + Pre + Post)   multiple reg, save output to object r
r    see all the output
names(r)   see the output segments available for viewing or further analysis
r$out_estimates   see just the piece of the estimates

 create R markdown file that does full interpretation of the output
r <- reg(Salary ~ Years + Pre + Post, Rmd= MultReg )   R markdown

 nested models analysis
Nest(Salary, c(Years), c(Pre, Post))  compare reduced to full model, with common data

 logit analysis, with a classification table
Logit(Gender ~ Salary)


 transformations
 
 use Recode to reverse score four Likert variables: m01, m02, m03, m10
mydata <- Read( Mach4 , format= lessR )   read a data file included with lessR
mydata <- Recode(c(m01:m03,m10), old=0:5, new=5:0)   R has no recode function

mydata <- rd( Employee , format= lessR , quiet=TRUE)   internal data, no console output
mydata <- Transform(Salary = Salary / 1000)   transform by formula
males <- Subset(Gender== M , columns=c(Years, Salary))   only Males, two vars
mydata <- Sort(Salary)   default from smallest to largest
mydata <- Sort(Salary, direction= - )   can also specify directiont
mydata <- Sort(row.names)   unlike standard R, can sort by row name
 also Merge for vertical or horizontal merge of two data tables


 variable labels
 
 read data file w/o variable labels, and then separately read labels
mydata <- Read( http://lessRstats.com/data/employee.csv )
mylabels <- VariableLabels( http://lessRstats.com/data/employee_lbl.csv )

 read data file w/o variable labels, and then read labels from console
mydata <- Read( http://lessRstats.com/data/employee.csv )
lbl <-  
Years, time of company employment
Gender, Male or Female
Dept, department employed
Salary, annual salary
Satisfaction, satisfaction with work environment
HealthPlan, 1=GoodHealth 2=YellowCross 3=BestCare
Pre, Test score on legal issues before instruction
Post, Test score on legal issues after instruction
 
mylabels <- VariableLabels(lbl)

 modify/display a single variable label
mylabels <- VariableLabels(Salary,  Annual Salary (USD) )  add/modify 1 label
VariableLabels(Salary)   list the contents of a single variable label

 display all variable labels
db()   also the variable names and sample values
vl()


 write a data table to an external file
 
Write( myfile )   write default mydata data table to myfile in csv format
Write( myfile , row.names=FALSE)   preferred if row names are only row numbers
Write( myfile , format= Excel , row.names=FALSE)   to Excel data table

 after reading original data and doing the transformations, save as is
Write( myfile , format= R )   native R format, straight copy of mydata


 correlation matrices and factor analysis
 
mydata <- Read( Mach4 , format= lessR )   read a data file included with lessR
 calculate the correlations and store in mycor
head(mydata)
mydata <- Recode(c(m03, m04, m06, m07, m09:m11, m14, m16, m17, m19), old=0:5, new=5:0)
mycor <- cr(m01:m20)
efa(n.factors=4)
 confirmatory factor analysis of 4-factor solution of Mach IV scale
 Hunter, Gerbing and Boster (1982)
MeasModel <-
   
Deceit =~ m07 + m06 + m10 + m09
Trust =~ m12 + m05 + m13 + m01
Cynicism =~ m11 + m16 + m04
Flattery =~ m15 + m02
 
c <- cfa(MeasModel)
 view all the output
c
 names of each output segment
names(c)
 view just the scale reliabilities
c$out_reliability

 correlation matrix operations
mycor <- cr(m01:m20, graphics=TRUE)
mydata <- corReorder()    simple re-order algorithm by highest remaining cor
prop()
scree()


 read fixed width data, requires parameters: widths, color.names
 
rep(1,20)   standard R function, here a 1 listed 20 times
to( m ,20)   lessR, names sequential vars with same widths [unlike paste0( m , 1:20)]
 specify the width of each data column, then match with the column name
 the Mach4 scale is 6-pt Likert data, so each response is a single column
mydata <- Read( http://lessRstats.com/data/Mach4Plus.fwd ,
               widths=c(4,2,1,5,1,rep(1,20)),
               col.names=c( ID ,  Age ,  Gender ,  Code ,  Form , to( m ,20)))

\end{verbatim}

\hypertarget{linear-regression-2}{%
\chapter{Linear Regression}\label{linear-regression-2}}

\url{https://www}..com/community/tutorials/linear-regression-R

\begin{verbatim}
{r, include=FALSE}
library(readxl)
ageandheight <- read_excel( data/ageandheight.xls , sheet =  Hoja2 ) 
lmHeight = lm(height~age, data = ageandheight)
summary(lmHeight)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lmHeight2 = lm(height~age + no_siblings, data = ageandheight)
summary(lmHeight2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lmHeight2$coefficients
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lmHeight2$residuals
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pressure <- read_excel( data/pressure.xlsx )
lmTemp <- lm(Pressure~Temperature, data = pressure)
summary(lmTemp)
plot(pressure, pch = 16, col =  blue )
abline(lmTemp)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(lmTemp$residuals, pch = 16, col =  red )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lmTemp2 = lm(Pressure~Temperature + I(Temperature^2), data = pressure) #Create a linear regression with a quadratic coefficient
summary(lmTemp2) #Review the results
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(lmTemp2$residuals, pch = 16, col =  red )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ageandheight[2, 2] = 7.7
head(ageandheight)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lmHeight3 = lm(height~age, data = ageandheight)#Create the linear regression
summary(lmHeight3)#Review the results
plot(cooks.distance(lmHeight3), pch = 16, col =  blue ) #Plot the Cooks Distances.
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(cooks.distance(lmHeight), pch = 16, col =  blue )
\end{verbatim}

\hypertarget{machine-learning}{%
\chapter{Machine Learning}\label{machine-learning}}

\hypertarget{code-for-workshop-introduction-to-machine-learning-with-r}{%
\chapter{Code for Workshop: Introduction to Machine Learning with R}\label{code-for-workshop-introduction-to-machine-learning-with-r}}

\url{https://shirinsplayground.netlify.com/2018/06/intro_to_ml_workshop_heidelberg/}

title: R ile analize ba≈ülarken\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara referans
  vermeye √ßalƒ±≈ütƒ±m.}

\begin{verbatim}
{r , echo=TRUE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print= 75 )
opts_chunk$set(echo=TRUE,
                 cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
\end{verbatim}

\hypertarget{r-hakkux131nda}{%
\chapter{R hakkƒ±nda}\label{r-hakkux131nda}}

\href{https://www..com/community/tutorials/data-science-pitfalls}{\includegraphics{http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530113077/Image_2_vfy48b.png}}

\begin{itemize}
\tightlist
\item
  R generation
\end{itemize}

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\hypertarget{r-yuxfckleme-3}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme-3}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\href{http://www.youtube.com/watch?v=XcBLEVknqvY}{\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}}

\hypertarget{r-project-3}{%
\section{R-project}\label{r-project-3}}

\url{https://cran.r-project.org/}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#6}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}}

\hypertarget{rstudio-3}{%
\section{RStudio}\label{rstudio-3}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\hypertarget{rstudio-eklentileri-3}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri-3}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{x11-3}{%
\section{X11}\label{x11-3}}

\url{https://www.xquartz.org/}

\hypertarget{java-os-3}{%
\section{Java OS}\label{java-os-3}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-3}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-3}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\hypertarget{r-paketleri-3}{%
\chapter{R paketleri}\label{r-paketleri-3}}

\hypertarget{neden-paketler-var-3}{%
\section{Neden paketler var}\label{neden-paketler-var-3}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\url{https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/}

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz-3}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz-3}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur-3}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur-3}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-iuxe7in-yardux131m-bulma-3}{%
\section{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma-3}}

\begin{verbatim}
# ?mean
# ??efetch
# help(merge)
# example(merge)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\includegraphics{figures/vignette.png}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Reproducible Examples
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\hypertarget{r-paket-yuxfckleme-3}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme-3}}

\begin{verbatim}
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r}
# install.packages( tidyverse , dependencies = TRUE)
# install.packages( jmv , dependencies = TRUE)
# install.packages( questionr , dependencies = TRUE)
# install.packages( Rcmdr , dependencies = TRUE)
# install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r, error=FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE}
# require(tidyverse)
# require(jmv)
# require(questionr)
# library(summarytools)
# library(gganimate)
\end{verbatim}

\hypertarget{r-studio-ile-proje-oluux15fturma-3}{%
\chapter{R studio ile proje olu≈üturma}\label{r-studio-ile-proje-oluux15fturma-3}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme-3}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme-3}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel-3}{%
\section{Excel}\label{excel-3}}

\hypertarget{spss-3}{%
\section{SPSS}\label{spss-3}}

\hypertarget{csv-3}{%
\section{csv}\label{csv-3}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-3}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-3}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\begin{verbatim}
{r, results= markup }
# library(nycflights13)
# summary(flights)
\end{verbatim}

\begin{verbatim}
View(data)
\end{verbatim}

\begin{verbatim}
data
\end{verbatim}

\begin{verbatim}
head
\end{verbatim}

\begin{verbatim}
tail
\end{verbatim}

\begin{verbatim}
glimpse
\end{verbatim}

\begin{verbatim}
str
\end{verbatim}

\begin{verbatim}
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme-3}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme-3}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim-3}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim-3}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme-3}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme-3}}

\includegraphics{figures/change_data.png}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode-3}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode-3}}

\emph{questionr} paketi kullanƒ±lacak

\includegraphics{figures/level_recode.png}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler-3}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler-3}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include = TRUE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )

scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools-3}{%
\section{summarytools}\label{summarytools-3}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\includegraphics{figures/dfsummary.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}

# First save the results

iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:

view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)

# view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

\hypertarget{skimr-4}{%
\section{skimr}\label{skimr-4}}

\begin{verbatim}
library(skimr)
skim(df)
\end{verbatim}

\hypertarget{dataexplorer-5}{%
\section{DataExplorer}\label{dataexplorer-5}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{grafikler-3}{%
\section{Grafikler}\label{grafikler-3}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{rcmdr-3}{%
\chapter{Rcmdr}\label{rcmdr-3}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi-3}{%
\chapter{jamovi}\label{jamovi-3}}

\url{https://www.jamovi.org/}

\begin{figure}
\centering
\includegraphics{https://www.jamovi.org/}
\caption{\includegraphics{https://www.jamovi.org/assets/main-screenshot.png}}
\end{figure}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\begin{figure}
\centering
\includegraphics{https://blog.jamovi.org/2018/07/30/rj.html}
\caption{\includegraphics{https://blog.jamovi.org/assets/images/rj.png}}
\end{figure}

\hypertarget{sonraki-konular-3}{%
\chapter{Sonraki Konular}\label{sonraki-konular-3}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub
\item
  Hipotez testleri
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\end{itemize}

\hypertarget{diux11fer-kodlar-3}{%
\chapter{Diƒüer kodlar}\label{diux11fer-kodlar-3}}

\begin{itemize}
\tightlist
\item
  Diƒüer kodlar i√ßin bakƒ±nƒ±z: \url{https://sbalci.github.io/}
\end{itemize}

\hypertarget{geri-bildirim-3}{%
\chapter{Geri Bildirim}\label{geri-bildirim-3}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\hypertarget{recipes-for-mining-twitter-data-with-rtweet}{%
\chapter{21 Recipes for Mining Twitter Data with rtweet}\label{recipes-for-mining-twitter-data-with-rtweet}}

\hypertarget{recipes-for-mining-twitter-data-with-rtweet-1}{%
\chapter{21 Recipes for Mining Twitter Data with rtweet}\label{recipes-for-mining-twitter-data-with-rtweet-1}}

\url{https://rud.is/books/21-recipes/}

\url{http://rtweet.info/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( mkearney/rtweet )
library(rtweet)
library(tidyverse)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(trends_avail <- trends_available())
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(us <- get_trends( united states ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(tr <- get_trends( turkey ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(DBI)
library(RSQLite)
library(rtweet) # mkearney/rtweet

repeat {
  message( Retrieveing trends... ) # optional
  us <- get_trends( united states )
  db_con <- dbConnect(RSQLite::SQLite(),  data/us-trends.db )
  dbWriteTable(db_con,  us_trends , us, append=TRUE) # append=TRUE will update the table vs overwrite and also create it on first run if it does not exist
  dbDisconnect(db_con)
  Sys.sleep(10 * 60) # sleep for 10 minutes
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(dplyr)

trends_db <- src_sqlite( data/us-trends.db )
us <- tbl(trends_db,  us_trends )
select(us, trend)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(rstats <- search_tweets( #rstats , n=300)) # pull 300 tweets that used the  #rstats  hashtag
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
glimpse(rstats)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rstats %>% 
select(hashtags) %>% 
  unnest() %>% 
  mutate(hashtags = tolower(hashtags)) %>% 
  count(hashtags, sort=TRUE) %>% 
  filter(hashtags !=  rstats ) %>% 
  top_n(10)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rstats <- search_tweets( #rstats -filter:retweets ) %>%
  select(text)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rstats <- search_tweets( to:kearneymw ) %>%
  select(text)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rstats <- search_tweets( #rstats url:github -#python ) %>% 
  select(text)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(tidyverse)
rstats <- search_tweets( #rstats , n=500)

glimpse(rstats)

filter(rstats, retweet_count > 0) %>% 
  select(text, mentions_screen_name, retweet_count) %>% 
  mutate(text = substr(text, 1, 30)) %>% 
  unnest()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# regex mod from https://stackoverflow.com/questions/655903/python-regular-expression-for-retweets
filter(rstats, str_detect(text,  (RT|via)((?:[[:blank:]:]\\W*@\\w+)+) )) %>% 
  select(text, mentions_screen_name, retweet_count) %>% 
  mutate(extracted = str_match(text,  (RT|via)((?:[[:blank:]:]\\W*@\\w+)+) )[,3]) %>% 
  mutate(text = substr(text, 1, 30)) %>% 
  unnest()  
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(igraph)
library(hrbrthemes)
library(tidyverse)
rstats <- search_tweets( #rstats , n=1500)

filter(rstats, retweet_count > 0) %>% 
  select(screen_name, mentions_screen_name) %>%
  unnest(mentions_screen_name) %>% 
  filter(!is.na(mentions_screen_name)) %>% 
  graph_from_data_frame() -> rt_g
  
summary(rt_g)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ggplot(data_frame(y=degree_distribution(rt_g), x=1:length(y))) +
  geom_segment(aes(x, y, xend=x, yend=0), color= slateblue ) +
  scale_y_continuous(expand=c(0,0), trans= sqrt ) +
  labs(x= Degree , y= Density (sqrt scale) , title= #rstats Retweet Degree Distribution ) +
  theme_ipsum_rc(grid= Y , axis= x )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
V(rt_g)$node_label <- unname(ifelse(degree(rt_g)[V(rt_g)] > 20, names(V(rt_g)),   )) 
V(rt_g)$node_size <- unname(ifelse(degree(rt_g)[V(rt_g)] > 20, degree(rt_g), 0)) 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(ggraph)

ggraph(rt_g, layout = 'linear', circular = TRUE) + 
  geom_edge_arc(edge_width=0.125, aes(alpha=..index..)) +
  geom_node_label(aes(label=node_label, size=node_size),
                  label.size=0, fill= #ffffff66 , segment.colour= springgreen ,
                  color= slateblue , repel=TRUE, family=font_rc, fontface= bold ) +
  coord_fixed() +
  scale_size_area(trans= sqrt ) +
  labs(title= Retweet Relationships , subtitle= Most retweeted screen names labeled. Darkers edges == more retweets. Node size == larger degree ) +
  theme_graph(base_family=font_rc) +
  theme(legend.position= none )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
stream_tweets(
  lookup_coords( usa ), # handy helper function in rtweet
  verbose = FALSE,
  timeout = (60 * 1),
) -> usa
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
count(usa, place_full_name, sort=TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
unnest(usa, hashtags) %>% 
  count(hashtags, sort=TRUE) %>% 
  filter(!is.na(hashtags))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
count(usa, source, sort=TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rtweet::write_as_csv()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(tidytext)
library(magick)
library(kumojars) # hrbrmstr/kumojars
library(kumo) # hrbrmstr/kumo
library(tidyverse)
\end{verbatim}

scifi \textless- search\_tweets( \#NationalScienceFictionDay , n=1500)

data\_frame(txt=str\_replace\_all(scifi\$text, \#NationalScienceFictionDay , )) \%\textgreater\%
unnest\_tokens(word, txt) \%\textgreater\%
anti\_join(stop\_words, word ) \%\textgreater\%
anti\_join(rtweet::stopwordslangs, word ) \%\textgreater\%
anti\_join(data\_frame(word=c( https , t.co )), word ) \%\textgreater\% \# need to make a more technical stopwords list or clean up the text better
filter(nchar(word)\textgreater3) \%\textgreater\%
pull(word) \%\textgreater\%
paste0(collapse= ) -\textgreater{} txt

cloud\_img \textless- word\_cloud(txt, width=800, height=500, min\_font\_size=10, max\_font\_size=60, scale= log )

image\_write(cloud\_img, data/wordcloud.png )

library(rtweet)
library(LSAfun)
library(jerichojars) \# hrbrmstr/jerichojars
library(jericho) \# hrbrmstr/jericho
library(tidyverse)
stiles \textless- get\_timeline( stiles )

filter(stiles, str\_detect(urls\_expanded\_url, nyti\textbar reut\textbar wapo\textbar lat\textbackslash.ms\textbar53ei )) \%\textgreater\% \# only get tweets with news links
pull(urls\_expanded\_url) \%\textgreater\% \# extract the links
flatten\_chr() \%\textgreater\% \# mush them into a nice character vector
head(3) \%\textgreater\% \# get the first 3
map\_chr(\textasciitilde\{
httr::GET(.x) \%\textgreater\% \# get the URL (I'm lazily calling fair use here vs check robots.txt since I'm suggesting you do this for your benefit vs profit)
httr::content(as= text ) \%\textgreater\% \# extract the HTML
jericho::html\_to\_text() \%\textgreater\% \# strip away extraneous HTML tags
LSAfun::genericSummary(k=3) \%\textgreater\% \# summarise!
paste0(collapse= \n\n ) \# easier to see
\}) \%\textgreater\%
walk(cat)

library(rtweet)
library(tidyverse)
(brooke\_followers \textless- rtweet::get\_followers( gbwanderson ))

(brooke\_friends \textless- rtweet::get\_friends( gbwanderson ))

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(tidyverse)
my_followers <- rtweet::get_followers( serdarbalci )
my_friends <- rtweet::get_friends( serdarbalci )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
length(intersect(my_followers$user_id, my_friends$user_id))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
length(setdiff(my_followers$user_id, my_friends$user_id))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
length(setdiff(my_friends$user_id, my_followers$user_id))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rtweet::lookup_users(my_friends$user_id)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(hrbrthemes)
library(tidyverse)
influence_snapshot <- function(user, trans=c( log10 ,  identity )) {
  
  user <- user[1]
  trans <- match.arg(tolower(trimws(trans[1])), c( log10 ,  identity ))
  
  user_info <- lookup_users(user)
  
  user_followers <- get_followers(user_info$user_id)
  uf_details <- lookup_users(user_followers$user_id)
  
  primary_influence <- scales::comma(sum(c(uf_details$followers_count, user_info$followers_count)))
  
  filter(uf_details, followers_count > 0) %>% 
    ggplot(aes(followers_count)) +
    geom_density(aes(y=..count..), color= lightslategray , fill= lightslategray ,
                 alpha=2/3, size=1) +
    scale_x_continuous(expand=c(0,0), trans= log10 , labels=scales::comma) +
    scale_y_comma() +
    labs(
      x= Number of Followers of Followers (log scale) , 
      y= Number of Followers ,
      title=sprintf( Follower chain distribution of %s (@%s) , user_info$name, user_info$screen_name),
      subtitle=sprintf( Follower count: %s; Primary influence/reach: %s , 
                       scales::comma(user_info$followers_count),
                       scales::comma(primary_influence))
    ) +
    theme_ipsum_rc(grid= XY ) -> gg
  
  print(gg)
  
  return(invisible(list(user_info=user_info, follower_details=uf_details)))
  
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
juliasilge <- influence_snapshot( juliasilge )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(broom)
library(eechidna)
library(cartogram) # chxy/cartogram
library(hrbrthemes)
library(tidyverse)
# search twitter for tweets
rstats_us <- search_tweets( #rstats , 3000, geocode =  2.877742,-97.380979,3000mi ) # geocode request isn't perfect but helps narrow down

# lookup each user (uniquely) so we can grab location information
user_info <- lookup_users(unique(rstats_us$user_id)) 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
discard(user_info$location, `==`,   ) %>% # ignore blank data
  str_match(sprintf( (%s) , paste0(state.abb, collapse= | ))) %>%  # try to match U.S. state abbreviations
  .[,2] %>% # the previous step creates a matrix with column 2 being the extracted information (if any)
  discard(is.na) %>%  # if no state match was found the value is NA so discard this one
  table() %>% # some habits are hard to break
  broom::tidy() %>% # but we can tidy them!
  set_names(c( state ,  n )) %>% # these are more representative names
  tbl_df() %>% # not really necessary but I was printing this when testing
  arrange(desc(n)) %>% # same as ^^
  left_join(
    as_tibble(maps::state.carto.center) %>% # join state cartographic center data
      mutate(state=state.abb)
  ) -> for_dor 
# %>% 
  # the GitHub-only cartogram package nas a data structure which holds state adjacency information
  # by specifying that here, it will help make the force-directed cartogram circle positioning more precise (and pretty)
  # filter(state %in% names(cartogram::statenbrs)) -> for_dor 

glimpse(for_dor)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
par(family=font_rc, col= white )

eechidna:::dorling(
  for_dor$state, for_dor$x, for_dor$y, sqrt(for_dor$n),
  # nbr=cartogram::statenbrs,
  animation = FALSE, nbredge = TRUE, iteration=100, name.text=TRUE, dist.ratio=1.2,
  main= Dorling Cartogram of U.S. #rstats , xlab='', ylab='', col= lightslategray ,
  frame=FALSE, asp=1, family=font_rc, cex.main=1.75, adj=0
) -> dor

par(family=font_rc, col= black )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(ggmap)
library(tidyverse)
rstats_us <- search_tweets( #rstats , 300)

user_info <- lookup_users(unique(rstats_us$user_id))

discard(user_info$location, `==`,   ) %>% 
  ggmap::geocode() -> coded

coded$location <- discard(user_info$location, `==`,   )

user_info <- left_join(user_info, coded,  location )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(tidyverse)
library(UpSetR)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# get a list of twitter handles you want to compare
rstaters <- c( dataandme , 
               serdarbalci ,
               JennyBryan ,
               hrbrmstr ,
               xieyihui 
              #  drob , 
              #  juliasilge , 
              #  thomasp85 
              )

# scrape the user_id of all followers for each handle in the list and bind into 1 dataframe
followers <- rstaters %>%
  map_df(~ get_followers(.x, n = 200, retryonratelimit = TRUE) %>% 
           mutate(account = .x))

head(followers)

tail(followers)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# get a de-duplicated list of all followers
aRdent_followers <- unique(followers$user_id)

# for each follower, get a binary indicator of whether they follow each tweeter or not and bind to one dataframe
binaries <- rstaters %>% 
  map_dfc(~ ifelse(aRdent_followers %in% filter(followers, account == .x)$user_id, 1, 0) %>% 
            as.data.frame) # UpSetR doesn't like tibbles

# set column names
names(binaries) <- rstaters

# have a look at the data
glimpse(binaries)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# plot the sets with UpSetR
upset(binaries, nsets = 7, main.bar.color =  SteelBlue , sets.bar.color =  DarkCyan , 
      sets.x.label =  Follower Count , text.scale = c(rep(1.4, 5), 1), order.by =  freq )
\end{verbatim}

\hypertarget{multiple-pages}{%
\chapter{Multiple Pages}\label{multiple-pages}}

\begin{verbatim}
output: flexdashboard::flex_dashboard
\end{verbatim}

\hypertarget{page-1}{%
\chapter{Page 1}\label{page-1}}

\hypertarget{column}{%
\section{Column}\label{column}}

\hypertarget{chart-1}{%
\subsection{Chart 1}\label{chart-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{column-1}{%
\section{Column}\label{column-1}}

\hypertarget{chart-2}{%
\subsection{Chart 2}\label{chart-2}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{chart-3}{%
\subsection{Chart 3}\label{chart-3}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{page-2}{%
\chapter{Page 2}\label{page-2}}

\hypertarget{row-2}{%
\section{Row}\label{row-2}}

\hypertarget{chart-1-1}{%
\subsection{Chart 1}\label{chart-1-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{row-3}{%
\section{Row}\label{row-3}}

\hypertarget{chart-2-1}{%
\subsection{Chart 2}\label{chart-2-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{chart-3-1}{%
\subsection{Chart 3}\label{chart-3-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{mxnet}{%
\chapter{mxnet}\label{mxnet}}

\url{https://mxnet.apache.org/versions/master/install/index.html?platform=MacOS\&language=R\&processor=CPU}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cran <- getOption( repos )
cran[ dmlc ] <-  https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/ 
options(repos = cran)
install.packages( mxnet )
\end{verbatim}

\url{https://mxnet.apache.org/versions/master/api/r/index.html}

\url{https://mxnet.apache.org/versions/master/tutorials/index.html}

R Tutorials

\begin{verbatim}
Getting Started
    Basic Classification
    Using a pre-trained model for Image Classification

Models
    MNIST Handwritten Digit Classification with Convolutional Network
    Shakespeare generation with Character-level RNN

API Guides
    NDArray API
    Symbol API
    Callbacks
    Custom Data Iterators
    Custom Loss Functions
\end{verbatim}

\hypertarget{mygist}{%
\chapter{MyGIST}\label{mygist}}

\url{https://gist.github.com/sbalci}

\url{https://docs.ropensci.org/gistr/}

\url{https://docs.ropensci.org/gistr/articles/gistr.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( gistr )
# devtools::install_github( ropensci/gistr )
# renv::install( gistr )
library( gistr )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
(mygists <- gistr::gists('minepublic'))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gistembedcodes <- purrr::map(.x = mygists, .f = gistr::embed)

gistembedcodes <- unlist(gistembedcodes)

gistembedcodes <- cat(gistembedcodes, sep = '\n\n\n')
\end{verbatim}

\begin{verbatim}
`{r #  gistembedcodes`
\end{verbatim}

\texttt{\{r\ \#\ \ gistembedcodes}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
citation(package = 'gistr')
\end{verbatim}

\hypertarget{news-1}{%
\chapter{News}\label{news-1}}

\begin{itemize}
\tightlist
\item
  Text Analysis of Newspaper News on Electoral Integrity and Electoral Violence in Turkey
\end{itemize}

\url{http://rpubs.com/emretoros/dievt}

\hypertarget{presentation-ninja}{%
\chapter{Presentation Ninja}\label{presentation-ninja}}

\begin{verbatim}
sub# ‚öî<br/>with xaringan 
author:  Yihui Xie 
date:  2016/12/12 (updated: ) 
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
options(htmltools.dir.version = FALSE)
\end{verbatim}

???

Image credit: \href{https://commons.wikimedia.org/wiki/File:Sharingan_triple.svg}{Wikimedia Commons}

class: center, middle

\hypertarget{xaringan}{%
\chapter{xaringan}\label{xaringan}}

\hypertarget{ux283uxe6.riux14b.ux261uxe6n}{%
\subsection{/ É√¶.'ri≈ã.…°√¶n/}\label{ux283uxe6.riux14b.ux261uxe6n}}

class: inverse, center, middle

\hypertarget{get-started}{%
\chapter{Get Started}\label{get-started}}

\hypertarget{hello-world}{%
\chapter{Hello World}\label{hello-world}}

Install the \textbf{xaringan} package from \href{https://github.com/yihui/xaringan}{Github}:

\begin{verbatim}
{r eval=FALSE, tidy=FALSE}
devtools::install_github( yihui/xaringan )
\end{verbatim}

--

You are recommended to use the \href{https://www.rstudio.com/products/rstudio/}{RStudio IDE}, but you do not have to.

\begin{itemize}
\tightlist
\item
  Create a new R Markdown document from the menu \texttt{File\ -\textgreater{}\ New\ File\ -\textgreater{}\ R\ Markdown\ -\textgreater{}\ From\ Template\ -\textgreater{}\ Ninja\ Presentation};1
\end{itemize}

--

\begin{itemize}
\tightlist
\item
  Click the \texttt{Knit} button to compile it;
\end{itemize}

--

\begin{itemize}
\tightlist
\item
  or use the \href{https://rstudio.github.io/rstudioaddins/}{RStudio Addin}2 Infinite Moon Reader to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer.
\end{itemize}

.footnote{[}
{[}1{]} ‰∏≠ÊñáÁî®Êà∑ËØ∑Áúã\href{http://slides.yihui.name/xaringan/zh-CN.html}{Ëøô‰ªΩÊïôÁ®ã}

{[}2{]} See \href{https://github.com/yihui/xaringan/issues/2}{\#2} if you do not see the template or addin in RStudio.
{]}

background-image: url(\texttt{\{r\ \#\ \ xaringan:::karl})
background-position: 50\% 50\%
class: center, bottom, inverse

\hypertarget{you-only-live-once}{%
\chapter{You only live once!}\label{you-only-live-once}}

\hypertarget{hello-ninja}{%
\chapter{Hello Ninja}\label{hello-ninja}}

As a presentation ninja, you certainly should not be satisfied by the Hello World example. You need to understand more about two things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \href{https://remarkjs.com}{remark.js} library;
\item
  The \textbf{xaringan} package;
\end{enumerate}

Basically \textbf{xaringan} injected the chakra of R Markdown (minus Pandoc) into \textbf{remark.js}. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (\textbf{knitr}).

\hypertarget{remark.js}{%
\chapter{remark.js}\label{remark.js}}

You can see an introduction of remark.js from \href{https://remarkjs.com}{its homepage}. You should read the \href{https://github.com/gnab/remark/wiki}{remark.js Wiki} at least once to know how to

\begin{itemize}
\item
  create a new slide (Markdown syntax* and slide properties);
\item
  format a slide (e.g.~text alignment);
\item
  configure the slideshow;
\item
  and use the presentation (keyboard shortcuts).
\end{itemize}

It is important to be familiar with remark.js before you can understand the options in \textbf{xaringan}.

.footnote{[}{[}*{]} It is different with Pandoc's Markdown! It is limited but should be enough for presentation purposes. Come on\ldots{} You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js \href{https://github.com/gnab/remark/issues/142}{may be improved} in the future.{]}

background-image: url(\texttt{\{r\ \#\ \ xaringan:::karl})
background-size: cover
class: center, bottom, inverse

\hypertarget{i-was-so-happy-to-have-discovered-remark.js}{%
\chapter{I was so happy to have discovered remark.js!}\label{i-was-so-happy-to-have-discovered-remark.js}}

class: inverse, middle, center

\hypertarget{using-xaringan}{%
\chapter{Using xaringan}\label{using-xaringan}}

\hypertarget{xaringan-1}{%
\chapter{xaringan}\label{xaringan-1}}

Provides an R Markdown output format \texttt{xaringan::moon\_reader} as a wrapper for remark.js, and you can use it in the YAML metadata, e.g.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# A Cool Presentation }
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{yolo}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{autoplay}\KeywordTok{:}\AttributeTok{ }\DecValTok{30000}
\end{Highlighting}
\end{Shaded}

See the help page \texttt{?xaringan::moon\_reader} for all possible options that you can use.

\hypertarget{remark.js-vs-xaringan}{%
\chapter{remark.js vs xaringan}\label{remark.js-vs-xaringan}}

Some differences between using remark.js (left) and using \textbf{xaringan} (right):

.pull-left{[}
1. Start with a boilerplate HTML file;

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Plain Markdown;
\item
  Write JavaScript to autoplay slides;
\item
  Manually configure MathJax;
\item
  Highlight code with \texttt{*};
\item
  Edit Markdown source and refresh browser to see updated slides;
  {]}
\end{enumerate}

.pull-right{[}
1. Start with an R Markdown document;

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  R Markdown (can embed R/other code chunks);
\item
  Provide an option \texttt{autoplay};
\item
  MathJax just works;*
\item
  Highlight code with \texttt{\{\{\}\}};
\item
  The RStudio addin Infinite Moon Reader automatically refreshes slides on changes;
  {]}
\end{enumerate}

.footnote{[}{[}*{]} Not really. See next page.{]}

\hypertarget{math-expressions}{%
\chapter{Math Expressions}\label{math-expressions}}

You can write LaTeX math expressions inside a pair of dollar signs, e.g.~\$\alpha+\beta\$ renders \(\alpha+\beta\). You can use the display style with double dollar signs:

\begin{verbatim}
$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
\end{verbatim}

\[\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i\]

Limitations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting \texttt{\$\$} must appear in the very beginning of a line, followed immediately by a non-space character, and the ending \texttt{\$\$} must be at the end of a line, led by a non-space character;
\item
  There should not be spaces after the opening \texttt{\$} or before the closing \texttt{\$}.
\item
  Math does not work on the title slide (see \href{https://github.com/yihui/xaringan/issues/61}{\#61} for a workaround).
\end{enumerate}

\hypertarget{r-code}{%
\chapter{R Code}\label{r-code}}

\begin{verbatim}
{r comment='#'}
# a boring regression
fit = lm(dist ~ 1 + speed, data = cars)
coef(summary(fit))
dojutsu = c('Âú∞ÁàÜÂ§©Êòü', 'Â§©ÁÖß', 'Âä†ÂÖ∑ÂúüÂëΩ', 'Á•ûÂ®Å', 'È†à‰ΩêËÉΩ‰πé', 'ÁÑ°ÈôêÊúàË™≠')
grep('Â§©', dojutsu, value = TRUE)
\end{verbatim}

\hypertarget{r-plots}{%
\chapter{R Plots}\label{r-plots}}

\begin{verbatim}
{r , fig.height=4, dev='svg'}
par(mar = c(4, 4, 1, .1))
plot(cars, pch = 19, col = 'darkgray', las = 1)
abline(fit, lwd = 2)
\end{verbatim}

\hypertarget{tables-1}{%
\chapter{Tables}\label{tables-1}}

If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(head(iris), format = 'html')
\end{verbatim}

\hypertarget{html-widgets}{%
\chapter{HTML Widgets}\label{html-widgets}}

I have not thoroughly tested HTML widgets against \textbf{xaringan}. Some may work well, and some may not. It is a little tricky.

Similarly, the Shiny mode (\texttt{\{r\ \#\ untime:\ shiny}) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications.

See the next page for two HTML widgets.

\begin{verbatim}
{r out.width='100%', fig.height=6, eval=require('leaflet')}
library(leaflet)
leaflet() %>% addTiles() %>% setView(-93.65, 42.0285, zoom = 17)
\end{verbatim}

\begin{verbatim}
{r eval=require('DT'), tidy=FALSE}
DT::datatable(
  head(iris, 10),
  fillContainer = FALSE, options = list(pageLength = 8)
)
\end{verbatim}

\hypertarget{some-tips}{%
\chapter{Some Tips}\label{some-tips}}

\begin{itemize}
\item
  When you use the Infinite Moon Reader addin in RStudio, your R session will be blocked by default. You can click the red button on the right of the console to stop serving the slides, or use the \emph{daemonized} mode so that it does not block your R session. To do the latter, you can set the option

\begin{verbatim}
{r # 
options(servr.daemon = TRUE)
\end{verbatim}

  in your current R session, or in \texttt{\textasciitilde{}/.Rprofile} so that it is applied to all future R sessions. I do the latter by myself.

  To know more about the web server, see the \href{https://github.com/yihui/servr}{\textbf{servr}} package.
\end{itemize}

--

\begin{itemize}
\item
  Do not forget to try the \texttt{yolo} option of \texttt{xaringan::moon\_reader}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{yolo}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{some-tips-1}{%
\chapter{Some Tips}\label{some-tips-1}}

\begin{itemize}
\item
  Slides can be automatically played if you set the \texttt{autoplay} option under \texttt{nature}, e.g.~go to the next slide every 30 seconds in a lightning talk:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{autoplay}\KeywordTok{:}\AttributeTok{ }\DecValTok{30000}
\end{Highlighting}
\end{Shaded}
\end{itemize}

--

\begin{itemize}
\item
  A countdown timer can be added to every page of the slides using the \texttt{countdown} option under \texttt{nature}, e.g.~if you want to spend one minute on every page when you give the talk, you can set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{countdown}\KeywordTok{:}\AttributeTok{ }\DecValTok{60000}
\end{Highlighting}
\end{Shaded}

  Then you will see a timer counting down from \texttt{01:00}, to \texttt{00:59}, \texttt{00:58}, \ldots{} When the time is out, the timer will continue but the time turns red.
\end{itemize}

\hypertarget{some-tips-2}{%
\chapter{Some Tips}\label{some-tips-2}}

\begin{itemize}
\item
  The title slide is created automatically by \textbf{xaringan}, but it is just another remark.js slide added before your other slides.

  The title slide is set to \texttt{class:\ center,\ middle,\ inverse,\ title-slide} by default. You can change the classes applied to the title slide with the \texttt{titleSlideClass} option of \texttt{nature} (\texttt{title-slide} is always applied).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{titleSlideClass}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{top}\KeywordTok{,}\AttributeTok{ left}\KeywordTok{,}\AttributeTok{ inverse}\KeywordTok{]}
\end{Highlighting}
\end{Shaded}
\end{itemize}

--

\begin{itemize}
\item
  If you'd like to create your own title slide, disable \textbf{xaringan}'s title slide with the \texttt{seal\ =\ FALSE} option of \texttt{moon\_reader}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{seal}\KeywordTok{:}\AttributeTok{ }\CharTok{false}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{some-tips-3}{%
\chapter{Some Tips}\label{some-tips-3}}

\begin{itemize}
\item
  There are several ways to build incremental slides. See \href{https://slides.yihui.name/xaringan/incremental.html}{this presentation} for examples.
\item
  The option \texttt{highlightLines:\ true} of \texttt{nature} will highlight code lines that start with \texttt{*}, or are wrapped in \texttt{\{\{\ \}\}}, or have trailing comments \texttt{\#\textless{}\textless{}};

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{highlightLines}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\end{Highlighting}
\end{Shaded}

  See examples on the next page.
\end{itemize}

\hypertarget{some-tips-4}{%
\chapter{Some Tips}\label{some-tips-4}}

.pull-left{[}
An example using a leading \texttt{*}:

\begin{verbatim}
```
\end{verbatim}

\{r \#
if (TRUE) \{
** message( Very important! )
\}
\texttt{Output:}
\{r \#
if (TRUE) \{
* message( Very important! )
\}

\begin{verbatim}

This is invalid R code, so it is a plain fenced code block that is not executed.
]

.pull-right[
An example using `{{}}`:

    `{r #  ''````
{r tidy=FALSE}
    if (TRUE) {
    *{{ message( Very important! ) }}
    }
    ```
Output:
\end{verbatim}

\{r tidy=FALSE\}
if (TRUE) \{
\{\{ message( Very important! ) \}\}
\}

\begin{verbatim}

It is valid R code so you can run it. Note that `{{}}` can wrap an R expression of multiple lines.
]



# Some Tips

An example of using the trailing comment `#<<` to highlight lines:

````markdown
`{r #  ''````
{r tidy=FALSE}
library(ggplot2)
ggplot(mtcars) + 
  aes(mpg, disp) + 
  geom_point() +   #<<
  geom_smooth()    #<<
\end{verbatim}

\begin{verbatim}

Output:

```
{r tidy=FALSE, eval=FALSE}
library(ggplot2)
ggplot(mtcars) + 
  aes(mpg, disp) + 
  geom_point() +   #<<
  geom_smooth()    #<<
```



# Some Tips

When you enable line-highlighting, you can also use the chunk option `highlight.output` to highlight specific lines of the text output from a code chunk. For example, `highlight.output = TRUE` means highlighting all lines, and `highlight.output = c(1, 3)` means highlighting the first and third line.

````md
`{r #  ''````
{r, highlight.output=c(1, 3)}
head(iris)
```
\end{verbatim}

\begin{verbatim}
{r, highlight.output=c(1, 3), echo=TRUE}
head(iris)
\end{verbatim}

Question: what does \texttt{highlight.output\ =\ c(TRUE,\ FALSE)} mean? (Hint: think about R's recycling of vectors)

\hypertarget{some-tips-5}{%
\chapter{Some Tips}\label{some-tips-5}}

\begin{itemize}
\item
  To make slides work offline, you need to download a copy of remark.js in advance, because \textbf{xaringan} uses the online version by default (see the help page \texttt{?xaringan::moon\_reader}).
\item
  You can use \texttt{xaringan::summon\_remark()} to download the latest or a specified version of remark.js. By default, it is downloaded to \texttt{libs/remark-latest.min.js}.
\item
  Then change the \texttt{chakra} option in YAML to point to this file, e.g.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{chakra}\KeywordTok{:}\AttributeTok{ libs/remark-latest.min.js}
\end{Highlighting}
\end{Shaded}
\item
  If you used Google fonts in slides (the default theme uses \emph{Yanone Kaffeesatz}, \emph{Droid Serif}, and \emph{Source Code Pro}), they won't work offline unless you download or install them locally. The Heroku app \href{https://google-webfonts-helper.herokuapp.com/fonts}{google-webfonts-helper} can help you download fonts and generate the necessary CSS.
\end{itemize}

\hypertarget{macros}{%
\chapter{Macros}\label{macros}}

\begin{itemize}
\item
  remark.js \href{https://github.com/yihui/xaringan/issues/80}{allows users to define custom macros} (JS functions) that can be applied to Markdown text using the syntax \texttt{!{[}:macroName\ arg1,\ arg2,\ ...{]}} or \texttt{!{[}:macroName\ arg1,\ arg2,\ ...{]}(this)}. For example, before remark.js initializes the slides, you can define a macro named \texttt{scale}:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{remark}\NormalTok{.}\VariableTok{macros}\NormalTok{.}\AttributeTok{scale} \OperatorTok{=} \KeywordTok{function}\NormalTok{ (percentage) }\OperatorTok{\{}
  \KeywordTok{var}\NormalTok{ url }\OperatorTok{=} \KeywordTok{this}\OperatorTok{;}
  \ControlFlowTok{return} \StringTok{'<img src= '} \OperatorTok{+}\NormalTok{ url }\OperatorTok{+} \StringTok{'  style= width: '} \OperatorTok{+}\NormalTok{ percentage }\OperatorTok{+} \StringTok{'  />'}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

  Then the Markdown text

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![:scale 50%](image.jpg)}
\end{Highlighting}
\end{Shaded}

  will be translated to

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<img}\OtherTok{ src=} \StringTok{image.jpg}\OtherTok{  style=} \StringTok{width:} \ErrorTok{50%}  \KeywordTok{/>}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{macros-continued}{%
\chapter{Macros (continued)}\label{macros-continued}}

\begin{itemize}
\item
  To insert macros in \textbf{xaringan} slides, you can use the option \texttt{beforeInit} under the option \texttt{nature}, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{beforeInit}\KeywordTok{:}\AttributeTok{  macros.js }
\end{Highlighting}
\end{Shaded}

  You save your remark.js macros in the file \texttt{macros.js}.
\item
  The \texttt{beforeInit} option can be used to insert arbitrary JS code before \texttt{\{r\ \#\ emark.create()}. Inserting macros is just one of its possible applications.
\end{itemize}

\hypertarget{css}{%
\chapter{CSS}\label{css}}

Among all options in \texttt{xaringan::moon\_reader}, the most challenging but perhaps also the most rewarding one is \texttt{css}, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know.

You can see the default CSS file \href{https://github.com/yihui/xaringan/blob/master/inst/rmarkdown/templates/xaringan/resources/default.css}{here}. You can completely replace it with your own CSS files, or define new rules to override the default. See the help page \texttt{?xaringan::moon\_reader} for more information.

\hypertarget{css-1}{%
\chapter{CSS}\label{css-1}}

For example, suppose you want to change the font for code from the default Source Code Pro to Ubuntu Mono . You can create a CSS file named, say, \texttt{ubuntu-mono.css}:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{@import} \FunctionTok{url(}\StringTok{https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic}\FunctionTok{)}\OperatorTok{;}

\FunctionTok{.remark-code}\OperatorTok{,} \FunctionTok{.remark-inline-code}\NormalTok{ \{ }\KeywordTok{font-family}\NormalTok{: }\StringTok{'Ubuntu Mono'}\OperatorTok{;}\NormalTok{ \}}
\end{Highlighting}
\end{Shaded}

Then set the \texttt{css} option in the YAML metadata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{ default }\KeywordTok{,}\AttributeTok{  ubuntu-mono.css }\KeywordTok{]}
\end{Highlighting}
\end{Shaded}

Here I assume \texttt{ubuntu-mono.css} is under the same directory as your Rmd.

See \href{https://github.com/yihui/xaringan/issues/83}{yihui/xaringan\#83} for an example of using the \href{https://github.com/tonsky/FiraCode}{Fira Code} font, which supports ligatures in program code.

\hypertarget{themes}{%
\chapter{Themes}\label{themes}}

Don't want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files \texttt{foo.css} and \texttt{foo-fonts.css}, where \texttt{foo} is the theme name. Below are some existing themes:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
names(xaringan:::list_css())
\end{verbatim}

\hypertarget{themes-1}{%
\chapter{Themes}\label{themes-1}}

To use a theme, you can specify the \texttt{css} option as an array of CSS filenames (without the \texttt{.css} extensions), e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{default}\KeywordTok{,}\AttributeTok{ metropolis}\KeywordTok{,}\AttributeTok{ metropolis-fonts}\KeywordTok{]}
\end{Highlighting}
\end{Shaded}

If you want to contribute a theme to \textbf{xaringan}, please read \href{https://yihui.name/en/2017/10/xaringan-themes}{this blog post}.

class: inverse, middle, center
background-image: url(\url{https://upload.wikimedia.org/wikipedia/commons/3/39/Naruto_Shiki_Fujin.svg})
background-size: contain

\hypertarget{naruto}{%
\chapter{Naruto}\label{naruto}}

background-image: url(\url{https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg})
background-size: 100px
background-position: 90\% 8\%

\hypertarget{sharingan}{%
\chapter{Sharingan}\label{sharingan}}

The R package name \textbf{xaringan} was derived1 from \textbf{Sharingan}, a d≈çjutsu in the Japanese anime \emph{Naruto} with two abilities:

\begin{itemize}
\item
  the Eye of Insight
\item
  the Eye of Hypnotism
\end{itemize}

I think a presentation is basically a way to communicate insights to the audience, and a great presentation may even hypnotize the audience.2,3

.footnote{[}
{[}1{]} In Chinese, the pronounciation of \emph{X} is \emph{Sh} / É/ (as in \emph{shrimp}). Now you should have a better idea of how to pronounce my last name \emph{Xie}.

{[}2{]} By comparison, bad presentations only put the audience to sleep.

{[}3{]} Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations.
{]}

\hypertarget{naruto-terminology}{%
\chapter{Naruto terminology}\label{naruto-terminology}}

The \textbf{xaringan} package borrowed a few terms from Naruto, such as

\begin{itemize}
\item
  \href{http://naruto.wikia.com/wiki/Sharingan}{Sharingan} (ÂÜôËº™Áúº; the package name)
\item
  The \href{http://naruto.wikia.com/wiki/Moon_Reader}{moon reader} (ÊúàË™≠; an attractive R Markdown output format)
\item
  \href{http://naruto.wikia.com/wiki/Chakra}{Chakra} (Êü•ÂÖãÊãâ; the path to the remark.js library, which is the power to drive the presentation)
\item
  \href{http://naruto.wikia.com/wiki/Nature_Transformation}{Nature transformation} (ÊÄßË≥™Â§âÂåñ; transform the chakra by setting different options)
\item
  The \href{http://naruto.wikia.com/wiki/Infinite_Tsukuyomi}{infinite moon reader} (ÁÑ°ÈôêÊúàË™≠; start a local web server to continuously serve your slides)
\item
  The \href{http://naruto.wikia.com/wiki/Summoning_Technique}{summoning technique} (download remark.js from the web)
\end{itemize}

You can click the links to know more about them if you want. The jutsu Moon Reader may seem a little evil, but that does not mean your slides are evil.

class: center

\hypertarget{hand-seals-ux5370}{%
\chapter{Hand seals (Âç∞)}\label{hand-seals-ux5370}}

Press \texttt{h} or \texttt{?} to see the possible ninjutsu you can use in remark.js.

\includegraphics{https://upload.wikimedia.org/wikipedia/commons/7/7e/Mudra-Naruto-KageBunshin.svg}

class: center, middle

\hypertarget{thanks}{%
\chapter{Thanks!}\label{thanks}}

Slides created via the R package \href{https://github.com/yihui/xaringan}{\textbf{xaringan}}.

The chakra comes from \href{https://remarkjs.com}{remark.js}, \href{http://yihui.name/knitr}{\textbf{knitr}}, and \href{https://rmarkdown.rstudio.com}{R Markdown}.

\hypertarget{opencpu}{%
\chapter{OpenCPU}\label{opencpu}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Install OpenCPU
# install.packages( opencpu )

# Run Apps directly from Github
library(opencpu)
ocpu_start_app( rwebapps/nabel )
ocpu_start_app( rwebapps/markdownapp )
ocpu_start_app( rwebapps/stockapp )

# Install / remove apps
# remove_apps( rwebapps/stockapp )
\end{verbatim}

\hypertarget{paper}{%
\chapter{papeR}\label{paper}}

copied from: \url{https://cran.r-project.org/web/packages/papeR/vignettes/papeR_introduction.html}

The package is intended to ease reporting of standard data analysis tasks such as descriptive statistics, simple test results, plots and to prettify the output of various statistical models.

\url{https://github.com/hofnerb/papeR}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( papeR )
# devtools::install_github( hofnerb/papeR )
library( papeR )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( nlme )
data(Orthodont, package =  nlme )
Orthodont_orig <- Orthodont
Orthodont
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
is.ldf(Orthodont)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont) <- c( fissure distance (mm) ,  age (years) ,  Subject ,  Sex )
Orthodont
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
is.ldf(Orthodont)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
class(Orthodont)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont, which = c( distance ,  age )) <- c( Fissure distance (mm) ,  Age (years) )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont, which =  age )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
labels(Orthodont, which = 1:2)
\end{verbatim}

\hypertarget{conversion-to-labeled-data-frames}{%
\subsubsection{Conversion to labeled data frames}\label{conversion-to-labeled-data-frames}}

Instead of manually setting labels, we can simply convert a data frame to a
labeled data frame, either with the function \texttt{as.ldf()} or with \texttt{convert.labels()}.
Actually, both calls reference the same function (for an object of class \texttt{data.frame}).

While \texttt{as.ldf()} can be seen as the classical counterpart of \texttt{is.ldf()}, the
function name \texttt{convert.labels()} is inspired by the fact that these functions either
convert the variable names to labels or convert other variable labels to \textbf{papeR}-type
variable labels. Hence, these functions can, for example, be used to convert labels
from data sets which are imported via the function \texttt{\{r\ \#\ ead.spss()} to \textbf{papeR}-type
variable labels.

If no variable labels are specified, the original variable names are used.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
Orthodont2 <- convert.labels(Orthodont_orig)
class(Orthodont2)
labels(Orthodont2)
\end{verbatim}

\hypertarget{plotting-labeled-data-frames}{%
\subsection{Plotting labeled data frames}\label{plotting-labeled-data-frames}}

For data frames of class \texttt{\textquotesingle{}ldf\textquotesingle{}}, there exist special plotting functions:

\begin{verbatim}
{r plot_labeled_dataframe, eval=FALSE, include=FALSE}
par(mfrow = c(2, 2))
plot(Orthodont)
\end{verbatim}

As one can see, the plot type is automatically determined
based on the data type and the axis label is defined by
the \texttt{labels()}.

To obtain group comparisons, we can use grouped plots. To plot all variable in the
groups of \texttt{Sex} one can use

\begin{verbatim}
{r grouped_plot, eval=FALSE, include=FALSE}
par(mfrow = c(1, 3))
plot(Orthodont, by =  Sex )
\end{verbatim}

We can as well plot everything against the metrical variable \texttt{distance}

\begin{verbatim}
{r with_x, eval=FALSE, include=FALSE}
par(mfrow = c(1, 3))
plot(Orthodont, with =  distance )
\end{verbatim}

To plot only a subset of the data, say all but \texttt{Subject}, against \texttt{distance} and
suppress the regression line we can use

\begin{verbatim}
{r univariate_no_regressionline, eval=FALSE, include=FALSE}
par(mfrow = c(1, 2))
plot(Orthodont, variables = -3, with =  distance , regression.line = FALSE)
\end{verbatim}

Note that again we can use either variable names or indices to specify the variables
which are to be plotted.

\hypertarget{summary-tables}{%
\subsection{Summary tables}\label{summary-tables}}

One can use the command \texttt{summarize()} to automatically produce summary tables for
either numerical variables (i.e., variables where \texttt{is.numeric()} is \texttt{TRUE}) or
categorical variables (where \texttt{is.factor()} is \texttt{TRUE}). We now extract a summary
table for numerical variables of the \texttt{Orthodont} data set:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(Orthodont, package =  nlme )
summarize(Orthodont, type =  numeric )
\end{verbatim}

Similarly, we can extract summaries for all factor variables. As one of the factors
is the \texttt{Subject} which has \texttt{\{r\ \#\ \ nlevels(Orthodont\$Subject)} levels, each with
\texttt{\{r\ \#\ \ unique(table(Orthodont\$Subject))} observations, we exclude this from the summary
table and only have a look at \texttt{Sex}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summarize(Orthodont, type =  factor , variables =  Sex )
\end{verbatim}

Again, as for the plots, one can specify \texttt{group}s to obtain grouped statistics:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summarize(Orthodont, type =  numeric , group =  Sex , test = FALSE)
\end{verbatim}

Per default, one also gets \texttt{test}s for group differences:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summarize(Orthodont, type =  numeric , group =  Sex )
\end{verbatim}

\hypertarget{converting-summaries-to-pdf}{%
\subsection{Converting summaries to PDF}\label{converting-summaries-to-pdf}}

So far, we only got standard R output. Yet, any of these summary tables can be
easily converted to LaTeX code using the package \textbf{xtable}. In \textbf{papeR} two
special functions \texttt{xtable.summary()} and \texttt{print.xtable.summary()} are defined
for easy and pretty conversion. In \texttt{Sweave} we can use

\begin{verbatim}
{r # 
<<echo = TRUE, results = tex>>=
xtable(summarize(Orthodont, type =  numeric ))
xtable(summarize(Orthodont, type =  factor , variables =  Sex ))
xtable(summarize(Orthodont, type =  numeric , group =  Sex ))
@
\end{verbatim}

and in \textbf{knitr} we can use

\begin{verbatim}
{r # 
<<echo = TRUE, results = 'asis'>>=
xtable(summarize(Orthodont, type =  numeric ))
xtable(summarize(Orthodont, type =  factor , variables =  Sex ))
xtable(summarize(Orthodont, type =  numeric , group =  Sex ))
@
\end{verbatim}

to get the following PDF output

\begin{figure}
\centering
\includegraphics{tables.png}
\caption{LaTeX Output}
\end{figure}

Note that per default, \texttt{booktabs} is set to \texttt{TRUE} in \texttt{print.xtable.summary}, and
thus \texttt{\textbackslash{}usepackage\{booktabs\}} is needed in the header of the LaTeX report. For details
on LaTeX summary tables see the dedicated vignette, which can be obtained, e.g., via
\texttt{vignette(\ papeR\textbackslash{}\_with\textbackslash{}\_latex\ ,\ package\ =\ \ papeR\ )}. See also there for more details
on summary tables in general.

\hypertarget{converting-summaries-to-markdown}{%
\subsection{Converting summaries to Markdown}\label{converting-summaries-to-markdown}}

To obtain markdown output we can use, for example, the function \texttt{kable()} from
package \textbf{knitr} on the summary objects:

\begin{verbatim}
{r , eval=FALSE, echo = TRUE, results = 'asis'}
library( knitr )
kable(summarize(Orthodont, type =  numeric ))
kable(summarize(Orthodont, type =  factor , variables =  Sex , cumulative = TRUE))
kable(summarize(Orthodont, type =  numeric , group =  Sex , test = FALSE))
\end{verbatim}

which gives the following results

\begin{verbatim}
{r, eval=FALSE, echo = TRUE, results = 'asis'}
library( knitr )
kable(summarize(Orthodont, type =  numeric ))
kable(summarize(Orthodont, type =  factor , variables =  Sex , cumulative = TRUE))
kable(summarize(Orthodont, type =  numeric , group =  Sex ))
\end{verbatim}

\hypertarget{prettify-model-output}{%
\subsection{Prettify model output}\label{prettify-model-output}}

To prettify the output of a linear model, one can use the function
\texttt{prettify()}. This function adds confidence intervals, properly
prints p-values, adds significance stars to the output (if desired)
and additionally adds pretty formatting for factors.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
linmod <- lm(distance ~ age + Sex, data = Orthodont)
## Extract pretty summary
(pretty_lm <- prettify(summary(linmod)))
\end{verbatim}

The resulting table can now be formatted for printing using packages like
\textbf{xtable} for LaTeX which can be used in \texttt{.Rnw} files with the option
\texttt{\{r\ \#\ esults=\textquotesingle{}asis\textquotesingle{}} (in \textbf{knitr}) or \texttt{\{r\ \#\ esults\ =\ tex} (in \texttt{Sweave})

\begin{verbatim}
{r, results='hide'}
xtable(pretty_lm)
\end{verbatim}

In markdown files (\texttt{.Rmd}) one can instead use the function \texttt{kable()} with the
chunk option \texttt{\{r\ \#\ esults=\textquotesingle{}asis\textquotesingle{}}. The result looks as follows:

\begin{verbatim}
{r, results='asis'}
kable(pretty_lm)
\end{verbatim}

\hypertarget{supported-objects}{%
\subsubsection{Supported objects}\label{supported-objects}}

The function \texttt{prettify} is \emph{currently} implemented for objects of the following classes:

\begin{itemize}
\tightlist
\item
  \texttt{lm} (linear models)
\item
  \texttt{glm} (generalized linear models)
\item
  \texttt{coxph} (Cox proportional hazards models)
\item
  \texttt{lme} (linear mixed models; implemented in package \textbf{nlme})
\item
  \texttt{mer} (linear mixed models; implemented in package \textbf{lme4}, version \textless{} 1.0)
\item
  \texttt{merMod} (linear mixed models; implemented in package \textbf{lme4}, version \textgreater= 1.0)
\item
  \texttt{anova} (anova objects)
\end{itemize}

\hypertarget{power-analysis-1}{%
\chapter{Power Analysis}\label{power-analysis-1}}

\begin{itemize}
\tightlist
\item
  How to calculate statistical power for your meta-analysis
\end{itemize}

\url{https://towardsdatascience.com/how-to-calculate-statistical-power-for-your-meta-analysis-e108ee586ae8}

\hypertarget{r-scripts}{%
\chapter{R scripts}\label{r-scripts}}

author: Marcello Gallucci, Giulio Constantini \& Marco Perugini

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(echo = TRUE)
if(!require( pacman )) install.packages( pacman )
pacman::p_load( ggplot2 ,  pwr ,  easypower ,  powerMediation ,  bmem )
\end{verbatim}

\hypertarget{introduction-2}{%
\chapter{Introduction}\label{introduction-2}}

In this page one can found all the R functions discussed in Perugini, Gallucci, Constantini (2018), A practical primer to power analysis for simple experimental designs. \textbf{International Review of Social Psychology}. \href{here}{rewf here}. Examples are taken from the papers. In all the examples that require multiple lines of code the user needs to update only the variables listed before \texttt{\#\#\#\ end\ of\ input\ \#\#\#} comment. The results are computed automatically for the required N. Small changes in the code are required to compute other power parameters.

\hypertarget{t-test}{%
\chapter{t-test}\label{t-test}}

\hypertarget{independent-samples}{%
\section{Independent Samples}\label{independent-samples}}

A very simple function for independent samples t-test. To use with Cohen's d, set \texttt{sd=1} and put \texttt{delta=d}, where \texttt{d} is your effect size.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}

power.t.test(power=.80, sig.level=.05, delta=.5, sd=1)
\end{verbatim}

Required n for each group should be rounded up to the first whole number. Exactly one of \texttt{n}, \texttt{delta}, \texttt{sd}, \texttt{power}, and \texttt{sig.level} must be NULL. The NULL parameter is estimated by the function. Thus, post-hoc analysis is done omitting \texttt{power} and including \texttt{n}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

power.t.test(n=64, sig.level=.05, delta=.5, sd=1)
\end{verbatim}

\texttt{?power.t.test} for all the other options.

\hypertarget{sensitivity-analysis}{%
\section{Sensitivity analysis}\label{sensitivity-analysis}}

In the paper we suggested to look at the relationship between total sample size and effect size for a given power level (.80 in the example) and alpha (.05 in the example). In R this can be done as follows:

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
library( ggplot2 )

N<-seq(20,140,by=20)

## end of input ##
dat<-data.frame(n=N)
for (i in seq(N)) {
   one.power<-power.t.test(power=.80, sig.level=.05, sd=1, n=N[i])
   dat$d[i]<-one.power$delta
}

plt<-ggplot(dat,aes(y=d,x=n, label = round(d,digits = 2))) +stat_smooth(method =  loess ,se=FALSE)
plt<-plt+labs(x= Totale sample size ,y= Effect size d )
plt<-plt+scale_x_continuous(breaks=seq(min(N),max(N),by=20))
plt<-plt+geom_label()
plt

\end{verbatim}

\hypertarget{paired-samples}{%
\section{Paired Samples}\label{paired-samples}}

Same function with the option \texttt{type\ =\ \ paired}

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}

power.t.test(power=.80, sig.level=.05, delta=0.527, sd=1,type =  paired )
\end{verbatim}

\hypertarget{one-way-analysis-of-variance}{%
\chapter{One way Analysis of Variance}\label{one-way-analysis-of-variance}}

For all F-test related power analysis, it is generally better to use \texttt{pwr.f2.test()} function from \href{https://cran.r-project.org/web/packages/pwr/index.html}{pwr package}. The function uses \(f^2\) as effect size, which is the square of the \(f\) used by GPower ANOVA: Fixed effects, omnibus and one-way . Here we assume one has the \(\eta_p^2\), which in one-way ANOVA is the \(R^2\). For required N (total sample size) one needs to input also \(k\), the number of groups defined by the independent variable.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
library( pwr )

## input ##
etap<-.326
k<-8 # number of groups in the design
## end of input ##
f2=etap/(1-etap)
dfn<-k-1 # numerator degrees of freedom

(res<-pwr.f2.test(u = dfn,f2 = f2,sig.level = .05,power = .80))
## required N ##
ceiling(res$v)+res$u+1
\end{verbatim}

\hypertarget{factorial-designs}{%
\chapter{Factorial Designs}\label{factorial-designs}}

Assume that in a 3 X 2 factorial design the researcher expects the interaction to explain around 10\% of the variance. If the researcher expects no main effect, the proportion of residual variance is 1-.10=.90, so the pŒ∑2=.10.

\hypertarget{method-1}{%
\section{method 1}\label{method-1}}

Here we keep using \texttt{pwr.f2.test} because it can be used for any F-test in the linear model. However, for prospective power (required total N) the function returns the required error degrees of freedom, so the required N must be approximate adding the effects degrees of freedom to the error degrees of freedom. The following code does it automatically.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
library( pwr )

## input for interaction##
etap<-.10
k1<-3 # levels of the first factor
k2<-2 # levels of the second factor
## end of input ##

(f2=etap/(1-etap))
dfn<-(k1-1)*(k2-1) # df for the interaction

(res<-pwr.f2.test(u = dfn,f2 = f2,sig.level = .05,power = .80))

## required N ##
ceiling(res$v)+(k1*k2)-1


## input for main effects##
etap<-.10
k1<-3 # levels of the first factor
k2<-2 # levels of the second factor
## end of input ##

(f2=etap/(1-etap))
dfn<-(k1-1) # df for the main effect 1
(res<-pwr.f2.test(u = dfn,f2 = f2,sig.level = .05,power = .80))

## required N ##
ceiling(res$v)+(k1*k2)-1

dfn<-(k2-1) # df for the main effect 2
(res<-pwr.f2.test(u = dfn,f2 = f2,sig.level = .05,power = .80))

## required N ##
ceiling(res$v)+(k1*k2)-1

\end{verbatim}

\hypertarget{method-2}{%
\section{Method 2}\label{method-2}}

The package \href{https://cran.r-project.org/web/packages/easypower/index.html}{easypower} provides short cuts for factorial ANOVA power analysis. It provides a dedicated function \texttt{n.multiway()} which simplifies computation of required N for main effects and interaction. It does not provide estimates for post-hoc power and other applications of power analysis.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}

library( easypower )
## input ##
etap<-.10
k1<-3
k2<-2
## end of input ##

main.eff1 <- list(name =  A , levels = k1, eta.sq = etap)
main.eff2 <- list(name =  C , levels = k2, eta.sq = etap)
int.eff1 <- list(name =  A*C , eta.sq = etap)
n.multiway(iv1 = main.eff1, iv2 = main.eff2, int1 = int.eff1)

\end{verbatim}

Results are the same than \emph{method 1} a part from rounding.

\hypertarget{power-analysis-for-contrasts}{%
\section{Power analysis for contrasts}\label{power-analysis-for-contrasts}}

\hypertarget{generic-contrasts}{%
\subsection{Generic Contrasts}\label{generic-contrasts}}

Main effects and interaction for example in Table 2. They are all equivalent, so we go for the interaction. We compute the \(f\) as in the paper, but use \(f^2\) as required by `pwr.f2.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}

## input ##
means<-c(10,0,0,0)
sd=5
contInt<-c(1,-1,-1,1)

## end input ##

### contrast value
cvInt<-contInt%*%means

## Effect sizes ##

fInt<-cvInt/sqrt(length(means)*sum(contInt^2*sd^2))

#### expected N
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=fInt^2)
ceiling(res$v)+length(means)
\end{verbatim}

\hypertarget{guessing-the-interaction-effect-size-from-one-way-designs}{%
\section{Guessing the interaction effect size from one-way designs}\label{guessing-the-interaction-effect-size-from-one-way-designs}}

Consider the case in which the pattern of means in Table 3, case 1, in the paper is taken from a one-way design in which A1 and A2 show means equal to 5 and 2, respectively, and the same within groups variability (say equal to 1). Basically, the researcher observes in the literature a one-way design with only A as a factor and wishes to test the moderating effect of B in a 2 x 2 design. The B factor has two levels, that for simplicity we name ``replicated'' and ``moderated''. The problem is to determine the power parameters of the expected interaction effect.

\hypertarget{means-based-method}{%
\section{Means based method}\label{means-based-method}}

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# observed means #
A1<-c(5,2)
# expected means #
A2<-c(0,0)

sd=1
contInt<-c(1,-1,-1,1)

## end input ##

means<-c(A1,A2)
cvInt<-contInt%*%means

## Effect sizes ##

fInt<-cvInt/sqrt(length(means)*sum(contInt^2*sd^2))

#### expected N
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=fInt^2)
ceiling(res$v)+length(means)

\end{verbatim}

\hypertarget{percentage-of-moderation}{%
\subsection{Percentage of moderation}\label{percentage-of-moderation}}

Researcher should estimate the percentage of moderation, where 100\% means full suppression of the effec, 200\% full reversing of the effect.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# observed means #
A1<-c(5,2)
cont1<-c(1,-1)
l<-2 #levels of moderators
sd=1
# percentage of moderation
pm<-100

## end of input ##

k1<-length(A1)
k2<-length(A1)*l
f0<-(A1%*%cont1)/(sqrt(length(A1)*sum(cont1^2)*sd^2))

f<-(pm/100)*f0*sqrt(length(cont1)/(length(cont1)*l^2))

#### expected N
(res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f^2))
ceiling(res$v)+length(cont1)*l

  
\end{verbatim}

\hypertarget{paper-example-an-example-of-a-more-complex-design}{%
\subsection{Paper example An example of a more complex design}\label{paper-example-an-example-of-a-more-complex-design}}

Consider a researcher who wishes to design a moderation study based on an one-way design with four conditions implementing an increasing intensity of a stimulus, such that the observed pattern of mean shows a linear trend. In particular, the observed linear trend contrast has an p=.184, corresponding to a f=0.475.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
### starting from eta-squared ###

# percentage of moderation
pm<-125
# observed parameters #
etap<-.184
cont<-c(-3,-1,1,3)
l<-2 # levels of moderator
### end of input ###

(f0<-sqrt(etap/(1-etap)))

(f<-(pm/100)*f0*sqrt(length(cont1)/(length(cont1)*l^2)))

#### expected N (total sample)
(res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f^2))
ceiling(res$v)+(length(cont)*l)
\end{verbatim}

The same results can be obtained if one anticipates all expected means and pooled standard deviation (tedious method)

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}

Replicated<-c(5,9,16,20)
sd<-12.239
Expected<-c(5,3,2,1)
cont<-c(-3,-1,1,3)
## end of input ##
contInt<-c(cont,-cont)
means<-c(Replicated,Expected)

(f<-(contInt%*%means)/sqrt(length(contInt)*sum(contInt^2)*sd^2))

#### expected N
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f^2)
ceiling(res$v)+length(cont1)*2

  
\end{verbatim}

\hypertarget{regression-analysis}{%
\chapter{Regression Analysis}\label{regression-analysis}}

Any effect in simple and the multiple regression for which the \(\eta_p^2\) is available can be evaluated witht he following code. here is an example for a regression with three predictors and a small effect size, according to Cohen's (Cohen, 1988) classification.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
## input ##
etap<-0.02
k<-3 # number of predictors
## end of input ###
(f2<-etap/(1-etap))
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f^2)
ceiling(res$v)+k
\end{verbatim}

\hypertarget{moderated-regression}{%
\chapter{Moderated regression}\label{moderated-regression}}

\hypertarget{interaction-between-continuous-and-dichotomous-predictors.}{%
\section{Interaction between continuous and dichotomous predictors.}\label{interaction-between-continuous-and-dichotomous-predictors.}}

The researcher needs to estimate the expected correlation between the continuous independent variable and the dependent variable for the two groups defined by the moderator.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
## input ##
ra<-.0
rb<-.50
k<-3 # number of coefficients in the regression (not considering the intercept)
## end of input ##

(bint<-abs(ra-rb))
(f2<-bint^2/(2*(2-ra^2-rb^2)))

## expected N ###
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f2)
ceiling(res$v)+k+1

\end{verbatim}

\hypertarget{interaction-between-continuous-predictors}{%
\section{Interaction between continuous predictors}\label{interaction-between-continuous-predictors}}

The researcher needs to estimate the expected correlation between the continuous independent variables and the dependent variable, and the change of correlation from the average value of the moderator to one standard deviation above average of the moderator. We assume here that there

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
## input ##
r_yx<-.35
r_ym<-.25
r_change<-.175
k<-3 # number of coefficients in the regression (not considering the intercept)
## end of input ##

(f2<-r_change^2/(1-r_yx^2-r_ym^2))

## expected N ###
res<-pwr.f2.test(u=1,power=.80,sig.level = .05, f2=f2)
ceiling(res$v)+k+1

\end{verbatim}

\hypertarget{mediation}{%
\chapter{Mediation}\label{mediation}}

\hypertarget{method-based-on-sobel-test}{%
\subsection{method based on Sobel test}\label{method-based-on-sobel-test}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library( powerMediation )
### input ###
# a, b,  are the coefficients as in standard mediational path diagram
a<-.8186
b<-.4039
c<- .4334
### end of input ###

# compute sigma.epsilon
sigma.epsilon<-sqrt(1-(b^2+c^2+2*a*b*c))

## results: expected N
res<-ssMediation.Sobel(power = .80,  theta.1a = .8186, lambda.a = .4039, sigma.x = 1, sigma.m = 1, sigma.epsilon = .6020)
ceiling(res$n)
\end{verbatim}

\hypertarget{method-based-on-bootstrap-analysis}{%
\subsection{method based on bootstrap analysis}\label{method-based-on-bootstrap-analysis}}

The code below allows computing the power achieved with a certain sample size, that must be indicated as nobs below. The achieved power for the Indirect/Mediation effect (ab) using a sample of size nobs can be read under column Power .

The following code is based on boostrap and it takes a lot of time (several hours) to run. Be extremely patient (or leave it running at night). If you have a multi-core processor, function power.boot implements parallel processing to speed-up computations. See ?power.boot for details.

\begin{verbatim}
{r eval=F}
library( bmem )
### input ###
# a, b,  are the coefficients as in standard mediational path diagram, n is the sample size-
a<-.8186
b<-.4039
c<- .4334
nobs <- 100

### end of input ###

model <- paste(c(
  'M ~ a*X + start(',a,')*X',
  'Y ~ b*M + c*X + start(',b,') * M + start(.4334)*X',
  'X ~~ start(1)*X',
  'M ~~ start(1)*M',
  'Y ~~ start(1)*Y'), collapse =  \n 
)
set.seed(1234)
power.result <- power.boot(model, indirect = 'ab := a*b', nobs = nobs) 
summary(power.result)
\end{verbatim}

\hypertarget{power-analysis-2}{%
\chapter{Power Analysis}\label{power-analysis-2}}

\begin{itemize}
\tightlist
\item
  A Practical Primer To Power Analysis for Simple Experimental Designs.
  International Review of Social Psychology, 31(1), 20.
\end{itemize}

DOI: \url{http://doi.org/10.5334/irsp.181}

\url{https://www.rips-irsp.com/article/10.5334/irsp.181/}

\url{https://github.com/mcfanda/primerPowerIRSP}

\hypertarget{my-r-codes-for-data-analysis-7}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-7}}

\hypertarget{prepare-data-for-analysis-veriyi-analiz-iuxe7in-hazux131rlamak-1}{%
\chapter{Prepare Data for Analysis / Veriyi Analiz i√ßin hazƒ±rlamak}\label{prepare-data-for-analysis-veriyi-analiz-iuxe7in-hazux131rlamak-1}}

\hypertarget{the-quartz-guide-to-bad-data}{%
\section{The Quartz guide to bad data}\label{the-quartz-guide-to-bad-data}}

\begin{quote}
An exhaustive reference to problems seen in real-world data along with suggestions on how to resolve them.
\end{quote}

\url{https://github.com/Quartz/bad-data-guide}

\hypertarget{kuxf6tuxfc-veri-kux131lavuzu}{%
\section{K√∂t√º veri kƒ±lavuzu}\label{kuxf6tuxfc-veri-kux131lavuzu}}

K√∂t√º veri kƒ±lavuzu

\url{https://sbalci.github.io/Kotu-Veri-Kilavuzu/index.html}

\hypertarget{data-organization-organizing-data-in-spreadsheets}{%
\section{data organization organizing data in spreadsheets}\label{data-organization-organizing-data-in-spreadsheets}}

\url{https://kbroman.org/dataorg/}

Daniel Kaplan. (2018) Teaching Stats for Data Science. The American Statistician 72:1, pages 89-96.

\url{https://doi.org/10.1080/00031305.2017.1375989}

\hypertarget{tidy-data}{%
\section{Tidy Data}\label{tidy-data}}

Hadley Wickham.
Tidy data.
The Journal of Statistical Software, vol.~59, 2014.

\url{http://vita.had.co.nz/papers/tidy-data.html}
\url{https://www.jstatsoft.org/article/view/v059i10}
\url{http://dx.doi.org/10.18637/jss.v059.i10}

\hypertarget{the-ten-commandments-for-a-well-formatted-database}{%
\section{The Ten Commandments for a well-formatted database}\label{the-ten-commandments-for-a-well-formatted-database}}

\begin{itemize}
\tightlist
\item
  The Ten Commandments for a well-formatted database
\end{itemize}

\url{https://rtask.thinkr.fr/blog/the-ten-commandments-for-a-well-formatted-database/}

\hypertarget{software-specific-problems}{%
\section{Software specific problems}\label{software-specific-problems}}

\hypertarget{keep-spss-labels-1}{%
\subsection{Keep SPSS labels}\label{keep-spss-labels-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(foreign) # foreign paketi y√ºkleniyor
\end{verbatim}

read.spss komutu ile deƒüer etiketlerini almasƒ±nƒ± ve bunu liste olarak deƒüil de data.frame olarak kaydetmesini istiyoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
mydata <- read.spss( mydata.sav , use.value.labels = TRUE, to.data.frame = TRUE)
\end{verbatim}

aktardƒ±ƒüƒ±mƒ±z data.frame'in √∂zellikleri (attr) i√ßinde deƒüi≈ükenlerin etiketleri var, bunlarƒ± dƒ±≈üarƒ± √ßƒ±kartƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels <- as.data.frame(attr(mydata,  variable.labels ))
\end{verbatim}

elde ettiƒüimiz data.frame'deki satƒ±r isimleri deƒüi≈ükenlerin isimleri oluyor, kar≈üƒ±larƒ±nda da deƒüi≈üken etiketleri var
satƒ±r isimlerini de dƒ±≈üarƒ± √ßƒ±kartƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels$original <- rownames(VariableLabels)
\end{verbatim}

Deƒüi≈üken etiketi olanlarƒ± etiketleri ile diƒüerlerini olduƒüu gibi saklƒ±yoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
VariableLabels$label[VariableLabels$label ==  ] <- NA 
VariableLabels$colname <- VariableLabels$original
VariableLabels$colname[!is.na(VariableLabels$label)] <- as.vector(VariableLabels$label[!is.na(VariableLabels$label)])
\end{verbatim}

son olarak da data.frame'deki s√ºtun isimlerini deƒüi≈ütiriyoruz

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
names(mydata) <- VariableLabels$colname
\end{verbatim}

\hypertarget{make-both-computer-and-human-readible-variable-names}{%
\subsection{Make both computer and human readible variable names}\label{make-both-computer-and-human-readible-variable-names}}

turkce karakter donusumu

\begin{verbatim}
{r turkce karakter donusumu, eval=FALSE, include=FALSE}
# https://suatatan.wordpress.com/2017/10/07/bulk-replacing-turkish-characters-in-r/

to.plain <- function(s) {
        # 1 character substitutions
    old1 <-  √ßƒü≈üƒ±√º√∂√áƒû≈ûƒ∞√ñ√ú 
    new1 <-  cgsiuocgsiou 
    s1 <- chartr(old1, new1, s)
    # 2 character substitutions
    old2 <- c( ≈ì ,  √ü ,  √¶ ,  √∏ )
    new2 <- c( oe ,  ss ,  ae ,  oe )
    s2 <- s1
    for(i in seq_along(old2)) s2 <- gsub(old2[i], new2[i], s2, fixed = TRUE)
    s2
}

names(df) <- make.names(to.plain(tolower(names(df))))

names(df) <- names(df) %>% 
    tolower() %>% 
    to.plain() %>% 
    make.names()

df$source=as.vector(sapply(df$source,to.plain))

make.names(tolower(names(df)))
to.plain(names(df))

purrr::map(df, to.plain)
\end{verbatim}

\hypertarget{anonimisation}{%
\subsection{Anonimisation}\label{anonimisation}}

\hypertarget{add-subject-id-to-the-data-veriye-id-ekleme}{%
\subsection{Add subject ID to the data / veriye ID ekleme}\label{add-subject-id-to-the-data-veriye-id-ekleme}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df <- tibble::rowid_to_column(df,  subject )
\end{verbatim}

\hypertarget{data-reorganization}{%
\section{Data reorganization}\label{data-reorganization}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
scabies <- read.csv(file =  http://datacompass.lshtm.ac.uk/607/2/S1-Dataset_CSV.csv , header = TRUE, sep =  , )

scabies$gender ==  male 

scabies$age[scabies$gender ==  male ]

mean(scabies$age[scabies$gender ==  male ])


scabies %>% 
    filter(gender ==  male ) %>% 
    summarise_at( age  ,mean) 

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

scabies$agegroups <- as.factor(cut(scabies$age, c(0,10,20,Inf), labels = c( 0-10 , 11-20 , 21+ ), include.lowest = TRUE)) 

scabies$house_cat <- as.factor(cut(scabies$house_inhabitants, c(0,5,10,Inf), labels = c( 0-5 , 6-10 , 10+ ), include.lowest = TRUE))


table(scabies$house_cat, scabies$house_inhabitants)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ebola$status <- as.numeric(ebola$status) 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ebola$transmission <- recode(ebola$transmission, syringe =  needle )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
scabies$house_cat <- relevel(scabies$house_cat, ref =  0-5 )
#Make 0-5 household size the baseline group
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df <- data.frame(month=rep(1:3,2),
                 student=rep(c( Amy ,  Bob ), each=3),
                 A=c(9, 7, 6, 8, 6, 9),
                 B=c(6, 7, 8, 5, 6, 7))
#Here we have a where each student is on a different row for each month
#The students took two tests A and B. 
#For each student/month combination we have a value for A and a value for B

df2 <- gather(df,test,score,A:B)
#Make a new datatable df2
#Have a column called  test . 
#This will have the value either A or B as these are the names of the columns we specified.
#Have a column called  score . 
#This will have the value previously in column A or B respectively for each row

df2
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#Now we have a single row for each combination of month/student/test 
#Their score is in the score column

df3 <- spread(df2,test,score)
#Make a new datatable df3
#Make a column for each unique value in the test variable.
#Name each of these columns based on that unique value
#Under each column put the corresponding value that was in the score column

df3
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dt3 <- expandRows(dt, 2)
#Expand the original datatable. Replicate each row by the value in column 2. 
dt3
\end{verbatim}

\url{https://stackoverflow.com/questions/22353633/filter-for-complete-cases-in-data-frame-using-dplyr-case-wise-deletion}

df \%\textgreater\% na.omit
or this:

df \%\textgreater\% filter(complete.cases(.))
or this:

library(tidyr)
df \%\textgreater\% drop\_na
If you want to filter based on one variable's missingness, use a conditional:

df \%\textgreater\% filter(!is.na(x1))
or

df \%\textgreater\% drop\_na(x1)
Other answers indicate that of the solutions above na.omit is much slower but that has to be balanced against the fact that it returns and row indices of the omitted rows as the na.action attribute whereas the other solutions above do not.

str(df \%\textgreater\% na.omit)
`data.frame': 2 obs. of 2 variables:
\$ x1: num 1 2
\$ x2: num 1 2
- attr(\emph{, na.action )= `omit' Named int 3 4
..- attr(}, names )= chr 3 4

ozp \textless- veri \%\textgreater\%
select(RaporNo, Hasta, cinsiyet, Yas,
ozp\_parca, ozp\_kaset, ozp\_cap, ozp\_tani, ozp\_kod) \%\textgreater\%
filter(!is.na(ozp\_parca) \textbar{} !is.na(ozp\_kaset) \textbar{} !is.na(ozp\_cap) \textbar{} !is.na(ozp\_tani) \textbar{} !is.na(ozp\_kod)
)

ozp2 \textless- veri \%\textgreater\%
select(RaporNo, Hasta, cinsiyet, Yas,
ozp\_parca, ozp\_kaset, ozp\_cap, ozp\_tani, ozp\_kod) \%\textgreater\%
filter(complete.cases(ozp\_parca, ozp\_kaset, ozp\_cap, ozp\_tani, ozp\_kod)
)

ozp3 \textless- veri \%\textgreater\%
select(RaporNo, Hasta, cinsiyet, Yas,
ozp\_parca, ozp\_kaset, ozp\_cap, ozp\_tani, ozp\_kod) \%\textgreater\%
na.omit(ozp\_parca, ozp\_kaset, ozp\_cap, ozp\_tani, ozp\_kod)

\hypertarget{xray}{%
\chapter{xray}\label{xray}}

The R Package to Have X Ray Vision on your Datasets

\url{https://blog.datascienceheroes.com/x-ray-vision-on-your-datasets/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( devtools )
devtools::install_github( sicarul/xray )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(longley)
badLongley <- longley
badLongley$GNP <- NA
xray::anomalies(badLongley)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
distrLongley <- longley
distrLongley$testCategorical <- c(rep('One',7), rep('Two', 9))
xray::distributions(distrLongley)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dateLongley <- longley
dateLongley$Year <- as.Date(paste0(dateLongley$Year,'-01-01'))
dateLongley$Data <- 'Original'
ndateLongley <- dateLongley
ndateLongley$GNP <- dateLongley$GNP+10
ndateLongley$Data <- 'Offseted'
xray::timebased(rbind(dateLongley, ndateLongley), 'Year')
\end{verbatim}

\hypertarget{convert-all-data.frame-into-character}{%
\chapter{convert all data.frame into character}\label{convert-all-data.frame-into-character}}

df \textless- purrr::map\_df(df, as.character)

\hypertarget{rcase4base---reshape-data-with-base-r}{%
\chapter{R:case4base - reshape data with base R}\label{rcase4base---reshape-data-with-base-r}}

\url{https://jozefhajnala.gitlab.io/r/r002-data-manipulation/}

\hypertarget{rcase4base---data-aggregation-with-base-r}{%
\chapter{R:case4base - data aggregation with base R}\label{rcase4base---data-aggregation-with-base-r}}

\url{https://jozefhajnala.gitlab.io/r/r003-aggregation/}

\hypertarget{tidyr}{%
\chapter{tidyr}\label{tidyr}}

This week I'm going to be looking at some \#tidyr functions! üí° First is uncount() which might come in handy if you want to transform a summary table to individual rows. \#rstats pic.twitter.com/UZE0wUcEHC

--- Nic Crane (\citet{nic_crane}) November 26, 2018

\begin{verbatim}
df <- data.frame(
          V1 = c(0, 0, 0, 0, 1, 1, 1, 1, 0, 1),
          V2 = c(1, 1, 1, 0, 0, 0, 0, 0, 0, 1),
          V3 = c(0, 0, 0, 1, 1, 1, 1, 1, 0, 1)
)


df$V1_rec <- grepl(pattern =  0 , x = df$V1)
df$V2_rec <- grepl(pattern =  0 , x = df$V2)
df$V3_rec <- grepl(pattern =  0 , x = df$V3)

df %>% 
    mutate(toplam = select(., V1_rec:V3_rec) %>% rowSums(na.rm = TRUE)
               )
\end{verbatim}

\hypertarget{python-pandas}{%
\chapter{Python Pandas}\label{python-pandas}}

\url{http://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb}

\url{https://www.youtube.com/watch?v=5_QXMwezPJE\&list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y\&index=2}

\url{https://developers.google.com/edu/python/}

\hypertarget{text-data}{%
\chapter{Text Data}\label{text-data}}

\hypertarget{quanteda-quantitative-analysis-of-textual-data}{%
\chapter{quanteda: Quantitative Analysis of Textual Data}\label{quanteda-quantitative-analysis-of-textual-data}}

An R package for the Quantitative Analysis of Textual Data

\url{https://quanteda.io}

\url{https://github.com/quanteda/quanteda}

\hypertarget{quick-start-guide}{%
\chapter{Quick Start Guide}\label{quick-start-guide}}

\url{https://quanteda.io/articles/pkgdown/quickstart.html}

\begin{verbatim}
{r download package}
# devtools package required to install quanteda from Github 
# devtools::install_github( quanteda/quanteda ) 
# install.packages( quanteda )
# install.packages( readtext )
\end{verbatim}

\hypertarget{readtext-import-and-handling-for-plain-and-formatted-text-files}{%
\chapter{readtext: Import and handling for plain and formatted text files}\label{readtext-import-and-handling-for-plain-and-formatted-text-files}}

\url{https://readtext.quanteda.io}

\url{https://github.com/quanteda/readtext}

\hypertarget{httpsgithub.comquantedareadtext}{%
\chapter{\texorpdfstring{\url{https://github.com/quanteda/readtext}}{https://github.com/quanteda/readtext}}\label{httpsgithub.comquantedareadtext}}

\hypertarget{httpsgithub.comquantedastopwords}{%
\chapter{\texorpdfstring{\url{https://github.com/quanteda/stopwords}}{https://github.com/quanteda/stopwords}}\label{httpsgithub.comquantedastopwords}}

\hypertarget{httpsgithub.comquantedaspacyr}{%
\chapter{\texorpdfstring{\url{https://github.com/quanteda/spacyr}}{https://github.com/quanteda/spacyr}}\label{httpsgithub.comquantedaspacyr}}

\hypertarget{httpsgithub.comquantedaquanteda.corpora}{%
\chapter{\texorpdfstring{\url{https://github.com/quanteda/quanteda.corpora}}{https://github.com/quanteda/quanteda.corpora}}\label{httpsgithub.comquantedaquanteda.corpora}}

\hypertarget{httpsgithub.comkbenoitquanteda.dictionaries}{%
\chapter{\texorpdfstring{\url{https://github.com/kbenoit/quanteda.dictionaries}}{https://github.com/kbenoit/quanteda.dictionaries}}\label{httpsgithub.comkbenoitquanteda.dictionaries}}

\hypertarget{httpsquanteda.ioarticlesquickstart.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/quickstart.html}}{https://quanteda.io/articles/quickstart.html}}\label{httpsquanteda.ioarticlesquickstart.html}}

\hypertarget{httpsquanteda.ioarticlespkgdowncomparison.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/comparison.html}}{https://quanteda.io/articles/pkgdown/comparison.html}}\label{httpsquanteda.ioarticlespkgdowncomparison.html}}

\hypertarget{httpsquanteda.ioarticlespkgdowndesign.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/design.html}}{https://quanteda.io/articles/pkgdown/design.html}}\label{httpsquanteda.ioarticlespkgdowndesign.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownexamplesphrase.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/examples/phrase.html}}{https://quanteda.io/articles/pkgdown/examples/phrase.html}}\label{httpsquanteda.ioarticlespkgdownexamplesphrase.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownexamplesplotting.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/examples/plotting.html}}{https://quanteda.io/articles/pkgdown/examples/plotting.html}}\label{httpsquanteda.ioarticlespkgdownexamplesplotting.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownexampleslsa.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/examples/lsa.html}}{https://quanteda.io/articles/pkgdown/examples/lsa.html}}\label{httpsquanteda.ioarticlespkgdownexampleslsa.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownexamplestwitter.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/examples/twitter.html}}{https://quanteda.io/articles/pkgdown/examples/twitter.html}}\label{httpsquanteda.ioarticlespkgdownexamplestwitter.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownreplicationdigital-humanities.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/replication/digital-humanities.html}}{https://quanteda.io/articles/pkgdown/replication/digital-humanities.html}}\label{httpsquanteda.ioarticlespkgdownreplicationdigital-humanities.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownreplicationtext2vec.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/replication/text2vec.html}}{https://quanteda.io/articles/pkgdown/replication/text2vec.html}}\label{httpsquanteda.ioarticlespkgdownreplicationtext2vec.html}}

\hypertarget{httpsquanteda.ioarticlespkgdownreplicationqss.html}{%
\chapter{\texorpdfstring{\url{https://quanteda.io/articles/pkgdown/replication/qss.html}}{https://quanteda.io/articles/pkgdown/replication/qss.html}}\label{httpsquanteda.ioarticlespkgdownreplicationqss.html}}

\hypertarget{footer}{%
\chapter{footer}\label{footer}}

\begin{verbatim}
{r citation 2}
citation(package =  quanteda )
\end{verbatim}

title: R Aray√ºzler\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara referans
  vermeye √ßalƒ±≈ütƒ±m.}

\hypertarget{r-iuxe7in-arayuxfczler}{%
\chapter{R i√ßin aray√ºzler}\label{r-iuxe7in-arayuxfczler}}

\hypertarget{analiz-iuxe7in-genel-gui}{%
\section{Analiz i√ßin genel GUI}\label{analiz-iuxe7in-genel-gui}}

\hypertarget{r-commander}{%
\subsection{R Commander}\label{r-commander}}

\url{https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/}

\begin{verbatim}
#### Obtain names of all packages on CRAN

names.available.packages <- rownames(available.packages())

#### Extract packages names that contain Rcmdr

Rcmdr.related.packages <- names.available.packages[grep( Rcmdr , names.available.packages)]
Rcmdr.related.packages

#### Install these packages
install.packages(pkgs = Rcmdr.related.packages)
\end{verbatim}

\begin{verbatim}
# load library & run Rcmdr
library(Rcmdr)
# run Rcmdr
Rcmdr::Commander()
\end{verbatim}

\hypertarget{ezr}{%
\subsubsection{EZR}\label{ezr}}

An extension for R Commander

\url{http://www.jichi.ac.jp/saitama-sct/SaitamaHP.files/statmedEN.html}

\href{http://www.nature.com/bmt/journal/vaop/ncurrent/pdf/bmt2012244a.pdf}{Investigation of the freely available easy-to-use software `EZR' for medical statistics}

\hypertarget{rkward}{%
\subsection{RKWard}\label{rkward}}

\url{https://rkward.kde.org/Main_Page}

\hypertarget{rattle}{%
\subsection{Rattle}\label{rattle}}

\url{https://rattle.togaware.com/}

\hypertarget{jamovi-4}{%
\subsection{Jamovi}\label{jamovi-4}}

\url{https://www.jamovi.org/}

\hypertarget{jasp}{%
\subsection{JASP}\label{jasp}}

\url{https://jasp-stats.org/}

\hypertarget{blue-sky-statistics}{%
\subsection{Blue Sky Statistics}\label{blue-sky-statistics}}

\url{https://www.blueskystatistics.com/}

\hypertarget{r-analyticflow}{%
\subsection{R AnalyticFlow}\label{r-analyticflow}}

\url{https://r.analyticflow.com/en/}

\hypertarget{deducer}{%
\subsection{Deducer}\label{deducer}}

\url{http://www.deducer.org/pmwiki/pmwiki.php?n=Main.DeducerManual}

\url{https://r4stats.com/2018/06/13/deducer/}

\begin{verbatim}
install.packages(c( JGR , Deducer , DeducerExtras ))
\end{verbatim}

\begin{verbatim}
library( JGR )
JGR()
\end{verbatim}

\hypertarget{radiant}{%
\subsection{Radiant}\label{radiant}}

\url{https://radiant-rstats.github.io/docs/tutorials.html}

\hypertarget{lessr-1}{%
\subsection{lessR}\label{lessr-1}}

\url{https://cran.r-project.org/web/packages/lessR/index.html}

\url{http://www.lessrstats.com/}

\url{http://www.lessrstats.com/videos.html}

\hypertarget{renjin}{%
\subsection{Renjin}\label{renjin}}

\url{http://www.renjin.org/}

\hypertarget{fastr}{%
\subsection{FastR}\label{fastr}}

\url{https://github.com/oracle/fastr}

\url{http://www.graalvm.org/docs/reference-manual/languages/r/}

\hypertarget{raporlama-iuxe7in}{%
\section{Raporlama i√ßin}\label{raporlama-iuxe7in}}

\hypertarget{stencila}{%
\subsection{Stencila}\label{stencila}}

\hypertarget{datazar}{%
\subsection{Datazar}\label{datazar}}

\hypertarget{grafikler-4}{%
\section{Grafikler}\label{grafikler-4}}

\hypertarget{esquisse}{%
\subsection{esquisse}\label{esquisse}}

\url{https://github.com/dreamRs/esquisse}

\hypertarget{ggextra}{%
\subsection{ggExtra}\label{ggextra}}

\url{https://github.com/daattali/ggExtra}

\hypertarget{ggplotassist}{%
\subsection{ggplotAssist}\label{ggplotassist}}

\url{https://github.com/cardiomoon/ggplotAssist}

\hypertarget{ggraptr}{%
\subsection{ggraptR}\label{ggraptr}}

\url{https://github.com/cargomoose/ggraptR}

\hypertarget{eclipse-an-alternative-to-rstudio}{%
\chapter{Eclipse -- an alternative to RStudio}\label{eclipse-an-alternative-to-rstudio}}

\url{https://datascienceplus.com/eclipse-an-alternative-to-rstudio-part-1/}

\hypertarget{diux11fer-kodlar-4}{%
\chapter{Diƒüer kodlar}\label{diux11fer-kodlar-4}}

\begin{itemize}
\tightlist
\item
  Diƒüer kodlar i√ßin bakƒ±nƒ±z: \url{https://sbalci.github.io/}
\end{itemize}

\hypertarget{geri-bildirim-4}{%
\chapter{Geri Bildirim}\label{geri-bildirim-4}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\hypertarget{r-drake}{%
\chapter{R drake}\label{r-drake}}

Reproducible workflows at scale with drake

\url{https://ropensci.org/commcalls/2019-09-24/}

title: R ile analize ba≈ülarken\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara referans
  vermeye √ßalƒ±≈ütƒ±m.}

\begin{verbatim}
{r setup global chunk settings, include=FALSE}
knitr::opts_chunk$set(
    message = FALSE,
    warning = FALSE,
    comment = NA,
    include = FALSE,
    tidy = TRUE
)
\end{verbatim}

\hypertarget{r-nerede-kullanux131lux131r}{%
\chapter{R nerede kullanƒ±lƒ±r}\label{r-nerede-kullanux131lux131r}}

\begin{itemize}
\tightlist
\item
  Veri d√ºzenleme
\item
  ƒ∞statistik analiz
\item
  Web sayfasƒ± hazƒ±rlama (Statik/Dinamik)
  \url{https://sbalci.github.io/}\\
  \url{https://kevinrue.shinyapps.io/isee-shiny-contest/}
\item
  Sunum hazƒ±rlama (bu sunum)
\item
  Programlama
  \url{https://serdarbalci.netlify.com/pathtweets/}
\item
  Otomatik, periodik ve tekrarlanabilir rapor hazƒ±rlama
  \url{https://sbalci.github.io/AutoJournalWatch/GallbladderRecent.html}
\item
  pdf, html, ppt olu≈üturma
\item
  tez yazma
\item
  kitap yazma
\item
  CV olu≈üturma
  \url{https://rpubs.com/sbalci/CV}\\
\item
  poster hazƒ±rlama
\item
  rapor ≈üablonu olu≈üturma
\item
  Robot uygulamalarƒ± (Arudino kodu)
\item
  \ldots{}
\end{itemize}

\hypertarget{r-generation}{%
\chapter{R generation}\label{r-generation}}

R yƒ±llar i√ßinde √ßok fazla deƒüi≈üim g√∂sterdi

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\includegraphics{https://wol-prod-cdn.literatumonline.com/pb-assets/journal-banners/17409713-1501384756037.jpg}

\begin{figure}
\centering
\includegraphics{https://wol-prod-cdn.literatumonline.com/cms/attachment/1a49c07b-b56f-4327-8e92-7827ef51a7bb/sign1169-gra-0002-m.jpg}
\caption{:scale 30\%}
\end{figure}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::include_graphics(path =  https://wol-prod-cdn.literatumonline.com/cms/attachment/1a49c07b-b56f-4327-8e92-7827ef51a7bb/sign1169-gra-0002-m.jpg )
\end{verbatim}

\hypertarget{r-yuxfckleme-4}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme-4}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\begin{figure}
\centering
\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}
\caption{What is R?}
\end{figure}

\hypertarget{r-project-4}{%
\section{R-project}\label{r-project-4}}

\url{https://cran.r-project.org/}

\hypertarget{rstudio-4}{%
\section{RStudio}\label{rstudio-4}}

\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}

\hypertarget{rstudio-5}{%
\subsection{RStudio}\label{rstudio-5}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\hypertarget{rstudio-6}{%
\subsection{RStudio}\label{rstudio-6}}

\hypertarget{rstudio-eklentileri-4}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri-4}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{macos-iuxe7in}{%
\section{MacOS i√ßin}\label{macos-iuxe7in}}

\hypertarget{x11-4}{%
\subsection{X11}\label{x11-4}}

\url{https://www.xquartz.org/}

\hypertarget{java-os-4}{%
\subsection{Java OS}\label{java-os-4}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-4}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-4}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\#RStats --- There are always several ways to do the same thing\ldots{} nice example on with the identity matrix by \citet{TeaStats} https://t.co/O3GXdPiM32

--- Colin Fay ü§ò (\citet{_ColinFay}) April 1, 2019

\hypertarget{r-paketleri-4}{%
\chapter{R paketleri}\label{r-paketleri-4}}

\hypertarget{neden-paketler-var-4}{%
\section{Neden paketler var}\label{neden-paketler-var-4}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz-4}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz-4}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  CRAN Task Views\\
  \url{https://cran.r-project.org/web/views/}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  CRANsearcher\\
  \url{https://github.com/RhoInc/CRANsearcher}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur-4}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur-4}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-paket-yuxfckleme-4}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme-4}}

\begin{verbatim}
{r # 
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\hypertarget{paket-uxe7aux11fux131rma}{%
\section{Paket √ßaƒüƒ±rma}\label{paket-uxe7aux11fux131rma}}

\begin{verbatim}
{r # 
require(tidyverse)  
require(jmv)  
require(questionr)  
library(summarytools)  
library(gganimate)  
\end{verbatim}

\hypertarget{r-iuxe7in-yardux131m-bulma-4}{%
\chapter{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma-4}}

\begin{verbatim}
{r # 
?mean
??efetch
help(merge)
example(merge)
RSiteSearch( shiny )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\begin{figure}
\centering
\includegraphics{figures/vignette.png}
\caption{:scale 80\%}
\end{figure}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\item
  Google'da ararken \texttt{{[}R{]}} yazmak da i≈üe yarayabiliyor.
\item
  searcher package üì¶
\end{itemize}

\href{https://github.com/coatless/searcher}{\includegraphics{https://camo.githubusercontent.com/12f0e2d18047f1b5f36fbeb09a1d0e548236883f/68747470733a2f2f692e696d6775722e636f6d2f5a7132726736472e676966}}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Use Reproducible Examples When Asking
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\begin{itemize}
\tightlist
\item
  Keeping up to date with R news\\
  \url{https://masalmon.eu/2019/01/25/uptodate/}
\end{itemize}

\hypertarget{rstudio-ile-proje-oluux15fturma}{%
\chapter{Rstudio ile proje olu≈üturma}\label{rstudio-ile-proje-oluux15fturma}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme-4}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme-4}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel-4}{%
\section{Excel}\label{excel-4}}

\hypertarget{spss-4}{%
\section{SPSS}\label{spss-4}}

\hypertarget{csv-4}{%
\section{CSV}\label{csv-4}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-4}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-4}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-5}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-5}}

\begin{verbatim}
{r # 
library(nycflights13)
summary(flights)
\end{verbatim}

\begin{verbatim}
{r # 
View(data)
\end{verbatim}

\begin{verbatim}
{r # 
data()
\end{verbatim}

\begin{verbatim}
{r # 
head(data, n = 10)
\end{verbatim}

\begin{verbatim}
{r # 
tail(data)
\end{verbatim}

\begin{verbatim}
{r # 
glimpse(data)
\end{verbatim}

\begin{verbatim}
{r # 
str(data)
\end{verbatim}

\begin{verbatim}
{r # 
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme-4}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme-4}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim-4}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim-4}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme-4}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme-4}}

\begin{figure}
\centering
\includegraphics{figures/change_data.png}
\caption{:scale 30\%}
\end{figure}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode-4}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode-4}}

\emph{questionr} paketi kullanƒ±lacak

\begin{figure}
\centering
\includegraphics{figures/level_recode.png}
\caption{:scale 30\%}
\end{figure}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler-4}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler-4}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include = TRUE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )
scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools-4}{%
\section{summarytools}\label{summarytools-4}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = FALSE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco,
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE),
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris,
      stats = c( mean ,  sd ,  min ,  med ,  max ),
      transpose = TRUE,
      headings = FALSE,
      style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# First save the results
iris_stats_by_species <- by(data = iris,
                            INDICES = iris$Species,
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ),
                            transpose = TRUE)
# Then use view(), like so:
view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco,
                   by(BMI, age.gr, descr,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco,
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\hypertarget{dataexplorer-6}{%
\section{DataExplorer}\label{dataexplorer-6}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{inspectdf}{%
\section{inspectdf}\label{inspectdf}}

\url{https://github.com/alastairrushworth/inspectdf}

\hypertarget{grafikler-5}{%
\section{Grafikler}\label{grafikler-5}}

\begin{verbatim}
{r echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

A beginner kit for \#rstats
The Landscape of R Packages for Automated Exploratory Data Analysis
\url{https://journal.r-project.org/archive/2019/RJ-2019-033/}

\citet{article}\{RJ-2019-033,
author = \{Mateusz Staniak and Przemys≈Çaw Biecek\},
title = \{\{The Landscape of R Packages for Automated Exploratory Data
Analysis\}\},
year = \{2019\},
journal = \{\{The R Journal\}\},
doi = \{10.32614/RJ-2019-033\},
url = \{\url{https://journal.r-project.org/archive/2019/RJ-2019-033/index.html}\}
\}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{bazux131-arayuxfczler}{%
\chapter{Bazƒ± aray√ºzler}\label{bazux131-arayuxfczler}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Arayuzler.nb.html}

\hypertarget{rcmdr-4}{%
\section{Rcmdr}\label{rcmdr-4}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi-5}{%
\section{jamovi}\label{jamovi-5}}

\url{https://www.jamovi.org/}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\hypertarget{r-nereden-uxf6ux11frenilir}{%
\chapter{R nereden √∂ƒürenilir}\label{r-nereden-uxf6ux11frenilir}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/WhereToLearnR.nb.html}

\hypertarget{sonraki-konular-4}{%
\chapter{Sonraki Konular}\label{sonraki-konular-4}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub kullanƒ±mƒ±
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\item
  Hipotez testleri
\end{itemize}

--

\hypertarget{geri-bildirim-5}{%
\chapter{Geri Bildirim}\label{geri-bildirim-5}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\hypertarget{libraries-used}{%
\chapter{Libraries Used}\label{libraries-used}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
citation()
\end{verbatim}

\begin{verbatim}
citation( tidyverse )
citation( foreign )
citation( tidylog )
citation( janitor )
citation( jmv )
citation( tangram )
citation( finalfit )
citation( summarytools )
citation( ggstatplot )
citation( readxl )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
citation( tidyverse )
citation( foreign )
citation( tidylog )
citation( janitor )
citation( jmv )
citation( tangram )
citation( finalfit )
citation( summarytools )
citation( ggstatplot )
citation( readxl )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
sessionInfo()
\end{verbatim}

\hypertarget{iletiux15fim}{%
\chapter{ƒ∞leti≈üim}\label{iletiux15fim}}

Completed on \texttt{\{r\ \#\ \ Sys.time()}.

Serdar Balci, MD, Pathologist\\
\href{mailto:drserdarbalci@gmail.com}{\nolinkurl{drserdarbalci@gmail.com}}

\url{https://rpubs.com/sbalci/CV}\\
\url{https://sbalci.github.io/}~\\
\url{https://github.com/sbalci}~\\
\url{https://twitter.com/serdarbalci}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
CommitMessage <- paste( updated on  , Sys.time(), sep =   )

wd <- getwd()

gitCommand <- paste( cd  , wd,   \n git add . \n git commit --message ' , CommitMessage,  ' \n git push origin master \n , sep =   )

system(command = gitCommand, intern = TRUE
)
\end{verbatim}

title: R, RStudio ve RMarkdown ile Tekrarlanabilir Rapor\footnote{Bu bir derlemedir, m√ºmk√ºn mertebe alƒ±ntƒ±lara linklerle referans vermeye √ßalƒ±≈ütƒ±m.}

\begin{verbatim}
author:  [Serdar Balcƒ±, MD, Pathologist](https://sbalci.github.io/) 
institute:  [serdarbalci.com](https://www.serdarbalci.com) 
date:  `{r #  format(Sys.Date())` 
output:
  revealjs::revealjs_presentation:
    incremental: true
    theme: sky
    highlight: pygments
    center: false
    smart: true
    transition: fade
    self_contained: true
    ig_width: 7
    fig_height: 6
    fig_caption: true
    reveal_options:
      slideNumber: true
      previewLinks: true
  rmdshower::shower_presentation:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      beforeInit: [ macros.js ,  https://platform.twitter.com/widgets.js ]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    self_contained: true
  html_notebook:
    fig_caption: yes
    highlight: kate
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
    toc_float: yes
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    fig_caption: yes
    keep_md: yes
    toc: yes
    toc_depth: 5
    toc_float: yes
editor_options: 
  chunk_output_type: inline
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.path = 'Figs/', echo = TRUE, warning = FALSE, message = FALSE, error = FALSE, eval = TRUE, tidy = TRUE, comment = NA, cache = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# xaringan::inf_mr()
# servr::daemon_stop(1)
\end{verbatim}

\hypertarget{tekrarlanabilir-analiz-ve-rapor}{%
\chapter{Tekrarlanabilir Analiz ve Rapor}\label{tekrarlanabilir-analiz-ve-rapor}}

\href{https://the-turing-way.netlify.com/reproducibility/03/definitions.html}{\includegraphics{https://the-turing-way.netlify.com/figures/reproducibility/ReproducibleMatrix.jpg}}

\hypertarget{replication-crisis}{%
\section{Replication Crisis}\label{replication-crisis}}

\includegraphics{figures/replicationCrisis.png}

\url{https://en.wikipedia.org/wiki/Replication_crisis}

\hypertarget{replication-crisis-excel-version}{%
\section{Replication Crisis Excel Version}\label{replication-crisis-excel-version}}

\href{https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7}{\includegraphics{figures/geneNamesExcel.png}}

\hypertarget{rstudio-ile-proje-oluux15ftur}{%
\chapter{RStudio ile proje olu≈ütur}\label{rstudio-ile-proje-oluux15ftur}}

\includegraphics{images/RStudio-NewProject.gif}

\hypertarget{r-notebook-3}{%
\chapter{R Notebook}\label{r-notebook-3}}

\hypertarget{r-notebook-duxf6kuxfcmanux131-oluux15fturma}{%
\section{R Notebook d√∂k√ºmanƒ± olu≈üturma}\label{r-notebook-duxf6kuxfcmanux131-oluux15fturma}}

\includegraphics{images/RNotebook1.gif}

\hypertarget{r-notebooktan-html-pdf-ve-word-oluux15fturma}{%
\section{R Notebook'tan html, pdf ve word olu≈üturma}\label{r-notebooktan-html-pdf-ve-word-oluux15fturma}}

\includegraphics{images/RNotebook2.gif}

\hypertarget{rnotebook-vs-rmarkdown}{%
\section{RNotebook vs RMarkdown}\label{rnotebook-vs-rmarkdown}}

\textless iframe width= 560 height= 315 src= \url{https://www.youtube.com/embed/zNzZ1PfUDNk} frameborder= 0 allow= accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture allowfullscreen\textgreater{}

\url{https://youtu.be/zNzZ1PfUDNk}

\hypertarget{r-markdown}{%
\chapter{R Markdown}\label{r-markdown}}

\hypertarget{hem-kendi-kodlarux131-hem-de-html-kodlarux131-yazux131labilir}{%
\section{Hem kendi kodlarƒ± hem de html kodlarƒ± yazƒ±labilir}\label{hem-kendi-kodlarux131-hem-de-html-kodlarux131-yazux131labilir}}

\url{https://rmarkdown.rstudio.com}

What is R Markdown? from RStudio, Inc. on Vimeo.

\hypertarget{r-markdown-the-definitive-guide}{%
\section{R Markdown: The Definitive Guide}\label{r-markdown-the-definitive-guide}}

\url{https://bookdown.org/yihui/rmarkdown/}

\hypertarget{r-markdown-syntax}{%
\section{R Markdown syntax}\label{r-markdown-syntax}}

\url{https://gist.github.com/MinhasKamal/7fdebb7c424d23149140}

\hypertarget{remedy-package}{%
\section{Remedy Package}\label{remedy-package}}

\href{https://github.com/ThinkR-open/remedy}{}

\hypertarget{remedy}{%
\subsection{Remedy}\label{remedy}}

\href{https://github.com/ThinkR-open/remedy}{}

\hypertarget{r-markdown-paket-ve-ux15fablonlarux131}{%
\section{R Markdown paket ve ≈üablonlarƒ±}\label{r-markdown-paket-ve-ux15fablonlarux131}}

\url{https://bookdown.org/yihui/rmarkdown/document-templates.html}

\includegraphics{images/RMarkdownTemplates.gif}

\hypertarget{render-markdown-via-code}{%
\section{Render Markdown via code}\label{render-markdown-via-code}}

\emph{inside R}

\begin{verbatim}
markdown::markdownToHTML('markdown_example.md', 
'markdown_example.html')
\end{verbatim}

\emph{command line}

\begin{verbatim}
R -e  markdown::markdownToHTML('markdown_example.md',
'markdown_example.html') 
\end{verbatim}

\hypertarget{pandoc-rstudio-integration}{%
\section{pandoc Rstudio integration}\label{pandoc-rstudio-integration}}

\emph{command line}

\begin{verbatim}
export PATH=$PATH:/Applications/RStudio.app/Contents/MacOS/pandoc
\end{verbatim}

\begin{verbatim}
R -e  rmarkdown::render('markdown_example.md') 
\end{verbatim}

\hypertarget{rmarkdown-chunk-iuxe7inde-r-kodlarux131nux131-uxe7alux131ux15ftux131rma}{%
\chapter{\texorpdfstring{RMarkdown \texttt{chunk} i√ßinde \texttt{R} kodlarƒ±nƒ± √ßalƒ±≈ütƒ±rma}{RMarkdown chunk i√ßinde R kodlarƒ±nƒ± √ßalƒ±≈ütƒ±rma}}\label{rmarkdown-chunk-iuxe7inde-r-kodlarux131nux131-uxe7alux131ux15ftux131rma}}

\begin{verbatim}
{r, results='asis'}
 iris %>%
  tibble::as_tibble() %>%
  details::details(summary = 'tibble')
\end{verbatim}

\hypertarget{metin-arasux131nda-r-kodlarux131nux131-uxe7alux131ux15ftux131rma}{%
\chapter{\texorpdfstring{Metin arasƒ±nda \texttt{R} kodlarƒ±nƒ± √ßalƒ±≈ütƒ±rma}{Metin arasƒ±nda R kodlarƒ±nƒ± √ßalƒ±≈ütƒ±rma}}\label{metin-arasux131nda-r-kodlarux131nux131-uxe7alux131ux15ftux131rma}}

\includegraphics{images/inlineRCode.png}

\hypertarget{chunk-options}{%
\chapter{Chunk Options}\label{chunk-options}}

\hypertarget{global-options}{%
\section{Global Options}\label{global-options}}

\begin{verbatim}
{r , include=FALSE}
knitr::opts_chunk$set(fig.width = 12,
                      fig.height = 8,
                      fig.path = 'Figs/',
                      echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE,
                      eval = TRUE,
                      tidy = TRUE,
                      comment = NA)
\end{verbatim}

\hypertarget{other-code-languages}{%
\section{Other Code Languages}\label{other-code-languages}}

\href{https://rmarkdown.rstudio.com/lesson-5.html}{\includegraphics{https://d33wubrfki0l68.cloudfront.net/162347ef5afe219da22fb7d7d9a5989f2c3e5a85/59316/lesson-images/languages-1-demos.png}}

\hypertarget{r-markdown-kod-uxf6rneux11fi}{%
\chapter{R Markdown kod √∂rneƒüi}\label{r-markdown-kod-uxf6rneux11fi}}

\begin{verbatim}
{r}
data( cancer )
cancer
foreign::write.foreign(df = cancer,
                        datafile =  data/cancer.sav ,
                        codefile =  data/cancer.spo ,
                        package =  SPSS 
                        )
\end{verbatim}

\hypertarget{r-markdown-paket-uxe7aux11fux131rma}{%
\chapter{R Markdown Paket √áaƒüƒ±rma üì¶}\label{r-markdown-paket-uxe7aux11fux131rma}}

\begin{verbatim}
{r}
suppressPackageStartupMessages(library( tidyverse ))
suppressPackageStartupMessages(library( survival ))
\end{verbatim}

\hypertarget{sux131k-kullandux131ux11fux131m-paketler}{%
\section{Sƒ±k kullandƒ±ƒüƒ±m paketler üì¶}\label{sux131k-kullandux131ux11fux131m-paketler}}

\{tidyverse\}
\{tidylog\}

\{lubridate\}
\{janitor\}

\{readxl\}
\{foreign\}

\{summarytools\}
\{ggstatsplot\}
\{tangram\}
\{finalfit\}
\{psycho\}
\{jmv\}

\{survival\}
\{survminer\}

\{report\}
\{kableExtra\}

\hypertarget{r-markdown-veri-yuxfckleme-spss}{%
\chapter{R Markdown Veri Y√ºkleme SPSS}\label{r-markdown-veri-yuxfckleme-spss}}

\includegraphics{images/importSPSS.gif}

\hypertarget{r-markdown-veri-yuxfckleme-excel}{%
\chapter{R Markdown Veri Y√ºkleme Excel}\label{r-markdown-veri-yuxfckleme-excel}}

\includegraphics{images/importExcel.gif}

\hypertarget{veri-guxf6ruxfcntuxfcleme}{%
\chapter{Veri G√∂r√ºnt√ºleme}\label{veri-guxf6ruxfcntuxfcleme}}

\begin{verbatim}
{r}
View(mydata)
glimpse(mydata)
\end{verbatim}

\hypertarget{veri-duxfczenleme}{%
\chapter{Veri D√ºzenleme}\label{veri-duxfczenleme}}

\begin{verbatim}
{r}
mydata <- janitor::clean_names(mydata)
\end{verbatim}

\begin{verbatim}
{r}
mydata$sontarih <- janitor::excel_numeric_to_date(
  as.numeric(mydata$olum_tarihi)
  )
\end{verbatim}

\hypertarget{recode}{%
\chapter{Recode}\label{recode}}

\begin{verbatim}
{r}
mydata$Outcome <-  Dead 
mydata$Outcome[mydata$olum_tarihi ==  yok ] <-  Alive 
\end{verbatim}

\begin{verbatim}
{r}
## Recoding mydata$cinsiyet into mydata$Cinsiyet
mydata$Cinsiyet <- recode(mydata$cinsiyet,
                K  =  Kadin ,
                E  =  Erkek )
mydata$Cinsiyet <- factor(mydata$Cinsiyet)
\end{verbatim}

\hypertarget{recode-regular-expression}{%
\chapter{Recode regular expression}\label{recode-regular-expression}}

\begin{verbatim}
{r recode TNM stage}
#pT2N0Mx -> 2
mydata$Tstage <- stringr::str_match(
  mydata$patolojik_evre, 
  paste('(.+)',  N , sep=''))[,2]
)
\end{verbatim}

\hypertarget{recode-regular-expression-case_when}{%
\chapter{Recode regular expression case\_when}\label{recode-regular-expression-case_when}}

\begin{verbatim}
{r recode TNM2}
mydata <- mydata %>% 
    mutate(
        T_stage = case_when(
            grepl(pattern =  T1 , x = .$Tstage) == TRUE ~  T1 ,
            grepl(pattern =  T2 , x = .$Tstage) == TRUE ~  T2 ,
            grepl(pattern =  T3 , x = .$Tstage) == TRUE ~  T3 ,
            grepl(pattern =  T4 , x = .$Tstage) == TRUE ~  T4 ,
            TRUE ~  Tx 
        )
    )
\end{verbatim}

\hypertarget{recode-regular-expression-case_when-1}{%
\chapter{Recode regular expression case\_when}\label{recode-regular-expression-case_when-1}}

\begin{verbatim}
{r}
mydata <- mydata %>% 
    mutate(
TumorPDL1gr1 = case_when(
        t_pdl1 < 1 ~  kucuk1 ,
        t_pdl1 >= 1 ~  buyukesit1 
    )
    )
\end{verbatim}

\hypertarget{r-markdown-tanux131mlayux131cux131-istatistikler}{%
\chapter{R Markdown Tanƒ±mlayƒ±cƒ± ƒ∞statistikler}\label{r-markdown-tanux131mlayux131cux131-istatistikler}}

\begin{verbatim}
{r}
library(summarytools)
view(dfSummary(colon_s))
\end{verbatim}

A beginner kit for \#rstats
The Landscape of R Packages for Automated Exploratory Data Analysis
\url{https://journal.r-project.org/archive/2019/RJ-2019-033/}

\citet{article}\{RJ-2019-033,
author = \{Mateusz Staniak and Przemys≈Çaw Biecek\},
title = \{\{The Landscape of R Packages for Automated Exploratory Data
Analysis\}\},
year = \{2019\},
journal = \{\{The R Journal\}\},
doi = \{10.32614/RJ-2019-033\},
url = \{\url{https://journal.r-project.org/archive/2019/RJ-2019-033/index.html}\}
\}

\hypertarget{table-one}{%
\section{Table One}\label{table-one}}

\begin{verbatim}
{r, results='asis'}
# cat(names(mydata), sep =   + \n )
library(arsenal)
tab1 <- tableby(~ Cinsiyet + 
Yas + 
TumorYerlesimi
                ,
                data = mydata)
summary(tab1)
\end{verbatim}

\hypertarget{the-grammar-of-tables}{%
\section{The Grammar of Tables}\label{the-grammar-of-tables}}

\href{https://cran.r-project.org/web/packages/tangram/}{tangram: The Grammar of Tables}

\href{https://github.com/leeper/tttable}{A grammar of tables}

\href{https://gist.github.com/leeper/f9cfbe6bd185763762e126a4d8d7c286}{Grammar of Tables?}

\href{https://gt.rstudio.com}{Easily generate information-rich, publication-quality tables from R}

\hypertarget{kategorik-veriler}{%
\section{Kategorik Veriler}\label{kategorik-veriler}}

\begin{verbatim}
{r}
mydata %>% 
  janitor::tabyl(Categorical) %>%
  adorn_pct_formatting(rounding = 'half up',
                       digits = 1) %>%
  knitr::kable()
\end{verbatim}

\begin{verbatim}
{r crosstable}
mydata %>%
    summary_factorlist(dependent = dependent, 
                       explanatory = explanatory,
                       total_col = TRUE,
                       p = TRUE,
                       add_dependent_label = TRUE) -> table
knitr::kable(table, row.names = FALSE, align = c('l', 'l', 'r', 'r', 'r'))
\end{verbatim}

\hypertarget{kategorik-veriler-iuxe7in-grafikler}{%
\section{Kategorik Veriler i√ßin Grafikler}\label{kategorik-veriler-iuxe7in-grafikler}}

\begin{verbatim}
{r ggstatplot, layout='l-page'}
mydata %>% 
    ggstatsplot::ggbarstats(data = .,
                            main = Categorical_variable,
                            condition =  dependent_variable
                            )
\end{verbatim}

\hypertarget{continious-variables}{%
\section{Continious Variables}\label{continious-variables}}

\begin{verbatim}
{r}
mydata %>% 
jmv::descriptives(
    data = .,
    vars = c(yas),
    hist = TRUE,
    dens = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sd = TRUE,
    variance = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE)
\end{verbatim}

\hypertarget{r-markdown-uxf6rneux11fi-uxe7apraz-tablolar}{%
\chapter{R Markdown √∂rneƒüi √áapraz Tablolar}\label{r-markdown-uxf6rneux11fi-uxe7apraz-tablolar}}

\begin{verbatim}
{r crosstable}
library(finalfit)
mydata %>%
    summary_factorlist(dependent = dependent, 
                       explanatory = explanatory,
                       column = TRUE,
                       total_col = TRUE,
                       p = TRUE,
                       add_dependent_label = TRUE,
                       na_include=FALSE
                       # catTest = catTestfisher
                       ) -> table
knitr::kable(table,
             row.names = FALSE,
             align = c('l', 'l', 'r', 'r', 'r'))
\end{verbatim}

\hypertarget{r-markdown-uxf6rneux11fi-saux11fkalux131m}{%
\chapter{R Markdown √∂rneƒüi Saƒükalƒ±m}\label{r-markdown-uxf6rneux11fi-saux11fkalux131m}}

\begin{itemize}
\tightlist
\item
  Drawing Survival Curves Using ggplot2\\
  \url{https://rpkgs.datanovia.com/survminer/reference/ggsurvplot.html}
\end{itemize}

\hypertarget{saux11fkalux131m-iuxe7in-veriyi-duxfczenleme}{%
\section{Saƒükalƒ±m i√ßin veriyi d√ºzenleme}\label{saux11fkalux131m-iuxe7in-veriyi-duxfczenleme}}

\begin{verbatim}
{r define survival time}
mydata$int <- lubridate::interval(
  lubridate::ymd(mydata$CerrahiTarih),
  lubridate::ymd(mydata$SonTarih)
  )
mydata$OverallTime <- lubridate::time_length(mydata$int,  month )
mydata$OverallTime <- round(mydata$OverallTime, digits = 1)
\end{verbatim}

\begin{verbatim}
{r}
## Recoding mydata$Outcome into mydata$Outcome2
mydata$Outcome2 <- recode(mydata$Outcome,
                Alive  =  0 ,
                Dead  =  1 )
mydata$Outcome2 <- as.numeric(mydata$Outcome2)
\end{verbatim}

\hypertarget{kaplan-meier}{%
\section{Kaplan-Meier}\label{kaplan-meier}}

\begin{verbatim}
{r Kaplan-Meier}
mydata %>%
  finalfit::surv_plot(dependent,
                      explanatory,
                      xlab='Time (months)',
                      pval=TRUE,
                      legend = 'none',
                      break.time.by = 12,
                      xlim = c(0,60),
                      legend.labs = c('a','b')
)
\end{verbatim}

\hypertarget{saux11fkalux131m-tablolarux131}{%
\section{Saƒükalƒ±m Tablolarƒ±}\label{saux11fkalux131m-tablolarux131}}

\begin{verbatim}
{r}
km_fit <- survfit(dependent ~ explanatory,
                  data = mydata)
km_fit
\end{verbatim}

\begin{verbatim}
{r, eval=FALSE, include=FALSE, echo=TRUE}
library(survival)
km <- with(mydata, Surv(OverallTime, Outcome2))
# head(km,80)
# plot(km)
\end{verbatim}

\begin{verbatim}
{r 1-3-5-yr}
summary(km_fit, times = c(12,36,60))
\end{verbatim}

\hypertarget{pairwise-comparison}{%
\section{Pairwise comparison}\label{pairwise-comparison}}

\begin{verbatim}
{r}
survminer::pairwise_survdiff(formula = Surv(time, Outcome) ~ Group, 
                             data = mydata,
                             p.adjust.method =  BH )
\end{verbatim}

\hypertarget{multivariate-analysis-survival}{%
\section{Multivariate Analysis Survival}\label{multivariate-analysis-survival}}

\begin{verbatim}
{r Multivariate Analysis, eval=FALSE, include=FALSE, echo=TRUE}
library(finalfit)
library(survival)
explanatoryMultivariate <- explanatoryKM
dependentMultivariate <- dependentKM
mydata %>%
  finalfit(dependentMultivariate, explanatoryMultivariate) -> tMultivariate
knitr::kable(tMultivariate, row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\hypertarget{jamovi-6}{%
\chapter{jamovi}\label{jamovi-6}}

\hypertarget{jamovi-ve-r-entegrasyonu}{%
\section{jamovi ve R entegrasyonu}\label{jamovi-ve-r-entegrasyonu}}

\href{https://blog.jamovi.org/2018/07/30/rj.html}{Rj Editor -- Analyse your data with R in jamovi}

\includegraphics{images/jamoviRjEditor.gif}

\hypertarget{jmv-paket-kodlarux131}{%
\section{\{jmv\} paket kodlarƒ±}\label{jmv-paket-kodlarux131}}

\href{https://www.jamovi.org/user-manual.html\#syntax-mode}{jamovi syntax mode}

\includegraphics{images/jamoviSyntaxMode.gif}

\hypertarget{guxfcncellemeler-olunca-kodlar-uxe7alux131ux15facak-mux131}{%
\chapter{G√ºncellemeler olunca kodlar √ßalƒ±≈üacak mƒ±?}\label{guxfcncellemeler-olunca-kodlar-uxe7alux131ux15facak-mux131}}

\hypertarget{paket-kuxfctuxfcphaneleri}{%
\section{Paket K√ºt√ºphaneleri}\label{paket-kuxfctuxfcphaneleri}}

\begin{itemize}
\tightlist
\item
  packrat / renv
\end{itemize}

\url{https://environments.rstudio.com}

\hypertarget{docker}{%
\section{Docker}\label{docker}}

\begin{itemize}
\tightlist
\item
  docker
\end{itemize}

\hypertarget{the-rocker-project}{%
\subsection{The Rocker Project}\label{the-rocker-project}}

Docker Containers for the R Environment

\begin{verbatim}
docker run --rm -ti rocker/r-base
\end{verbatim}

Or get started with an RStudio¬Æ instance:

\begin{verbatim}
docker run -e PASSWORD=yourpassword --rm -p 8787:8787 rocker/rstudio
\end{verbatim}

and point your browser to \url{localhost:8787}
Log in with user/password rstudio/yourpassword

\href{https://www.rocker-project.org}{\includegraphics{images/TheRockerProject.png}}

\href{https://www.rocker-project.org/use/managing_containers/}{Managing containers}

\hypertarget{yeni-r-suxfcruxfcmleri}{%
\section{Yeni R s√ºr√ºmleri}\label{yeni-r-suxfcruxfcmleri}}

\begin{itemize}
\tightlist
\item
  RSwitch
\end{itemize}

\url{https://rud.is/rswitch/}

\begin{itemize}
\tightlist
\item
  Using RSwitch
\end{itemize}

\url{https://rud.is/rswitch/guide/}

\begin{figure}
\centering
\includegraphics{https://rud.is/rswitch/guide/menu-info.png}
\caption{: scale 30\%}
\end{figure}

\hypertarget{yedeklemeyi-nasux131l-yapacaux11fux131z}{%
\chapter{Yedeklemeyi nasƒ±l yapacaƒüƒ±z}\label{yedeklemeyi-nasux131l-yapacaux11fux131z}}

\hypertarget{projeyi-duxfczguxfcn-organize-edin}{%
\section{Projeyi d√ºzg√ºn organize edin}\label{projeyi-duxfczguxfcn-organize-edin}}

\begin{itemize}
\tightlist
\item
  pdf
\item
  R
\item
  images
\item
  bib
\end{itemize}

\begin{verbatim}
{r load library}
source(file = here::here( R ,  loadLibrary.R ))
\end{verbatim}

\hypertarget{save-final-data}{%
\section{Save Final Data}\label{save-final-data}}

\begin{verbatim}
{r}
saved data after analysis to `mydata.xlsx`.

save.image(file = here::here( data ,  mydata_work_space.RData ))

readr::write_rds(x = mydata, path = here::here( data ,  mydata_afteranalysis.rds ))

saveRDS(object = mydata, file = here::here( data ,  mydata.rds ))

writexl::write_xlsx(mydata, here::here( data ,  mydata.xlsx ))

paste0(rownames(file.info(here::here( data ,  mydata.xlsx ))),   :  , file.info(here::here( data ,  mydata.xlsx ))$ctime)
\end{verbatim}

\hypertarget{github-1}{%
\section{GitHub}\label{github-1}}

\begin{verbatim}
{r github push}
CommitMessage <- paste( updated on  , Sys.time(), sep =   )
wd <- getwd()
gitCommand <- paste( cd  , 
                    wd,
                      \n git add . \n git commit --message ' ,
                    CommitMessage,
                     ' \n git push origin master \n ,
                    sep =   
                    )
system(command = gitCommand,
       intern = TRUE
)
\end{verbatim}

\hypertarget{github-yedekleme}{%
\section{GitHub Yedekleme}\label{github-yedekleme}}

\begin{verbatim}
{r github push, echo=TRUE}
CommitMessage <- paste( updated on  , Sys.time(), sep =   )
wd <- getwd()
gitCommand <- paste( cd  , 
                    wd,
                      \n git add . \n git commit --message ' ,
                    CommitMessage,
                     ' \n git push origin master \n ,
                    sep =   
                    )
system(command = gitCommand,
       intern = TRUE
)
\end{verbatim}

\hypertarget{her-duxf6kuxfcmanux131n-sonuna-kullandux131ux11fux131nux131z-kuxfctuxfcphaneler-iuxe7in-atux131f-yazdux131rabilirsiniz}{%
\chapter{Her d√∂k√ºmanƒ±n sonuna kullandƒ±ƒüƒ±nƒ±z k√ºt√ºphaneler i√ßin atƒ±f yazdƒ±rabilirsiniz}\label{her-duxf6kuxfcmanux131n-sonuna-kullandux131ux11fux131nux131z-kuxfctuxfcphaneler-iuxe7in-atux131f-yazdux131rabilirsiniz}}

\begin{verbatim}
{r}
citation()
\end{verbatim}

\hypertarget{libraries-used-1}{%
\section{Libraries Used}\label{libraries-used-1}}

\begin{verbatim}
{r  citation, echo=TRUE}
citation()
\end{verbatim}

\hypertarget{bu-oturuma-spesifik-kullanux131lan-paketler}{%
\section{Bu oturuma spesifik kullanƒ±lan paketler}\label{bu-oturuma-spesifik-kullanux131lan-paketler}}

\begin{verbatim}
{r  citation as report, echo=TRUE, results='asis'}
# report::cite_packages(session = sessionInfo())
\end{verbatim}

\hypertarget{tek-tek-paket-atux131flarux131}{%
\section{Tek tek paket atƒ±flarƒ±}\label{tek-tek-paket-atux131flarux131}}

\begin{verbatim}
{r  citations}
citation( tidyverse )
citation( readxl )
citation( janitor )
citation( report )
citation( finalfit )
citation( ggstatplot )
\end{verbatim}

\hypertarget{jamovi-ve-r-iuxe7in-atux131f-uxf6rneux11fi}{%
\section{Jamovi ve R i√ßin atƒ±f √∂rneƒüi}\label{jamovi-ve-r-iuxe7in-atux131f-uxf6rneux11fi}}

\begin{itemize}
\item
  The jamovi project (2019). jamovi. (Version 0.9) {[}Computer Software{]}. Retrieved from \url{https://www.jamovi.org}.
\item
  R Core Team (2018). R: A Language and envionment for statistical computing. {[}Computer software{]}. Retrieved from \url{https://cran.r-project.org/}.
\item
  Fox, J., \& Weisberg, S. (2018). car: Companion to Applied Regression. {[}R package{]}. Retrieved from \url{https://cran.r-project.org/package=car}.
\end{itemize}

\hypertarget{her-duxf6kuxfcmanux131n-sonuna-oturum-detaylarux131nux131zux131-yazdux131rabilirsiniz}{%
\chapter{Her d√∂k√ºmanƒ±n sonuna oturum detaylarƒ±nƒ±zƒ± yazdƒ±rabilirsiniz}\label{her-duxf6kuxfcmanux131n-sonuna-oturum-detaylarux131nux131zux131-yazdux131rabilirsiniz}}

\begin{verbatim}
{r session info, echo=TRUE}
sessionInfo()
\end{verbatim}

\hypertarget{session-info}{%
\section{Session Info}\label{session-info}}

\begin{verbatim}
{r session info, echo=TRUE}
sessionInfo()
\end{verbatim}

\hypertarget{sonraki-konular-5}{%
\chapter{Sonraki Konular}\label{sonraki-konular-5}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub kullanƒ±mƒ±
\item
  \ldots{}
\end{itemize}

\hypertarget{uxf6nerilen-kaynaklar}{%
\chapter{√ñnerilen Kaynaklar}\label{uxf6nerilen-kaynaklar}}

\begin{itemize}
\item
  \href{https://www.coursera.org/learn/reproducible-templates-analysis/home/info}{Reproducible Templates for Analysis and Dissemination}
\item
  \href{https://happygitwithr.com/}{Happy Git and GitHub for the useR}
\end{itemize}

\hypertarget{sunum-linkleri}{%
\chapter{Sunum Linkleri}\label{sunum-linkleri}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.nb.html}
\url{https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.html}

\url{https://forms.gle/UqGJBiAjB8uLPRon8}

\hypertarget{geri-bildirim-6}{%
\chapter{Geri Bildirim}\label{geri-bildirim-6}}

\begin{itemize}
\tightlist
\item
  Geri bildirim i√ßin tƒ±klayƒ±nƒ±z: \emph{\href{https://goo.gl/forms/YjGZ5DHgtPlR1RnB3}{Geri bildirim formu}}
\end{itemize}

\hypertarget{disqus_thread}{}

Please enable JavaScript to view the comments powered by Disqus.

\hypertarget{iletiux15fim-1}{%
\chapter{ƒ∞leti≈üim}\label{iletiux15fim-1}}

Completed on .

Serdar Balci, MD, Pathologist\\
\href{mailto:drserdarbalci@gmail.com}{\nolinkurl{drserdarbalci@gmail.com}}

\url{https://rpubs.com/sbalci/CV}\\
\url{https://sbalci.github.io/}~\\
\url{https://github.com/sbalci}~\\
\url{https://twitter.com/serdarbalci}

\hypertarget{other-links}{%
\chapter{Other Links}\label{other-links}}

\url{https://andrewbtran.github.io/NICAR/2018/workflow/docs/02-rmarkdown.html}

\begin{itemize}
\tightlist
\item
  Troubleshooting in R Markdown
\end{itemize}

\url{https://smithcollege-sds.github.io/sds-public/rmarkdown_problems.html}

\url{http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html}

\url{https://kbroman.org/knitr_knutshell/pages/overview.html}

\url{https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html}

\url{https://kbroman.org/knitr_knutshell/pages/markdown.html}

\url{https://onp4.com/}

\begin{verbatim}
csv {headers: true, # **Drawing Tables In Markdown** }
Name, Surname, Known As, Age
Marcelo, David, coldzera, 22
Oleksandr, Kostyliev, s1mple, 19
Nikola, Kovaƒç, NiKo, 20
Richard, Papillon, shox, 25
Nicolai, Reedtz, dev1ce, 21
\end{verbatim}

\begin{verbatim}
{pgn}
[Event  Bled-Zagreb-Belgrade Candidates ]
[Site  Bled, Zagreb & Belgrade YUG ]
[Date  1959.10.11 ]
[Round  20 ]
[Result  1-0 ]
[White  Mikhail Tal ]
[Black  Robert James Fischer ]

1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5.
Be2 O-O 6. Nf3 e5 7. d5 Nbd7 8. Bg5 h6 9.
Bh4 a6 10. O-O Qe8 11. Nd2 Nh7 12. b4 Bf6
13. Bxf6 Nhxf6 14. Nb3 Qe7 15. Qd2 Kh7 16.
Qe3 Ng8 17. c5 f5 18. exf5 gxf5 19. f4 exf4
20. Qxf4 dxc5 21. Bd3 cxb4 22. Rae1 Qf6 23.
Re6 Qxc3 24. Bxf5+ Rxf5 25. Qxf5+ Kh8 26.
Rf3 Qb2 27. Re8 Nf6 28. Qxf6+ Qxf6 29. Rxf6
Kg7 30. Rff8 Ne7 31. Na5 h5 32. h4 Rb8 33.
Nc4 b5 34. Ne5 1-0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Keeping Credentials Secret with Keyrings in R
\end{itemize}

\url{https://ras44.github.io/blog/2019/01/19/keeping-credentials-secret-with-keyrings-in-r.html}

\begin{itemize}
\tightlist
\item
  How to build a website with Blogdown in R
\end{itemize}

\url{http://www.storybench.org/how-to-build-a-website-with-blogdown-in-r/}

\hypertarget{r-tipps}{%
\chapter{R-Tipps}\label{r-tipps}}

\hypertarget{readclipboard}{%
\chapter{readClipboard}\label{readclipboard}}

setwd(readClipboard())

\#Rstats: When using setwd(), R expects forward-slashes in the directory name. But on Windows, copying the directory from folder gives back-slashes. To `de-windowsify' the path name, copy the windows directory \& use:setwd(readClipboard())\#phdchat \#phd pic.twitter.com/cMbdmhNVuf

--- Guy Prochilo üè≥Ô∏è
üåà (\citet{GuyProchilo}) January 9, 2019

\hypertarget{separate}{%
\chapter{separate}\label{separate}}

One form of messy data is a table in which multiple variables are stored in a single column. The \#tidyverse separate() function will transform this type of data into one column per variable by simply specifying the separator! \#rstats \#tidytuesday \#animation \#dataviz pic.twitter.com/jjVvqWToIg

--- Omni Analytics Group (\citet{OmniAnalytics}) January 22, 2019

\hypertarget{glue-1}{%
\chapter{glue}\label{glue-1}}

ü§© glue:: finally clicked for me this AM! ü§ìI work with monthly data files and need to update filenames often. My go-to is paste0(). Gave glue() another try. Way less fiddling with commas \& quote marks, and it's easier to see the filename. \#Rstats \#tidyverse pic.twitter.com/EdpozMxrtM

--- Adam Stone (\citet{foundinblank}) January 23, 2019

\includegraphics{images/DxlxObOW0AASiaP.png}

\#RStats --- \{dplyr\} debugging tip: put a browser() somewhere inside your mutate() call to have access to the intermediate elements and to the columns: pic.twitter.com/KN53YJIMOe

--- Colin Fay ü§ò (\citet{_ColinFay}) January 23, 2019

Accidentally discovered if you copy \& paste a file into your \#R script you get the filepath including filename with / (not ) and you just delete "\url{file:///\%22}; off the start and don't have to change ~to / \citet{RossGlvr} demanded I tweet this \#rstats

--- Faye Jackson (\citet{Faye_L_Jackson}) January 18, 2019

\hypertarget{radiant-1}{%
\chapter{radiant}\label{radiant-1}}

\url{https://radiant-rstats.github.io/docs/}

\hypertarget{rchess}{%
\chapter{rchess}\label{rchess}}

\url{http://jkunst.com/rchess/}

\url{https://github.com/jbkunst/rchess}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( rchess )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
devtools::install_github( jbkunst/rchess )
\end{verbatim}

\hypertarget{rcookbook}{%
\chapter{RCookbook}\label{rcookbook}}

\url{https://rc2e.com/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(cars)
library(purrr)
map_dbl(cars, mean)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
map_dbl(cars, sd)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
map_dbl(cars, median)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
var(cars)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cor(cars)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
cov(cars)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
v <- c(3, pi, 4)
any(v == pi) # Return TRUE if any element of v equals pi
all(v == 0) # Return TRUE if all elements of v are zero
\end{verbatim}

\begin{verbatim}
{r , echo=TRUE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print= 75 )
opts_chunk$set(echo=TRUE,
                 cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
\end{verbatim}

\href{https://www..com/community/tutorials/data-science-pitfalls}{\includegraphics{http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530113077/Image_2_vfy48b.png}}

\begin{itemize}
\tightlist
\item
  R generation
\end{itemize}

\url{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}

\hypertarget{r-yuxfckleme-5}{%
\chapter{R y√ºkleme}\label{r-yuxfckleme-5}}

\url{http://www.youtube.com/watch?v=XcBLEVknqvY}

\href{http://www.youtube.com/watch?v=XcBLEVknqvY}{\includegraphics{http://img.youtube.com/vi/XcBLEVknqvY/0.jpg}}

\hypertarget{r-project-5}{%
\section{R-project}\label{r-project-5}}

\url{https://cran.r-project.org/}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#6}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/engine.png}}

\hypertarget{rstudio-7}{%
\section{RStudio}\label{rstudio-7}}

\url{https://www.rstudio.com/}

\url{https://www.rstudio.com/products/rstudio/download/}

\url{https://moderndive.com/2-getting-started.html}

\hypertarget{rstudio-eklentileri-5}{%
\subsection{RStudio eklentileri}\label{rstudio-eklentileri-5}}

\begin{itemize}
\tightlist
\item
  Discover and install useful RStudio addins
\end{itemize}

\url{https://cran.r-project.org/web/packages/addinslist/README.html}

\url{https://rstudio.github.io/rstudioaddins/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( rstudio/addinexamples , type =  source )
\end{verbatim}

\hypertarget{x11-5}{%
\section{X11}\label{x11-5}}

\url{https://www.xquartz.org/}

\hypertarget{java-os-5}{%
\section{Java OS}\label{java-os-5}}

\url{https://support.apple.com/kb/dl1572}

\hypertarget{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-5}{%
\chapter{R zor ≈üeyler i√ßin kolay, kolay ≈üeyler i√ßin zor}\label{r-zor-ux15feyler-iuxe7in-kolay-kolay-ux15feyler-iuxe7in-zor-5}}

\begin{itemize}
\item
  \href{http://r4stats.com/articles/why-r-is-hard-to-learn/}{R makes easy things hard, and hard things easy}
\item
  Aynƒ± ≈üeyi √ßok fazla ≈üekilde yapmak m√ºmk√ºn
\end{itemize}

R Syntax Comparison::CHEAT SHEET

\url{https://www.amelia.mn/Syntax-cheatsheet.pdf}

\hypertarget{r-paketleri-5}{%
\chapter{R paketleri}\label{r-paketleri-5}}

\hypertarget{neden-paketler-var-5}{%
\section{Neden paketler var}\label{neden-paketler-var-5}}

\href{https://ismayc.github.io/talks/ness-infer/slide_deck.html\#7}{\includegraphics{https://ismayc.github.io/talks/ness-infer/img/appstore.png}}

I love the \#rstats community.Someone is like, ``oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.''What a tribe.

--- Frank Elavsky ·¥∞·µÉ·µó·µÉ ·µÇ·∂¶·∂ª·µÉ ≥·µà (\citet{Frankly_Data}) July 3, 2018

\url{https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/}

\includegraphics{https://blog.mitchelloharawild.com/blog/2018-07-11-user-2018-feature-wall_files/final.jpg}

\hypertarget{paketleri-nereden-bulabiliriz-5}{%
\section{Paketleri nereden bulabiliriz}\label{paketleri-nereden-bulabiliriz-5}}

\begin{itemize}
\item
  Available CRAN Packages By Name\\
  \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
\item
  Bioconductor\\
  \url{https://www.bioconductor.org}
\item
  RecommendR\\
  \url{http://recommendr.info/}
\item
  pkgsearch\\
  CRAN package search\\
  \url{https://github.com/metacran/pkgsearch}
\item
  Awesome R\\
  \url{https://awesome-r.com/}
\end{itemize}

\hypertarget{kendi-paket-evrenini-oluux15ftur-5}{%
\section{Kendi paket evrenini olu≈ütur}\label{kendi-paket-evrenini-oluux15ftur-5}}

\begin{itemize}
\tightlist
\item
  pkgverse: Build a Meta-Package Universe\\
  \url{https://cran.r-project.org/web/packages/pkgverse/index.html}
\end{itemize}

\hypertarget{r-iuxe7in-yardux131m-bulma-5}{%
\section{R i√ßin yardƒ±m bulma}\label{r-iuxe7in-yardux131m-bulma-5}}

\begin{verbatim}
# ?mean
# ??efetch
# help(merge)
# example(merge)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Vignette
\end{itemize}

\includegraphics{figures/vignette.png}

\begin{itemize}
\item
  RDocumentation
  \url{https://www.rdocumentation.org}
\item
  R Package Documentation
  \url{https://rdrr.io/}
\item
  GitHub
\item
  Stackoverflow
\end{itemize}

\url{https://stackoverflow.com/}

\begin{itemize}
\tightlist
\item
  Google uygun anahtar kelime
\end{itemize}

How I use \#rstats h/t \citet{ThePracticalDev} pic.twitter.com/erRnTG0Ujr

--- Emily Bovee (\citet{ebovee09}) August 10, 2018

\includegraphics{figures/Google-package-name.png}

\includegraphics{figures/Google-start-with-R.png}

\begin{itemize}
\tightlist
\item
  Awesome Cheatsheet
  \url{https://github.com/detailyang/awesome-cheatsheet}
\end{itemize}

\url{http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf}

\url{https://www.rstudio.com/resources/cheatsheets/}

\begin{itemize}
\tightlist
\item
  Awesome R
\end{itemize}

\url{https://github.com/qinwf/awesome-R\#readme}

\url{https://awesome-r.com/}

\begin{itemize}
\tightlist
\item
  Twitter
\end{itemize}

\url{https://twitter.com/hashtag/rstats?src=hash}

\begin{itemize}
\tightlist
\item
  Reproducible Examples
\end{itemize}

Got a question to ask on \citet{SlackHQ} or post on \citet{github}? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by \citet{JennyBryan}) \#rstat pic.twitter.com/gpuGXpFIsX

--- ZhiYang (\citet{zhiiiyang}) October 18, 2018

\hypertarget{r-paket-yuxfckleme-5}{%
\section{R paket y√ºkleme}\label{r-paket-yuxfckleme-5}}

\begin{verbatim}
install.packages( tidyverse , dependencies = TRUE)
install.packages( jmv , dependencies = TRUE)
install.packages( questionr , dependencies = TRUE)
install.packages( Rcmdr , dependencies = TRUE)
install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r}
# install.packages( tidyverse , dependencies = TRUE)
# install.packages( jmv , dependencies = TRUE)
# install.packages( questionr , dependencies = TRUE)
# install.packages( Rcmdr , dependencies = TRUE)
# install.packages( summarytools )
\end{verbatim}

\begin{verbatim}
{r, error=FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE}
# require(tidyverse)
# require(jmv)
# require(questionr)
# library(summarytools)
# library(gganimate)
\end{verbatim}

\hypertarget{r-studio-ile-proje-oluux15fturma-4}{%
\chapter{R studio ile proje olu≈üturma}\label{r-studio-ile-proje-oluux15fturma-4}}

\url{https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects}

\includegraphics{http://www.rstudio.com/images/docs/projects_new.png}

\hypertarget{rstudio-ile-veri-yuxfckleme-5}{%
\chapter{RStudio ile veri y√ºkleme}\label{rstudio-ile-veri-yuxfckleme-5}}

\url{https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio}

\includegraphics{https://support.rstudio.com/hc/en-us/article_attachments/206277618/data-import-overview.gif}

\hypertarget{excel-5}{%
\section{Excel}\label{excel-5}}

\hypertarget{spss-5}{%
\section{SPSS}\label{spss-5}}

\hypertarget{csv-5}{%
\section{csv}\label{csv-5}}

\hypertarget{veriyi-guxf6ruxfcntuxfcleme-6}{%
\chapter{Veriyi g√∂r√ºnt√ºleme}\label{veriyi-guxf6ruxfcntuxfcleme-6}}

Spreadsheet users using \#rstats: where's the data?\#rstats users using spreadsheets: where's the code?

--- Leonard Kiefer (\citet{lenkiefer}) July 7, 2018

\begin{verbatim}
{r, results= markup }
# library(nycflights13)
# summary(flights)
\end{verbatim}

\begin{verbatim}
View(data)
\end{verbatim}

\begin{verbatim}
data
\end{verbatim}

\begin{verbatim}
head
\end{verbatim}

\begin{verbatim}
tail
\end{verbatim}

\begin{verbatim}
glimpse
\end{verbatim}

\begin{verbatim}
str
\end{verbatim}

\begin{verbatim}
skimr::skim()
\end{verbatim}

\hypertarget{veriyi-deux11fiux15ftirme-5}{%
\chapter{Veriyi deƒüi≈ütirme}\label{veriyi-deux11fiux15ftirme-5}}

\hypertarget{veriyi-kod-ile-deux11fiux15ftirelim-5}{%
\section{Veriyi kod ile deƒüi≈ütirelim}\label{veriyi-kod-ile-deux11fiux15ftirelim-5}}

\hypertarget{veriyi-eklentilerle-deux11fiux15ftirme-5}{%
\section{Veriyi eklentilerle deƒüi≈ütirme}\label{veriyi-eklentilerle-deux11fiux15ftirme-5}}

\includegraphics{figures/change_data.png}

\hypertarget{rstudio-aracux131lux131ux11fux131yla-recode-5}{%
\section{RStudio aracƒ±lƒ±ƒüƒ±yla recode}\label{rstudio-aracux131lux131ux11fux131yla-recode-5}}

\emph{questionr} paketi kullanƒ±lacak

\includegraphics{figures/level_recode.png}

\url{https://juba.github.io/questionr/articles/recoding_addins.html}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_1.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_2.png}

\includegraphics{https://raw.githubusercontent.com/juba/questionr/master/resources/screenshots/irec_3.png}

\hypertarget{basit-tanux131mlayux131cux131-istatistikler-5}{%
\chapter{Basit tanƒ±mlayƒ±cƒ± istatistikler}\label{basit-tanux131mlayux131cux131-istatistikler-5}}

\begin{verbatim}
summary()
\end{verbatim}

\begin{verbatim}
mean
\end{verbatim}

\begin{verbatim}
median
\end{verbatim}

\begin{verbatim}
min
\end{verbatim}

\begin{verbatim}
max
\end{verbatim}

\begin{verbatim}
sd
\end{verbatim}

\begin{verbatim}
table()
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include = TRUE}
library(readr)
irisdata <- read_csv( data/iris.csv )

jmv::descriptives(
    data = irisdata,
    vars =  Sepal.Length ,
    splitBy =  Species ,
    freq = TRUE,
    hist = TRUE,
    dens = TRUE,
    bar = TRUE,
    box = TRUE,
    violin = TRUE,
    dot = TRUE,
    mode = TRUE,
    sum = TRUE,
    sd = TRUE,
    variance = TRUE,
    range = TRUE,
    se = TRUE,
    skew = TRUE,
    kurt = TRUE,
    quart = TRUE,
    pcEqGr = TRUE)
\end{verbatim}

\begin{verbatim}
{r, echo=TRUE, include=FALSE}
# install.packages( scatr )

scatr::scat(
    data = irisdata,
    x =  Sepal.Length ,
    y =  Sepal.Width ,
    group =  Species ,
    marg =  dens ,
    line =  linear ,
    se = TRUE)
\end{verbatim}

\hypertarget{summarytools-5}{%
\section{summarytools}\label{summarytools-5}}

\url{https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
library(summarytools)
summarytools::freq(iris$Species, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
summarytools::descr(iris, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(dfSummary(iris))
\end{verbatim}

\includegraphics{figures/dfsummary.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}

# First save the results

iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:

view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
# view(iris_stats_by_species)
\end{verbatim}

\includegraphics{figures/DescriptiveStatistics.png}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))

view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)

# view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\begin{verbatim}
{r, include=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
what.is(iris)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

\hypertarget{skimr-5}{%
\section{skimr}\label{skimr-5}}

\begin{verbatim}
library(skimr)
skim(df)
\end{verbatim}

\hypertarget{dataexplorer-7}{%
\section{DataExplorer}\label{dataexplorer-7}}

\begin{verbatim}
library(DataExplorer)
DataExplorer::create_report(df)
\end{verbatim}

\href{https://www.littlemissdata.com/blog/simple-eda}{\includegraphics{https://static1.squarespace.com/static/58eef8846a4963e429687a4d/t/5bdfc2fb4d7a9c04ee50b7aa/1541391160702/dataExplorerGifLg.gif?format=1500w}}

\hypertarget{grafikler-6}{%
\section{Grafikler}\label{grafikler-6}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(ggplot2)
# library(mosaic)
# mPlot(irisdata)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

\begin{verbatim}
descr(tobacco, style = 'rmarkdown')

print(descr(tobacco), method = 'render', table.classes = 'st-small')

dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)

print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Here, building up a \#ggplot2 as slowly as possible, \#rstats. Incremental adjustments. \#rstatsteachingideas pic.twitter.com/nUulQl8bPh

--- Gina Reynolds (\citet{EvaMaeRey}) August 13, 2018

\href{https://github.com/dreamRs/esquisse}{\includegraphics{https://raw.githubusercontent.com/dreamRs/esquisse/master/man/figures/esquisse.gif}}

Dreaming of a fancy \#Rstats \#ggplot \#dataviz but still scared of typing \#code? \citet{_pvictorr} esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv

--- Radoslaw Panczak (\citet{RPanczak}) October 2, 2018

\hypertarget{rcmdr-5}{%
\chapter{Rcmdr}\label{rcmdr-5}}

\begin{verbatim}
library(Rcmdr)

Rcmdr::Commander()
\end{verbatim}

\begin{itemize}
\tightlist
\item
  A Comparative Review of the R Commander GUI for R
\end{itemize}

\url{http://r4stats.com/articles/software-reviews/r-commander/}

\hypertarget{jamovi-7}{%
\chapter{jamovi}\label{jamovi-7}}

\url{https://www.jamovi.org/}

\begin{figure}
\centering
\includegraphics{https://www.jamovi.org/}
\caption{\includegraphics{https://www.jamovi.org/assets/main-screenshot.png}}
\end{figure}

\url{https://blog.jamovi.org/2018/07/30/rj.html}

\begin{figure}
\centering
\includegraphics{https://blog.jamovi.org/2018/07/30/rj.html}
\caption{\includegraphics{https://blog.jamovi.org/assets/images/rj.png}}
\end{figure}

\hypertarget{sonraki-konular-6}{%
\chapter{Sonraki Konular}\label{sonraki-konular-6}}

\begin{itemize}
\tightlist
\item
  RStudio ile GitHub
\item
  Hipotez testleri
\item
  R Markdown ve R Notebook ile tekrarlanabilir rapor
\end{itemize}

output:
rmarkdown::html\_vignette:
css:
- !expr system.file( rmarkdown/templates/html\_vignette/resources/vignette.css , package = rmarkdown )
vignette: \textgreater{}
\%\VignetteIndexEntry{Recommendations for Rmarkdown}
\%\VignetteEngine{knitr::rmarkdown}
\%\VignetteEncoding{UTF-8}

\begin{verbatim}
{r summarytool options 1, include=FALSE}
library(knitr)
opts_chunk$set(comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis')
\end{verbatim}

\begin{verbatim}
{r summarytool options 2, echo=TRUE}
library(summarytools)
st_css()
\end{verbatim}

\begin{verbatim}
{r summarytool options 3}
st_options(bootstrap.css     = FALSE,       # Already part of the theme so no need for it
           plain.ascii       = FALSE,       # One of the essential settings
           style             =  rmarkdown , # Idem.
           dfSummary.silent  = TRUE,        # Suppresses messages about temporary files
           footnote          = NA,          # Keeping the results minimalistic
           subtitle.emphasis = FALSE)       # For the vignette theme, this gives
                                            # much better results. Your mileage may vary.
\end{verbatim}

\begin{verbatim}
{r summarytools freq Rmarkdown Style}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering}{%
\section{HTML Rendering}\label{html-rendering}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

If you find the table too large, you can use \texttt{table.classes\ =\ \textquotesingle{}st-small\textquotesingle{}} - an
example is provided further below.

--

Back to top

\hypertarget{rmarkdown-style}{%
\section{Rmarkdown Style}\label{rmarkdown-style}}

Tables with heading spanning over 2 rows are not fully supported in markdown
(yet), but the result is getting close to acceptable. This, however, is not
true for all themes. That's why the rendering method is preferred.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering-1}{%
\section{HTML Rendering}\label{html-rendering-1}}

For best results, use this method.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

--

Back to top

\hypertarget{descr2}{%
\chapter{descr() 2}\label{descr2}}

\texttt{descr()} is also best used with \texttt{style\ =\ \textquotesingle{}rmarkdown\textquotesingle{}}, and HTML rendering is
also supported.

\hypertarget{rmarkdown-style-1}{%
\section{Rmarkdown Style}\label{rmarkdown-style-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
descr(tobacco, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering-2}{%
\section{HTML Rendering}\label{html-rendering-2}}

We'll use table.classes = `st-small' to show how it affects the table's size
(compare to the \texttt{freq()} table rendered earlier).

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(descr(tobacco), method = 'render', table.classes = 'st-small')
\end{verbatim}

--

Back to top

\hypertarget{dfsummary1}{%
\chapter{dfSummary() 1}\label{dfsummary1}}

\hypertarget{grid-style}{%
\section{Grid Style}\label{grid-style}}

This style gives good results, and since v0.9, the graphs are shown as true
images. Don't forget to specify \texttt{plain.ascii\ =\ FALSE} (or set it as a global
option with \texttt{st\_options(plain.ascii\ =\ FALSE)}), or you won't get good results.

\begin{verbatim}
{r , eval=FALSE}
dfSummary(tobacco, style = 'grid', graph.magnif = 0.75, tmp.img.dir =  /tmp )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

\hypertarget{regression-1}{%
\chapter{Regression}\label{regression-1}}

\begin{itemize}
\tightlist
\item
  Logistic Regression in R Tutorial
\end{itemize}

\url{https://www}..com/community/tutorials/logistic-regression-R

\hypertarget{reprex}{%
\chapter{reprex}\label{reprex}}

author: Serdar Balcƒ±, MD, Pathologist
date: 21 09 2018
output: html\_document

\url{https://www.youtube.com/watch?v=MmTPhGQWPUo}

\url{https://reprex.tidyverse.org/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( reprex )
# library(reprex)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(y <-}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\CommentTok{#> [1] 1 2 3 4}
\KeywordTok{mean}\NormalTok{(y)}
\CommentTok{#> [1] 2.5}
\end{Highlighting}
\end{Shaded}

Created on 2018-09-21 by the \href{https://reprex.tidyverse.org}{reprex package} (v0.2.1)

\hypertarget{reproducible-research-1}{%
\chapter{Reproducible Research}\label{reproducible-research-1}}

\begin{itemize}
\tightlist
\item
  karthik/binder-test
\end{itemize}

Example repo for testing holepunch

\url{https://github.com/karthik/binder-test}

\begin{itemize}
\tightlist
\item
  Hole punch
\end{itemize}

\url{https://karthik.github.io/holepunch/}

\begin{itemize}
\tightlist
\item
  How to set up a My Binder for your R project
\end{itemize}

rstudio2019/binder-notes.md

\url{https://github.com/karthik/rstudio2019/blob/master/binder-notes.md}

\begin{itemize}
\tightlist
\item
  reproducibility guidelines
\end{itemize}

\url{https://kbroman.org/blog/2019/04/01/reproducibility-guidelines/}

\begin{itemize}
\tightlist
\item
  Disease risk modelling and visualization using R
\end{itemize}

\url{http://manio.org/2015/06/22/my-approach-to-reproducible-research.html}

\begin{itemize}
\tightlist
\item
  initial steps toward reproducible research
\end{itemize}

\url{https://kbroman.org/steps2rr/}

\begin{itemize}
\tightlist
\item
  Comments on reproducibility
\end{itemize}

\url{https://kbroman.org/knitr_knutshell/pages/reproducible.html}

\begin{itemize}
\tightlist
\item
  Reproducible science in R
\end{itemize}

\url{https://grunwaldlab.github.io/Reproducible-science-in-R/index.html}

\begin{itemize}
\tightlist
\item
  The Practice of Reproducible Research Case Studies and Lessons from the Data-Intensive Sciences
\end{itemize}

\url{https://www.practicereproducibleresearch.org/}

\begin{itemize}
\tightlist
\item
  papaja
\end{itemize}

papaja (Preparing APA Journal Articles) is an R package that provides document formats and helper functions to produce complete APA manscripts from RMarkdown-files (PDF and Word documents).

\url{https://crsh.github.io/papaja/}

\begin{itemize}
\tightlist
\item
  Stencila
\end{itemize}

An open source office suite for reproducible research

\url{http://stenci.la/}

\begin{itemize}
\tightlist
\item
  redoc - reversible R Markdown/MS Word documents.
\end{itemize}

\url{https://noamross.github.io/redoc/}

\begin{verbatim}

output:
  redoc::rdocx_reversible:
    keep_md: TRUE
    highlight_outputs: TRUE
\end{verbatim}

\begin{verbatim}
redoc::undoc( reversible2.docx )
redoc::undoc(file.choose())
\end{verbatim}

\begin{verbatim}
redoc::redoc_extract_rmd( reversible.docx )
\end{verbatim}

\hypertarget{docker-1}{%
\chapter{docker}\label{docker-1}}

\begin{itemize}
\tightlist
\item
  An Introduction to Docker for R Users
\end{itemize}

\url{https://colinfay.me/docker-r-reproducibility/}

\hypertarget{naming-files}{%
\chapter{Naming Files}\label{naming-files}}

\begin{itemize}
\tightlist
\item
  How to name files\\
  \url{https://speakerdeck.com/jennybc/how-to-name-files}
\end{itemize}

\hypertarget{example-articles}{%
\chapter{Example Articles}\label{example-articles}}

\begin{itemize}
\tightlist
\item
  Increasing the Transparency of Research Papers withExplorable Multiverse Analyses
\end{itemize}

\url{https://hal.inria.fr/hal-01976951/document}

\begin{itemize}
\tightlist
\item
  Replication Study: Transcriptional amplification in tumor cells with elevated c-Myc
\end{itemize}

\url{https://repro.elifesciences.org/example.html}

\begin{itemize}
\tightlist
\item
  Introducing eLife's first computationally reproducible article
\end{itemize}

\url{https://elifesciences.org/labs/ad58f08d/introducing-elife-s-first-computationally-reproducible-article}

\begin{itemize}
\tightlist
\item
  Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis
\end{itemize}

\url{https://explorablemultiverse.github.io/examples/frequentist/}

\begin{itemize}
\tightlist
\item
  R Online
\end{itemize}

Try R
Run a piece of code against a specific version of R, from 3.6.0 to 3.1.0.

\url{https://srv.colinfay.me:1001/\#about}

\url{https://github.com/ColinFay/ronline}

\begin{verbatim}
Sys.setenv(
  DSN =  database_name ,
  UID =  User ID ,
  PASS =  Password 
)

db <- DBI::dbConnect(
  drv = odbc::odbc(),
  dsn = Sys.getenv( DSN ),
  uid = Sys.getenv( UID ),
  pwd = Sys.getenv( PASS )
)
\end{verbatim}

\hypertarget{r-in-pathology-research}{%
\chapter{R in Pathology Research}\label{r-in-pathology-research}}

\begin{itemize}
\tightlist
\item
  Progesterone Receptor Status Predicts Response to Progestin Therapy in Endometriosis
\end{itemize}

\url{https://www.ncbi.nlm.nih.gov/pubmed/30357380}

irr: Various Coefficients of Interrater Reliability and Agreement

\url{https://cran.r-project.org/web/packages/irr/index.html}

\hypertarget{r-notebook-4}{%
\chapter{R Notebook}\label{r-notebook-4}}

library(RISmed)
library(ggplot2)

query \textless- (exome OR whole OR deep OR high-throughput OR (next AND generation) OR (massively AND parallel)) AND sequencing

ngs\_search \textless- EUtilsSummary(query, type= esearch ,db = pubmed ,mindate=1980, maxdate=2013, retmax=30000)
QueryCount(ngs\_search)
ngs\_records \textless- EUtilsGet(ngs\_search)
years \textless- Year(ngs\_records)
ngs\_pubs\_count \textless- as.data.frame(table(years))

total \textless- NULL
for (i in 1980:2013)\{
peryear \textless- EUtilsSummary( , type= esearch , db= pubmed , mindate=i, maxdate=i)
total{[}i{]} \textless- QueryCount(peryear)
\}
year \textless- 1980:2013
total\_pubs\_count\textless- as.data.frame(cbind(year,total{[}year{]}))
names(total\_pubs\_count) \textless- c( year , Total\_publications )
names(ngs\_pubs\_count) \textless- c( year , NGS\_publications )
pubs\_year \textless- merge(ngs\_pubs\_count,total\_pubs\_count,by= year )
pubs\_year\(NGS_publications_normalized <- pubs_year\)NGS\_publications *100000 / pubs\_year\$Total\_publications

write.table(pubs\_year, NGS\_publications\_per\_year.txt ,quote=F,sep= \t ,row.names=F)

journal \textless- MedlineTA(ngs\_records)
ngs\_journal\_count \textless- as.data.frame(table(journal))
ngs\_journal\_count\_top25 \textless- ngs\_journal\_count{[}order(-ngs\_journal\_count{[},2{]}),{]}{[}1:25,{]}

journal\_names \textless- paste(ngs\_journal\_count\_top25\$journal, {[}jo{]} ,sep= )

total\_journal \textless- NULL
for (i in journal\_names)\{
perjournal \textless- EUtilsSummary(i, type=`esearch', db=`pubmed',mindate=1980, maxdate=2013)
total\_journal{[}i{]} \textless- QueryCount(perjournal)
\}

journal\_ngs\_total \textless- cbind(ngs\_journal\_count\_top25,total\_journal)
names(journal\_ngs\_total) \textless- c( journal , NGS\_publications , Total\_publications )
journal\_ngs\_total\(NGS_publications_normalized <- journal_ngs_total\)NGS\_publications / journal\_ngs\_total\$Total\_publications

write.table(journal\_ngs\_total, NGS\_publications\_per\_journal.txt ,quote=F,sep= \t ,row.names=F)

pubs\_per\_year \textless- read.table( NGS\_publications\_per\_year.txt ,header = T,sep= \t )
pubs\_per\_journal \textless- read.table( NGS\_publications\_per\_journal.txt ,header = T,sep= \t )

ggplot(pubs\_per\_year,aes(year, NGS\_publications\_normalized)) + geom\_line (colour= blue ,size=2) +
xlab( Year ) +
ylab( NGS/100000 articles )+
ggtitle( NGS PubMed articles )

ggplot(pubs\_per\_journal,aes(journal, NGS\_publications,fill=journal)) + geom\_bar(stat= identity )+
coord\_flip()+
theme(legend.position= none )

ggplot(pubs\_per\_journal ,aes(journal, NGS\_publications\_normalized,fill=journal)) + geom\_bar(stat= identity )+
coord\_flip()+
theme(legend.position= none )

\hypertarget{creating-websites-in-r-1}{%
\chapter{Creating websites in R}\label{creating-websites-in-r-1}}

author: Emily C. Zabor
output:
html\_document:
toc: TRUE
toc\_float: TRUE

\url{http://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html}

This tutorial provides an introduction to creating websites using R, R Markdown and GitHub pages.

This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center Department of Epidemiology and Biostatistics R User Group meeting on January 23, 2018.

The current version was updated and presented at the R Ladies NYC Meetup on February 15, 2018.

\hypertarget{types-of-websites}{%
\section{Types of websites}\label{types-of-websites}}

The main types of websites you may want to create include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Personal websites
\item
  Package websites
\item
  Project websites
\item
  Blogs
\end{enumerate}

\hypertarget{r-markdown-website-basics}{%
\section{R Markdown website basics}\label{r-markdown-website-basics}}

The minimum requirements for an R Markdown website are:

\begin{itemize}
\tightlist
\item
  \texttt{index.Rmd}: contains the content for the website homepage
\item
  \texttt{\_site.yml}: contains metadata for the website
\end{itemize}

A basic example of a \texttt{\_site.yml} file for a website with two pages:

\begin{verbatim}
{r eval = FALSE}
name:  my-website 
navbar:
  # My Website 
  left:
    - text:  Home 
      href: index.html
    - text:  About 
      href: about.html
\end{verbatim}

And a basic \texttt{index.Rmd} to create the Home page:

\begin{verbatim}
{r eval = FALSE}

# My Website 

    
Hello, Website! Welcome to the world.
\end{verbatim}

You can find an overview of R Markdown website basics \href{http://rmarkdown.rstudio.com/rmarkdown_websites.html}{here}.

\hypertarget{github-2}{%
\section{GitHub}\label{github-2}}

This tutorial will focus on hosting websites through GitHub pages. Hosting websites on GitHub pages is free.

If you don't have a GitHub account already, sign up for one at \url{https://github.com/join?source=header-home} with username YOUR\_GH\_NAME. I'll be referring to this username, YOUR\_GH\_NAME, as your GitHub username throughout this tutorial.

There are other free sites for website hosting, and another popular choice is \href{https://www.netlify.com/}{Netlify}.

\hypertarget{personal-websites}{%
\section{Personal websites}\label{personal-websites}}

An example from the homepage of \href{http://www.emilyzabor.com/}{my personal website}:

\textless img src= img/personal.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

There are two main steps for creating a personal website that will be hosted on GitHub:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  GitHub setup
\item
  Local setup
\end{enumerate}

\hypertarget{github-setup}{%
\subsection{GitHub setup}\label{github-setup}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a GitHub repository ( repo ) named YOUR\_GH\_NAME.github.io, where YOUR\_GH\_NAME is your GitHub username.
\item
  Initialize it with a README

  \begin{itemize}
  \tightlist
  \item
    For the GitHub inexperienced: this can ease the process of cloning the repo by initializing the remote repo with a master branch
  \end{itemize}
\end{enumerate}

\hypertarget{local-setup}{%
\subsection{Local setup}\label{local-setup}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clone this remote repository to a local directory with the same name, YOUR\_GH\_NAME.github.io
\item
  Add an R Project to this directory
\item
  Create a \texttt{\_site.yml} and \texttt{index.Rmd} file in your new directory
\end{enumerate}

\hypertarget{why-do-i-need-an-r-project}{%
\subsection{Why do I need an R Project?}\label{why-do-i-need-an-r-project}}

The R Project is useful because RStudio will recognize your project as a website, and provide appropriate build tools.

Note: After creating the R Project and initial files, you may need to close the project and reopen it before R will recognize it as a website and show the appropriate build tools.

\hypertarget{create-content}{%
\subsection{Create content}\label{create-content}}

Edit the \texttt{\_site.yml} file to change the metadata, layout, and theme of your website. Preview Jekyll themes \href{http://jekyllthemes.org/}{here} and play around with different options. Themes are easy to change even after you have added content.

For example, the \texttt{\_site.yml} for my personal website looks like this:

\begin{verbatim}
{r eval = FALSE}
name:  Emily C. Zabor 
output_dir:  . 
navbar:
  # Emily C. Zabor 
  left:
    - text:  Writing 
      href: research.html
    - text:  Speaking 
      href: talks.html
    - text:  Programming 
      href: software.html
    - text:  Teaching 
      href: teaching.html
  right:
    - icon: fa-envelope fa-lg
      href: contact.html
    - icon: fa-github fa-lg
      href: http://github.com/zabore
    - icon: fa-twitter fa-lg
      href: https://twitter.com/zabormetrics
    - icon: fa-linkedin fa-lg
      href: https://www.linkedin.com/in/emily-zabor-59b902b7/
output:
  html_document:
    theme: paper
    css: 'styles.css'
\end{verbatim}

Edit and create \texttt{.Rmd} files that contain your website content, which will produce the html pages of your website when you knit them.

For example, the \texttt{index.Rmd} file for my personal website homepage looks like this:

\begin{verbatim}
{r eval = FALSE}



<link rel= stylesheet  href= styles.css  type= text/css >

<img src= images/emily_2.jpg  style= width:25%; border:10px solid; margin-right: 20px  align= left >

I like to analyze data to answer research questions and test hypotheses. Currently I investigate questions related to breast cancer through my work as a Research Biostatistician at [Memorial Sloan Kettering Cancer Center](https://www.mskcc.org/departments/epidemiology-biostatistics) in the department of Epidemiology & Biostatistics. 

I graduated from the [University of Minnesota](http://www.sph.umn.edu/academics/divisions/biostatistics/) with a MS in biostatistics in 2010. In 2012 I began working toward my DrPH in biostatistics as a part-time student at [Columbia University](https://www.mailman.columbia.edu/become-student/departments/biostatistics), where I am investigating statistical methods for the study of etiologic heterogeneity in epidemiologic studies under the advisement of [Dr. Shuang Wang](https://www.mailman.columbia.edu/people/our-faculty/sw2206) at Columbia University and [Dr. Colin Begg](https://www.mskcc.org/profile/colin-begg) at Memorial Sloan Kettering Cancer Center. I expect to graduate by the end of 2018.

I am a well-known R enthusiast, including serving on the board and being an active member of [R Ladies NYC](http://www.rladiesnyc.org/). 

My full CV is available [here](files/Zabor_CV_2017_Q4.pdf).
\end{verbatim}

Once you have your content written and the layout setup, on the Build tab in RStudio, select Build Website :

\textless img src= img/build.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Now your local directory contains all of the files needed for your website:

\textless img src= img/directory.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{deploy-website}{%
\subsection{Deploy website}\label{deploy-website}}

Basic approach:

\begin{itemize}
\tightlist
\item
  Select Upload files from the main page of your GitHub repo:
\end{itemize}

\textless img src= img/uploadbutton.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\tightlist
\item
  And simply drag or select the files from the local repository:
\end{itemize}

\textless img src= img/upload.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Advanced approach (recommended):

\begin{itemize}
\tightlist
\item
  use Git from the shell, from a Git client, or from within RStudio (another great reason to use an R Project!)
\end{itemize}

\textless img src= img/rstudiogit.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\tightlist
\item
  But this is not a Git/GitHub tutorial. If you want to learn more about Git/GitHub, which I encourage you to do, here's a great resource to get you started: \url{http://happygitwithr.com/}
\end{itemize}

\hypertarget{custom-domains}{%
\subsection{Custom domains}\label{custom-domains}}

The default is for your site to be hosted at \url{http://YOUR_GH_NAME.github.io}, but you can add a custom domain name as well. There are two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In your GitHub repository YOUR\_GH\_NAME.github.io, go to Settings \textgreater{} GitHub pages. Type your domain name in the box under Custom domain and hit Save.
\end{enumerate}

\textless img src= img/domain.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Add a CNAME file to your GitHub repsitory YOUR\_GH\_NAME.github.io.
\end{enumerate}

It will appear like this in your repository:

\textless img src= img/cname1.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

And inside the file you will simply have your domain name:

\textless img src= img/cname2.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{package-websites}{%
\section{Package websites}\label{package-websites}}

An example from the \href{http://www.emilyzabor.com/ezfun/}{website} for my package \texttt{ezfun}:

\textless img src= img/package.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Use Hadley Wickham's great package \texttt{pkgdown} to easily build a website from your package that is hosted on GitHub. Details of \texttt{pkgdown} can be found on \href{http://pkgdown.r-lib.org/}{the pkgdown website}, which was also created using \texttt{pkgdown}.

This assumes you already have an R package with a local directory and a GitHub repository.

From within your package directory run:

\begin{verbatim}
{r eval = FALSE}
devtools::install_github( hadley/pkgdown )
pkgdown::build_site()
\end{verbatim}

\begin{itemize}
\item
  This will add a folder called \texttt{docs} to the local directory for your package
\item
  Upload/push these changes to the GitHub repository for your package
\item
  In the GitHub repository for your package go to Settings \textgreater{} GitHub pages. Select master branch/docs folder as the source and hit Save
\end{itemize}

\textless img src= img/ghsource.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\item
  The page will be added as to your personal website as YOUR\_GH\_NAME.github.io/repo\_name

  \begin{itemize}
  \tightlist
  \item
    The Home page of the site will be pulled from the README file on your package repository
  \item
    The Reference page of the site lists the included functions with their description
  \item
    Each function can be clicked through to see the help page, if any
  \item
    Would also build pages for any available vignettes
  \end{itemize}
\end{itemize}

And you're done, it's that easy.

\hypertarget{project-websites}{%
\section{Project websites}\label{project-websites}}

You can create a website for a non-package repository as well. For example, I have \href{http://www.emilyzabor.com/tutorials/}{a page} on my website linking to the repository in which this tutorial is stored.

\textless img src= img/project.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{local-setup-1}{%
\subsection{Local setup}\label{local-setup-1}}

From within the local directory of the project of interest:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a \texttt{\_site.yml} and \texttt{index.Rmd} file in your new directory
\item
  Edit these files to create content and manage layout, as before for personal websites
\end{enumerate}

\hypertarget{github-setup-1}{%
\subsection{GitHub setup}\label{github-setup-1}}

\begin{itemize}
\item
  Upload/push these new files to the GitHub repository for your project
\item
  Enable GitHub pages for the repository by going to Settings \textgreater{} GitHub Pages, where you'll select the master branch folder and hit Save
\end{itemize}

\textless img src= img/ghpages.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{blogs}{%
\section{Blogs}\label{blogs}}

R Markdown websites are simple to create and deploy, but can become cumbersome if you make frequent updates or additions to the website, as in the case of a blog. Luckily, the R package \texttt{blogdown} exists just for this purpose. \texttt{blogdown} is an R package that allows you to create static websites, which means that the deployed version of the website only consists of JavaScript, HTML, CSS, and images. Luckily the \texttt{blogdown} package makes it so that you don't have to know any of those things to create a beautiful website for your blog, powered by Hugo.

For a complete resource on using the \texttt{blogdown} website, checkout this \href{https://bookdown.org/yihui/blogdown/}{short blogdown book}.

I don't have a personal blog, so let's look at the website I built to feature the events and blog of the \href{http://www.rladiesnyc.org/}{R-Ladies NYC} organization as an example.

\textless img src= img/rladiesnychome.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{setup}{%
\subsection{Setup}\label{setup}}

The first three steps are similar to those from creating a basic R Markdown website:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a GitHub repository named YOUR\_GH\_NAME.github.io, where YOUR\_GH\_NAME is your GitHub username, initialized with a README file
\item
  Clone the GitHub repo to a local directory with the same name
\item
  Add an R Project to the local directoroy
\end{enumerate}

Next we get started with \texttt{blogdown}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Install \texttt{blogdown} and Hugo
\end{enumerate}

\begin{verbatim}
{r eval = FALSE}
install.packages( blogdown )
blogdown::install_hugo()
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  Choose a \href{https://themes.gohugo.io/}{theme} and find the link to the theme's GitHub repository. In this case themes aren't quite as easy to change as with basic R Markdown websites, so choose carefully.
\item
  Within your project session, generate a new site. The option \texttt{theme\_example\ =\ TRUE} will obtain the files for an example site that you can then customize for your needs. Below user/repo refers to the GitHub username and GitHub repository for your selected theme.
\end{enumerate}

\begin{verbatim}
{r eval = FALSE}
blogdown::new_site(theme =  user/repo , theme_example = TRUE)
\end{verbatim}

This will generate all of the file structure for your new blog.

\textless img src= img/blogdirectory.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

After this is complete, you should quit and then reopen the project. Upon reopening, RStudio will recognize the project as a website.

\hypertarget{customizing-the-appearance}{%
\subsection{Customizing the appearance}\label{customizing-the-appearance}}

Make changes to the \texttt{config.toml} file (equivalent to the \texttt{\_site.yml} from basic R Markdown websites) to change the layout and appearance of your website. The available features of the \texttt{config.toml} file will differ depending on your theme, and most theme examples come with a well annotated \texttt{config.toml} that you can use as a template.

Once you have customized your website features, click on the RStudio addin Serve Site to preview the site locally.

\textless img src= img/servesite.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{writing-a-new-blog-post}{%
\subsection{Writing a new blog post}\label{writing-a-new-blog-post}}

There are several ways to create a new post for your site, but the easiest is using the RStudio addin New Post :

\textless img src= img/newpost.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

This opens a pop-up where you can enter the meta-data for a new post:

\textless img src= img/newpostbox.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

In addition to setting the Title, Author and Date of the post, you can additionally create categories, which will organize your posts in folders, and can add tags to posts, which can make them searchable within your site's content. Be aware that the functioning of these features will vary by theme. Dates can be in the future to allow future release of a post.

Notice at the bottom that you can select whether to use a regular markdown (\texttt{.md}) or R markdown (\texttt{.Rmd}) file. \texttt{.Rmd} files will have to be rendered before generating html pages so it is best practice to limit their use to cases where R code is included.

A file name and slug will automatically be generated based on the other metadata. The slug is a URL friendly title of your post.

\textless img src= img/newpostboxfilled.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{hosting}{%
\subsection{Hosting}\label{hosting}}

A \texttt{blogdown} site is a bit more cumbersome both to build and to host on GitHub as compared to a regular R Markdown website, and as compared to what I described above.

\emph{Problem 1}: Because it is a static site, upon building, the files needed to generate the site online are automatically created in a separate subdirectory called \texttt{public} within your local directory. However this will cause problems with GitHub hosting since the files to host need to be in the local YOUR\_GH\_NAME.github.io directory

My solution:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Maintain separate directories for the source files (I named this directory source ) and for the static files (the directory YOUR\_GH\_NAME.github.io) that will be generated on build. The source folder is where your R project and \texttt{config.toml} files will live.
\end{enumerate}

\textless img src= img/blogfolders.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In your \texttt{config.toml} use the option \texttt{publishDir\ =} to customize \texttt{blogdown} to publish to the YOUR\_GH\_NAME.github.io folder, rather than to the default local location
\end{enumerate}

\textless img src= img/publishdir.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\emph{Problem 2}: GitHub defaults to using Jekyll with website content, and this needs to be disabled since \texttt{blogdown} sites are built with Hugo

To get around this, you need to include an empty file named \texttt{.nojekyll} in your GitHub repo YOUR\_GH\_NAME.github.io, prior to publishing.

\textless img src= img/nojekyll.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{additional-resources}{%
\section{Additional resources}\label{additional-resources}}

A compiled list of the additional resources/links presented throughout this tutorial:

\begin{itemize}
\tightlist
\item
  \url{http://rmarkdown.rstudio.com/rmarkdown_websites.html}: an overview of R Markdown website basics
\item
  \url{http://jekyllthemes.org/}: Jekyll themes for use with your R Markdown website
\item
  \url{http://happygitwithr.com/}: an introduction to Git/GitHub
\item
  \url{http://pkgdown.r-lib.org/}: Hadley Wickham's \texttt{pkgdown} website
\item
  \url{https://bookdown.org/yihui/blogdown/}: Yihui Xie's blogdown book
\item
  \url{https://themes.gohugo.io/}: Hugo themes for use with your \texttt{blogdown} website
\end{itemize}

\hypertarget{demo}{%
\section{Demo}\label{demo}}

\hypertarget{creating-websites-in-r-2}{%
\chapter{Creating websites in R}\label{creating-websites-in-r-2}}

author: Emily C. Zabor
output:
html\_document:
toc: TRUE
toc\_float: TRUE

This tutorial provides an introduction to creating websites using R, R Markdown and GitHub pages.

This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center Department of Epidemiology and Biostatistics R User Group meeting on January 23, 2018.

The current version was updated and presented at the R Ladies NYC Meetup on February 15, 2018.

\hypertarget{types-of-websites-1}{%
\section{Types of websites}\label{types-of-websites-1}}

The main types of websites you may want to create include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Personal websites
\item
  Package websites
\item
  Project websites
\item
  Blogs
\end{enumerate}

\hypertarget{r-markdown-website-basics-1}{%
\section{R Markdown website basics}\label{r-markdown-website-basics-1}}

The minimum requirements for an R Markdown website are:

\begin{itemize}
\tightlist
\item
  \texttt{index.Rmd}: contains the content for the website homepage
\item
  \texttt{\_site.yml}: contains metadata for the website
\end{itemize}

A basic example of a \texttt{\_site.yml} file for a website with two pages:

\begin{verbatim}
{r eval = FALSE}
name:  my-website 
navbar:
  # My Website 
  left:
    - text:  Home 
      href: index.html
    - text:  About 
      href: about.html
\end{verbatim}

And a basic \texttt{index.Rmd} to create the Home page:

\begin{verbatim}
{r eval = FALSE}

# My Website 

    
Hello, Website! Welcome to the world.
\end{verbatim}

You can find an overview of R Markdown website basics \href{http://rmarkdown.rstudio.com/rmarkdown_websites.html}{here}.

\hypertarget{github-3}{%
\section{GitHub}\label{github-3}}

This tutorial will focus on hosting websites through GitHub pages. Hosting websites on GitHub pages is free.

If you don't have a GitHub account already, sign up for one at \url{https://github.com/join?source=header-home} with username YOUR\_GH\_NAME. I'll be referring to this username, YOUR\_GH\_NAME, as your GitHub username throughout this tutorial.

There are other free sites for website hosting, and another popular choice is \href{https://www.netlify.com/}{Netlify}.

\hypertarget{personal-websites-1}{%
\section{Personal websites}\label{personal-websites-1}}

An example from the homepage of \href{http://www.emilyzabor.com/}{my personal website}:

\textless img src= img/personal.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

There are two main steps for creating a personal website that will be hosted on GitHub:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  GitHub setup
\item
  Local setup
\end{enumerate}

\hypertarget{github-setup-2}{%
\subsection{GitHub setup}\label{github-setup-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a GitHub repository ( repo ) named YOUR\_GH\_NAME.github.io, where YOUR\_GH\_NAME is your GitHub username.
\item
  Initialize it with a README

  \begin{itemize}
  \tightlist
  \item
    For the GitHub inexperienced: this can ease the process of cloning the repo by initializing the remote repo with a master branch
  \end{itemize}
\end{enumerate}

\hypertarget{local-setup-2}{%
\subsection{Local setup}\label{local-setup-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clone this remote repository to a local directory with the same name, YOUR\_GH\_NAME.github.io
\item
  Add an R Project to this directory
\item
  Create a \texttt{\_site.yml} and \texttt{index.Rmd} file in your new directory
\end{enumerate}

\hypertarget{why-do-i-need-an-r-project-1}{%
\subsection{Why do I need an R Project?}\label{why-do-i-need-an-r-project-1}}

The R Project is useful because RStudio will recognize your project as a website, and provide appropriate build tools.

Note: After creating the R Project and initial files, you may need to close the project and reopen it before R will recognize it as a website and show the appropriate build tools.

\hypertarget{create-content-1}{%
\subsection{Create content}\label{create-content-1}}

Edit the \texttt{\_site.yml} file to change the metadata, layout, and theme of your website. Preview Jekyll themes \href{http://jekyllthemes.org/}{here} and play around with different options. Themes are easy to change even after you have added content.

For example, the \texttt{\_site.yml} for my personal website looks like this:

\begin{verbatim}
{r eval = FALSE}
name:  Emily C. Zabor 
output_dir:  . 
navbar:
  # Emily C. Zabor 
  left:
    - text:  Writing 
      href: research.html
    - text:  Speaking 
      href: talks.html
    - text:  Programming 
      href: software.html
    - text:  Teaching 
      href: teaching.html
  right:
    - icon: fa-envelope fa-lg
      href: contact.html
    - icon: fa-github fa-lg
      href: http://github.com/zabore
    - icon: fa-twitter fa-lg
      href: https://twitter.com/zabormetrics
    - icon: fa-linkedin fa-lg
      href: https://www.linkedin.com/in/emily-zabor-59b902b7/
output:
  html_document:
    theme: paper
    css: 'styles.css'
\end{verbatim}

Edit and create \texttt{.Rmd} files that contain your website content, which will produce the html pages of your website when you knit them.

For example, the \texttt{index.Rmd} file for my personal website homepage looks like this:

\begin{verbatim}
{r eval = FALSE}



<link rel= stylesheet  href= styles.css  type= text/css >

<img src= images/emily_2.jpg  style= width:25%; border:10px solid; margin-right: 20px  align= left >

I like to analyze data to answer research questions and test hypotheses. Currently I investigate questions related to breast cancer through my work as a Research Biostatistician at [Memorial Sloan Kettering Cancer Center](https://www.mskcc.org/departments/epidemiology-biostatistics) in the department of Epidemiology & Biostatistics. 

I graduated from the [University of Minnesota](http://www.sph.umn.edu/academics/divisions/biostatistics/) with a MS in biostatistics in 2010. In 2012 I began working toward my DrPH in biostatistics as a part-time student at [Columbia University](https://www.mailman.columbia.edu/become-student/departments/biostatistics), where I am investigating statistical methods for the study of etiologic heterogeneity in epidemiologic studies under the advisement of [Dr. Shuang Wang](https://www.mailman.columbia.edu/people/our-faculty/sw2206) at Columbia University and [Dr. Colin Begg](https://www.mskcc.org/profile/colin-begg) at Memorial Sloan Kettering Cancer Center. I expect to graduate by the end of 2018.

I am a well-known R enthusiast, including serving on the board and being an active member of [R Ladies NYC](http://www.rladiesnyc.org/). 

My full CV is available [here](files/Zabor_CV_2017_Q4.pdf).
\end{verbatim}

Once you have your content written and the layout setup, on the Build tab in RStudio, select Build Website :

\textless img src= img/build.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Now your local directory contains all of the files needed for your website:

\textless img src= img/directory.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{deploy-website-1}{%
\subsection{Deploy website}\label{deploy-website-1}}

Basic approach:

\begin{itemize}
\tightlist
\item
  Select Upload files from the main page of your GitHub repo:
\end{itemize}

\textless img src= img/uploadbutton.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\tightlist
\item
  And simply drag or select the files from the local repository:
\end{itemize}

\textless img src= img/upload.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Advanced approach (recommended):

\begin{itemize}
\tightlist
\item
  use Git from the shell, from a Git client, or from within RStudio (another great reason to use an R Project!)
\end{itemize}

\textless img src= img/rstudiogit.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\tightlist
\item
  But this is not a Git/GitHub tutorial. If you want to learn more about Git/GitHub, which I encourage you to do, here's a great resource to get you started: \url{http://happygitwithr.com/}
\end{itemize}

\hypertarget{custom-domains-1}{%
\subsection{Custom domains}\label{custom-domains-1}}

The default is for your site to be hosted at \url{http://YOUR_GH_NAME.github.io}, but you can add a custom domain name as well. There are two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In your GitHub repository YOUR\_GH\_NAME.github.io, go to Settings \textgreater{} GitHub pages. Type your domain name in the box under Custom domain and hit Save.
\end{enumerate}

\textless img src= img/domain.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Add a CNAME file to your GitHub repsitory YOUR\_GH\_NAME.github.io.
\end{enumerate}

It will appear like this in your repository:

\textless img src= img/cname1.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

And inside the file you will simply have your domain name:

\textless img src= img/cname2.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{package-websites-1}{%
\section{Package websites}\label{package-websites-1}}

An example from the \href{http://www.emilyzabor.com/ezfun/}{website} for my package \texttt{ezfun}:

\textless img src= img/package.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

Use Hadley Wickham's great package \texttt{pkgdown} to easily build a website from your package that is hosted on GitHub. Details of \texttt{pkgdown} can be found on \href{http://pkgdown.r-lib.org/}{the pkgdown website}, which was also created using \texttt{pkgdown}.

This assumes you already have an R package with a local directory and a GitHub repository.

From within your package directory run:

\begin{verbatim}
{r eval = FALSE}
devtools::install_github( hadley/pkgdown )
pkgdown::build_site()
\end{verbatim}

\begin{itemize}
\item
  This will add a folder called \texttt{docs} to the local directory for your package
\item
  Upload/push these changes to the GitHub repository for your package
\item
  In the GitHub repository for your package go to Settings \textgreater{} GitHub pages. Select master branch/docs folder as the source and hit Save
\end{itemize}

\textless img src= img/ghsource.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{itemize}
\item
  The page will be added as to your personal website as YOUR\_GH\_NAME.github.io/repo\_name

  \begin{itemize}
  \tightlist
  \item
    The Home page of the site will be pulled from the README file on your package repository
  \item
    The Reference page of the site lists the included functions with their description
  \item
    Each function can be clicked through to see the help page, if any
  \item
    Would also build pages for any available vignettes
  \end{itemize}
\end{itemize}

And you're done, it's that easy.

\hypertarget{project-websites-1}{%
\section{Project websites}\label{project-websites-1}}

You can create a website for a non-package repository as well. For example, I have \href{http://www.emilyzabor.com/tutorials/}{a page} on my website linking to the repository in which this tutorial is stored.

\textless img src= img/project.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{local-setup-3}{%
\subsection{Local setup}\label{local-setup-3}}

From within the local directory of the project of interest:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a \texttt{\_site.yml} and \texttt{index.Rmd} file in your new directory
\item
  Edit these files to create content and manage layout, as before for personal websites
\end{enumerate}

\hypertarget{github-setup-3}{%
\subsection{GitHub setup}\label{github-setup-3}}

\begin{itemize}
\item
  Upload/push these new files to the GitHub repository for your project
\item
  Enable GitHub pages for the repository by going to Settings \textgreater{} GitHub Pages, where you'll select the master branch folder and hit Save
\end{itemize}

\textless img src= img/ghpages.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{blogs-1}{%
\section{Blogs}\label{blogs-1}}

R Markdown websites are simple to create and deploy, but can become cumbersome if you make frequent updates or additions to the website, as in the case of a blog. Luckily, the R package \texttt{blogdown} exists just for this purpose. \texttt{blogdown} is an R package that allows you to create static websites, which means that the deployed version of the website only consists of JavaScript, HTML, CSS, and images. Luckily the \texttt{blogdown} package makes it so that you don't have to know any of those things to create a beautiful website for your blog, powered by Hugo.

For a complete resource on using the \texttt{blogdown} website, checkout this \href{https://bookdown.org/yihui/blogdown/}{short blogdown book}.

I don't have a personal blog, so let's look at the website I built to feature the events and blog of the \href{http://www.rladiesnyc.org/}{R-Ladies NYC} organization as an example.

\textless img src= img/rladiesnychome.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{setup-1}{%
\subsection{Setup}\label{setup-1}}

The first three steps are similar to those from creating a basic R Markdown website:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a GitHub repository named YOUR\_GH\_NAME.github.io, where YOUR\_GH\_NAME is your GitHub username, initialized with a README file
\item
  Clone the GitHub repo to a local directory with the same name
\item
  Add an R Project to the local directoroy
\end{enumerate}

Next we get started with \texttt{blogdown}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Install \texttt{blogdown} and Hugo
\end{enumerate}

\begin{verbatim}
{r eval = FALSE}
install.packages( blogdown )
blogdown::install_hugo()
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  Choose a \href{https://themes.gohugo.io/}{theme} and find the link to the theme's GitHub repository. In this case themes aren't quite as easy to change as with basic R Markdown websites, so choose carefully.
\item
  Within your project session, generate a new site. The option \texttt{theme\_example\ =\ TRUE} will obtain the files for an example site that you can then customize for your needs. Below user/repo refers to the GitHub username and GitHub repository for your selected theme.
\end{enumerate}

\begin{verbatim}
{r eval = FALSE}
blogdown::new_site(theme =  user/repo , theme_example = TRUE)
\end{verbatim}

This will generate all of the file structure for your new blog.

\textless img src= img/blogdirectory.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

After this is complete, you should quit and then reopen the project. Upon reopening, RStudio will recognize the project as a website.

\hypertarget{customizing-the-appearance-1}{%
\subsection{Customizing the appearance}\label{customizing-the-appearance-1}}

Make changes to the \texttt{config.toml} file (equivalent to the \texttt{\_site.yml} from basic R Markdown websites) to change the layout and appearance of your website. The available features of the \texttt{config.toml} file will differ depending on your theme, and most theme examples come with a well annotated \texttt{config.toml} that you can use as a template.

Once you have customized your website features, click on the RStudio addin Serve Site to preview the site locally.

\textless img src= img/servesite.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{writing-a-new-blog-post-1}{%
\subsection{Writing a new blog post}\label{writing-a-new-blog-post-1}}

There are several ways to create a new post for your site, but the easiest is using the RStudio addin New Post :

\textless img src= img/newpost.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

This opens a pop-up where you can enter the meta-data for a new post:

\textless img src= img/newpostbox.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

In addition to setting the Title, Author and Date of the post, you can additionally create categories, which will organize your posts in folders, and can add tags to posts, which can make them searchable within your site's content. Be aware that the functioning of these features will vary by theme. Dates can be in the future to allow future release of a post.

Notice at the bottom that you can select whether to use a regular markdown (\texttt{.md}) or R markdown (\texttt{.Rmd}) file. \texttt{.Rmd} files will have to be rendered before generating html pages so it is best practice to limit their use to cases where R code is included.

A file name and slug will automatically be generated based on the other metadata. The slug is a URL friendly title of your post.

\textless img src= img/newpostboxfilled.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{hosting-1}{%
\subsection{Hosting}\label{hosting-1}}

A \texttt{blogdown} site is a bit more cumbersome both to build and to host on GitHub as compared to a regular R Markdown website, and as compared to what I described above.

\emph{Problem 1}: Because it is a static site, upon building, the files needed to generate the site online are automatically created in a separate subdirectory called \texttt{public} within your local directory. However this will cause problems with GitHub hosting since the files to host need to be in the local YOUR\_GH\_NAME.github.io directory

My solution:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Maintain separate directories for the source files (I named this directory source ) and for the static files (the directory YOUR\_GH\_NAME.github.io) that will be generated on build. The source folder is where your R project and \texttt{config.toml} files will live.
\end{enumerate}

\textless img src= img/blogfolders.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In your \texttt{config.toml} use the option \texttt{publishDir\ =} to customize \texttt{blogdown} to publish to the YOUR\_GH\_NAME.github.io folder, rather than to the default local location
\end{enumerate}

\textless img src= img/publishdir.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\emph{Problem 2}: GitHub defaults to using Jekyll with website content, and this needs to be disabled since \texttt{blogdown} sites are built with Hugo

To get around this, you need to include an empty file named \texttt{.nojekyll} in your GitHub repo YOUR\_GH\_NAME.github.io, prior to publishing.

\textless img src= img/nojekyll.png style= border: \#A9A9A9 1px solid; width:75\% \textgreater{}

\hypertarget{additional-resources-1}{%
\section{Additional resources}\label{additional-resources-1}}

A compiled list of the additional resources/links presented throughout this tutorial:

\begin{itemize}
\tightlist
\item
  \url{http://rmarkdown.rstudio.com/rmarkdown_websites.html}: an overview of R Markdown website basics
\item
  \url{http://jekyllthemes.org/}: Jekyll themes for use with your R Markdown website
\item
  \url{http://happygitwithr.com/}: an introduction to Git/GitHub
\item
  \url{http://pkgdown.r-lib.org/}: Hadley Wickham's \texttt{pkgdown} website
\item
  \url{https://bookdown.org/yihui/blogdown/}: Yihui Xie's blogdown book
\item
  \url{https://themes.gohugo.io/}: Hugo themes for use with your \texttt{blogdown} website
\end{itemize}

\hypertarget{demo-1}{%
\section{Demo}\label{demo-1}}

\hypertarget{roc}{%
\chapter{ROC}\label{roc}}

\hypertarget{tidyroc}{%
\chapter{tidyroc}\label{tidyroc}}

\url{https://github.com/dariyasydykova/tidyroc}

\hypertarget{section}{%
\chapter{}\label{section}}

\hypertarget{orcid-1}{%
\chapter{ORCID}\label{orcid-1}}

\begin{itemize}
\tightlist
\item
  Introduction to ORCID Researcher Identifiers in R with rorcid
\end{itemize}

\url{https://www.pauloldham.net/introduction-to-orcid-with-rorcid/}

\hypertarget{r-packages-used}{%
\chapter{R Packages Used}\label{r-packages-used}}

\hypertarget{r-package-development}{%
\chapter{R package development}\label{r-package-development}}

\begin{itemize}
\item
  Analyses as Packages\\
  \url{http://rmflight.github.io/posts/2014/07/analyses_as_packages.html}
\item
  Creating an analysis as a package and vignette
  \url{http://rmflight.github.io/posts/2014/07/vignetteAnalysis.html}
\item
  pkgdown\\
  \url{https://pkgdown.r-lib.org/index.html}
\item
  Writing an R package from scratch\\
  \url{https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/}
\item
  R packages\\
  \url{http://r-pkgs.had.co.nz/intro.html}~\\
  \url{https://r-pkgs.org}
\item
  devtools\\
  \url{https://github.com/r-lib/devtools}
\end{itemize}

\hypertarget{purrr}{%
\chapter{purrr}\label{purrr}}

\begin{itemize}
\tightlist
\item
  Learning Functional Programming \& purrr
\end{itemize}

\url{https://paulvanderlaken.com/2018/12/05/learning-functional-programming-purrr/}

\hypertarget{diagrammer}{%
\chapter{DiagrammeR}\label{diagrammer}}

\url{http://rich-iannone.github.io/DiagrammeR/}

\hypertarget{gggenes}{%
\chapter{gggenes}\label{gggenes}}

\url{https://cran.r-project.org/web/packages/gggenes/vignettes/introduction-to-gggenes.html}

\hypertarget{textminer}{%
\chapter{textmineR}\label{textminer}}

\url{https://cran.r-project.org/web/packages/textmineR/vignettes/a_start_here.html}

\url{https://cran.r-project.org/web/packages/textmineR/vignettes/b_document_clustering.html}

\url{https://cran.r-project.org/web/packages/textmineR/vignettes/c_topic_modeling.html}

\url{https://cran.r-project.org/web/packages/textmineR/vignettes/d_text_embeddings.html}

\url{https://cran.r-project.org/web/packages/textmineR/vignettes/e_doc_summarization.html}

\hypertarget{tidyshiny}{%
\chapter{tidyshiny}\label{tidyshiny}}

\url{https://github.com/MangoTheCat/tidyshiny/}

\hypertarget{rio-1}{%
\chapter{rio}\label{rio-1}}

\url{https://cran.r-project.org/web/packages/rio/README.html}

install.packages( rio )
install\_formats()

\hypertarget{addinplots}{%
\chapter{addinplots}\label{addinplots}}

RStudio Addins for plotting

\url{https://github.com/homerhanumat/addinplots/}

\hypertarget{citr}{%
\chapter{citr}\label{citr}}

citr: RStudio Addin to Insert Markdown Citations

\url{https://github.com/crsh/citr}

\hypertarget{ggplotassist-1}{%
\chapter{ggplotAssist}\label{ggplotassist-1}}

\url{https://github.com/cardiomoon/ggplotAssist/blob/master/README.md}

\hypertarget{radiant-2}{%
\chapter{Radiant}\label{radiant-2}}

Radiant -- Business analytics using R and Shiny

\url{https://radiant-rstats.github.io/docs/tutorials.html}

\hypertarget{rspivot}{%
\chapter{rspivot}\label{rspivot}}

\url{https://ryantimpe.github.io/rspivot/index.html}

\hypertarget{finalfit-3}{%
\chapter{finalfit}\label{finalfit-3}}

\url{http://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/}

\hypertarget{ggraptr-1}{%
\chapter{ggraptR}\label{ggraptr-1}}

\url{https://github.com/cargomoose/ggraptR}

\href{https://github.com/cargomoose/ggraptR}{\includegraphics{https://raw.githubusercontent.com/cargomoose/ggraptR/master/inst/ggraptR/www/demo.gif}}

\hypertarget{bookdownthemeeditor}{%
\chapter{bookdownThemeEditor}\label{bookdownthemeeditor}}

\url{https://github.com/hebrewseniorlife/bookdownThemeEditor}

\hypertarget{esquisse-1}{%
\chapter{esquisse}\label{esquisse-1}}

\url{https://github.com/dreamRs/esquisse}

\hypertarget{ggtextures}{%
\chapter{ggtextures}\label{ggtextures}}

\url{https://github.com/clauswilke/ggtextures}

\hypertarget{ggstatsplot}{%
\chapter{ggstatsplot}\label{ggstatsplot}}

ggplot2 Based Plots with Statistical Details

\url{https://indrajeetpatil.github.io/ggstatsplot/}

\hypertarget{ggcoefstats}{%
\section{ggcoefstats}\label{ggcoefstats}}

\url{https://indrajeetpatil.github.io/ggstatsplot/articles/ggcoefstats.html}

\hypertarget{choroplethr}{%
\chapter{Choroplethr}\label{choroplethr}}

\url{https://arilamstein.com/open-source/}

\hypertarget{purrr-1}{%
\chapter{purrr}\label{purrr-1}}

\url{https://colinfay.me/happy-dev-purrr/}

\hypertarget{knitcitations-1}{%
\chapter{knitcitations}\label{knitcitations-1}}

\url{http://www.carlboettiger.info/2012/05/30/knitcitations.html}

\hypertarget{infer-3}{%
\chapter{infer}\label{infer-3}}

Tidy Statistical Inference\\
\url{https://cran.r-project.org/web/packages/infer/index.html}

\url{https://kbroman.org/pkg_primer/}

\hypertarget{packages-to-be-studied}{%
\section{Packages to be studied}\label{packages-to-be-studied}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
packagefinder::findPackage(c( pubmed ,  bibliography ))
\end{verbatim}

\url{https://cran.rstudio.com/web/packages/sys/}

\hypertarget{scales}{%
\chapter{scales}\label{scales}}

Scale Functions for Visualization

\url{https://cran.r-project.org/web/packages/scales/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
paste0(round(.20394*100, 1),  % )
scales::percent(.20394)
\end{verbatim}

\hypertarget{animation}{%
\chapter{animation}\label{animation}}

A Gallery of Animations in Statistics and Utilities to Create Animations
\url{https://cran.r-project.org/web/packages/animation/}

\hypertarget{gganimate-2}{%
\chapter{gganimate}\label{gganimate-2}}

A Grammar of Animated Graphics
\url{https://github.com/thomasp85/gganimate}

\url{https://cran.r-project.org/web/packages/naniar/index.html}

\url{https://hughjonesd.github.io/anim.plots/anim.plots.html}

You Can Design a Good Chart with R
\url{https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e}

Bubble-grid-maps
\url{https://jschoeley.github.io/2018/06/30/bubble-grid-map.html}

Taking control of animations in R and demystifying them in the process
\url{https://www.data-imaginist.com/2017/animating-the-logo/?utm_content=bufferd418f\&utm_medium=social\&utm_source=twitter.com\&utm_campaign=buffer}

\url{https://cran.r-project.org/web/packages/rticles/rticles.pdf}

\url{https://colinfay.me/build-api-wrapper-package-r/}

\url{https://www}..com/community/tutorials/setup-data-science-environment

\url{https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\#\#\#\#installation}

\url{https://cran.r-project.org/web/packages/expss/vignettes/tables-with-labels.html}

\url{https://cran.r-project.org/web/packages/tabulizer/vignettes/tabulizer.html}

\url{https://github.com/benjaminrich/table1}

\url{https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html}

\url{https://twitter.com/mitchoharawild/status/1007297976711110659?s=12}

\url{https://twitter.com/mf_viz/status/1004954297962917891?s=12}

\url{https://github.com/cmap/morpheus.R}

\url{https://github.com/talgalili/heatmaply/}

\url{https://github.com/rstudio/d3heatmap}

\url{http://worksmarter.pl/en/post/webscraping-case-study-1/}

\url{http://worksmarter.pl/en/post/job-automation-r-1/}

\url{http://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/}

\url{https://www.r-bloggers.com/how-to-plot-with-ggiraph/}

\url{https://www.r-bloggers.com/understanding-pca-using-stack-overflow-data/}

\url{https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r/}

\url{http://journals.plos.org/plosone/article?id=10.1371\%2Fjournal.pone.0188299}

\url{https://github.com/trinker/reports}

Animated Directional Chord Diagrams
\url{https://guyabel.com/post/animated-directional-chord-diagrams/}

modelDown: a website generator for your predictive models
\url{http://smarterpoland.pl/index.php/2018/06/modeldown-a-website-generator-for-your-predictive-models/}

\hypertarget{drake}{%
\chapter{drake}\label{drake}}

\url{https://ropensci.github.io/drake/}

\hypertarget{chromomap}{%
\section{chromoMap}\label{chromomap}}

An R package for Interactive visualization and mapping of human chromosomes

\url{https://cran.r-project.org/web/packages/chromoMap/vignettes/chromoMap.html}

\hypertarget{tabplot}{%
\section{tabplot}\label{tabplot}}

Tableplot, a Visualization of Large Datasets

\url{https://cran.r-project.org/web/packages/tabplot/index.html}

\url{https://cran.r-project.org/web/packages/tabplot/vignettes/tabplot-vignette.html}

\url{https://cran.r-project.org/web/packages/tabplot/vignettes/tabplot-timings.html}

\hypertarget{treemap}{%
\section{treemap}\label{treemap}}

Treemap Visualization

\url{https://cran.r-project.org/web/packages/treemap/index.html}

\hypertarget{vim}{%
\section{VIM}\label{vim}}

Visualization and Imputation of Missing Values

\url{https://cran.r-project.org/web/packages/VIM/index.html}

\hypertarget{survey}{%
\section{survey}\label{survey}}

\url{https://cran.r-project.org/web/packages/survey/index.html}

\hypertarget{tidytext}{%
\section{tidytext}\label{tidytext}}

\url{https://cran.r-project.org/web/packages/tidytext/index.html}

\url{https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html}

\url{https://cran.r-project.org/web/packages/tidytext/vignettes/tidying_casting.html}

\url{https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html}

\url{https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html}

\hypertarget{rapport-an-r-templating-system}{%
\section{rapport an R templating system}\label{rapport-an-r-templating-system}}

\url{http://rapport-package.info/}

\hypertarget{ztable}{%
\section{ztable}\label{ztable}}

\url{https://github.com/cardiomoon/ztable}

\hypertarget{texreg}{%
\section{texreg}\label{texreg}}

\url{https://cran.r-project.org/web/packages/texreg/vignettes/texreg.pdf}

\hypertarget{sortablehtmltables}{%
\section{SortableHTMLTables}\label{sortablehtmltables}}

\url{https://cran.r-project.org/web/packages/SortableHTMLTables/index.html}

\hypertarget{hwriter}{%
\section{hwriter}\label{hwriter}}

\url{https://cran.r-project.org/web/packages/hwriter/vignettes/hwriter.pdf}

\hypertarget{htmlutils}{%
\section{HTMLUtils}\label{htmlutils}}

\url{https://cran.r-project.org/web/packages/HTMLUtils/index.html}

\hypertarget{htmltable}{%
\section{htmlTable}\label{htmltable}}

\url{https://cran.r-project.org/web/packages/htmlTable/index.html}

\hypertarget{formattable-2}{%
\section{formattable}\label{formattable-2}}

\url{https://cran.r-project.org/web/packages/formattable/index.html}

\hypertarget{dt}{%
\section{DT}\label{dt}}

DT: An R interface to the DataTables library

\url{https://rstudio.github.io/DT/}

\hypertarget{stargazer-1}{%
\section{stargazer}\label{stargazer-1}}

Well-Formatted Regression and Summary Statistics Tables

\url{https://cran.r-project.org/web/packages/stargazer/index.html}

\hypertarget{conflicted}{%
\section{conflicted}\label{conflicted}}

\hypertarget{psycho}{%
\section{psycho}\label{psycho}}

\begin{verbatim}
{r, eval=FALSE, include=FALSE}
install.packages( devtools )
library( devtools )
install_github( neuropsychology/psycho.R )
library( psycho )
\end{verbatim}

\hypertarget{styler}{%
\section{styler}\label{styler}}

\hypertarget{tidyverse}{%
\section{tidyverse}\label{tidyverse}}

\hypertarget{splitstackshape}{%
\section{splitstackshape}\label{splitstackshape}}

\begin{itemize}
\tightlist
\item
  The ``splitstackshape'' package for R
\end{itemize}

\url{https://www.r-bloggers.com/the-splitstackshape-package-for-r/}

\hypertarget{epir}{%
\section{epiR}\label{epir}}

Basic Epi

install.packages( epiR )

\hypertarget{lmtest}{%
\section{lmtest}\label{lmtest}}

Some useful epitools especially 2*2 tables and stratified MH Odds

install.packages( lmtest )

\hypertarget{popepi}{%
\section{popEpi}\label{popepi}}

install.packages( popEpi )

\hypertarget{extra-tools-to-go-with-epi-and-make-nice-rate-tables}{%
\section{Extra tools to go with `Epi' and make nice rate tables}\label{extra-tools-to-go-with-epi-and-make-nice-rate-tables}}

\hypertarget{survival}{%
\section{survival}\label{survival}}

install.packages( survival )

for survial analysis, kaplan-meier plots and cox regression

\hypertarget{survminer}{%
\section{survminer}\label{survminer}}

install.packages( survminer )

Really nice KM plots!

\hypertarget{random-effects-modeks}{%
\section{Random-Effects Modeks}\label{random-effects-modeks}}

install.packages( lme4 )

install.packages( sjstats )

\hypertarget{multiple-imputation}{%
\section{Multiple Imputation}\label{multiple-imputation}}

install.packages( mice )

install.packages( arsenal )

\hypertarget{really-nice-summmary-tables}{%
\section{Really nice summmary tables}\label{really-nice-summmary-tables}}

\hypertarget{complex-survey-data-analysis}{%
\section{Complex survey data analysis}\label{complex-survey-data-analysis}}

install.packages( survey )

\hypertarget{for-handling-complex-survey-data}{%
\section{For handling complex survey data}\label{for-handling-complex-survey-data}}

install.packages( ICC )

\hypertarget{alternative-methods-for-icc-calculation-from-survey-data}{%
\section{Alternative methods for ICC calculation from survey data}\label{alternative-methods-for-icc-calculation-from-survey-data}}

\hypertarget{meta-analysis}{%
\section{Meta-analysis}\label{meta-analysis}}

install.packages( meta )

install.packages( metafor )

install.packages( workflowr )

install.packages( DiagrammeR )

install.packages( tangram )

devtools::install\_github( lbusett/insert\_table )

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#### Obtain names of all packages on CRAN
names.available.packages <- rownames(available.packages())

#### Extract packages names that contain Rcmdr
Rcmdr.related.packages <- names.available.packages[grep( Rcmdr , names.available.packages)]
Rcmdr.related.packages

#### Install these packages
install.packages(pkgs = Rcmdr.related.packages)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
usePackage <- function(p) {
  if (!is.element(p, installed.packages()[, 1])) {
    install.packages(p, dep = TRUE)
  }
  require(p, character.only = TRUE)
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
file.edit( ~/Desktop/foo/.Rprofile )
## This opens up a script window, within which you can enter in your library commands
library(ggplot2)
library(scales)
library(plyr)
library(reshape2)
\end{verbatim}

\hypertarget{abind}{%
\section{abind}\label{abind}}

\hypertarget{acepack}{%
\section{acepack}\label{acepack}}

\hypertarget{algdesign}{%
\section{AlgDesign}\label{algdesign}}

\hypertarget{annotationdbi}{%
\section{AnnotationDbi}\label{annotationdbi}}

\hypertarget{aplpack}{%
\section{aplpack}\label{aplpack}}

\hypertarget{arm}{%
\section{arm}\label{arm}}

\hypertarget{assertthat}{%
\section{assertthat}\label{assertthat}}

\hypertarget{backports}{%
\section{backports}\label{backports}}

\hypertarget{base}{%
\section{base}\label{base}}

\hypertarget{base64enc}{%
\section{base64enc}\label{base64enc}}

\hypertarget{bca}{%
\section{BCA}\label{bca}}

\hypertarget{bh}{%
\section{BH}\label{bh}}

\hypertarget{biasedurn}{%
\section{BiasedUrn}\label{biasedurn}}

\hypertarget{bindr}{%
\section{bindr}\label{bindr}}

\hypertarget{bindrcpp}{%
\section{bindrcpp}\label{bindrcpp}}

\hypertarget{biobase}{%
\section{Biobase}\label{biobase}}

\hypertarget{biocgenerics}{%
\section{BiocGenerics}\label{biocgenerics}}

\hypertarget{biocinstaller}{%
\section{BiocInstaller}\label{biocinstaller}}

\hypertarget{bit}{%
\section{bit}\label{bit}}

\hypertarget{bit64}{%
\section{bit64}\label{bit64}}

\hypertarget{bitops}{%
\section{bitops}\label{bitops}}

\hypertarget{blob}{%
\section{blob}\label{blob}}

\hypertarget{boot}{%
\section{boot}\label{boot}}

\hypertarget{broom}{%
\section{broom}\label{broom}}

\hypertarget{bsmd}{%
\section{BsMD}\label{bsmd}}

\hypertarget{ca}{%
\section{ca}\label{ca}}

\hypertarget{car}{%
\section{car}\label{car}}

\hypertarget{catools}{%
\section{caTools}\label{catools}}

\hypertarget{cellranger}{%
\section{cellranger}\label{cellranger}}

\hypertarget{checkmate}{%
\section{checkmate}\label{checkmate}}

\hypertarget{class}{%
\section{class}\label{class}}

\hypertarget{cluster}{%
\section{cluster}\label{cluster}}

\hypertarget{clv}{%
\section{clv}\label{clv}}

\hypertarget{coda}{%
\section{coda}\label{coda}}

\hypertarget{codetools}{%
\section{codetools}\label{codetools}}

\hypertarget{coin}{%
\section{coin}\label{coin}}

\hypertarget{colorspace}{%
\section{colorspace}\label{colorspace}}

\hypertarget{combinat}{%
\section{combinat}\label{combinat}}

\hypertarget{compiler}{%
\section{compiler}\label{compiler}}

\hypertarget{conf.design}{%
\section{conf.design}\label{conf.design}}

\hypertarget{curl}{%
\section{curl}\label{curl}}

\hypertarget{data.table-1}{%
\section{data.table}\label{data.table-1}}

\hypertarget{datasets}{%
\section{datasets}\label{datasets}}

\hypertarget{date}{%
\section{date}\label{date}}

\hypertarget{dbi}{%
\section{DBI}\label{dbi}}

\hypertarget{deldir}{%
\section{deldir}\label{deldir}}

\hypertarget{depthtools}{%
\section{depthTools}\label{depthtools}}

\hypertarget{dicedesign}{%
\section{DiceDesign}\label{dicedesign}}

\hypertarget{dichromat}{%
\section{dichromat}\label{dichromat}}

\hypertarget{digest}{%
\section{digest}\label{digest}}

\hypertarget{doe.base}{%
\section{DoE.base}\label{doe.base}}

\hypertarget{doe.wrapper}{%
\section{DoE.wrapper}\label{doe.wrapper}}

\hypertarget{doparallel}{%
\section{doParallel}\label{doparallel}}

\hypertarget{dplyr}{%
\section{dplyr}\label{dplyr}}

\hypertarget{e1071}{%
\section{e1071}\label{e1071}}

\hypertarget{effects}{%
\section{effects}\label{effects}}

\hypertarget{enmisc}{%
\section{ENmisc}\label{enmisc}}

\hypertarget{epir-1}{%
\section{epiR}\label{epir-1}}

\hypertarget{estimability}{%
\section{estimability}\label{estimability}}

\hypertarget{evaluate}{%
\section{evaluate}\label{evaluate}}

\hypertarget{ez}{%
\section{ez}\label{ez}}

\hypertarget{flexclust}{%
\section{flexclust}\label{flexclust}}

\hypertarget{forcats}{%
\section{forcats}\label{forcats}}

\hypertarget{foreach}{%
\section{foreach}\label{foreach}}

\hypertarget{foreign}{%
\section{foreign}\label{foreign}}

\hypertarget{formatr}{%
\section{formatR}\label{formatr}}

\hypertarget{formula}{%
\section{Formula}\label{formula}}

\hypertarget{fracdiff}{%
\section{fracdiff}\label{fracdiff}}

\hypertarget{frf2}{%
\section{FrF2}\label{frf2}}

\hypertarget{gdata}{%
\section{gdata}\label{gdata}}

\hypertarget{ggplot2-1}{%
\section{ggplot2}\label{ggplot2-1}}

\url{http://www.cookbook-r.com/Graphs/}

\hypertarget{ggplot2-extensions}{%
\subsection{ggplot2 extensions}\label{ggplot2-extensions}}

\url{http://www.ggplot2-exts.org/gallery/}

\url{http://corybrunson.github.io/ggalluvial/}

\url{http://www.sthda.com/english/rpkgs/survminer/}

\hypertarget{ggthemes}{%
\section{ggthemes}\label{ggthemes}}

\hypertarget{ggvis}{%
\section{ggvis}\label{ggvis}}

\hypertarget{glue-2}{%
\section{glue}\label{glue-2}}

\hypertarget{goftest}{%
\section{goftest}\label{goftest}}

\hypertarget{graphics}{%
\section{graphics}\label{graphics}}

\hypertarget{grdevices}{%
\section{grDevices}\label{grdevices}}

\hypertarget{grid}{%
\section{grid}\label{grid}}

\hypertarget{gridbase}{%
\section{gridBase}\label{gridbase}}

\hypertarget{gridextra}{%
\section{gridExtra}\label{gridextra}}

\hypertarget{gtable}{%
\section{gtable}\label{gtable}}

\hypertarget{gtools}{%
\section{gtools}\label{gtools}}

\hypertarget{haven}{%
\section{haven}\label{haven}}

\hypertarget{highr}{%
\section{highr}\label{highr}}

\hypertarget{hmisc}{%
\section{Hmisc}\label{hmisc}}

\hypertarget{hms}{%
\section{hms}\label{hms}}

\hypertarget{htmltable-1}{%
\section{htmlTable}\label{htmltable-1}}

\hypertarget{htmltools}{%
\section{htmltools}\label{htmltools}}

\hypertarget{htmlwidgets}{%
\section{htmlwidgets}\label{htmlwidgets}}

\hypertarget{httpuv}{%
\section{httpuv}\label{httpuv}}

\hypertarget{httr}{%
\section{httr}\label{httr}}

\hypertarget{igraph}{%
\section{igraph}\label{igraph}}

\hypertarget{iranges}{%
\section{IRanges}\label{iranges}}

\hypertarget{irlba}{%
\section{irlba}\label{irlba}}

\hypertarget{iterators}{%
\section{iterators}\label{iterators}}

\hypertarget{jsonlite}{%
\section{jsonlite}\label{jsonlite}}

\hypertarget{kernsmooth}{%
\section{KernSmooth}\label{kernsmooth}}

\hypertarget{knitr}{%
\section{knitr}\label{knitr}}

\hypertarget{labeling}{%
\section{labeling}\label{labeling}}

\hypertarget{lattice}{%
\section{lattice}\label{lattice}}

\hypertarget{latticeextra}{%
\section{latticeExtra}\label{latticeextra}}

\hypertarget{lazyeval}{%
\section{lazyeval}\label{lazyeval}}

\hypertarget{leaps}{%
\section{leaps}\label{leaps}}

\hypertarget{lhs}{%
\section{lhs}\label{lhs}}

\hypertarget{lme4}{%
\section{lme4}\label{lme4}}

\hypertarget{lmtest-1}{%
\section{lmtest}\label{lmtest-1}}

\hypertarget{lsmeans}{%
\section{lsmeans}\label{lsmeans}}

\hypertarget{lubridate}{%
\section{lubridate}\label{lubridate}}

\hypertarget{magrittr}{%
\section{magrittr}\label{magrittr}}

\hypertarget{markdown}{%
\section{markdown}\label{markdown}}

\hypertarget{mass}{%
\section{MASS}\label{mass}}

\hypertarget{matrix}{%
\section{Matrix}\label{matrix}}

\hypertarget{matrixcalc}{%
\section{matrixcalc}\label{matrixcalc}}

\hypertarget{matrixmodels}{%
\section{MatrixModels}\label{matrixmodels}}

\hypertarget{memoise}{%
\section{memoise}\label{memoise}}

\hypertarget{methods}{%
\section{methods}\label{methods}}

\hypertarget{mgcv}{%
\section{mgcv}\label{mgcv}}

\hypertarget{mi}{%
\section{mi}\label{mi}}

\hypertarget{mime}{%
\section{mime}\label{mime}}

\hypertarget{minqa}{%
\section{minqa}\label{minqa}}

\hypertarget{mnormt}{%
\section{mnormt}\label{mnormt}}

\hypertarget{modelr}{%
\section{modelr}\label{modelr}}

\hypertarget{modeltools}{%
\section{modeltools}\label{modeltools}}

\hypertarget{multcomp}{%
\section{multcomp}\label{multcomp}}

\hypertarget{munsell}{%
\section{munsell}\label{munsell}}

\hypertarget{mvtnorm}{%
\section{mvtnorm}\label{mvtnorm}}

\hypertarget{nlme}{%
\section{nlme}\label{nlme}}

\hypertarget{nloptr}{%
\section{nloptr}\label{nloptr}}

\hypertarget{nlp}{%
\section{NLP}\label{nlp}}

\hypertarget{nmf}{%
\section{NMF}\label{nmf}}

\hypertarget{nnet}{%
\section{nnet}\label{nnet}}

\hypertarget{nortest}{%
\section{nortest}\label{nortest}}

\hypertarget{openssl}{%
\section{openssl}\label{openssl}}

\hypertarget{ordinal}{%
\section{ordinal}\label{ordinal}}

\hypertarget{orloca}{%
\section{orloca}\label{orloca}}

\hypertarget{orloca.es}{%
\section{orloca.es}\label{orloca.es}}

\hypertarget{parallel}{%
\section{parallel}\label{parallel}}

\hypertarget{pbkrtest}{%
\section{pbkrtest}\label{pbkrtest}}

\hypertarget{pkgconfig}{%
\section{pkgconfig}\label{pkgconfig}}

\hypertarget{pkgmaker}{%
\section{pkgmaker}\label{pkgmaker}}

\hypertarget{plogr}{%
\section{plogr}\label{plogr}}

\hypertarget{plyr}{%
\section{plyr}\label{plyr}}

\hypertarget{polyclip}{%
\section{polyclip}\label{polyclip}}

\hypertarget{psych}{%
\section{psych}\label{psych}}

\hypertarget{purrr-2}{%
\section{purrr}\label{purrr-2}}

\url{https://colinfay.me/happy-dev-purrr/}

\hypertarget{quadprog}{%
\section{quadprog}\label{quadprog}}

\hypertarget{quantmod}{%
\section{quantmod}\label{quantmod}}

\hypertarget{quantreg}{%
\section{quantreg}\label{quantreg}}

\hypertarget{r2html}{%
\section{R2HTML}\label{r2html}}

\hypertarget{r6}{%
\section{R6}\label{r6}}

\hypertarget{randtests}{%
\section{randtests}\label{randtests}}

\hypertarget{rcmdr-6}{%
\section{Rcmdr}\label{rcmdr-6}}

\hypertarget{rcmdrmisc}{%
\section{RcmdrMisc}\label{rcmdrmisc}}

\hypertarget{rcmdrplugin.bca}{%
\section{RcmdrPlugin.BCA}\label{rcmdrplugin.bca}}

\hypertarget{rcmdrplugin.coin}{%
\section{RcmdrPlugin.coin}\label{rcmdrplugin.coin}}

\hypertarget{rcmdrplugin.depthtools}{%
\section{RcmdrPlugin.depthTools}\label{rcmdrplugin.depthtools}}

\hypertarget{rcmdrplugin.doe}{%
\section{RcmdrPlugin.DoE}\label{rcmdrplugin.doe}}

\hypertarget{rcmdrplugin.doex}{%
\section{RcmdrPlugin.doex}\label{rcmdrplugin.doex}}

\hypertarget{rcmdrplugin.eacspir}{%
\section{RcmdrPlugin.EACSPIR}\label{rcmdrplugin.eacspir}}

\hypertarget{rcmdrplugin.ebm}{%
\section{RcmdrPlugin.EBM}\label{rcmdrplugin.ebm}}

\hypertarget{rcmdrplugin.epack}{%
\section{RcmdrPlugin.epack}\label{rcmdrplugin.epack}}

\hypertarget{rcmdrplugin.ezr}{%
\section{RcmdrPlugin.EZR}\label{rcmdrplugin.ezr}}

\hypertarget{rcmdrplugin.kmggplot2}{%
\section{RcmdrPlugin.KMggplot2}\label{rcmdrplugin.kmggplot2}}

\hypertarget{rcmdrplugin.mosaic}{%
\section{RcmdrPlugin.mosaic}\label{rcmdrplugin.mosaic}}

\hypertarget{rcmdrplugin.mpastats}{%
\section{RcmdrPlugin.MPAStats}\label{rcmdrplugin.mpastats}}

\hypertarget{rcmdrplugin.orloca}{%
\section{RcmdrPlugin.orloca}\label{rcmdrplugin.orloca}}

\hypertarget{rcmdrplugin.plotbygroup}{%
\section{RcmdrPlugin.plotByGroup}\label{rcmdrplugin.plotbygroup}}

\hypertarget{rcmdrplugin.qual}{%
\section{RcmdrPlugin.qual}\label{rcmdrplugin.qual}}

\hypertarget{rcmdrplugin.scda}{%
\section{RcmdrPlugin.SCDA}\label{rcmdrplugin.scda}}

\hypertarget{rcmdrplugin.sampling}{%
\section{RcmdrPlugin.sampling}\label{rcmdrplugin.sampling}}

Tools for sampling in Official Statistical Surveys

\url{https://cran.r-project.org/web/packages/RcmdrPlugin.sampling/index.html}

\hypertarget{rcmdrplugin.seeg}{%
\section{RcmdrPlugin.seeg}\label{rcmdrplugin.seeg}}

\hypertarget{rcmdrplugin.slc}{%
\section{RcmdrPlugin.SLC}\label{rcmdrplugin.slc}}

\hypertarget{rcmdrplugin.sm}{%
\section{RcmdrPlugin.SM}\label{rcmdrplugin.sm}}

\hypertarget{rcmdrplugin.steepness}{%
\section{RcmdrPlugin.steepness}\label{rcmdrplugin.steepness}}

\hypertarget{rcmdrplugin.survival}{%
\section{RcmdrPlugin.survival}\label{rcmdrplugin.survival}}

\hypertarget{rcmdrplugin.teachingdemos}{%
\section{RcmdrPlugin.TeachingDemos}\label{rcmdrplugin.teachingdemos}}

\hypertarget{rcmdrplugin.temis}{%
\section{RcmdrPlugin.temis}\label{rcmdrplugin.temis}}

\hypertarget{rcmdrplugin.uca}{%
\section{RcmdrPlugin.UCA}\label{rcmdrplugin.uca}}

\hypertarget{rcolorbrewer-1}{%
\section{RColorBrewer}\label{rcolorbrewer-1}}

\hypertarget{rcpp}{%
\section{Rcpp}\label{rcpp}}

\hypertarget{rcpparmadillo}{%
\section{RcppArmadillo}\label{rcpparmadillo}}

\hypertarget{rcppeigen}{%
\section{RcppEigen}\label{rcppeigen}}

\hypertarget{readr}{%
\section{readr}\label{readr}}

\hypertarget{readxl}{%
\section{readxl}\label{readxl}}

\hypertarget{registry}{%
\section{registry}\label{registry}}

\hypertarget{relimp}{%
\section{relimp}\label{relimp}}

\hypertarget{rematch}{%
\section{rematch}\label{rematch}}

\hypertarget{reshape}{%
\section{reshape}\label{reshape}}

\hypertarget{reshape2}{%
\section{reshape2}\label{reshape2}}

\hypertarget{rgl}{%
\section{rgl}\label{rgl}}

\hypertarget{rismed-1}{%
\section{RISmed}\label{rismed-1}}

\hypertarget{rjava}{%
\section{rJava}\label{rjava}}

\hypertarget{rlang}{%
\section{rlang}\label{rlang}}

\hypertarget{rmarkdown}{%
\section{rmarkdown}\label{rmarkdown}}

\hypertarget{rmysql}{%
\section{RMySQL}\label{rmysql}}

\hypertarget{rngtools}{%
\section{rngtools}\label{rngtools}}

\hypertarget{rpart}{%
\section{rpart}\label{rpart}}

\hypertarget{rpart.plot}{%
\section{rpart.plot}\label{rpart.plot}}

\hypertarget{rprojroot}{%
\section{rprojroot}\label{rprojroot}}

\hypertarget{rsm}{%
\section{rsm}\label{rsm}}

\hypertarget{rticles-tufte}{%
\section{rticles tufte}\label{rticles-tufte}}

\url{https://github.com/rstudio/rticles}

\url{https://www.coursera.org/learn/reproducible-templates-analysis/lecture/QaDy7/building-a-document-template-part-2}

\url{https://www.coursera.org/learn/reproducible-templates-analysis/supplement/GQz0G/lecture-prep-code-file}

\url{https://github.com/rstudio/tufte}

\hypertarget{rsqlite}{%
\section{RSQLite}\label{rsqlite}}

\hypertarget{rvest}{%
\section{rvest}\label{rvest}}

\hypertarget{s4vectors}{%
\section{S4Vectors}\label{s4vectors}}

\hypertarget{sandwich}{%
\section{sandwich}\label{sandwich}}

\hypertarget{scales-1}{%
\section{scales}\label{scales-1}}

\hypertarget{scatterplot3d}{%
\section{scatterplot3d}\label{scatterplot3d}}

\hypertarget{scma}{%
\section{SCMA}\label{scma}}

\hypertarget{scrt}{%
\section{SCRT}\label{scrt}}

\hypertarget{scva}{%
\section{SCVA}\label{scva}}

\hypertarget{seeg}{%
\section{seeg}\label{seeg}}

\hypertarget{selectr}{%
\section{selectr}\label{selectr}}

\hypertarget{sem}{%
\section{sem}\label{sem}}

\hypertarget{sfsmisc}{%
\section{sfsmisc}\label{sfsmisc}}

\hypertarget{sgeostat}{%
\section{sgeostat}\label{sgeostat}}

\hypertarget{shiny-1}{%
\section{shiny}\label{shiny-1}}

\hypertarget{shinythemes}{%
\section{shinythemes}\label{shinythemes}}

\hypertarget{slam}{%
\section{slam}\label{slam}}

\hypertarget{slc}{%
\section{SLC}\label{slc}}

\hypertarget{sourcetools}{%
\section{sourcetools}\label{sourcetools}}

\hypertarget{sparsem}{%
\section{SparseM}\label{sparsem}}

\hypertarget{spatial}{%
\section{spatial}\label{spatial}}

\hypertarget{spatstat}{%
\section{spatstat}\label{spatstat}}

\hypertarget{spatstat.utils}{%
\section{spatstat.utils}\label{spatstat.utils}}

\hypertarget{splines}{%
\section{splines}\label{splines}}

\hypertarget{stats}{%
\section{stats}\label{stats}}

\hypertarget{stats4}{%
\section{stats4}\label{stats4}}

\hypertarget{steepness}{%
\section{steepness}\label{steepness}}

\hypertarget{stringi}{%
\section{stringi}\label{stringi}}

\hypertarget{stringr}{%
\section{stringr}\label{stringr}}

\hypertarget{survival-1}{%
\section{survival}\label{survival-1}}

\hypertarget{tcltk}{%
\section{tcltk}\label{tcltk}}

\hypertarget{tcltk2}{%
\section{tcltk2}\label{tcltk2}}

\hypertarget{teachingdemos}{%
\section{TeachingDemos}\label{teachingdemos}}

\hypertarget{tensor}{%
\section{tensor}\label{tensor}}

\hypertarget{th.data}{%
\section{TH.data}\label{th.data}}

\hypertarget{tibble}{%
\section{tibble}\label{tibble}}

\hypertarget{tidyr-1}{%
\section{tidyr}\label{tidyr-1}}

\hypertarget{tidyverse-1}{%
\section{tidyverse}\label{tidyverse-1}}

\hypertarget{timedate}{%
\section{timeDate}\label{timedate}}

\hypertarget{tkrplot}{%
\section{tkrplot}\label{tkrplot}}

\hypertarget{tm}{%
\section{tm}\label{tm}}

\hypertarget{tools}{%
\section{tools}\label{tools}}

\hypertarget{tseries}{%
\section{tseries}\label{tseries}}

\hypertarget{ttr}{%
\section{TTR}\label{ttr}}

\hypertarget{ucminf}{%
\section{ucminf}\label{ucminf}}

\hypertarget{utils}{%
\section{utils}\label{utils}}

\hypertarget{vcd}{%
\section{vcd}\label{vcd}}

\hypertarget{viridis}{%
\section{viridis}\label{viridis}}

\hypertarget{viridislite}{%
\section{viridisLite}\label{viridislite}}

\hypertarget{xlconnect}{%
\section{XLConnect}\label{xlconnect}}

\hypertarget{xlconnectjars}{%
\section{XLConnectJars}\label{xlconnectjars}}

\hypertarget{xml2}{%
\section{xml2}\label{xml2}}

\hypertarget{xtable}{%
\section{xtable}\label{xtable}}

\hypertarget{xts}{%
\section{xts}\label{xts}}

\hypertarget{yaml}{%
\section{yaml}\label{yaml}}

\hypertarget{zoo}{%
\section{zoo}\label{zoo}}

install.packages( stargazer )

install.packages( pander )

install.packages( tables )

install.packages( ascii )

install.packages( xtable )

devtools::install\_github( hadley/dplyr )

install.packages( gapminder )

install.packages( alluvial )

vignette( databases , package = dplyr )

install.packages( robustbase )

install.packages( insuranceData )

install.packages( Lahman )

install.packages( tidyverse )

install.packages( qdap )

install.packages( openxlsx )

devtools::install\_github( kassambara/r2excel )

install.packages( WriteXLS )

install.packages( XLConnect )

library(XLConnect)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
if (!require(wordcloud)) {
  install.packages( wordcloud )
  library(wordcloud)
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
installed <- as.data.frame(installed.packages())
write.csv(installed,  installed_previously.csv )

installedPreviously <- read.csv( installed_previously.csv )
baseR <- as.data.frame(installed.packages())
toInstall <- setdiff(installedPreviously, baseR)

install.packages(toInstall)


packagelist <- installed.packages()
class(packagelist)
packagelist[, 1]
\end{verbatim}

\hypertarget{rcmdr-7}{%
\section{Rcmdr}\label{rcmdr-7}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( Rcmdr )
install.packages( RcmdrPlugin.BCA )
install.packages( RcmdrPlugin.coin )
install.packages( RcmdrPlugin.depthTools )
install.packages( RcmdrPlugin.doBy )
install.packages( RcmdrPlugin.DoE )
install.packages( RcmdrPlugin.doex )
install.packages( RcmdrPlugin.EACSPIR )
install.packages( RcmdrPlugin.EBM )
install.packages( RcmdrPlugin.epack )
install.packages( RcmdrPlugin.EZR )
install.packages( RcmdrPlugin.HH )
install.packages( RcmdrPlugin.IPSUR )
install.packages( RcmdrPlugin.KMggplot2 )
install.packages( RcmdrPlugin.mosaic )
install.packages( RcmdrPlugin.MPAStats )
install.packages( RcmdrPlugin.orloca )
install.packages( RcmdrPlugin.plotByGroup )
install.packages( RcmdrPlugin.qcc )
install.packages( RcmdrPlugin.qual )
install.packages( RcmdrPlugin.SCDA )
install.packages( RcmdrPlugin.seeg )
install.packages( RcmdrPlugin.SLC )
install.packages( RcmdrPlugin.SM )
install.packages( RcmdrPlugin.StatisticalURV )
install.packages( RcmdrPlugin.steepness )
install.packages( RcmdrPlugin.survival )
install.packages( RcmdrPlugin.TeachingDemos )
install.packages( RcmdrPlugin.temis )
install.packages( RcmdrPlugin.UCA )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
source( https://bioconductor.org/biocLite.R )
biocLite()
\end{verbatim}

install.packages( tidyverse )

install.packages( devtools )

devtools::install\_github( hadley/colformat )

devtools::install\_github( ropenscilabs/skimr )

install.packages( hflights )

install.packages( dbplyr )

install.packages( xlsx )

require(devtools)

install\_github( ProjectMOSAIC/mosaic )

install.packages( jmv )

install.packages( wordcloud )

install.packages( \url{https://cran.r-project.org/src/contrib/Archive/tm/tm_0.6.tar.gz} , repos = NULL)

install.packages( SnowballC )

install.packages( RColorBrewer )

install.packages( tidytext )

install.packages( packrat )

install.packages( testthat )

install.packages( prettydoc )

install.packages( rmdformats )

install.packages(c( fivethirtyeight , tidyverse , knitr , kableExtra , ggthemes ))

library(devtools)

install\_github( SPSStoR , username = lebebr01 )

library(SPSStoR)

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ip <- installed.packages()
pkgs.to.remove <- ip[!(ip[,  Priority ] %in% c( base ,  recommended )), 1]
sapply(pkgs.to.remove, remove.packages)
sapply(pkgs.to.remove, install.packages)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( devtools )
devtools::install_github( AndreaCirilloAC/updateR )
library(updateR)
updateR(admin_password =   ) ## Where  PASSWORD  stands for your system password
\end{verbatim}

survival

survminer

install.packages( tutorial )

devtools::install\_github( romainfrancois/highlight )

install.packages( highr , repos = \url{http://rforge.net} , type = source )

install.packages( xplain )

\begin{verbatim}
{r remove all user installed packages in R, eval=FALSE, include=FALSE}
## How to remove all user installed packages in R
## https://www.r-bloggers.com/how-to-remove-all-user-installed-packages-in-r/

## create a list of all installed packages
ip <- as.data.frame(installed.packages())
head(ip)
## if you use MRO, make sure that no packages in this library will be removed
ip <- subset(ip, !grepl( MRO , ip$LibPath))
## we don't want to remove base or recommended packages either\
ip <- ip[!(ip[, Priority ] %in% c( base ,  recommended )),]
## determine the library where the packages are installed
path.lib <- unique(ip$LibPath)
## create a vector with all the names of the packages you want to remove
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)
## remove the packages
sapply(pkgs.to.remove, remove.packages, lib = path.lib)
\end{verbatim}

\hypertarget{schedule-r-script}{%
\section{Schedule R Script}\label{schedule-r-script}}

library(knitr)

library(markdown)

knit( SchedulePubMedAnalysis.Rmd )

markdownToHTML( SchedulePubMedAnalysis.md , docs/SchedulePubMedAnalysis.html )

setwd( \textasciitilde{} )

file.choose()

library(rmarkdown)

Preperation Packages Schedule R Script

\url{https://github.com/jkeirstead/scholar}

\url{http://rogiersbart.blogspot.com.tr/2015/05/put-google-scholar-citations-on-your.html}

\url{http://tuxette.nathalievilla.org/?p=1682}

\url{https://github.com/sunitj/scholar}

\url{https://tgmstat.wordpress.com/2013/09/11/schedule-rscript-with-cron/}

\url{https://github.com/ropensci/git2r}

library(knitr)

library(markdown)

install.packages(`data.table')

install.packages(`knitr')

install.packages(`miniUI')

install.packages(`shiny')

install.packages(`shinyFiles')

install.packages( taskscheduleR , repos = \url{http://www.datatailor.be/rcube} , type = source )

devtools::install\_github( bnosac/cronR )

install.packages(`scholar')

install.packages( git2r )

\hypertarget{flatxml}{%
\section{flatxml}\label{flatxml}}

\url{http://www.zuckarelli.de/flatxml/articles/example/example.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
xmldata <- flatxml::fxml_importXMLFlat( data/PathologyTurkey.xml )
\end{verbatim}

\hypertarget{roomba}{%
\section{roomba}\label{roomba}}

General purpose API response tidier

\url{https://github.com/ropenscilabs/roomba/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
roomba::shiny_roomba()
\end{verbatim}

\hypertarget{tufterhandout}{%
\section{tufterhandout}\label{tufterhandout}}

Tufte-style html document format for rmarkdown

\url{https://cran.r-project.org/web/packages/tufterhandout/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## install.packages( tufterhandout )
library(tufterhandout)
\end{verbatim}

\hypertarget{paper-1}{%
\section{papeR}\label{paper-1}}

\url{https://sbalci.github.io/MyRCodesForDataAnalysis/papeR.nb.html}

\hypertarget{tm-1}{%
\section{tm}\label{tm-1}}

install.packages( tm )

\url{https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf}

\url{https://atom.io/packages/hydrogen}

R Package Documentation
\url{https://rdrr.io/}
R Packages Search and Statistics
\url{https://www.rpackages.io/}
ReporteRs is an R package for creating Microsoft Word and Powerpoint documents.
\url{https://davidgohel.github.io/ReporteRs/}
officer Manipulation of Microsoft Word and PowerPoint Documents
\url{https://cran.r-project.org/web/packages/officer/}
pubh
\url{https://cran.rstudio.com/web/packages/pubh/vignettes/introduction.html}
What does visdat do?
Initially inspired by csv-fingerprint, vis\_dat helps you visualise a dataframe and ``get a look at the data'' by displaying the variable classes in a dataframe as a plot with vis\_dat, and getting a brief look into missing data patterns using vis\_miss.
\url{https://www.tidyverse.org/}
\url{https://cran.r-project.org/web/packages/shiny/index.html}
\url{https://rmarkdown.rstudio.com/}
\url{http://ggplot2.org/}
\url{https://yihui.name/knitr/}
\url{http://vita.had.co.nz/papers/tidy-data.html}
\url{https://blog.rstudio.com/2015/04/09/readr-0-1-0/}
\url{http://readxl.tidyverse.org/}
\url{https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html}
\url{https://github.com/r-lib/devtools}
\url{https://cran.r-project.org/web/packages/magrittr/index.html}
\url{http://rstudio.github.io/packrat/}
\url{https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html}
\url{https://github.com/tidyverse/dplyr}
\url{https://cran.r-project.org/web/packages/broom/vignettes/broom.html}
\url{https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html}
\url{http://tibble.tidyverse.org/}
\url{https://blog.rstudio.com/2016/03/29/feather/}
\url{https://blog.rstudio.com/2016/08/31/forcats-0-1-0/}
\url{https://github.com/tidyverse/hms}
\url{https://github.com/trestletech/plumber}
\url{https://github.com/r-lib/testthat}
\url{http://purrr.tidyverse.org/}

\hypertarget{broom-1}{%
\chapter{broom}\label{broom-1}}

summarizes key information about models

\url{https://broom.tidyverse.org/index.html}

\hypertarget{abind-1}{%
\section{abind}\label{abind-1}}

\hypertarget{acepack-1}{%
\section{acepack}\label{acepack-1}}

\hypertarget{addinexamples}{%
\section{addinexamples}\label{addinexamples}}

\hypertarget{additivitytests}{%
\section{additivityTests}\label{additivitytests}}

\hypertarget{ade4}{%
\section{ade4}\label{ade4}}

\hypertarget{aer}{%
\section{AER}\label{aer}}

\hypertarget{afex}{%
\section{afex}\label{afex}}

\hypertarget{algdesign-1}{%
\section{AlgDesign}\label{algdesign-1}}

\hypertarget{alluvial}{%
\section{alluvial}\label{alluvial}}

\hypertarget{alr4}{%
\section{alr4}\label{alr4}}

\hypertarget{animation-1}{%
\section{animation}\label{animation-1}}

\hypertarget{antsr}{%
\section{ANTsR}\label{antsr}}

\hypertarget{antsrcore}{%
\section{ANTsRCore}\label{antsrcore}}

\hypertarget{anytime}{%
\section{anytime}\label{anytime}}

\hypertarget{apatables}{%
\section{apaTables}\label{apatables}}

\hypertarget{aplpack-1}{%
\section{aplpack}\label{aplpack-1}}

\hypertarget{arm-1}{%
\section{arm}\label{arm-1}}

\hypertarget{arsenal-1}{%
\section{arsenal}\label{arsenal-1}}

\hypertarget{ash}{%
\section{ash}\label{ash}}

\hypertarget{assertthat-1}{%
\section{assertthat}\label{assertthat-1}}

\hypertarget{aws.s3}{%
\section{aws.s3}\label{aws.s3}}

\hypertarget{aws.signature}{%
\section{aws.signature}\label{aws.signature}}

\hypertarget{backports-1}{%
\section{backports}\label{backports-1}}

\hypertarget{base-1}{%
\section{base}\label{base-1}}

\hypertarget{base64enc-1}{%
\section{base64enc}\label{base64enc-1}}

\hypertarget{bayesfactor}{%
\section{BayesFactor}\label{bayesfactor}}

\hypertarget{bayesplot}{%
\section{bayesplot}\label{bayesplot}}

\hypertarget{bca-1}{%
\section{BCA}\label{bca-1}}

\hypertarget{bcdiag}{%
\section{BcDiag}\label{bcdiag}}

\hypertarget{bdgraph}{%
\section{BDgraph}\label{bdgraph}}

\hypertarget{bdsmatrix}{%
\section{bdsmatrix}\label{bdsmatrix}}

\hypertarget{bh-1}{%
\section{BH}\label{bh-1}}

\hypertarget{biasedurn-1}{%
\section{BiasedUrn}\label{biasedurn-1}}

\hypertarget{bibitr}{%
\section{BiBitR}\label{bibitr}}

\hypertarget{bibtex-1}{%
\section{bibtex}\label{bibtex-1}}

\hypertarget{biclust}{%
\section{biclust}\label{biclust}}

\hypertarget{bindr-1}{%
\section{bindr}\label{bindr-1}}

\hypertarget{bindrcpp-1}{%
\section{bindrcpp}\label{bindrcpp-1}}

\hypertarget{biocgenerics-1}{%
\section{BiocGenerics}\label{biocgenerics-1}}

\hypertarget{biocinstaller-1}{%
\section{BiocInstaller}\label{biocinstaller-1}}

\hypertarget{biostatmethods}{%
\section{biostatmethods}\label{biostatmethods}}

\hypertarget{bit-1}{%
\section{bit}\label{bit-1}}

\hypertarget{bit64-1}{%
\section{bit64}\label{bit64-1}}

\hypertarget{bitops-1}{%
\section{bitops}\label{bitops-1}}

\hypertarget{blob-1}{%
\section{blob}\label{blob-1}}

\hypertarget{blogdown}{%
\section{blogdown}\label{blogdown}}

\hypertarget{bookdown}{%
\section{bookdown}\label{bookdown}}

\hypertarget{boot-1}{%
\section{boot}\label{boot-1}}

\hypertarget{brew}{%
\section{brew}\label{brew}}

\hypertarget{bridgesampling}{%
\section{bridgesampling}\label{bridgesampling}}

\hypertarget{brms}{%
\section{brms}\label{brms}}

\hypertarget{brobdingnag}{%
\section{Brobdingnag}\label{brobdingnag}}

\hypertarget{broom-2}{%
\section{broom}\label{broom-2}}

\hypertarget{bsmd-1}{%
\section{BsMD}\label{bsmd-1}}

\hypertarget{ca-1}{%
\section{ca}\label{ca-1}}

\hypertarget{cairodevice}{%
\section{cairoDevice}\label{cairodevice}}

\hypertarget{callr}{%
\section{callr}\label{callr}}

\hypertarget{car-1}{%
\section{car}\label{car-1}}

\hypertarget{cardata}{%
\section{carData}\label{cardata}}

\hypertarget{carbonate}{%
\section{carbonate}\label{carbonate}}

\url{https://yonicd.github.io/carbonate/}

\url{https://carbon.now.sh/}

\hypertarget{catools-1}{%
\section{caTools}\label{catools-1}}

\hypertarget{cellranger-1}{%
\section{cellranger}\label{cellranger-1}}

\hypertarget{checkmate-1}{%
\section{checkmate}\label{checkmate-1}}

\hypertarget{class-1}{%
\section{class}\label{class-1}}

\hypertarget{classint}{%
\section{classInt}\label{classint}}

\hypertarget{cli}{%
\section{cli}\label{cli}}

\hypertarget{clipr}{%
\section{clipr}\label{clipr}}

\hypertarget{clisymbols}{%
\section{clisymbols}\label{clisymbols}}

\hypertarget{clue}{%
\section{clue}\label{clue}}

\hypertarget{cluster-1}{%
\section{cluster}\label{cluster-1}}

\hypertarget{clv-1}{%
\section{clv}\label{clv-1}}

\hypertarget{cmaker}{%
\section{cmaker}\label{cmaker}}

\hypertarget{cmprsk}{%
\section{cmprsk}\label{cmprsk}}

\hypertarget{coauthornetwork-1}{%
\section{coauthornetwork}\label{coauthornetwork-1}}

\hypertarget{cobs}{%
\section{cobs}\label{cobs}}

\hypertarget{coda-1}{%
\section{coda}\label{coda-1}}

\hypertarget{codedepends}{%
\section{CodeDepends}\label{codedepends}}

\hypertarget{codetools-1}{%
\section{codetools}\label{codetools-1}}

\hypertarget{coin-1}{%
\section{coin}\label{coin-1}}

\hypertarget{colorspace-1}{%
\section{colorspace}\label{colorspace-1}}

\hypertarget{colourpicker}{%
\section{colourpicker}\label{colourpicker}}

\hypertarget{combinat-1}{%
\section{combinat}\label{combinat-1}}

\hypertarget{commonmark}{%
\section{commonmark}\label{commonmark}}

\hypertarget{compiler-1}{%
\section{compiler}\label{compiler-1}}

\hypertarget{conf.design-1}{%
\section{conf.design}\label{conf.design-1}}

\hypertarget{config}{%
\section{config}\label{config}}

\hypertarget{conflicted-1}{%
\section{conflicted}\label{conflicted-1}}

\hypertarget{contfrac}{%
\section{contfrac}\label{contfrac}}

\hypertarget{corpcor}{%
\section{corpcor}\label{corpcor}}

\hypertarget{covr}{%
\section{covr}\label{covr}}

\hypertarget{cowplot}{%
\section{cowplot}\label{cowplot}}

\hypertarget{coxme}{%
\section{coxme}\label{coxme}}

\hypertarget{cramer}{%
\section{cramer}\label{cramer}}

\hypertarget{crayon}{%
\section{crayon}\label{crayon}}

\hypertarget{cronr}{%
\section{cronR}\label{cronr}}

\hypertarget{crosstalk}{%
\section{crosstalk}\label{crosstalk}}

\hypertarget{csvy}{%
\section{csvy}\label{csvy}}

\hypertarget{curl-1}{%
\section{curl}\label{curl-1}}

\hypertarget{d3network}{%
\section{d3Network}\label{d3network}}

\hypertarget{data.table-2}{%
\section{data.table}\label{data.table-2}}

\hypertarget{data.tree}{%
\section{data.tree}\label{data.tree}}

\hypertarget{datapasta}{%
\section{datapasta}\label{datapasta}}

\url{https://github.com/MilesMcBain/datapasta}

\hypertarget{datasets-1}{%
\section{datasets}\label{datasets-1}}

\hypertarget{date-1}{%
\section{date}\label{date-1}}

\hypertarget{dbi-1}{%
\section{DBI}\label{dbi-1}}

\hypertarget{dbplyr}{%
\section{dbplyr}\label{dbplyr}}

\hypertarget{debugme}{%
\section{debugme}\label{debugme}}

\hypertarget{deducer-1}{%
\section{Deducer}\label{deducer-1}}

\hypertarget{deducerextras}{%
\section{DeducerExtras}\label{deducerextras}}

\hypertarget{demography}{%
\section{demography}\label{demography}}

\hypertarget{dendextend}{%
\section{dendextend}\label{dendextend}}

\hypertarget{deoptimr}{%
\section{DEoptimR}\label{deoptimr}}

\hypertarget{depthtools-1}{%
\section{depthTools}\label{depthtools-1}}

\hypertarget{desc}{%
\section{desc}\label{desc}}

\hypertarget{descr1}{%
\section{descr1}\label{descr1}}

\hypertarget{desctools}{%
\section{DescTools}\label{desctools}}

\hypertarget{desolve}{%
\section{deSolve}\label{desolve}}

\hypertarget{devtools}{%
\section{devtools}\label{devtools}}

\hypertarget{diagrammer-1}{%
\section{DiagrammeR}\label{diagrammer-1}}

\hypertarget{dicedesign-1}{%
\section{DiceDesign}\label{dicedesign-1}}

\hypertarget{dichromat-1}{%
\section{dichromat}\label{dichromat-1}}

\hypertarget{digest-1}{%
\section{digest}\label{digest-1}}

\hypertarget{diptest}{%
\section{diptest}\label{diptest}}

\hypertarget{doe.base-1}{%
\section{DoE.base}\label{doe.base-1}}

\hypertarget{doe.wrapper-1}{%
\section{DoE.wrapper}\label{doe.wrapper-1}}

\hypertarget{doparallel-1}{%
\section{doParallel}\label{doparallel-1}}

\hypertarget{downloader}{%
\section{downloader}\label{downloader}}

\hypertarget{dplyr-1}{%
\section{dplyr}\label{dplyr-1}}

\hypertarget{dt-1}{%
\section{DT}\label{dt-1}}

\hypertarget{dtplyr}{%
\section{dtplyr}\label{dtplyr}}

\hypertarget{dunn.test}{%
\section{dunn.test}\label{dunn.test}}

\hypertarget{dygraphs}{%
\section{dygraphs}\label{dygraphs}}

\hypertarget{e1071-1}{%
\section{e1071}\label{e1071-1}}

\hypertarget{ecovirtual}{%
\section{EcoVirtual}\label{ecovirtual}}

\hypertarget{effects-1}{%
\section{effects}\label{effects-1}}

\hypertarget{effsize}{%
\section{effsize}\label{effsize}}

\hypertarget{ellipse}{%
\section{ellipse}\label{ellipse}}

\hypertarget{elliptic}{%
\section{elliptic}\label{elliptic}}

\hypertarget{emmeans}{%
\section{emmeans}\label{emmeans}}

\hypertarget{enc}{%
\section{enc}\label{enc}}

\hypertarget{enmisc-1}{%
\section{ENmisc}\label{enmisc-1}}

\hypertarget{epi}{%
\section{Epi}\label{epi}}

\hypertarget{epibasix}{%
\section{epibasix}\label{epibasix}}

\hypertarget{epidisplay}{%
\section{epiDisplay}\label{epidisplay}}

\hypertarget{epir-2}{%
\section{epiR}\label{epir-2}}

\hypertarget{epitools}{%
\section{epitools}\label{epitools}}

\hypertarget{errorist}{%
\section{errorist}\label{errorist}}

Automatic Error and Warning Search

\url{https://github.com/coatless/errorist}

\hypertarget{estimability-1}{%
\section{estimability}\label{estimability-1}}

\hypertarget{etm}{%
\section{etm}\label{etm}}

\hypertarget{evaluate-1}{%
\section{evaluate}\label{evaluate-1}}

\hypertarget{exact2x2}{%
\section{exact2x2}\label{exact2x2}}

\hypertarget{exactci}{%
\section{exactci}\label{exactci}}

\hypertarget{exactranktests}{%
\section{exactRankTests}\label{exactranktests}}

\hypertarget{experiment}{%
\section{experiment}\label{experiment}}

\hypertarget{expm}{%
\section{expm}\label{expm}}

\hypertarget{extrantsr}{%
\section{extrantsr}\label{extrantsr}}

\hypertarget{ez-1}{%
\section{ez}\label{ez-1}}

\hypertarget{factominer}{%
\section{FactoMineR}\label{factominer}}

\hypertarget{fahrmeir}{%
\section{Fahrmeir}\label{fahrmeir}}

\hypertarget{fansi}{%
\section{fansi}\label{fansi}}

\hypertarget{fastmatch}{%
\section{fastmatch}\label{fastmatch}}

\hypertarget{fbasics}{%
\section{fBasics}\label{fbasics}}

\hypertarget{fda}{%
\section{fda}\label{fda}}

\hypertarget{fdrtool}{%
\section{fdrtool}\label{fdrtool}}

\hypertarget{feather}{%
\section{feather}\label{feather}}

\hypertarget{ff}{%
\section{ff}\label{ff}}

\hypertarget{ffbase}{%
\section{ffbase}\label{ffbase}}

\hypertarget{finalfit-4}{%
\section{finalfit}\label{finalfit-4}}

\hypertarget{fit.models}{%
\section{fit.models}\label{fit.models}}

\hypertarget{fivethirtyeight}{%
\section{fivethirtyeight}\label{fivethirtyeight}}

\hypertarget{flashclust}{%
\section{flashClust}\label{flashclust}}

\hypertarget{flatxml-1}{%
\section{flatxml}\label{flatxml-1}}

\hypertarget{flexclust-1}{%
\section{flexclust}\label{flexclust-1}}

\hypertarget{flexmix}{%
\section{flexmix}\label{flexmix}}

\hypertarget{flextable}{%
\section{flextable}\label{flextable}}

\hypertarget{fnn}{%
\section{FNN}\label{fnn}}

\hypertarget{forcats-1}{%
\section{forcats}\label{forcats-1}}

\hypertarget{foreach-1}{%
\section{foreach}\label{foreach-1}}

\hypertarget{forecast}{%
\section{forecast}\label{forecast}}

\hypertarget{forecasthybrid}{%
\section{forecastHybrid}\label{forecasthybrid}}

\hypertarget{foreign-1}{%
\section{foreign}\label{foreign-1}}

\hypertarget{formatr-1}{%
\section{formatR}\label{formatr-1}}

\hypertarget{formattable-3}{%
\section{formattable}\label{formattable-3}}

\hypertarget{formula-1}{%
\section{Formula}\label{formula-1}}

\hypertarget{fpc}{%
\section{fpc}\label{fpc}}

\hypertarget{fracdiff-1}{%
\section{fracdiff}\label{fracdiff-1}}

\hypertarget{frf2-1}{%
\section{FrF2}\label{frf2-1}}

\hypertarget{fslr}{%
\section{fslr}\label{fslr}}

\hypertarget{fst}{%
\section{fst}\label{fst}}

\hypertarget{ftsa}{%
\section{ftsa}\label{ftsa}}

\hypertarget{gdata-1}{%
\section{gdata}\label{gdata-1}}

\hypertarget{gdtools}{%
\section{gdtools}\label{gdtools}}

\hypertarget{gee}{%
\section{gee}\label{gee}}

\hypertarget{getpass}{%
\section{getPass}\label{getpass}}

\hypertarget{ggally}{%
\section{GGally}\label{ggally}}

\hypertarget{ggcorrplot}{%
\section{ggcorrplot}\label{ggcorrplot}}

\hypertarget{ggdendro}{%
\section{ggdendro}\label{ggdendro}}

\hypertarget{ggextra-1}{%
\section{ggExtra}\label{ggextra-1}}

\hypertarget{ggforce-1}{%
\section{ggforce}\label{ggforce-1}}

\hypertarget{ggformula}{%
\section{ggformula}\label{ggformula}}

\hypertarget{ggfortify}{%
\section{ggfortify}\label{ggfortify}}

\hypertarget{ggm}{%
\section{ggm}\label{ggm}}

\hypertarget{ggplot2-2}{%
\section{ggplot2}\label{ggplot2-2}}

\hypertarget{ggplot2movies}{%
\section{ggplot2movies}\label{ggplot2movies}}

\hypertarget{ggpubr-2}{%
\section{ggpubr}\label{ggpubr-2}}

\hypertarget{ggraph}{%
\section{ggraph}\label{ggraph}}

\hypertarget{ggrepel}{%
\section{ggrepel}\label{ggrepel}}

\hypertarget{ggridges}{%
\section{ggridges}\label{ggridges}}

\hypertarget{ggsci}{%
\section{ggsci}\label{ggsci}}

\hypertarget{ggsignif}{%
\section{ggsignif}\label{ggsignif}}

\hypertarget{ggstance}{%
\section{ggstance}\label{ggstance}}

\hypertarget{ggstatsplot-1}{%
\section{ggstatsplot}\label{ggstatsplot-1}}

\hypertarget{ggthemes-1}{%
\section{ggthemes}\label{ggthemes-1}}

\hypertarget{ggvis-1}{%
\section{ggvis}\label{ggvis-1}}

\hypertarget{gh}{%
\section{gh}\label{gh}}

\hypertarget{git2r}{%
\section{git2r}\label{git2r}}

\hypertarget{glasso}{%
\section{glasso}\label{glasso}}

\hypertarget{glmmtmb}{%
\section{glmmTMB}\label{glmmtmb}}

\hypertarget{glue-3}{%
\section{glue}\label{glue-3}}

\hypertarget{gmailr}{%
\section{gmailr}\label{gmailr}}

\hypertarget{gmodels}{%
\section{gmodels}\label{gmodels}}

\hypertarget{gmp}{%
\section{gmp}\label{gmp}}

\hypertarget{gnm}{%
\section{gnm}\label{gnm}}

\hypertarget{googledrive}{%
\section{googledrive}\label{googledrive}}

\url{https://googledrive.tidyverse.org/}

\hypertarget{markdrive}{%
\section{markdrive}\label{markdrive}}

\url{https://github.com/MilesMcBain/markdrive}

\hypertarget{googlevis}{%
\section{googleVis}\label{googlevis}}

\hypertarget{gparotation}{%
\section{GPArotation}\label{gparotation}}

\hypertarget{gplots}{%
\section{gplots}\label{gplots}}

\hypertarget{graph}{%
\section{graph}\label{graph}}

\hypertarget{graphics-1}{%
\section{graphics}\label{graphics-1}}

\hypertarget{graphtweets}{%
\section{graphTweets}\label{graphtweets}}

\hypertarget{grdevices-1}{%
\section{grDevices}\label{grdevices-1}}

\hypertarget{grid-1}{%
\section{grid}\label{grid-1}}

\hypertarget{gridextra-1}{%
\section{gridExtra}\label{gridextra-1}}

\hypertarget{gsl}{%
\section{gsl}\label{gsl}}

\hypertarget{gss}{%
\section{gss}\label{gss}}

\hypertarget{gtable-1}{%
\section{gtable}\label{gtable-1}}

\hypertarget{gtools-1}{%
\section{gtools}\label{gtools-1}}

\hypertarget{gwidgets}{%
\section{gWidgets}\label{gwidgets}}

\hypertarget{gwidgetstcltk}{%
\section{gWidgetstcltk}\label{gwidgetstcltk}}

\hypertarget{gwrm}{%
\section{GWRM}\label{gwrm}}

\hypertarget{h2o-1}{%
\section{h2o}\label{h2o-1}}

\hypertarget{hash}{%
\section{hash}\label{hash}}

\hypertarget{haven-1}{%
\section{haven}\label{haven-1}}

\hypertarget{hdrcde}{%
\section{hdrcde}\label{hdrcde}}

\hypertarget{hexbin}{%
\section{hexbin}\label{hexbin}}

\hypertarget{hh}{%
\section{HH}\label{hh}}

\hypertarget{highlight}{%
\section{highlight}\label{highlight}}

\hypertarget{highr-1}{%
\section{highr}\label{highr-1}}

\hypertarget{hmisc-1}{%
\section{Hmisc}\label{hmisc-1}}

\hypertarget{hms-1}{%
\section{hms}\label{hms-1}}

\hypertarget{htmltable-2}{%
\section{htmlTable}\label{htmltable-2}}

\hypertarget{htmltools-1}{%
\section{htmltools}\label{htmltools-1}}

\hypertarget{htmlwidgets-1}{%
\section{htmlwidgets}\label{htmlwidgets-1}}

\hypertarget{httpuv-1}{%
\section{httpuv}\label{httpuv-1}}

\hypertarget{httr-1}{%
\section{httr}\label{httr-1}}

\hypertarget{huge}{%
\section{huge}\label{huge}}

\hypertarget{hunspell}{%
\section{hunspell}\label{hunspell}}

\hypertarget{hypergeo}{%
\section{hypergeo}\label{hypergeo}}

\hypertarget{icc}{%
\section{ICC}\label{icc}}

\hypertarget{irdisplay}{%
\section{IRdisplay}\label{irdisplay}}

\hypertarget{irkernel}{%
\section{IRkernel}\label{irkernel}}

\hypertarget{islr}{%
\section{ISLR}\label{islr}}

\hypertarget{iswr}{%
\section{ISwR}\label{iswr}}

\hypertarget{itkr}{%
\section{ITKR}\label{itkr}}

\hypertarget{igraph-1}{%
\section{igraph}\label{igraph-1}}

\hypertarget{influencer}{%
\section{influenceR}\label{influencer}}

\hypertarget{ini}{%
\section{ini}\label{ini}}

\hypertarget{inline}{%
\section{inline}\label{inline}}

\hypertarget{ipred}{%
\section{ipred}\label{ipred}}

\hypertarget{irlba-1}{%
\section{irlba}\label{irlba-1}}

\hypertarget{irr}{%
\section{irr}\label{irr}}

\hypertarget{iterators-1}{%
\section{iterators}\label{iterators-1}}

\hypertarget{javagd}{%
\section{JavaGD}\label{javagd}}

\hypertarget{jgr}{%
\section{JGR}\label{jgr}}

\hypertarget{jmv}{%
\section{jmv}\label{jmv}}

\hypertarget{jmvcore}{%
\section{jmvcore}\label{jmvcore}}

\hypertarget{jmvconnect}{%
\section{jmvconnect}\label{jmvconnect}}

\url{https://cran.r-project.org/package=jmvconnect}

\hypertarget{jomo}{%
\section{jomo}\label{jomo}}

\hypertarget{jose}{%
\section{jose}\label{jose}}

\hypertarget{jpeg}{%
\section{jpeg}\label{jpeg}}

\hypertarget{jsonlite-1}{%
\section{jsonlite}\label{jsonlite-1}}

\hypertarget{kableextra}{%
\section{kableExtra}\label{kableextra}}

\hypertarget{kernlab}{%
\section{kernlab}\label{kernlab}}

\hypertarget{kernsmooth-1}{%
\section{KernSmooth}\label{kernsmooth-1}}

\hypertarget{klar}{%
\section{klaR}\label{klar}}

\hypertarget{km.ci}{%
\section{km.ci}\label{km.ci}}

\hypertarget{kmsurv}{%
\section{KMsurv}\label{kmsurv}}

\hypertarget{knitr-1}{%
\section{knitr}\label{knitr-1}}

\hypertarget{kohonen}{%
\section{kohonen}\label{kohonen}}

\hypertarget{ks}{%
\section{ks}\label{ks}}

\hypertarget{labeling-1}{%
\section{labeling}\label{labeling-1}}

\hypertarget{labelled}{%
\section{labelled}\label{labelled}}

\hypertarget{lahman}{%
\section{Lahman}\label{lahman}}

\hypertarget{later}{%
\section{later}\label{later}}

\hypertarget{lattice-1}{%
\section{lattice}\label{lattice-1}}

\hypertarget{latticeextra-1}{%
\section{latticeExtra}\label{latticeextra-1}}

\hypertarget{lava}{%
\section{lava}\label{lava}}

\hypertarget{lavaan}{%
\section{lavaan}\label{lavaan}}

\hypertarget{lazyeval-1}{%
\section{lazyeval}\label{lazyeval-1}}

\hypertarget{leaps-1}{%
\section{leaps}\label{leaps-1}}

\hypertarget{lfstat}{%
\section{lfstat}\label{lfstat}}

\hypertarget{lhs-1}{%
\section{lhs}\label{lhs-1}}

\hypertarget{lintr}{%
\section{lintr}\label{lintr}}

\hypertarget{lisreltor}{%
\section{lisrelToR}\label{lisreltor}}

\hypertarget{lme4-1}{%
\section{lme4}\label{lme4-1}}

\hypertarget{lmertest}{%
\section{lmerTest}\label{lmertest}}

\hypertarget{lmom}{%
\section{lmom}\label{lmom}}

\hypertarget{lmomrfa}{%
\section{lmomRFA}\label{lmomrfa}}

\hypertarget{lmtest-2}{%
\section{lmtest}\label{lmtest-2}}

\hypertarget{locfit}{%
\section{locfit}\label{locfit}}

\hypertarget{loo}{%
\section{loo}\label{loo}}

\hypertarget{lpsolve}{%
\section{lpSolve}\label{lpsolve}}

\hypertarget{lubridate-1}{%
\section{lubridate}\label{lubridate-1}}

\hypertarget{mad}{%
\section{MAd}\label{mad}}

\hypertarget{magic}{%
\section{magic}\label{magic}}

\hypertarget{magicfor}{%
\section{magicfor}\label{magicfor}}

\url{https://cran.r-project.org/web/packages/magicfor/vignettes/magicfor.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
magicfor::magic_for(silent = TRUE)

for (i in 1:3) {
  squared <- i ^ 2
  cubed <- i ^ 3
  put(squared, cubed)
}

magicfor::magic_result_as_dataframe()
\end{verbatim}

\hypertarget{magrittr-1}{%
\section{magrittr}\label{magrittr-1}}

\hypertarget{manipulate}{%
\section{manipulate}\label{manipulate}}

\hypertarget{manipulatewidget}{%
\section{manipulateWidget}\label{manipulatewidget}}

\hypertarget{mapproj}{%
\section{mapproj}\label{mapproj}}

\hypertarget{maps}{%
\section{maps}\label{maps}}

\hypertarget{maptools}{%
\section{maptools}\label{maptools}}

\hypertarget{markdown-1}{%
\section{markdown}\label{markdown-1}}

\hypertarget{mass-1}{%
\section{MASS}\label{mass-1}}

\hypertarget{matrix-1}{%
\section{Matrix}\label{matrix-1}}

\hypertarget{matrixcalc-1}{%
\section{matrixcalc}\label{matrixcalc-1}}

\hypertarget{matrixmodels-1}{%
\section{MatrixModels}\label{matrixmodels-1}}

\hypertarget{matrixstats}{%
\section{matrixStats}\label{matrixstats}}

\hypertarget{maxstat}{%
\section{maxstat}\label{maxstat}}

\hypertarget{mbess}{%
\section{MBESS}\label{mbess}}

\hypertarget{mc2d}{%
\section{mc2d}\label{mc2d}}

\hypertarget{mclust}{%
\section{mclust}\label{mclust}}

\hypertarget{memisc}{%
\section{memisc}\label{memisc}}

\hypertarget{memoise-1}{%
\section{memoise}\label{memoise-1}}

\hypertarget{meta}{%
\section{meta}\label{meta}}

\hypertarget{metafor}{%
\section{metafor}\label{metafor}}

\hypertarget{methods-1}{%
\section{methods}\label{methods-1}}

\hypertarget{mgcv-1}{%
\section{mgcv}\label{mgcv-1}}

\hypertarget{mi-1}{%
\section{mi}\label{mi-1}}

\hypertarget{mice}{%
\section{mice}\label{mice}}

\url{http://www.stefvanbuuren.nl/mi/FIMD.html}

\begin{itemize}
\tightlist
\item
  Flexible Imputation of Missing Data
\end{itemize}

\url{https://stefvanbuuren.name/fimd/}

\hypertarget{microbenchmark}{%
\section{microbenchmark}\label{microbenchmark}}

\hypertarget{mime-1}{%
\section{mime}\label{mime-1}}

\hypertarget{miniui}{%
\section{miniUI}\label{miniui}}

\hypertarget{minpack.lm}{%
\section{minpack.lm}\label{minpack.lm}}

\hypertarget{minqa-1}{%
\section{minqa}\label{minqa-1}}

\hypertarget{misc3d}{%
\section{misc3d}\label{misc3d}}

\hypertarget{mitml}{%
\section{mitml}\label{mitml}}

\hypertarget{mixlm}{%
\section{mixlm}\label{mixlm}}

\hypertarget{mixomics}{%
\section{mixOmics}\label{mixomics}}

\hypertarget{mlbench}{%
\section{mlbench}\label{mlbench}}

\hypertarget{mnormt-1}{%
\section{mnormt}\label{mnormt-1}}

\hypertarget{modelr-1}{%
\section{modelr}\label{modelr-1}}

\hypertarget{modeltools-1}{%
\section{modeltools}\label{modeltools-1}}

\hypertarget{mosaic}{%
\section{mosaic}\label{mosaic}}

\url{https://github.com/ProjectMOSAIC/mosaic/blob/master/vignettes/mosaic-resources.Rmd}

\url{http://mosaic-web.org/}

\hypertarget{mosaiccore}{%
\section{mosaicCore}\label{mosaiccore}}

\hypertarget{mosaicdata}{%
\section{mosaicData}\label{mosaicdata}}

\hypertarget{multcomp-1}{%
\section{multcomp}\label{multcomp-1}}

\hypertarget{multcompview}{%
\section{multcompView}\label{multcompview}}

\hypertarget{multicool}{%
\section{multicool}\label{multicool}}

\hypertarget{mumin}{%
\section{MuMIn}\label{mumin}}

\hypertarget{munsell-1}{%
\section{munsell}\label{munsell-1}}

\hypertarget{mvnormtest}{%
\section{mvnormtest}\label{mvnormtest}}

\hypertarget{mvtnorm-1}{%
\section{mvtnorm}\label{mvtnorm-1}}

\hypertarget{network}{%
\section{network}\label{network}}

\hypertarget{networkd3}{%
\section{networkD3}\label{networkd3}}

\hypertarget{neurobase}{%
\section{neurobase}\label{neurobase}}

\hypertarget{neuroim}{%
\section{neuroim}\label{neuroim}}

\hypertarget{nfactors}{%
\section{nFactors}\label{nfactors}}

\hypertarget{nleqslv}{%
\section{nleqslv}\label{nleqslv}}

\hypertarget{nlme-1}{%
\section{nlme}\label{nlme-1}}

\hypertarget{nloptr-1}{%
\section{nloptr}\label{nloptr-1}}

\hypertarget{nlp-1}{%
\section{NLP}\label{nlp-1}}

\hypertarget{nnet-1}{%
\section{nnet}\label{nnet-1}}

\hypertarget{nortest-1}{%
\section{nortest}\label{nortest-1}}

\hypertarget{nparld}{%
\section{nparLD}\label{nparld}}

\hypertarget{numbers}{%
\section{numbers}\label{numbers}}

\hypertarget{numderiv}{%
\section{numDeriv}\label{numderiv}}

\hypertarget{nycflights13}{%
\section{nycflights13}\label{nycflights13}}

\hypertarget{oceanview}{%
\section{OceanView}\label{oceanview}}

\hypertarget{officer}{%
\section{officer}\label{officer}}

\hypertarget{openmx}{%
\section{OpenMx}\label{openmx}}

\hypertarget{openssl-1}{%
\section{openssl}\label{openssl-1}}

\hypertarget{openxlsx}{%
\section{openxlsx}\label{openxlsx}}

\hypertarget{optimclassifier}{%
\section{OptimClassifier}\label{optimclassifier}}

\hypertarget{ordinal-1}{%
\section{ordinal}\label{ordinal-1}}

\hypertarget{orloca-1}{%
\section{orloca}\label{orloca-1}}

\hypertarget{orloca.es-1}{%
\section{orloca.es}\label{orloca.es-1}}

\hypertarget{oro.dicom}{%
\section{oro.dicom}\label{oro.dicom}}

\hypertarget{oro.nifti}{%
\section{oro.nifti}\label{oro.nifti}}

\hypertarget{packagefinder}{%
\section{packagefinder}\label{packagefinder}}

\hypertarget{packrat}{%
\section{packrat}\label{packrat}}

\hypertarget{pacman}{%
\section{pacman}\label{pacman}}

\hypertarget{pan}{%
\section{pan}\label{pan}}

\hypertarget{pander}{%
\section{pander}\label{pander}}

\hypertarget{paper-2}{%
\section{papeR}\label{paper-2}}

\hypertarget{parallel-1}{%
\section{parallel}\label{parallel-1}}

\hypertarget{party}{%
\section{party}\label{party}}

\hypertarget{pbapply}{%
\section{pbapply}\label{pbapply}}

\hypertarget{pbdzmq}{%
\section{pbdZMQ}\label{pbdzmq}}

\hypertarget{pbivnorm}{%
\section{pbivnorm}\label{pbivnorm}}

\hypertarget{pbkrtest-1}{%
\section{pbkrtest}\label{pbkrtest-1}}

\hypertarget{pcapp}{%
\section{pcaPP}\label{pcapp}}

\hypertarget{permute}{%
\section{permute}\label{permute}}

\hypertarget{phia}{%
\section{phia}\label{phia}}

\hypertarget{pillar}{%
\section{pillar}\label{pillar}}

\hypertarget{pkgbuild}{%
\section{pkgbuild}\label{pkgbuild}}

\hypertarget{pkgconfig-1}{%
\section{pkgconfig}\label{pkgconfig-1}}

\hypertarget{pkgload}{%
\section{pkgload}\label{pkgload}}

\hypertarget{pki}{%
\section{PKI}\label{pki}}

\hypertarget{plogr-1}{%
\section{plogr}\label{plogr-1}}

\hypertarget{plot3d}{%
\section{plot3D}\label{plot3d}}

\hypertarget{plot3drgl}{%
\section{plot3Drgl}\label{plot3drgl}}

\hypertarget{plotly}{%
\section{plotly}\label{plotly}}

\hypertarget{pls}{%
\section{pls}\label{pls}}

\hypertarget{plyr-1}{%
\section{plyr}\label{plyr-1}}

\hypertarget{pmcmr}{%
\section{PMCMR}\label{pmcmr}}

\hypertarget{png}{%
\section{png}\label{png}}

\hypertarget{popepi-1}{%
\section{popEpi}\label{popepi-1}}

\hypertarget{ppcor}{%
\section{ppcor}\label{ppcor}}

\hypertarget{prabclus}{%
\section{prabclus}\label{prabclus}}

\hypertarget{pracma}{%
\section{pracma}\label{pracma}}

\hypertarget{praise}{%
\section{praise}\label{praise}}

\hypertarget{prediction}{%
\section{prediction}\label{prediction}}

\hypertarget{prettydoc}{%
\section{prettydoc}\label{prettydoc}}

\hypertarget{prettyr}{%
\section{prettyR}\label{prettyr}}

\hypertarget{prettyunits}{%
\section{prettyunits}\label{prettyunits}}

\hypertarget{proc}{%
\section{pROC}\label{proc}}

\hypertarget{processx}{%
\section{processx}\label{processx}}

\hypertarget{prodlim}{%
\section{prodlim}\label{prodlim}}

\hypertarget{progress}{%
\section{progress}\label{progress}}

\hypertarget{promises}{%
\section{promises}\label{promises}}

\hypertarget{pspearman}{%
\section{pspearman}\label{pspearman}}

\hypertarget{psych-1}{%
\section{psych}\label{psych-1}}

\hypertarget{psycho-1}{%
\section{psycho}\label{psycho-1}}

\hypertarget{pubh}{%
\section{pubh}\label{pubh}}

\hypertarget{purrr-3}{%
\section{purrr}\label{purrr-3}}

\hypertarget{purrrlyr}{%
\section{purrrlyr}\label{purrrlyr}}

\hypertarget{pwr}{%
\section{pwr}\label{pwr}}

\hypertarget{qgraph}{%
\section{qgraph}\label{qgraph}}

\hypertarget{quadprog-1}{%
\section{quadprog}\label{quadprog-1}}

\hypertarget{quantmod-1}{%
\section{quantmod}\label{quantmod-1}}

\hypertarget{quantreg-1}{%
\section{quantreg}\label{quantreg-1}}

\hypertarget{questionr}{%
\section{questionr}\label{questionr}}

\hypertarget{qvcalc}{%
\section{qvcalc}\label{qvcalc}}

\hypertarget{r.cache}{%
\section{R.cache}\label{r.cache}}

\hypertarget{r.matlab}{%
\section{R.matlab}\label{r.matlab}}

\hypertarget{r.methodss3}{%
\section{R.methodsS3}\label{r.methodss3}}

\hypertarget{r.oo}{%
\section{R.oo}\label{r.oo}}

\hypertarget{r.utils}{%
\section{R.utils}\label{r.utils}}

\hypertarget{r2html-1}{%
\section{R2HTML}\label{r2html-1}}

\hypertarget{r6-1}{%
\section{R6}\label{r6-1}}

\hypertarget{rainbow}{%
\section{rainbow}\label{rainbow}}

\hypertarget{rainfreq}{%
\section{rainfreq}\label{rainfreq}}

\hypertarget{randomcolor}{%
\section{randomcoloR}\label{randomcolor}}

\hypertarget{randtests-1}{%
\section{randtests}\label{randtests-1}}

\hypertarget{ranger}{%
\section{ranger}\label{ranger}}

\hypertarget{rapidatetime}{%
\section{RApiDatetime}\label{rapidatetime}}

\hypertarget{rappdirs}{%
\section{rappdirs}\label{rappdirs}}

\hypertarget{rarpack}{%
\section{rARPACK}\label{rarpack}}

\hypertarget{raster}{%
\section{raster}\label{raster}}

\hypertarget{rattle-1}{%
\section{rattle}\label{rattle-1}}

\hypertarget{rcharts}{%
\section{rCharts}\label{rcharts}}

\hypertarget{rcmdcheck}{%
\section{rcmdcheck}\label{rcmdcheck}}

\hypertarget{rcmdr-8}{%
\section{Rcmdr}\label{rcmdr-8}}

\hypertarget{rcmdrmisc-1}{%
\section{RcmdrMisc}\label{rcmdrmisc-1}}

\hypertarget{rcmdrplugin.arnova}{%
\section{RcmdrPlugin.aRnova}\label{rcmdrplugin.arnova}}

\hypertarget{rcmdrplugin.bca-1}{%
\section{RcmdrPlugin.BCA}\label{rcmdrplugin.bca-1}}

\hypertarget{rcmdrplugin.biclustgui}{%
\section{RcmdrPlugin.BiclustGUI}\label{rcmdrplugin.biclustgui}}

\hypertarget{rcmdrplugin.coin-1}{%
\section{RcmdrPlugin.coin}\label{rcmdrplugin.coin-1}}

\hypertarget{rcmdrplugin.depthtools-1}{%
\section{RcmdrPlugin.depthTools}\label{rcmdrplugin.depthtools-1}}

\hypertarget{rcmdrplugin.doe-1}{%
\section{RcmdrPlugin.DoE}\label{rcmdrplugin.doe-1}}

\hypertarget{rcmdrplugin.doex-1}{%
\section{RcmdrPlugin.doex}\label{rcmdrplugin.doex-1}}

\hypertarget{rcmdrplugin.eacspir-1}{%
\section{RcmdrPlugin.EACSPIR}\label{rcmdrplugin.eacspir-1}}

\hypertarget{rcmdrplugin.ebm-1}{%
\section{RcmdrPlugin.EBM}\label{rcmdrplugin.ebm-1}}

\hypertarget{rcmdrplugin.ecovirtual}{%
\section{RcmdrPlugin.EcoVirtual}\label{rcmdrplugin.ecovirtual}}

\hypertarget{rcmdrplugin.epack-1}{%
\section{RcmdrPlugin.epack}\label{rcmdrplugin.epack-1}}

\hypertarget{rcmdrplugin.export}{%
\section{RcmdrPlugin.Export}\label{rcmdrplugin.export}}

\hypertarget{rcmdrplugin.ezr-1}{%
\section{RcmdrPlugin.EZR}\label{rcmdrplugin.ezr-1}}

\hypertarget{rcmdrplugin.factominer}{%
\section{RcmdrPlugin.FactoMineR}\label{rcmdrplugin.factominer}}

\hypertarget{rcmdrplugin.fuzzyclust}{%
\section{RcmdrPlugin.FuzzyClust}\label{rcmdrplugin.fuzzyclust}}

\hypertarget{rcmdrplugin.gwrm}{%
\section{RcmdrPlugin.GWRM}\label{rcmdrplugin.gwrm}}

\hypertarget{rcmdrplugin.hh}{%
\section{RcmdrPlugin.HH}\label{rcmdrplugin.hh}}

\hypertarget{rcmdrplugin.ipsur}{%
\section{RcmdrPlugin.IPSUR}\label{rcmdrplugin.ipsur}}

\hypertarget{rcmdrplugin.kmggplot2-1}{%
\section{RcmdrPlugin.KMggplot2}\label{rcmdrplugin.kmggplot2-1}}

\hypertarget{rcmdrplugin.lfstat}{%
\section{RcmdrPlugin.lfstat}\label{rcmdrplugin.lfstat}}

\hypertarget{rcmdrplugin.ma}{%
\section{RcmdrPlugin.MA}\label{rcmdrplugin.ma}}

\hypertarget{rcmdrplugin.mosaic-1}{%
\section{RcmdrPlugin.mosaic}\label{rcmdrplugin.mosaic-1}}

\hypertarget{rcmdrplugin.mpastats-1}{%
\section{RcmdrPlugin.MPAStats}\label{rcmdrplugin.mpastats-1}}

\hypertarget{rcmdrplugin.nmbu}{%
\section{RcmdrPlugin.NMBU}\label{rcmdrplugin.nmbu}}

\hypertarget{rcmdrplugin.optimclassifier}{%
\section{RcmdrPlugin.OptimClassifier}\label{rcmdrplugin.optimclassifier}}

\hypertarget{rcmdrplugin.orloca-1}{%
\section{RcmdrPlugin.orloca}\label{rcmdrplugin.orloca-1}}

\hypertarget{rcmdrplugin.pcarobust}{%
\section{RcmdrPlugin.PcaRobust}\label{rcmdrplugin.pcarobust}}

\hypertarget{rcmdrplugin.plotbygroup-1}{%
\section{RcmdrPlugin.plotByGroup}\label{rcmdrplugin.plotbygroup-1}}

\hypertarget{rcmdrplugin.pointg}{%
\section{RcmdrPlugin.pointG}\label{rcmdrplugin.pointg}}

\hypertarget{rcmdrplugin.qual-1}{%
\section{RcmdrPlugin.qual}\label{rcmdrplugin.qual-1}}

\hypertarget{rcmdrplugin.riskdemo}{%
\section{RcmdrPlugin.RiskDemo}\label{rcmdrplugin.riskdemo}}

\hypertarget{rcmdrplugin.rmtcjags}{%
\section{RcmdrPlugin.RMTCJags}\label{rcmdrplugin.rmtcjags}}

\hypertarget{rcmdrplugin.roc}{%
\section{RcmdrPlugin.ROC}\label{rcmdrplugin.roc}}

\hypertarget{rcmdrplugin.sampling-1}{%
\section{RcmdrPlugin.sampling}\label{rcmdrplugin.sampling-1}}

\hypertarget{rcmdrplugin.scda-1}{%
\section{RcmdrPlugin.SCDA}\label{rcmdrplugin.scda-1}}

\hypertarget{rcmdrplugin.slc-1}{%
\section{RcmdrPlugin.SLC}\label{rcmdrplugin.slc-1}}

\hypertarget{rcmdrplugin.sm-1}{%
\section{RcmdrPlugin.SM}\label{rcmdrplugin.sm-1}}

\hypertarget{rcmdrplugin.sos}{%
\section{RcmdrPlugin.sos}\label{rcmdrplugin.sos}}

\hypertarget{rcmdrplugin.steepness-1}{%
\section{RcmdrPlugin.steepness}\label{rcmdrplugin.steepness-1}}

\hypertarget{rcmdrplugin.survival-1}{%
\section{RcmdrPlugin.survival}\label{rcmdrplugin.survival-1}}

\hypertarget{rcmdrplugin.sutteforecastr}{%
\section{RcmdrPlugin.sutteForecastR}\label{rcmdrplugin.sutteforecastr}}

\hypertarget{rcmdrplugin.teachingdemos-1}{%
\section{RcmdrPlugin.TeachingDemos}\label{rcmdrplugin.teachingdemos-1}}

\hypertarget{rcmdrplugin.temis-1}{%
\section{RcmdrPlugin.temis}\label{rcmdrplugin.temis-1}}

\hypertarget{rcmdrplugin.uca-1}{%
\section{RcmdrPlugin.UCA}\label{rcmdrplugin.uca-1}}

\hypertarget{rcolorbrewer-2}{%
\section{RColorBrewer}\label{rcolorbrewer-2}}

\hypertarget{rcpp-1}{%
\section{Rcpp}\label{rcpp-1}}

\hypertarget{rcpparmadillo-1}{%
\section{RcppArmadillo}\label{rcpparmadillo-1}}

\hypertarget{rcppeigen-1}{%
\section{RcppEigen}\label{rcppeigen-1}}

\hypertarget{rcurl}{%
\section{RCurl}\label{rcurl}}

\hypertarget{readods}{%
\section{readODS}\label{readods}}

\hypertarget{readr-1}{%
\section{readr}\label{readr-1}}

\hypertarget{readstata13}{%
\section{readstata13}\label{readstata13}}

\hypertarget{readxl-1}{%
\section{readxl}\label{readxl-1}}

\hypertarget{refmanager-1}{%
\section{RefManageR}\label{refmanager-1}}

\hypertarget{relimp-1}{%
\section{relimp}\label{relimp-1}}

\hypertarget{rematch-1}{%
\section{rematch}\label{rematch-1}}

\hypertarget{rematch2}{%
\section{rematch2}\label{rematch2}}

\hypertarget{remotes}{%
\section{remotes}\label{remotes}}

\hypertarget{repr}{%
\section{repr}\label{repr}}

\hypertarget{reprex-1}{%
\section{reprex}\label{reprex-1}}

\hypertarget{reshape-1}{%
\section{reshape}\label{reshape-1}}

\hypertarget{reshape2-1}{%
\section{reshape2}\label{reshape2-1}}

\hypertarget{resourceselection}{%
\section{ResourceSelection}\label{resourceselection}}

\hypertarget{rex}{%
\section{rex}\label{rex}}

\hypertarget{rgexf}{%
\section{rgexf}\label{rgexf}}

\hypertarget{rgl-1}{%
\section{rgl}\label{rgl-1}}

\hypertarget{rgtk2}{%
\section{RGtk2}\label{rgtk2}}

\hypertarget{rhandsontable}{%
\section{rhandsontable}\label{rhandsontable}}

\hypertarget{rismed-2}{%
\section{RISmed}\label{rismed-2}}

\hypertarget{rio-2}{%
\section{rio}\label{rio-2}}

\hypertarget{rjags}{%
\section{rjags}\label{rjags}}

\hypertarget{rjava-1}{%
\section{rJava}\label{rjava-1}}

\hypertarget{rjson}{%
\section{rjson}\label{rjson}}

\hypertarget{rjsonio}{%
\section{RJSONIO}\label{rjsonio}}

\hypertarget{rlang-1}{%
\section{rlang}\label{rlang-1}}

\hypertarget{rmarkdown-1}{%
\section{rmarkdown}\label{rmarkdown-1}}

\hypertarget{rmatio}{%
\section{rmatio}\label{rmatio}}

\hypertarget{rmdformats}{%
\section{rmdformats}\label{rmdformats}}

\hypertarget{rmeta}{%
\section{rmeta}\label{rmeta}}

\hypertarget{rmpfr}{%
\section{Rmpfr}\label{rmpfr}}

\hypertarget{rmysql-1}{%
\section{RMySQL}\label{rmysql-1}}

\hypertarget{rnifti}{%
\section{RNifti}\label{rnifti}}

\hypertarget{robets}{%
\section{robets}\label{robets}}

\hypertarget{robust}{%
\section{robust}\label{robust}}

\hypertarget{robustbase}{%
\section{robustbase}\label{robustbase}}

\hypertarget{rockchalk}{%
\section{rockchalk}\label{rockchalk}}

\hypertarget{rocr}{%
\section{ROCR}\label{rocr}}

\hypertarget{rook}{%
\section{Rook}\label{rook}}

\hypertarget{roomba-1}{%
\section{roomba}\label{roomba-1}}

\hypertarget{roxygen2}{%
\section{roxygen2}\label{roxygen2}}

\hypertarget{rpart-1}{%
\section{rpart}\label{rpart-1}}

\hypertarget{rpart.plot-1}{%
\section{rpart.plot}\label{rpart.plot-1}}

\hypertarget{rpf}{%
\section{rpf}\label{rpf}}

\hypertarget{rpostgresql}{%
\section{RPostgreSQL}\label{rpostgresql}}

\hypertarget{rprojroot-1}{%
\section{rprojroot}\label{rprojroot-1}}

\hypertarget{rrcov}{%
\section{rrcov}\label{rrcov}}

\hypertarget{rsconnect}{%
\section{rsconnect}\label{rsconnect}}

\hypertarget{rsm-1}{%
\section{rsm}\label{rsm-1}}

\hypertarget{rspectra}{%
\section{RSpectra}\label{rspectra}}

\hypertarget{rsqlite-1}{%
\section{RSQLite}\label{rsqlite-1}}

\hypertarget{rstan}{%
\section{rstan}\label{rstan}}

\hypertarget{rstanarm}{%
\section{rstanarm}\label{rstanarm}}

\hypertarget{rstantools}{%
\section{rstantools}\label{rstantools}}

\hypertarget{rstudioapi}{%
\section{rstudioapi}\label{rstudioapi}}

\hypertarget{rstudioconsolerender}{%
\section{RStudioConsoleRender}\label{rstudioconsolerender}}

\hypertarget{rsvd}{%
\section{rsvd}\label{rsvd}}

\hypertarget{rtsne}{%
\section{Rtsne}\label{rtsne}}

\hypertarget{rtweet}{%
\section{rtweet}\label{rtweet}}

\hypertarget{runjags}{%
\section{runjags}\label{runjags}}

\hypertarget{rvaidememoire}{%
\section{RVAideMemoire}\label{rvaidememoire}}

\hypertarget{rversions}{%
\section{rversions}\label{rversions}}

\hypertarget{rvest-1}{%
\section{rvest}\label{rvest-1}}

\hypertarget{rvg}{%
\section{rvg}\label{rvg}}

\url{https://github.com/davidgohel/rvg}

\hypertarget{s4vd}{%
\section{s4vd}\label{s4vd}}

\hypertarget{sampling}{%
\section{sampling}\label{sampling}}

\hypertarget{sandwich-1}{%
\section{sandwich}\label{sandwich-1}}

\hypertarget{scales-2}{%
\section{scales}\label{scales-2}}

\hypertarget{scatr}{%
\section{scatr}\label{scatr}}

\hypertarget{scatterplot3d-1}{%
\section{scatterplot3d}\label{scatterplot3d-1}}

\hypertarget{scholar-2}{%
\section{scholar}\label{scholar-2}}

\hypertarget{scma-1}{%
\section{SCMA}\label{scma-1}}

\hypertarget{scrt-1}{%
\section{SCRT}\label{scrt-1}}

\hypertarget{scva-1}{%
\section{SCVA}\label{scva-1}}

\hypertarget{sde}{%
\section{sde}\label{sde}}

\hypertarget{sdmtools}{%
\section{SDMTools}\label{sdmtools}}

\hypertarget{selectr-1}{%
\section{selectr}\label{selectr-1}}

\hypertarget{sem-1}{%
\section{sem}\label{sem-1}}

\hypertarget{semicomprisks}{%
\section{SemiCompRisks}\label{semicomprisks}}

\hypertarget{semplot}{%
\section{semPlot}\label{semplot}}

\hypertarget{semtools}{%
\section{semTools}\label{semtools}}

\hypertarget{sendmailr}{%
\section{sendmailR}\label{sendmailr}}

\hypertarget{servr}{%
\section{servr}\label{servr}}

\hypertarget{sessioninfo}{%
\section{sessioninfo}\label{sessioninfo}}

\hypertarget{sf}{%
\section{sf}\label{sf}}

\hypertarget{sfsmisc-1}{%
\section{sfsmisc}\label{sfsmisc-1}}

\hypertarget{shape}{%
\section{shape}\label{shape}}

\hypertarget{shiny-2}{%
\section{shiny}\label{shiny-2}}

\hypertarget{shinyfiles}{%
\section{shinyFiles}\label{shinyfiles}}

\hypertarget{shinyjs}{%
\section{shinyjs}\label{shinyjs}}

\hypertarget{shinystan}{%
\section{shinystan}\label{shinystan}}

\hypertarget{shinythemes-1}{%
\section{shinythemes}\label{shinythemes-1}}

\hypertarget{sjlabelled}{%
\section{sjlabelled}\label{sjlabelled}}

\hypertarget{sjmisc}{%
\section{sjmisc}\label{sjmisc}}

\hypertarget{sjstats}{%
\section{sjstats}\label{sjstats}}

\hypertarget{skimr-6}{%
\section{skimr}\label{skimr-6}}

\hypertarget{slam-1}{%
\section{slam}\label{slam-1}}

\hypertarget{slc-1}{%
\section{SLC}\label{slc-1}}

\hypertarget{sleuth2}{%
\section{Sleuth2}\label{sleuth2}}

\hypertarget{smcure}{%
\section{smcure}\label{smcure}}

\hypertarget{sna}{%
\section{sna}\label{sna}}

\hypertarget{snakecase}{%
\section{snakecase}\label{snakecase}}

\hypertarget{som}{%
\section{som}\label{som}}

\hypertarget{sos}{%
\section{sos}\label{sos}}

\hypertarget{sourcetools-1}{%
\section{sourcetools}\label{sourcetools-1}}

\hypertarget{sp}{%
\section{sp}\label{sp}}

\hypertarget{sparklyr}{%
\section{sparklyr}\label{sparklyr}}

\hypertarget{sparsem-1}{%
\section{SparseM}\label{sparsem-1}}

\hypertarget{spatial-1}{%
\section{spatial}\label{spatial-1}}

\hypertarget{spdata}{%
\section{spData}\label{spdata}}

\hypertarget{splines-1}{%
\section{splines}\label{splines-1}}

\hypertarget{splitstackshape-1}{%
\section{splitstackshape}\label{splitstackshape-1}}

\hypertarget{squarem}{%
\section{SQUAREM}\label{squarem}}

\hypertarget{ssanv}{%
\section{ssanv}\label{ssanv}}

\hypertarget{ssgraph}{%
\section{ssgraph}\label{ssgraph}}

\hypertarget{stabledist}{%
\section{stabledist}\label{stabledist}}

\hypertarget{stanheaders}{%
\section{StanHeaders}\label{stanheaders}}

\hypertarget{stapler}{%
\section{stapler}\label{stapler}}

\hypertarget{stargazer-2}{%
\section{stargazer}\label{stargazer-2}}

\hypertarget{statisticalmodeling}{%
\section{statisticalModeling}\label{statisticalmodeling}}

\hypertarget{statnet.common}{%
\section{statnet.common}\label{statnet.common}}

\hypertarget{stats-1}{%
\section{stats}\label{stats-1}}

\hypertarget{stats4-1}{%
\section{stats4}\label{stats4-1}}

\hypertarget{steepness-1}{%
\section{steepness}\label{steepness-1}}

\hypertarget{stencila-1}{%
\section{stencila}\label{stencila-1}}

\hypertarget{stringdist}{%
\section{stringdist}\label{stringdist}}

\hypertarget{stringi-1}{%
\section{stringi}\label{stringi-1}}

\hypertarget{stringr-1}{%
\section{stringr}\label{stringr-1}}

\hypertarget{strucchange}{%
\section{strucchange}\label{strucchange}}

\hypertarget{styler-1}{%
\section{styler}\label{styler-1}}

\hypertarget{superbiclust}{%
\section{superbiclust}\label{superbiclust}}

\hypertarget{suppdists}{%
\section{SuppDists}\label{suppdists}}

\hypertarget{survey-1}{%
\section{survey}\label{survey-1}}

\hypertarget{survival-2}{%
\section{survival}\label{survival-2}}

\hypertarget{survminer-1}{%
\section{survminer}\label{survminer-1}}

\hypertarget{survmisc}{%
\section{survMisc}\label{survmisc}}

\hypertarget{sutteforecastr}{%
\section{sutteForecastR}\label{sutteforecastr}}

\hypertarget{svglite}{%
\section{svglite}\label{svglite}}

\hypertarget{tableone}{%
\section{tableone}\label{tableone}}

\url{https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html}

\hypertarget{tables-2}{%
\section{tables}\label{tables-2}}

\hypertarget{tabplot-1}{%
\section{tabplot}\label{tabplot-1}}

\hypertarget{tangram}{%
\section{tangram}\label{tangram}}

\url{https://github.com/spgarbet/tangram}

\url{https://cran.r-project.org/web/packages/tangram/index.html}

\url{https://cran.r-project.org/web/packages/tangram/vignettes/summary-example.html}

\begin{itemize}
\item
  Global Style for Rmd Example
\end{itemize}

\url{https://cran.r-project.org/web/packages/tangram/vignettes/fda-example.html}

\url{https://cran.r-project.org/web/packages/tangram/vignettes/example.html}

\url{https://cran.r-project.org/web/packages/tangram/vignettes/single-style.html}

\hypertarget{tcltk-1}{%
\section{tcltk}\label{tcltk-1}}

\hypertarget{tcltk2-1}{%
\section{tcltk2}\label{tcltk2-1}}

\hypertarget{teachingdemos-1}{%
\section{TeachingDemos}\label{teachingdemos-1}}

\hypertarget{testit}{%
\section{testit}\label{testit}}

\hypertarget{testthat}{%
\section{testthat}\label{testthat}}

\hypertarget{th.data-1}{%
\section{TH.data}\label{th.data-1}}

\hypertarget{threejs}{%
\section{threejs}\label{threejs}}

\hypertarget{tibble-1}{%
\section{tibble}\label{tibble-1}}

\hypertarget{tidybayes}{%
\section{tidybayes}\label{tidybayes}}

Bayesian analysis + tidy data + geoms

\url{http://mjskay.github.io/tidybayes/}

\hypertarget{tidygraph}{%
\section{tidygraph}\label{tidygraph}}

\hypertarget{tidyr-2}{%
\section{tidyr}\label{tidyr-2}}

\hypertarget{tidyselect}{%
\section{tidyselect}\label{tidyselect}}

\hypertarget{tidyverse-2}{%
\section{tidyverse}\label{tidyverse-2}}

\hypertarget{timedate-1}{%
\section{timeDate}\label{timedate-1}}

\hypertarget{timeseries}{%
\section{timeSeries}\label{timeseries}}

\hypertarget{tinytex}{%
\section{tinytex}\label{tinytex}}

\hypertarget{tkrplot-1}{%
\section{tkrplot}\label{tkrplot-1}}

\hypertarget{tm-2}{%
\section{tm}\label{tm-2}}

\hypertarget{tmb}{%
\section{TMB}\label{tmb}}

\hypertarget{tools-1}{%
\section{tools}\label{tools-1}}

\hypertarget{tree}{%
\section{tree}\label{tree}}

\hypertarget{triebeard}{%
\section{triebeard}\label{triebeard}}

\hypertarget{trimcluster}{%
\section{trimcluster}\label{trimcluster}}

\hypertarget{tseries-1}{%
\section{tseries}\label{tseries-1}}

\hypertarget{ttr-1}{%
\section{TTR}\label{ttr-1}}

\hypertarget{tufterhandout-1}{%
\section{tufterhandout}\label{tufterhandout-1}}

\hypertarget{tutorial}{%
\section{tutorial}\label{tutorial}}

\hypertarget{tweenr}{%
\section{tweenr}\label{tweenr}}

\hypertarget{ucminf-1}{%
\section{ucminf}\label{ucminf-1}}

\hypertarget{units}{%
\section{units}\label{units}}

\hypertarget{updater}{%
\section{updateR}\label{updater}}

\hypertarget{urca}{%
\section{urca}\label{urca}}

\hypertarget{urltools}{%
\section{urltools}\label{urltools}}

\hypertarget{uroot}{%
\section{uroot}\label{uroot}}

\hypertarget{userfriendlyscience}{%
\section{userfriendlyscience}\label{userfriendlyscience}}

\hypertarget{usethis}{%
\section{usethis}\label{usethis}}

\hypertarget{utf8}{%
\section{utf8}\label{utf8}}

\hypertarget{utils-1}{%
\section{utils}\label{utils-1}}

\hypertarget{uuid}{%
\section{uuid}\label{uuid}}

\hypertarget{v8}{%
\section{V8}\label{v8}}

\hypertarget{vcd-1}{%
\section{vcd}\label{vcd-1}}

\hypertarget{vcdextra}{%
\section{vcdExtra}\label{vcdextra}}

\hypertarget{vegan}{%
\section{vegan}\label{vegan}}

\hypertarget{vgam}{%
\section{VGAM}\label{vgam}}

\hypertarget{viewpipesteps}{%
\section{ViewPipeSteps}\label{viewpipesteps}}

\url{https://github.com/daranzolin/ViewPipeSteps}

\hypertarget{viridis-1}{%
\section{viridis}\label{viridis-1}}

\hypertarget{viridislite-1}{%
\section{viridisLite}\label{viridislite-1}}

\hypertarget{visdat}{%
\section{visdat}\label{visdat}}

\hypertarget{visnetwork}{%
\section{visNetwork}\label{visnetwork}}

\hypertarget{visreg}{%
\section{visreg}\label{visreg}}

\hypertarget{wbstats}{%
\section{wbstats}\label{wbstats}}

\hypertarget{webshot}{%
\section{webshot}\label{webshot}}

\hypertarget{whisker}{%
\section{whisker}\label{whisker}}

\hypertarget{whitestripe}{%
\section{WhiteStripe}\label{whitestripe}}

\hypertarget{withr}{%
\section{withr}\label{withr}}

\hypertarget{wordcloud}{%
\section{wordcloud}\label{wordcloud}}

\hypertarget{workflowr}{%
\section{workflowr}\label{workflowr}}

\hypertarget{writexl}{%
\section{writexl}\label{writexl}}

\hypertarget{wrs2}{%
\section{WRS2}\label{wrs2}}

\hypertarget{xfun}{%
\section{xfun}\label{xfun}}

\hypertarget{xlconnect-1}{%
\section{XLConnect}\label{xlconnect-1}}

\hypertarget{xlconnectjars-1}{%
\section{XLConnectJars}\label{xlconnectjars-1}}

\hypertarget{xlsx}{%
\section{xlsx}\label{xlsx}}

\hypertarget{xlsxjars}{%
\section{xlsxjars}\label{xlsxjars}}

\hypertarget{xml}{%
\section{XML}\label{xml}}

\hypertarget{xml2-1}{%
\section{xml2}\label{xml2-1}}

\hypertarget{xplain}{%
\section{xplain}\label{xplain}}

\hypertarget{xray-1}{%
\section{xray}\label{xray-1}}

\hypertarget{xtable-1}{%
\section{xtable}\label{xtable-1}}

\hypertarget{xts-1}{%
\section{xts}\label{xts-1}}

\hypertarget{yaimpute}{%
\section{yaImpute}\label{yaimpute}}

\hypertarget{yaml-1}{%
\section{yaml}\label{yaml-1}}

\hypertarget{zip}{%
\section{zip}\label{zip}}

\hypertarget{zoo-1}{%
\section{zoo}\label{zoo-1}}

\hypertarget{effsize-1}{%
\section{Effsize}\label{effsize-1}}

a package for efficient effect size computation

\url{https://github.com/mtorchiano/effsize}

\hypertarget{keyring}{%
\section{keyring}\label{keyring}}

\url{https://www.infoworld.com/video/91987/r-tip-keep-passwords-and-tokens-secure-with-the-keyring-package}

\hypertarget{testthat-1}{%
\section{testthat}\label{testthat-1}}

R tip: Test your code with testthat

\url{https://www.infoworld.com/video/87735/r-tip-test-your-code-with-testthat}

\hypertarget{cronr-1}{%
\section{cronR}\label{cronr-1}}

Schedule R scripts on a Mac

\url{https://www.infoworld.com/video/90629/r-tip-schedule-r-scripts-on-a-mac}

\hypertarget{sankey-diagrams-1}{%
\chapter{Sankey Diagrams}\label{sankey-diagrams-1}}

\begin{quote}
\url{https://www.r-bloggers.com/creating-custom-sankey-diagrams-using-r/}
\end{quote}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(networkD3)
nodes = data.frame( name  = 
 c( Node A , # Node 0
  Node B , # Node 1
  Node C , # Node 2
  Node D ))# Node 3
links = as.data.frame(matrix(c(
 0, 1, 10, # Each row represents a link. The first number
 0, 2, 20, # represents the node being conntected from. 
 1, 3, 30, # the second number represents the node connected to.
 2, 3, 40),# The third number is the value of the node
 byrow = TRUE, ncol = 3))
names(links) = c( source ,  target ,  value )
sankeyNetwork(Links = links, Nodes = nodes,
 Source =  source , Target =  target ,
 Value =  value , NodeID =  name ,
 fontSize= 12, nodeWidth = 30)
\end{verbatim}

\begin{quote}
\url{https://plot.ly/r/sankey-diagram/}
\end{quote}

\begin{quote}
\url{https://cran.r-project.org/web/packages/riverplot/riverplot.pdf}
\end{quote}

\hypertarget{sensitivity-specificity}{%
\chapter{Sensitivity Specificity}\label{sensitivity-specificity}}

\hypertarget{classification-and-regression-training}{%
\chapter{Classification And REgression Training}\label{classification-and-regression-training}}

\url{http://topepo.github.io/caret/index.html}

\hypertarget{calculate-sensitivity-specificity-and-predictive-values}{%
\section{Calculate Sensitivity, Specificity And Predictive Values}\label{calculate-sensitivity-specificity-and-predictive-values}}

\url{https://www.rdocumentation.org/packages/caret/versions/3.51/topics/sensitivity}

\begin{verbatim}
sensitivity(data, reference, positive = levels(reference)[1])
specificity(data, reference, negative = levels(reference)[2])
posPredValue(data, reference, positive = levels(reference)[1])
negPredValue(data, reference, negative = levels(reference)[2])
\end{verbatim}

\hypertarget{shiny-3}{%
\chapter{Shiny}\label{shiny-3}}

\begin{itemize}
\tightlist
\item
  Some notes on my first shiny app
\end{itemize}

\url{https://ggvy.cl/post/some-notes-on-my-first-shiny-app/}

\hypertarget{shiny-4}{%
\chapter{Shiny}\label{shiny-4}}

\hypertarget{shiny-online-documentation}{%
\chapter{Shiny Online Documentation}\label{shiny-online-documentation}}

\url{https://shiny.rstudio.com}

\hypertarget{mastering-shiny}{%
\chapter{Mastering Shiny}\label{mastering-shiny}}

\url{https://mastering-shiny.org/}

\hypertarget{shinycodes}{%
\chapter{ShinyCodes}\label{shinycodes}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# from CRAN
# install.packages( bs4Dash )
# latest devel version
# devtools::install_github( RinteRface/bs4Dash )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(bs4Dash)
# classic theme
# bs4DashGallery()
# old_school theme
# bs4DashGallery(theme =  old_school )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( argonR )
# devtools::install_github( RinteRface/argonDash )
library(argonR)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{snahelper}{%
\chapter{snahelper}\label{snahelper}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( schochastics/snahelper )
# devtools::install_github( schochastics/smglr )
\end{verbatim}

\url{http://blog.schochastics.net/post/an-rstudio-addin-for-network-analysis-and-visualization/}

\includegraphics{http://blog.schochastics.net/img/example.png}

\hypertarget{introduction-to-summarytools}{%
\chapter{Introduction to summarytools}\label{introduction-to-summarytools}}

author: Dominic Comtois
date:\\
output:
rmarkdown::html\_vignette:
css:
- !expr system.file( rmarkdown/templates/html\_vignette/resources/vignette.css , package = rmarkdown )
- !expr system.file( includes/stylesheets/summarytools.css , package = summarytools )
vignette: \textgreater{}
\%\VignetteIndexEntry{Introduction to summarytools 0.8}
\%\VignetteEngine{knitr::rmarkdown}
\%\VignetteEncoding{UTF-8}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(knitr)
opts_chunk$set(comment=NA, prompt=FALSE, cache=FALSE, results='asis')
library(summarytools)
st_options('footnote', NA)
\end{verbatim}

\emph{summarytools} is an \emph{R} package providing tools
to \emph{neatly and quickly summarize data}. It can also make \emph{R} a little easier to
learn and use. Four functions are at the core of the package:

\begin{itemize}
\tightlist
\item
  \texttt{freq()} : \textbf{frequency tables} with proportions, cumulative
  proportions and missing data information.
\item
  \texttt{ctable()} : \textbf{cross-tabulations} between two factors or any
  discrete data, with total, rows or columns proportions, as well
  as marginal totals.
\item
  \texttt{descr()} : \textbf{descriptive (univariate) statistics} for numerical data.
\item
  \texttt{dfSummary()} : Extensive \textbf{data frame summaries} that facilitate
  data cleaning and firsthand evaluation.
\end{itemize}

An emphasis has been put on both \emph{what} and \emph{how} results are presented, so that the
package can serve both as a data exploration \emph{and} reporting tool, which can be used
either on its own for minimal reports, or along with larger sets of tools such as
RStudio's for \href{http://rmarkdown.rstudio.com/}{rmarkdown}, and \href{https://yihui.name/knitr/}{knitr}.

\textbf{Building on the strengths of \href{https://github.com/Rapporter/pander}{pander} and
\href{https://CRAN.R-project.org/package=htmltools}{htmltools}}, the
outputs produced by summarytools can be:

\begin{itemize}
\tightlist
\item
  Displayed in plain text in the \emph{R} console (default behaviour)
\item
  Used in \emph{Rmardown} documents and \emph{knitted} along with other text and
  \emph{R} output
\item
  Written to \emph{html} files that fire up in
  \href{http://www.rstudio.com/}{\emph{RStudio}}'s Viewer pane or in your
  system's default browser
\item
  Written to plain text files / \emph{Rmarkdown} text files
\end{itemize}

\hypertarget{latest-improvements}{%
\subsection{Latest Improvements}\label{latest-improvements}}

Version 0.8.3 brings several improvements to \emph{summarytools}, notably:

\begin{itemize}
\tightlist
\item
  Introduction of global settings (customizable defaults)
\item
  Options to make content fit more naturally in \emph{shiny} apps or \emph{Rmarkdown} documents
\item
  A better handling of split-group statistics with \texttt{by()}
\item
  A more thorough documentation
\end{itemize}

\hypertarget{summarytools-core-functions}{%
\section{summarytool's Core Functions}\label{summarytools-core-functions}}

\hypertarget{freq-frequency-tables}{%
\section{1 - freq() : Frequency Tables}\label{freq-frequency-tables}}

The \texttt{freq()} function generates a table of frequencies with counts and
proportions. Since this page use \emph{markdown} rendering, we'll set \texttt{style\ =\ \textquotesingle{}rmarkdown\textquotesingle{}} to take advantage of it.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(summarytools)
freq(iris$Species, style =  rmarkdown )
\end{verbatim}

If we do not worry about missing data, we can set \texttt{\{r\ \#\ eport.nas\ =\ FALSE}:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(iris$Species, report.nas = FALSE, style =  rmarkdown , headings = TRUE)
\end{verbatim}

We could simplify further and omit the \emph{Totals} row by setting \texttt{totals\ =\ FALSE}.

To get familiar with the output styles, try different values for \texttt{style=}
and see how results look in the console.

\hypertarget{ctable-cross-tabulations}{%
\section{2 - ctable() : Cross-Tabulations}\label{ctable-cross-tabulations}}

We'll now use a sample data frame called \emph{tobacco}, which is included in
the package. We want to cross-tabulate the two categorical variables
\texttt{smoker} and \texttt{diseased}. By default, \texttt{ctable()} gives row proportions,
but we'll include the full syntax anyway.

Since \emph{markdown} has not support (yet) for multi-line headings, we'll
show an image of the resulting html table.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
with(tobacco, print(ctable(smoker, diseased), method = 'render'))
\end{verbatim}

Notice that instead of \texttt{ctable(tobacco\$smoker,\ tobacco\$diseased,\ ...)},
we used the \texttt{with()} function, making the syntax less redundant.

It is possible to display \emph{column}, \emph{total}, or no proportions at all.
We can also omit the marginal totals to have a simple ``2 x 2'' table.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
with(tobacco, 
     print(ctable(smoker, diseased, prop = 'n', totals = FALSE), 
           headings = TRUE, method =  render ))
\end{verbatim}

\hypertarget{descr-descriptive-univariate-stats}{%
\section{3 - descr() : Descriptive Univariate Stats}\label{descr-descriptive-univariate-stats}}

The \texttt{descr()} function generates common central tendency statistics and
measures of dispersion for numerical data. It can handle single vectors
as well as data frames, in which case it just ignores non-numerical
columns (and displays a message to that effect).

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
descr(iris, style =  rmarkdown )
\end{verbatim}

\hypertarget{transposing-and-selecting-only-the-stats-you-need}{%
\subsection{Transposing and selecting only the stats you need}\label{transposing-and-selecting-only-the-stats-you-need}}

If your eyes/brain prefer seeing things the other way around, just use
\texttt{transpose\ =\ TRUE}. Here, we also select only the statistics we wish to
see, and specify \texttt{headings\ =\ TRUE} to avoid reprinting the same
information as above.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
descr(iris, stats = c( mean ,  sd ,  min ,  med ,  max ), transpose = TRUE, 
      headings = TRUE, style =  rmarkdown )
\end{verbatim}

\hypertarget{dfsummary-data-frame-summaries}{%
\section{4 - dfSummary() : Data Frame Summaries}\label{dfsummary-data-frame-summaries}}

\texttt{dfSummary()} collects information about all variables
in a data frame and displays it in a singe, legible table.

To generate a summary report and have it displayed in
\href{http://www.rstudio.com/}{\emph{RStudio}}'s Viewer pane (or in your default
Web Browser if working with another interface), we simply do like this:

\begin{verbatim}
{r, eval=FALSE}
view(dfSummary(iris))
\end{verbatim}

It is also possible to use \texttt{dfSummary()} in \emph{Rmarkdown} documents. In this next example,
note that due to rmarkdown compatibility issues, histograms are not shown. We're working
on this. Further down, we'll see how tu use \emph{html} rendering to go around this problem.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dfSummary(tobacco, plain.ascii = FALSE, style =  grid )
\end{verbatim}

\hypertarget{the-print-and-view-functions}{%
\section{The print() and view() Functions}\label{the-print-and-view-functions}}

\emph{summarytools} has a generic \texttt{print} method, \texttt{print.summarytools()}. By
default, its \texttt{method} argument is set to \texttt{\textquotesingle{}pander\textquotesingle{}}. One of the ways in
which \texttt{view()} is useful is that we can use it to easily display \emph{html}
outputs in \emph{RStudio}'s Viewer. In this case, the \texttt{view()} function
simply acts as a wrapper around the generic \texttt{print()} function,
specifying the \texttt{method\ =\ \textquotesingle{}viewer\textquotesingle{}} for us. When used outside \emph{RStudio},
the \texttt{method} falls back on \texttt{\textquotesingle{}browser\textquotesingle{}} and the report is fired up in the
system's default browser.

\hypertarget{using-by-to-show-results-by-groups}{%
\section{Using by() to Show Results By Groups}\label{using-by-to-show-results-by-groups}}

With \texttt{freq()} and \texttt{descr()}, you can use \emph{R}'s base function \texttt{by()} to
show statistics split by a ventilation / categorical variable. \emph{R}'s
\texttt{by()} function returns a \texttt{list} containing as many \emph{summarytools} objects
as there are categories in our ventilation variable.

To propertly display the content present in that list, \textbf{we use
the \texttt{view()} function}. Using \texttt{print()}, while technically possible,
will not give as much satisfactory results.

\hypertarget{example}{%
\subsubsection{Example}\label{example}}

Using the \emph{iris} data frame, we will display descriptive statistics
broken down by Species.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# First save the results
iris_stats_by_species <- by(data = iris, 
                            INDICES = iris$Species, 
                            FUN = descr, stats = c( mean ,  sd ,  min ,  med ,  max ), 
                            transpose = TRUE)

# Then use view(), like so:
view(iris_stats_by_species, method =  pander , style =  rmarkdown )
\end{verbatim}

To see an \emph{html} version of these results, we'd simply do this (results not shown):

\begin{verbatim}
{r, eval=FALSE}
view(iris_stats_by_species)
\end{verbatim}

\hypertarget{special-case---using-descr-with-by-for-a-single-variable}{%
\subsection{Special Case - Using descr() With by() For A Single Variable}\label{special-case---using-descr-with-by-for-a-single-variable}}

Instead of showing several tables having only one column each, the
\texttt{view()} function will assemble the results into a single table:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(tobacco) # tobacco is an example dataframe included in the package
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr, 
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown )
\end{verbatim}

The transposed version looks like this:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
BMI_by_age <- with(tobacco, 
                   by(BMI, age.gr, descr,  transpose = TRUE,
                      stats = c( mean ,  sd ,  min ,  med ,  max )))
view(BMI_by_age,  pander , style =  rmarkdown , headings = TRUE)
\end{verbatim}

\hypertarget{using-lapply-to-show-several-freq-tables-at-once}{%
\section{Using lapply() to Show Several freq() tables at once}\label{using-lapply-to-show-several-freq-tables-at-once}}

As is the case for \texttt{by()}, the \texttt{view()} function is essential for making
results nice and tidy.

\begin{verbatim}
{r, eval=FALSE}
tobacco_subset <- tobacco[ ,c( gender ,  age.gr ,  smoker )]
freq_tables <- lapply(tobacco_subset, freq)
view(freq_tables, footnote = NA, file = 'freq-tables.html')
\end{verbatim}

\hypertarget{using-summarytools-in-rmarkdown-documents}{%
\section{Using summarytools in Rmarkdown documents}\label{using-summarytools-in-rmarkdown-documents}}

As we have seen, \emph{summarytools} can generate both text (including
rmarkdown) and html results. Both can be used in Rmarkdown, according to
your preferences. There is a vignette dedicated to this, which gives
several examples, but if you're in a hurry, here are a few tips to
get started:

\begin{itemize}
\tightlist
\item
  Always set the \texttt{knitr} chunk option \texttt{\{r\ \#\ esults\ =\ \textquotesingle{}asis\textquotesingle{}}. You can do
  this on a chunk-by-chunk basis, but here is how to do it globally:
\end{itemize}

\begin{verbatim}
{r, eval=FALSE, tidy=FALSE}
    knitr::opts_chunk$set(echo = TRUE, results = 'asis')
\end{verbatim}

~~~~~~~~~~Refer to \href{https://yihui.name/knitr/options/}{this page} for
more on \emph{knitr}'s options.

\begin{itemize}
\tightlist
\item
  To get better results when using html (with \texttt{method\ =\ \textquotesingle{}render\textquotesingle{}}),
  set up your .Rmd document so it includes \emph{summarytool}'s css.
\end{itemize}

\hypertarget{example-1}{%
\subsubsection{Example}\label{example-1}}

\begin{verbatim}
# 
# # RMarkdown using summarytools 
# output: 
#   html_document: 
#     css: C:/R/win-library/3.4/summarytools/includes/stylesheets/summarytools.css
# 
\end{verbatim}

For more details on using \emph{summarytools} in \emph{Rmarkdown} documents, please refer to
the corresponding vignette.

\hypertarget{writing-output-to-files}{%
\section{Writing Output to Files}\label{writing-output-to-files}}

The console will always tell you the location of the temporary \emph{html}
file that is created in the process. However, you can specify the name
and location of that file explicitly if you need to reuse it later on:

\begin{verbatim}
{r, eval=FALSE}
view(iris_stats_by_species, file =  ~/iris_stats_by_species.html )
\end{verbatim}

Based on the file extension you provide (\emph{.html} vs others), \emph{summarytools} will
use the appropriate method; there is no need to specify the \texttt{method} argument.

\hypertarget{appending-output-files}{%
\subsection{Appending output files}\label{appending-output-files}}

There is also an \texttt{append\ =} logical argument for adding content to
existing reports, both text/Rmarkdown and html. This is useful if you want to
quickly include several statistical tables in a single file. It is fast
alternative to creating an \emph{.Rmd} document if you don't need the extra
content that the latter allows.

\hypertarget{global-options-1}{%
\section{Global options}\label{global-options-1}}

Version 0.8.3 introduced the following set of global options:

\begin{itemize}
\tightlist
\item
  \texttt{\{r\ \#\ ound.digits} = \texttt{2}
\item
  \texttt{plain.ascii} = \texttt{TRUE}
\item
  \texttt{headings} = \texttt{FALSE} (if using in a markdown document or a
  shiny app, setting this to \texttt{TRUE} might be preferable
\item
  \texttt{footnote} = \texttt{\textquotesingle{}default\textquotesingle{}} (set to empty string or \texttt{NA} to omit
  footnote)
\item
  \texttt{display.labels} = \texttt{TRUE}
\item
  \texttt{freq.totals} = \texttt{TRUE}
\item
  \texttt{freq.display.nas} = \texttt{TRUE}
\item
  \texttt{ctable.totals} = \texttt{TRUE}
\item
  \texttt{ctable.prop} = \texttt{\textquotesingle{}r\textquotesingle{}} (display \emph{r}ow proportions by default)
\item
  \texttt{descr.stats} = \texttt{\textquotesingle{}all\textquotesingle{}}
\item
  \texttt{descr.transpose} = \texttt{FALSE}
\item
  \texttt{bootstrap.css} = \texttt{TRUE} (if using in a markdown document or a shiny
  app, setting this to \texttt{FALSE} might be preferable
\item
  \texttt{custom.css} = \texttt{NA}
\item
  \texttt{escape.pipe} = \texttt{FALSE}
\end{itemize}

\hypertarget{examples}{%
\subsubsection{Examples}\label{examples}}

\begin{verbatim}
{r, eval=FALSE}
st_options()                      # display all global options' values
st_options('round.digits')        # display only one option
st_options('headings', TRUE) # change an option's value
st_options('footnote', NA)        # Turn off the footnote on all outputs.
                                  # This option was used prior to generating
                                  # the present document.
\end{verbatim}

\hypertarget{overriding-formatting-attributes}{%
\section{Overriding formatting attributes}\label{overriding-formatting-attributes}}

When a \emph{summarytools} object is stored, its formatting attributes are
stored with it. However, you can override most of them when using the
\texttt{print()} and \texttt{view()}
functions.

\hypertarget{example-2}{%
\subsubsection{Example}\label{example-2}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
age_stats <- freq(tobacco$age.gr)  # age_stats contains a regular output for freq 
                                   # including headings, NA counts, and Totals
print(age_stats, style =  rmarkdown , report.nas = FALSE, 
                 totals = FALSE, headings = TRUE)
\end{verbatim}

Note that the omitted attributes are stil part of the \emph{age\_stats} object.

\hypertarget{order-of-priority-for-options-parameters}{%
\section{Order of Priority for Options / Parameters}\label{order-of-priority-for-options-parameters}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Options over-ridden explicitly with \texttt{print()} or \texttt{view()} have
  precendence
\item
  options specified as explicit arguments to \texttt{freq()\ /\ ctable()\ /\ descr()\ /\ dfSummary()} come second
\item
  Global options, which can be set with \texttt{st\_options}, come third
\end{enumerate}

\hypertarget{customizing-looks-with-css}{%
\section{Customizing looks with CSS}\label{customizing-looks-with-css}}

Version 0.8 of \emph{summarytools} uses \emph{RStudio}'s \href{https://CRAN.R-project.org/package=htmltools}{htmltools
package}
and version 4 of \href{https://getbootstrap.com/}{Bootstrap}'s cascading
stylesheets.

It is possible to include your own \emph{css} if you wish to customize the
look of the output tables. See the documentation for the package's
\texttt{print.summarytools()} function for details, but here is a quick example
to give you the gist of it.

\hypertarget{example-3}{%
\subsubsection{Example}\label{example-3}}

Say you need to make the font size really small, smaller than by using
the \texttt{st-small} class as seen in a previous example. For this, you would
create a CSS file - let's call it ``custom.css'' - containing a class such
as the following:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{.table-condensed}\NormalTok{ \{}
  \KeywordTok{font-size}\NormalTok{: }\DecValTok{8}\DataTypeTok{px}\OperatorTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Then, to apply it to a \emph{summarytools} object and display it in your browser:

\begin{verbatim}
{r, eval=FALSE}
view(dfSummary(tobacco), custom.css = 'path/to/custom.css', 
     table.classes = 'table-condensed')
\end{verbatim}

\hypertarget{working-with-shiny-apps}{%
\section{\texorpdfstring{Working with \emph{shiny} apps}{Working with shiny apps}}\label{working-with-shiny-apps}}

To include \emph{summarytools} functions into \emph{shiny} apps, it is recommended that you:

\begin{itemize}
\tightlist
\item
  set \texttt{bootstrap.css\ =\ FASE} to avoid interacting with the app's layout\\
\item
  adjust the size of the graphs in \texttt{dfSummary()}
\item
  set \texttt{headings} to \texttt{TRUE}
\end{itemize}

\hypertarget{example-4}{%
\subsubsection{Example}\label{example-4}}

\begin{verbatim}
{r # 
print(dfSummary(somedata, graph.magnif = 0.8), 
      method = 'render',
      headings = TRUE,
      bootstrap.css = FALSE)
\end{verbatim}

\hypertarget{getting-most-properties-of-an-object-with-what.is}{%
\section{\texorpdfstring{Getting Most Properties of an Object With \texttt{what.is()}}{Getting Most Properties of an Object With what.is()}}\label{getting-most-properties-of-an-object-with-what.is}}

When developing, we often use a number of functions to obtain an object's properties.
\texttt{what.is()} proposes to lump together the results of most of these functions (\texttt{class()},
\texttt{typeof()}, \texttt{attributes()} and others).

\begin{verbatim}
{r what_is, warning=FALSE, results='markup'}
what.is(iris)
\end{verbatim}

\hypertarget{limitations}{%
\section{Limitations}\label{limitations}}

\begin{itemize}
\tightlist
\item
  The text histograms in dfSummary are not yet supported in \texttt{\{r\ \#\ markdown}. Better use the
  `render' method.
\item
  It is not possible to control the heading levels of individual items. You can however
  choose to \texttt{headings} altogether.
\end{itemize}

\hypertarget{stay-up-to-date}{%
\section{Stay Up-to-date}\label{stay-up-to-date}}

Check out the \href{https://github.com/dcomtois/summarytools}{project's page} -
from there you can see the latest updates and also submit feature requests.

To install the version of summarytools that is on CRAN, but that might have
benefited from quick fixes:

\begin{verbatim}
{r # 
install.packages('devtools')
library(devtools)
install_github('dcomtois/summarytools')
\end{verbatim}

To install the package in its development version, use

\begin{verbatim}
{r # 
install_github('dcomtois/summarytools', ref='dev-current')
\end{verbatim}

\hypertarget{final-notes}{%
\chapter{Final notes}\label{final-notes}}

The package comes with no guarantees. It is a work in progress and
feedback / feature requests are welcome. Just send me an email
(dominic.comtois (at) gmail.com), or open an
\href{https://github.com/dcomtois/summarytools/issues}{Issue on GitHub} if you find a
bug.

\hypertarget{recommendations-for-using-summarytools-with-rmarkdown}{%
\chapter{Recommendations for Using summarytools With Rmarkdown}\label{recommendations-for-using-summarytools-with-rmarkdown}}

author: Dominic Comtois
date:\\
output:
rmarkdown::html\_vignette:
css:
- !expr system.file( rmarkdown/templates/html\_vignette/resources/vignette.css , package = rmarkdown )
- !expr system.file( includes/stylesheets/summarytools.css , package = summarytools )
vignette: \textgreater{}
\%\VignetteIndexEntry{Recommendations for Rmarkdown}
\%\VignetteEngine{knitr::rmarkdown}
\%\VignetteEncoding{UTF-8}

\begin{verbatim}
{r, include=FALSE}
library(knitr)
opts_chunk$set(comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis')
library(summarytools)
\end{verbatim}

This document uses theme \texttt{\{r\ \#\ markdown::html\_vignette}.

Below are examples using recommended styles for \emph{Rmarkdown} rendering. Available styles in
summarytools are the same as \texttt{pander}'s:

\begin{itemize}
\tightlist
\item
  \emph{simple} (default)\\
\item
  \emph{rmarkdown}\\
\item
  \emph{grid}\\
\item
  \emph{multiline}
\end{itemize}

For \texttt{freq()}, \texttt{descr()} (and \texttt{ctable()}, although with caveats), \emph{rmarkdown} style is recommended. For
\texttt{dfSummary()}, \emph{grid} is recommended.

\hypertarget{important-note}{%
\section{Important Note}\label{important-note}}

\texttt{knitr} option \texttt{\{r\ \#\ esults\ =\ \textquotesingle{}asis\textquotesingle{}} must be specified to get good results. This can be done globally via
\texttt{opts\_chunk\$set(results=\textquotesingle{}asis\textquotesingle{})}, or in the individual chunks.

The following summarytools global options have been set:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
#st_options('headings', TRUE)
st_options('bootstrap.css', FALSE)
st_options('footnote', NA)
\end{verbatim}

\hypertarget{using-method-render}{%
\section{Using method = `render'}\label{using-method-render}}

To generate tables using summarytool's own html rendering, the \emph{.Rmd} document's configuration part
(yaml) must point to the package's \texttt{summarytools.css} file. This can be achieved in several ways;
the current vignette uses this configuration:

\begin{verbatim}
output: 
  rmarkdown::html_vignette: 
    css: 
    - !expr system.file( rmarkdown/templates/html_vignette/resources/vignette.css , package =  rmarkdown )
    - !expr system.file( includes/stylesheets/summarytools.css , package =  summarytools )
\end{verbatim}

An alternative is to point to the directory on your system containing \emph{summarytools.css}:

\begin{verbatim}

# RMarkdown using summarytools 
output: 
  html_document: 
    css: C:/R/win-library/3.4/summarytools/includes/stylesheets/summarytools.css
\end{verbatim}

Starting with \texttt{freq()}, we'll review the recommended methods and styles to get going with \emph{summarytools}
in \emph{Rmarkdown} documents.

Jump to\ldots{}

\begin{itemize}
\tightlist
\item
  \protect\hyperlink{ctable}{ctable()}\\
\item
  \protect\hyperlink{descr}{descr()}\\
\item
  \protect\hyperlink{dfsummary}{dfSummary()}
\end{itemize}

--

\hypertarget{freq}{%
\chapter{freq()}\label{freq}}

\texttt{freq()} is best used with `style = `rmarkdown'; html rendering is also possible.

\hypertarget{rmarkdown-style-2}{%
\section{Rmarkdown Style}\label{rmarkdown-style-2}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
freq(tobacco$gender, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering-3}{%
\section{HTML Rendering}\label{html-rendering-3}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(freq(tobacco$gender), method = 'render')
\end{verbatim}

If you find the table too large, you can use \texttt{table.classes\ =\ \textquotesingle{}st-small\textquotesingle{}} - an example is provided
further below.

--

Back to top

\hypertarget{ctable}{%
\chapter{ctable()}\label{ctable}}

\hypertarget{rmarkdown-style-3}{%
\section{Rmarkdown Style}\label{rmarkdown-style-3}}

Tables with heading spanning over 2 rows are not fully supported in markdown (yet), but the result is
getting close to acceptable.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
ctable(tobacco$gender, tobacco$smoker, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering-4}{%
\section{HTML Rendering}\label{html-rendering-4}}

For best results, use this method.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
print(ctable(tobacco$gender, tobacco$smoker), method = 'render')
\end{verbatim}

--

Back to top

\hypertarget{descr3}{%
\chapter{descr() 3}\label{descr3}}

\texttt{descr()} is also best used with \texttt{style\ =\ \textquotesingle{}rmarkdown\textquotesingle{}}, and HTML rendering is also supported.

\hypertarget{rmarkdown-style-4}{%
\section{Rmarkdown Style}\label{rmarkdown-style-4}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
descr(tobacco, style = 'rmarkdown')
\end{verbatim}

\hypertarget{html-rendering-5}{%
\section{HTML Rendering}\label{html-rendering-5}}

We'll use table.classes = `st-small' to show how it affects the table's size (compare to the \texttt{freq()}
table rendered earlier).

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(descr(tobacco), method = 'render', table.classes = 'st-small')
\end{verbatim}

--

Back to top

\hypertarget{dfsummary}{%
\chapter{dfSummary()}\label{dfsummary}}

\hypertarget{grid-style-1}{%
\section{Grid Style}\label{grid-style-1}}

This gives good results, although the histograms are not shown. This has to do with an unresolved issue,
but we're working hard to figure out a solution. Don't forget to specify \texttt{plain.ascii\ =\ FALSE}, or
you won't get good results.

\begin{verbatim}
{r , results='asis'}
dfSummary(tobacco, style = 'grid', plain.ascii = FALSE)
\end{verbatim}

\hypertarget{html-rendering-6}{%
\section{HTML Rendering}\label{html-rendering-6}}

Although the results are not as neat as they are when simply generating an html report from
the R interpreter -- the transparency of the graphs is lost in translation --, this is the
best method still.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
print(dfSummary(tobacco, graph.magnif = 0.75), method = 'render')
\end{verbatim}

Back to top

\hypertarget{r-project-giriux15f}{%
\chapter{R-project giri≈ü}\label{r-project-giriux15f}}

background-image: url(\url{https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg})

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
options(htmltools.dir.version = FALSE)
\end{verbatim}

???

Image credit: \href{https://commons.wikimedia.org/wiki/File:Sharingan_triple.svg}{Wikimedia Commons}

class: center, middle

\hypertarget{xaringan-2}{%
\chapter{xaringan}\label{xaringan-2}}

\hypertarget{ux283aux2d0.riux14b.ux261an}{%
\subsection{/ ÉaÀê.'ri≈ã.…°an/}\label{ux283aux2d0.riux14b.ux261an}}

class: inverse, center, middle

\hypertarget{get-started-1}{%
\chapter{Get Started}\label{get-started-1}}

\hypertarget{hello-world-1}{%
\chapter{Hello World}\label{hello-world-1}}

Install the \textbf{xaringan} package from \href{https://github.com/yihui/xaringan}{Github}:

\begin{verbatim}
{r eval=FALSE, tidy=FALSE}
devtools::install_github( yihui/xaringan )
\end{verbatim}

--

You are recommended to use the \href{https://www.rstudio.com/products/rstudio/}{RStudio IDE}, but you do not have to.

\begin{itemize}
\tightlist
\item
  Create a new R Markdown document from the menu \texttt{File\ -\textgreater{}\ New\ File\ -\textgreater{}\ R\ Markdown\ -\textgreater{}\ From\ Template\ -\textgreater{}\ Ninja\ Presentation};1
\end{itemize}

--

\begin{itemize}
\tightlist
\item
  Click the \texttt{Knit} button to compile it;
\end{itemize}

--

\begin{itemize}
\tightlist
\item
  or use the \href{https://rstudio.github.io/rstudioaddins/}{RStudio Addin}2 Infinite Moon Reader to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer.
\end{itemize}

.footnote{[}
{[}1{]} ‰∏≠ÊñáÁî®Êà∑ËØ∑Áúã\href{http://slides.yihui.name/xaringan/zh-CN.html}{Ëøô‰ªΩÊïôÁ®ã}

{[}2{]} See \href{https://github.com/yihui/xaringan/issues/2}{\#2} if you do not see the template or addin in RStudio.
{]}

background-image: url(\texttt{\{r\ \#\ \ xaringan:::karl})
background-position: 50\% 50\%
class: center, bottom, inverse

\hypertarget{you-only-live-once-1}{%
\chapter{You only live once!}\label{you-only-live-once-1}}

\hypertarget{hello-ninja-1}{%
\chapter{Hello Ninja}\label{hello-ninja-1}}

As a presentation ninja, you certainly should not be satisfied by the Hello World example. You need to understand more about two things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \href{https://remarkjs.com}{remark.js} library;
\item
  The \textbf{xaringan} package;
\end{enumerate}

Basically \textbf{xaringan} injected the chakra of R Markdown (minus Pandoc) into \textbf{remark.js}. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (\textbf{knitr}).

\hypertarget{remark.js-1}{%
\chapter{remark.js}\label{remark.js-1}}

You can see an introduction of remark.js from \href{https://remarkjs.com}{its homepage}. You should read the \href{https://github.com/gnab/remark/wiki}{remark.js Wiki} at least once to know how to

\begin{itemize}
\item
  create a new slide (Markdown syntax* and slide properties);
\item
  format a slide (e.g.~text alignment);
\item
  configure the slideshow;
\item
  and use the presentation (keyboard shortcuts).
\end{itemize}

It is important to be familiar with remark.js before you can understand the options in \textbf{xaringan}.

.footnote{[}{[}*{]} It is different with Pandoc's Markdown! It is limited but should be enough for presentation purposes. Come on\ldots{} You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js \href{https://github.com/gnab/remark/issues/142}{may be improved} in the future.{]}

background-image: url(\texttt{\{r\ \#\ \ xaringan:::karl})
background-size: cover
class: center, bottom, inverse

\hypertarget{i-was-so-happy-to-have-discovered-remark.js-1}{%
\chapter{I was so happy to have discovered remark.js!}\label{i-was-so-happy-to-have-discovered-remark.js-1}}

class: inverse, middle, center

\hypertarget{using-xaringan-1}{%
\chapter{Using xaringan}\label{using-xaringan-1}}

\hypertarget{xaringan-3}{%
\chapter{xaringan}\label{xaringan-3}}

Provides an R Markdown output format \texttt{xaringan::moon\_reader} as a wrapper for remark.js, and you can use it in the YAML metadata, e.g.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# A Cool Presentation }
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{yolo}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{autoplay}\KeywordTok{:}\AttributeTok{ }\DecValTok{30000}
\end{Highlighting}
\end{Shaded}

See the help page \texttt{?xaringan::moon\_reader} for all possible options that you can use.

\hypertarget{remark.js-vs-xaringan-1}{%
\chapter{remark.js vs xaringan}\label{remark.js-vs-xaringan-1}}

Some differences between using remark.js (left) and using \textbf{xaringan} (right):

.pull-left{[}
1. Start with a boilerplate HTML file;

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Plain Markdown;
\item
  Write JavaScript to autoplay slides;
\item
  Manually configure MathJax;
\item
  Highlight code with \texttt{*};
\item
  Edit Markdown source and refresh browser to see updated slides;
  {]}
\end{enumerate}

.pull-right{[}
1. Start with an R Markdown document;

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  R Markdown (can embed R/other code chunks);
\item
  Provide an option \texttt{autoplay};
\item
  MathJax just works;*
\item
  Highlight code with \texttt{\{\{\}\}};
\item
  The RStudio addin Infinite Moon Reader automatically refreshes slides on changes;
  {]}
\end{enumerate}

.footnote{[}{[}*{]} Not really. See next page.{]}

\hypertarget{math-expressions-1}{%
\chapter{Math Expressions}\label{math-expressions-1}}

\hypertarget{r-code-1}{%
\chapter{R Code}\label{r-code-1}}

\begin{verbatim}
{r comment='#'}
# a boring regression
fit = lm(dist ~ 1 + speed, data = cars)
coef(summary(fit))
dojutsu = c('Âú∞ÁàÜÂ§©Êòü', 'Â§©ÁÖß', 'Âä†ÂÖ∑ÂúüÂëΩ', 'Á•ûÂ®Å', 'È†à‰ΩêËÉΩ‰πé', 'ÁÑ°ÈôêÊúàË™≠')
grep('Â§©', dojutsu, value = TRUE)
\end{verbatim}

\hypertarget{r-plots-1}{%
\chapter{R Plots}\label{r-plots-1}}

\begin{verbatim}
{r , fig.height=4, dev='svg'}
par(mar = c(4, 4, 1, .1))
plot(cars, pch = 19, col = 'darkgray', las = 1)
abline(fit, lwd = 2)
\end{verbatim}

\hypertarget{tables-3}{%
\chapter{Tables}\label{tables-3}}

If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(head(iris), format = 'html')
\end{verbatim}

\hypertarget{html-widgets-1}{%
\chapter{HTML Widgets}\label{html-widgets-1}}

I have not thoroughly tested HTML widgets against \textbf{xaringan}. Some may work well, and some may not. It is a little tricky.

Similarly, the Shiny mode (\texttt{\{r\ \#\ untime:\ shiny}) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications.

See the next page for two HTML widgets.

\begin{verbatim}
{r out.width='100%', fig.height=6, eval=require('leaflet')}
library(leaflet)
leaflet() %>% addTiles() %>% setView(-93.65, 42.0285, zoom = 17)
\end{verbatim}

\begin{verbatim}
{r eval=require('DT'), tidy=FALSE}
DT::datatable(
  head(iris, 10),
  fillContainer = FALSE, options = list(pageLength = 8)
)
\end{verbatim}

\hypertarget{some-tips-6}{%
\chapter{Some Tips}\label{some-tips-6}}

\begin{itemize}
\item
  When you use the Infinite Moon Reader addin in RStudio, your R session will be blocked by default. You can click the red button on the right of the console to stop serving the slides, or use the \emph{daemonized} mode so that it does not block your R session. To do the latter, you can set the option

\begin{verbatim}
{r # 
options(servr.daemon = TRUE)
\end{verbatim}

  in your current R session, or in \texttt{\textasciitilde{}/.Rprofile} so that it is applied to all future R sessions. I do the latter by myself.

  To know more about the web server, see the \href{https://github.com/yihui/servr}{\textbf{servr}} package.
\end{itemize}

--

\begin{itemize}
\item
  Do not forget to try the \texttt{yolo} option of \texttt{xaringan::moon\_reader}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{yolo}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{some-tips-7}{%
\chapter{Some Tips}\label{some-tips-7}}

\begin{itemize}
\item
  Slides can be automatically played if you set the \texttt{autoplay} option under \texttt{nature}, e.g.~go to the next slide every 30 seconds in a lightning talk:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{autoplay}\KeywordTok{:}\AttributeTok{ }\DecValTok{30000}
\end{Highlighting}
\end{Shaded}
\end{itemize}

--

\begin{itemize}
\item
  A countdown timer can be added to every page of the slides using the \texttt{countdown} option under \texttt{nature}, e.g.~if you want to spend one minute on every page when you give the talk, you can set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{countdown}\KeywordTok{:}\AttributeTok{ }\DecValTok{60000}
\end{Highlighting}
\end{Shaded}

  Then you will see a timer counting down from \texttt{01:00}, to \texttt{00:59}, \texttt{00:58}, \ldots{} When the time is out, the timer will continue but the time turns red.
\end{itemize}

\hypertarget{some-tips-8}{%
\chapter{Some Tips}\label{some-tips-8}}

\begin{itemize}
\item
  The title slide is created automatically by \textbf{xaringan}, but it is just another remark.js slide added before your other slides.

  The title slide is set to \texttt{class:\ center,\ middle,\ inverse,\ title-slide} by default. You can change the classes applied to the title slide with the \texttt{titleSlideClass} option of \texttt{nature} (\texttt{title-slide} is always applied).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{titleSlideClass}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{top}\KeywordTok{,}\AttributeTok{ left}\KeywordTok{,}\AttributeTok{ inverse}\KeywordTok{]}
\end{Highlighting}
\end{Shaded}
\end{itemize}

--

\begin{itemize}
\item
  If you'd like to create your own title slide, disable \textbf{xaringan}'s title slide with the \texttt{seal\ =\ FALSE} option of \texttt{moon\_reader}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{seal}\KeywordTok{:}\AttributeTok{ }\CharTok{false}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{some-tips-9}{%
\chapter{Some Tips}\label{some-tips-9}}

\begin{itemize}
\item
  There are several ways to build incremental slides. See \href{https://slides.yihui.name/xaringan/incremental.html}{this presentation} for examples.
\item
  The option \texttt{highlightLines:\ true} of \texttt{nature} will highlight code lines that start with \texttt{*}, or are wrapped in \texttt{\{\{\ \}\}}, or have trailing comments \texttt{\#\textless{}\textless{}};

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{highlightLines}\KeywordTok{:}\AttributeTok{ }\CharTok{true}
\end{Highlighting}
\end{Shaded}

  See examples on the next page.
\end{itemize}

\hypertarget{some-tips-10}{%
\chapter{Some Tips}\label{some-tips-10}}

.pull-left{[}
An example using a leading \texttt{*}:

\begin{verbatim}
```
\end{verbatim}

\{r \#
if (TRUE) \{
** message( Very important! )
\}
\texttt{Output:}
\{r \#
if (TRUE) \{
* message( Very important! )
\}

\begin{verbatim}

This is invalid R code, so it is a plain fenced code block that is not executed.
]

.pull-right[
An example using `{{}}`:
\end{verbatim}

`\{r \# ''\texttt{\{r\ tidy=FALSE\}\ if\ (TRUE)\ \{\ *\{\{\ message(\ Very\ important!\ )\ \}\}\ \}\ \textasciigrave{}\textasciigrave{}\textasciigrave{}}
Output:

\begin{verbatim}
{r tidy=FALSE}
if (TRUE) {
{{ message( Very important! ) }}
}
\end{verbatim}

It is valid R code so you can run it. Note that \texttt{\{\{\}\}} can wrap an R expression of multiple lines.
{]}

\hypertarget{some-tips-11}{%
\chapter{Some Tips}\label{some-tips-11}}

An example of using the trailing comment \texttt{\#\textless{}\textless{}} to highlight lines:

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{`\{r #  ''````}
\BaseNTok{\{r tidy=FALSE\}}
\BaseNTok{library(ggplot2)}
\BaseNTok{ggplot(mtcars) + }
\BaseNTok{  aes(mpg, disp) + }
\BaseNTok{  geom_point() +   #<<}
\BaseNTok{  geom_smooth()    #<<}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
{r tidy=FALSE, eval=FALSE}
library(ggplot2)
ggplot(mtcars) + 
  aes(mpg, disp) + 
  geom_point() +   #<<
  geom_smooth()    #<<
\end{verbatim}

\hypertarget{some-tips-12}{%
\chapter{Some Tips}\label{some-tips-12}}

When you enable line-highlighting, you can also use the chunk option \texttt{highlight.output} to highlight specific lines of the text output from a code chunk. For example, \texttt{highlight.output\ =\ TRUE} means highlighting all lines, and \texttt{highlight.output\ =\ c(1,\ 3)} means highlighting the first and third line.

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{`\{r #  ''````}
\BaseNTok{\{r, highlight.output=c(1, 3)\}}
\BaseNTok{head(iris)}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{r, highlight.output=c(1, 3), echo=TRUE}
head(iris)
\end{verbatim}

Question: what does \texttt{highlight.output\ =\ c(TRUE,\ FALSE)} mean? (Hint: think about R's recycling of vectors)

\hypertarget{some-tips-13}{%
\chapter{Some Tips}\label{some-tips-13}}

\begin{itemize}
\item
  To make slides work offline, you need to download a copy of remark.js in advance, because \textbf{xaringan} uses the online version by default (see the help page \texttt{?xaringan::moon\_reader}).
\item
  You can use \texttt{xaringan::summon\_remark()} to download the latest or a specified version of remark.js. By default, it is downloaded to \texttt{libs/remark-latest.min.js}.
\item
  Then change the \texttt{chakra} option in YAML to point to this file, e.g.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{chakra}\KeywordTok{:}\AttributeTok{ libs/remark-latest.min.js}
\end{Highlighting}
\end{Shaded}
\item
  If you used Google fonts in slides (the default theme uses \emph{Yanone Kaffeesatz}, \emph{Droid Serif}, and \emph{Source Code Pro}), they won't work offline unless you download or install them locally. The Heroku app \href{https://google-webfonts-helper.herokuapp.com/fonts}{google-webfonts-helper} can help you download fonts and generate the necessary CSS.
\end{itemize}

\hypertarget{macros-1}{%
\chapter{Macros}\label{macros-1}}

\begin{itemize}
\item
  remark.js \href{https://github.com/yihui/xaringan/issues/80}{allows users to define custom macros} (JS functions) that can be applied to Markdown text using the syntax \texttt{!{[}:macroName\ arg1,\ arg2,\ ...{]}} or \texttt{!{[}:macroName\ arg1,\ arg2,\ ...{]}(this)}. For example, before remark.js initializes the slides, you can define a macro named \texttt{scale}:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{remark}\NormalTok{.}\VariableTok{macros}\NormalTok{.}\AttributeTok{scale} \OperatorTok{=} \KeywordTok{function}\NormalTok{ (percentage) }\OperatorTok{\{}
  \KeywordTok{var}\NormalTok{ url }\OperatorTok{=} \KeywordTok{this}\OperatorTok{;}
  \ControlFlowTok{return} \StringTok{'<img src= '} \OperatorTok{+}\NormalTok{ url }\OperatorTok{+} \StringTok{'  style= width: '} \OperatorTok{+}\NormalTok{ percentage }\OperatorTok{+} \StringTok{'  />'}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

  Then the Markdown text

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![:scale 50%](image.jpg)}
\end{Highlighting}
\end{Shaded}

  will be translated to

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<img}\OtherTok{ src=} \StringTok{image.jpg}\OtherTok{  style=} \StringTok{width:} \ErrorTok{50%}  \KeywordTok{/>}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{macros-continued-1}{%
\chapter{Macros (continued)}\label{macros-continued-1}}

\begin{itemize}
\item
  To insert macros in \textbf{xaringan} slides, you can use the option \texttt{beforeInit} under the option \texttt{nature}, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{nature}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{beforeInit}\KeywordTok{:}\AttributeTok{  macros.js }
\end{Highlighting}
\end{Shaded}

  You save your remark.js macros in the file \texttt{macros.js}.
\item
  The \texttt{beforeInit} option can be used to insert arbitrary JS code before \texttt{\{r\ \#\ emark.create()}. Inserting macros is just one of its possible applications.
\end{itemize}

\hypertarget{css-2}{%
\chapter{CSS}\label{css-2}}

Among all options in \texttt{xaringan::moon\_reader}, the most challenging but perhaps also the most rewarding one is \texttt{css}, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know.

You can see the default CSS file \href{https://github.com/yihui/xaringan/blob/master/inst/rmarkdown/templates/xaringan/resources/default.css}{here}. You can completely replace it with your own CSS files, or define new rules to override the default. See the help page \texttt{?xaringan::moon\_reader} for more information.

\hypertarget{css-3}{%
\chapter{CSS}\label{css-3}}

For example, suppose you want to change the font for code from the default Source Code Pro to Ubuntu Mono . You can create a CSS file named, say, \texttt{ubuntu-mono.css}:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{@import} \FunctionTok{url(}\StringTok{https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic}\FunctionTok{)}\OperatorTok{;}

\FunctionTok{.remark-code}\OperatorTok{,} \FunctionTok{.remark-inline-code}\NormalTok{ \{ }\KeywordTok{font-family}\NormalTok{: }\StringTok{'Ubuntu Mono'}\OperatorTok{;}\NormalTok{ \}}
\end{Highlighting}
\end{Shaded}

Then set the \texttt{css} option in the YAML metadata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{ default }\KeywordTok{,}\AttributeTok{  ubuntu-mono.css }\KeywordTok{]}
\end{Highlighting}
\end{Shaded}

Here I assume \texttt{ubuntu-mono.css} is under the same directory as your Rmd.

See \href{https://github.com/yihui/xaringan/issues/83}{yihui/xaringan\#83} for an example of using the \href{https://github.com/tonsky/FiraCode}{Fira Code} font, which supports ligatures in program code.

\hypertarget{themes-2}{%
\chapter{Themes}\label{themes-2}}

Don't want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files \texttt{foo.css} and \texttt{foo-fonts.css}, where \texttt{foo} is the theme name. Below are some existing themes:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
names(xaringan:::list_css())
\end{verbatim}

\hypertarget{themes-3}{%
\chapter{Themes}\label{themes-3}}

To use a theme, you can specify the \texttt{css} option as an array of CSS filenames (without the \texttt{.css} extensions), e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{default}\KeywordTok{,}\AttributeTok{ metropolis}\KeywordTok{,}\AttributeTok{ metropolis-fonts}\KeywordTok{]}
\end{Highlighting}
\end{Shaded}

If you want to contribute a theme to \textbf{xaringan}, please read \href{https://yihui.name/en/2017/10/xaringan-themes}{this blog post}.

class: inverse, middle, center
background-image: url(\url{https://upload.wikimedia.org/wikipedia/commons/3/39/Naruto_Shiki_Fujin.svg})
background-size: contain

\hypertarget{naruto-1}{%
\chapter{Naruto}\label{naruto-1}}

background-image: url(\url{https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg})
background-size: 100px
background-position: 90\% 8\%

\hypertarget{sharingan-1}{%
\chapter{Sharingan}\label{sharingan-1}}

The R package name \textbf{xaringan} was derived1 from \textbf{Sharingan}, a d≈çjutsu in the Japanese anime \emph{Naruto} with two abilities:

\begin{itemize}
\item
  the Eye of Insight
\item
  the Eye of Hypnotism
\end{itemize}

I think a presentation is basically a way to communicate insights to the audience, and a great presentation may even hypnotize the audience.2,3

.footnote{[}
{[}1{]} In Chinese, the pronounciation of \emph{X} is \emph{Sh} / É/ (as in \emph{shrimp}). Now you should have a better idea of how to pronounce my last name \emph{Xie}.

{[}2{]} By comparison, bad presentations only put the audience to sleep.

{[}3{]} Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations.
{]}

\hypertarget{naruto-terminology-1}{%
\chapter{Naruto terminology}\label{naruto-terminology-1}}

The \textbf{xaringan} package borrowed a few terms from Naruto, such as

\begin{itemize}
\item
  \href{http://naruto.wikia.com/wiki/Sharingan}{Sharingan} (ÂÜôËº™Áúº; the package name)
\item
  The \href{http://naruto.wikia.com/wiki/Moon_Reader}{moon reader} (ÊúàË™≠; an attractive R Markdown output format)
\item
  \href{http://naruto.wikia.com/wiki/Chakra}{Chakra} (Êü•ÂÖãÊãâ; the path to the remark.js library, which is the power to drive the presentation)
\item
  \href{http://naruto.wikia.com/wiki/Nature_Transformation}{Nature transformation} (ÊÄßË≥™Â§âÂåñ; transform the chakra by setting different options)
\item
  The \href{http://naruto.wikia.com/wiki/Infinite_Tsukuyomi}{infinite moon reader} (ÁÑ°ÈôêÊúàË™≠; start a local web server to continuously serve your slides)
\item
  The \href{http://naruto.wikia.com/wiki/Summoning_Technique}{summoning technique} (download remark.js from the web)
\end{itemize}

You can click the links to know more about them if you want. The jutsu Moon Reader may seem a little evil, but that does not mean your slides are evil.

class: center

\hypertarget{hand-seals-ux5370-1}{%
\chapter{Hand seals (Âç∞)}\label{hand-seals-ux5370-1}}

Press \texttt{h} or \texttt{?} to see the possible ninjutsu you can use in remark.js.

\includegraphics{https://upload.wikimedia.org/wikipedia/commons/7/7e/Mudra-Naruto-KageBunshin.svg}

class: center, middle

\hypertarget{thanks-1}{%
\chapter{Thanks!}\label{thanks-1}}

Slides created via the R package \href{https://github.com/yihui/xaringan}{\textbf{xaringan}}.

The chakra comes from \href{https://remarkjs.com}{remark.js}, \href{http://yihui.name/knitr}{\textbf{knitr}}, and \href{https://rmarkdown.rstudio.com}{R Markdown}.

\hypertarget{survival-analysis-in-r-1}{%
\chapter{Survival Analysis in R}\label{survival-analysis-in-r-1}}

output:
html\_document:
toc: TRUE
toc\_float: TRUE

\url{http://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html}

This tutorial provides an introduction to survival analysis, and to conducting a survival analysis in R.

This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center R-Presenters series on August 30, 2018.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# load packages
library(knitr)
library(tidyverse)
library(broom)

# load my package to access msk_palette with MSK brand colors
devtools::install_github( zabore/ezfun )
\end{verbatim}

\begin{verbatim}
{r loaddata, echo = TRUE}
# load(here::here( data ,  survival_data_example.RData ))
\end{verbatim}

\hypertarget{introduction-3}{%
\chapter{Introduction}\label{introduction-3}}

\hypertarget{what-is-survival-data}{%
\section{What is survival data?}\label{what-is-survival-data}}

Time-to-event data that consists of a distinct start time and end time.

Examples from cancer:

\begin{itemize}
\tightlist
\item
  Time from surgery to death
\item
  Time from start of treatment to progression
\item
  Time from response to recurrence
\end{itemize}

\hypertarget{examples-from-other-fields}{%
\section{Examples from other fields}\label{examples-from-other-fields}}

Time-to-event data is common in many fields including, but not limited to:

\begin{itemize}
\tightlist
\item
  Time from HIV infection to development of AIDS
\item
  Time to heart attack
\item
  Time to onset of substance abuse
\item
  Time to initiation of sexual activity
\item
  Time to machine malfunction
\end{itemize}

\hypertarget{aliases-for-survival-analysis}{%
\section{Aliases for survival analysis}\label{aliases-for-survival-analysis}}

Because survival analysis is common in many other fields, it also goes by other names:

\begin{itemize}
\tightlist
\item
  Reliability analysis
\item
  Duration analysis
\item
  Event history analysis
\item
  Time-to-event analysis
\end{itemize}

\hypertarget{questions-of-interest}{%
\section{Questions of interest}\label{questions-of-interest}}

The two most common questions I encounter related to survival analysis are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the probability of survival to a certain point in time?
\item
  What is the average survival time?
\end{enumerate}

\hypertarget{censoring}{%
\chapter{Censoring}\label{censoring}}

\hypertarget{what-is-censoring}{%
\section{What is censoring?}\label{what-is-censoring}}

In survival analysis it is common for the exact event time to be unknown, or unobserved, which is called censoring. A subject may be censored due to:

\begin{itemize}
\tightlist
\item
  Loss to follow-up
\item
  Withdrawal from study
\item
  No event by end of fixed study period
\end{itemize}

Specifically these are examples of \textbf{right} censoring. Other common types of censoring include:

\begin{itemize}
\tightlist
\item
  Left
\item
  Interval
\end{itemize}

\hypertarget{censored-survival-data}{%
\section{Censored survival data}\label{censored-survival-data}}

When the exact event time is unknown then some patients are censored, and survival analysis methods are required.

\begin{verbatim}
{r swimmer, eval=FALSE, include=FALSE}
# make fake data
set.seed(20180809)
fkdt <- data_frame(Subject = as.factor(1:10), 
                   Years = sample(4:20, 10, replace = T),
                   censor = sample(c( Censor , rep( Event , 2)), 10, 
                                   replace = T)) 
# %>% mutate(Subject = fct_reorder(Subject, Years, desc = TRUE))

# plot with shapes to indicate censoring or event
ggplot(fkdt, aes(Subject, Years)) + 
    geom_bar(stat =  identity , width = 0.5, 
             fill = ezfun::msk_palette( main )[3]) + 
    geom_point(data = fkdt, 
               aes(Subject, Years, color = censor, shape = censor), 
               size = 6) +
    scale_color_manual(values = ezfun::msk_palette( contrast )[2:3]) +
    coord_flip() +
    theme_minimal() + 
    theme(legend.title = element_blank(),
          legend.position =  bottom )
\end{verbatim}

In this example, how would we compute the proportion who are event-free at 10 years?

\begin{itemize}
\tightlist
\item
  Subjects 2, 3, 5, 6, 8, 9, and 10 were all event-free at 10 years.
\item
  Subjects 4 and 7 had the event before 10 years.
\item
  Subject 1 was censored before 10 years, so we don't know whether they had the event or not by 10 years. How do we incorporate this subject into our estimate?
\end{itemize}

\hypertarget{we-can-incorporate-censored-data-using-survival-analysis-techniques}{%
\section{We can incorporate censored data using survival analysis techniques}\label{we-can-incorporate-censored-data-using-survival-analysis-techniques}}

Toy example of a Kaplan-Meier curve for this simple data (details to follow):

\begin{verbatim}
{r eval=FALSE, include=FALSE}
library(survival)
plot(survfit(Surv(Years, ifelse(censor ==  Event , 1, 0)) ~ 1, data = fkdt), 
     xlab =  Years , 
     ylab =  Survival probability , 
     mark.time = T, 
     conf.int = FALSE)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Horizontal lines represent survival duration for the interval
\item
  An interval is terminated by an event
\item
  The height of vertical lines show the change in cumulative probability
\item
  Censored observations, indicated by tick marks, reduces the cumulative survival between intervals
\end{itemize}

\hypertarget{danger-of-ignoring-censoring}{%
\section{Danger of ignoring censoring}\label{danger-of-ignoring-censoring}}

\href{https://callingbullshit.org/case_studies/case_study_musician_mortality.html}{Case study: musicians and mortality}

Conclusion: Musical genre is associated with early death among musicians.

Problem: this graph does not account for the right-censored nature of the data.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# include_graphics( ./img/musician_death_graph.jpg )
\end{verbatim}

\hypertarget{components-of-survival-data}{%
\section{Components of survival data}\label{components-of-survival-data}}

For subject \(i\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Event time \(T_i\)
\item
  Censoring time \(C_i\)
\item
  Event indicator \(\delta_i\):

  \begin{itemize}
  \tightlist
  \item
    1 if event observed (i.e.~\(T_i \leq C_i\))
  \item
    0 if censored (i.e.~\(T_i > C_i\))
  \end{itemize}
\item
  Observed time \(Y_i = \min(T_i, C_i)\)
\end{enumerate}

\hypertarget{data-example}{%
\chapter{Data example}\label{data-example}}

\hypertarget{research-question-of-interest}{%
\section{Research question of interest}\label{research-question-of-interest}}

Investigating the obesity paradox in kidney cancer patients.

\begin{itemize}
\tightlist
\item
  Increased BMI associated with risk of kidney cancer
\item
  Is increased BMI also associated with worse prognosis among kidney cancer patients?
\end{itemize}

\hypertarget{data-structure}{%
\section{Data structure}\label{data-structure}}

\begin{itemize}
\tightlist
\item
  \texttt{\{r\ \#\ \ nrow(df)} kidney cancer patients
\item
  Outcome: overall survival
\item
  Predictor: BMI
\end{itemize}

\begin{verbatim}
{r peekdata, eval=FALSE, include=FALSE}
df[, c( os_yrs ,  os ,  bmi_cat )] %>% 
    head
\end{verbatim}

Variables:

\begin{itemize}
\tightlist
\item
  os\_yrs : the observed time \(Y_i = min(T_i, C_i)\)
\item
  os : the event indicator \(\delta_i\)
\item
  bmi\_cat : 1 = Normal BMI \textless{} 25, 2 = Overweight BMI 25-30, 3 = Obese BMI \textgreater{} 30
\end{itemize}

\hypertarget{preparing-data-for-analysis}{%
\chapter{Preparing data for analysis}\label{preparing-data-for-analysis}}

\hypertarget{dates}{%
\section{Dates}\label{dates}}

Data will often come with start and end dates rather than pre-calculated survival times. Our data example includes the following variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  proc\_date : Date of surgery
\item
  last\_status\_date : Date of death or last follow-up
\item
  last\_status : Character variable denoting whether the patient is alive, and the cause of death if dead
\end{enumerate}

The first step is to make sure these are formatted as dates in R.

\hypertarget{formatting-dates---base-r}{%
\section{Formatting dates - base R}\label{formatting-dates---base-r}}

First let's look at the current format of our surgery date:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date)
\end{verbatim}

We see this is a character variable in a certain format, but we need it to be formatted as a Date.

\begin{verbatim}
{r format_date1, eval=FALSE, include=FALSE}
df <- df %>% 
    mutate(proc_date_format1 = as.Date(proc_date, format =  %d%b%Y ))
\end{verbatim}

And after formatting we see that surgery date has Date format now:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date_format1)
\end{verbatim}

\begin{itemize}
\item
  Note that in base R the format must include the separator as well as the symbol. e.g.~if your date is in format m/d/Y then you would need \texttt{format\ =\ \ \%m/\%d/\%Y}
\item
  See a full list of date format symbols at \url{https://www.statmethods.net/input/dates.html}
\end{itemize}

\hypertarget{formatting-dates---lubridate}{%
\section{Formatting dates - lubridate}\label{formatting-dates---lubridate}}

We can also use the \texttt{lubridate} package to format dates. Again we look at our original surgery date variable:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date)
\end{verbatim}

And now use the \texttt{lubridate::dmy} function to format this into a Date:

\begin{verbatim}
{r format_date2, eval=FALSE, include=FALSE}
df <- df %>% 
    mutate(proc_date_format2 = lubridate::dmy(proc_date))
\end{verbatim}

And again we see that \texttt{R} now recognizes surgery date as a Date format:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date_format2)
\end{verbatim}

\begin{itemize}
\item
  The help page for \texttt{?ymd} will show all format options.
\item
  Note that unlike the base R option, the separators do not need to be specified
\end{itemize}

\hypertarget{event-indicator}{%
\section{Event indicator}\label{event-indicator}}

Most functions used in survival analysis will also require a binary indicator of event that is:

\begin{itemize}
\tightlist
\item
  0 for no event
\item
  1 for event
\end{itemize}

Currently our data example contains a character variable indicating whehter the patient is alive, and if not indicating the cause of death, so we must create a binary indicator.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(df$last_status, useNA = 'ifany')

df <- df %>% 
    mutate(os_event = ifelse(last_status ==  Alive , 0, 1))

table(df$os_event)
\end{verbatim}

\hypertarget{calculating-survival-times---base-r}{%
\section{Calculating survival times - base R}\label{calculating-survival-times---base-r}}

Now that we have our dates formatted, we need to calculate the difference between start and end time in some units, usually months or years.

A base \texttt{R} solution to calculate the number of years from surgery to death:

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# need to actually properly format the real dates for use
df <- df %>% 
    mutate(proc_date = as.Date(proc_date, format =  %d%b%Y ),
           last_status_date = as.Date(last_status_date, format =  %d%b%Y ))
\end{verbatim}

\begin{verbatim}
{r difftime_ex1, eval=FALSE, include=FALSE}
df <- df %>% 
    mutate(os_yrs_opt1 = as.numeric(difftime(last_status_date, proc_date, 
                                             units =  days )) / 365.25)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(df$os_yrs_opt1)
\end{verbatim}

\begin{itemize}
\item
  Here we use \texttt{difftime} to calculate the number of days between our two dates and convert it to a numeric value using \texttt{as.numeric}. We then convert to years by dividing by 365.25, the average number of days in a year.
\item
  \emph{Sidenote}: the \textgreater0 nature of survival times is another reason why standard regression techniques such as linear regression would not be an appropriate way to analyze time-to-event data
\end{itemize}

\hypertarget{calculating-survival-times---lubridate}{%
\section{Calculating survival times - lubridate}\label{calculating-survival-times---lubridate}}

We can also use the \texttt{lubridate} package to calculate the number of years from surgery to death:

\begin{verbatim}
{r difftime_ex2, message = FALSE, warning = FALSE}
library(lubridate)

df <- df %>% 
    mutate(os_yrs_opt2 = 
               as.duration(proc_date %--% last_status_date) /
               dyears(1))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(df$os_yrs_opt2)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Here the operator \texttt{\%-\/-\%} is used to designate a time interval, which is then converted to the number of elapsed seconds using \texttt{as.duration} and finally converted to years by dividing by \texttt{dyears(1)}, which gives the number of seconds in a year.
\item
  If you look closely you will see the result differs slightly from the previous result due to rounding differences, but nothing that would impact our results
\item
  \emph{Note}: we need to load the \texttt{lubridate} package using a call to \texttt{library} in order to be able to access the special operators (similar to situation with pipes)
\end{itemize}

\hypertarget{analyzing-survival-data}{%
\chapter{Analyzing survival data}\label{analyzing-survival-data}}

\hypertarget{questions-of-interest-1}{%
\section{Questions of interest}\label{questions-of-interest-1}}

Recall the questions of interest:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the probability of surviving to a certain point in time?
\item
  What is the average survival time?
\end{enumerate}

\hypertarget{creating-survival-objects}{%
\section{Creating survival objects}\label{creating-survival-objects}}

The Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs.

\begin{itemize}
\tightlist
\item
  The \texttt{Surv} function from the \texttt{survival} package creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a \texttt{+} if the subject was censored. Let's look at the first 10 observations:
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::Surv(df$os_yrs, df$os)[1:10]
\end{verbatim}

\hypertarget{estimating-survival-curves-with-the-kaplan-meier-method}{%
\section{Estimating survival curves with the Kaplan-Meier method}\label{estimating-survival-curves-with-the-kaplan-meier-method}}

\begin{itemize}
\tightlist
\item
  The \texttt{survival::survfit} function creates survival curves based on a formula. Let's generate the overall survival curve for the entire cohort, assign it to object \texttt{f1}, and look at the \texttt{names} of that object:
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
f1 <- survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df)
names(f1)
\end{verbatim}

Some key components of this \texttt{survfit} object that will be used to create survival curves include:

\begin{itemize}
\tightlist
\item
  \texttt{time}, which contains the start and endpoints of each time interval
\item
  \texttt{surv}, which contains the survival probability corresponding to each \texttt{time}
\end{itemize}

\hypertarget{kaplan-meier-plot---base-r}{%
\section{Kaplan-Meier plot - base R}\label{kaplan-meier-plot---base-r}}

Now we plot the \texttt{survfit} object in base \texttt{R} to get the Kaplan-Meier plot:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
     xlab =  Years , 
     ylab =  Overall survival probability )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The default plot in base \texttt{R} shows the step function (solid line) with associated confidence intervals (dotted lines). Note that the tick marks for censored patients are not shown by default, but could be added using \texttt{mark.time\ =\ TRUE}
\end{itemize}

\hypertarget{kaplan-meier-plot---ggsurvplot}{%
\section{Kaplan-Meier plot - ggsurvplot}\label{kaplan-meier-plot---ggsurvplot}}

Alternatively, the \texttt{ggsurvplot} function from the \texttt{survminer} package is built on \texttt{ggplot2}, and can be used to create Kaplan-Meier plots:

\begin{verbatim}
{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
survminer::ggsurvplot(
    fit = survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
    xlab =  Years , 
    ylab =  Overall survival probability )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The default plot using \texttt{survminer::ggsurvplot} shows the step function (solid line) with associated confidence bands (shaded area). The tick marks for censored patients are shown by default, somewhat obscuring the line itself in this example, and could be supressed using \texttt{censor\ =\ FALSE}
\end{itemize}

\hypertarget{estimating-x-year-survival}{%
\section{\texorpdfstring{Estimating \(x\)-year survival}{Estimating x-year survival}}\label{estimating-x-year-survival}}

One quantity often of interest in a survival analysis is the probability of surviving a certain number (\(x\)) of years.

For example, to estimate the probability of survivng to 5 years, use \texttt{summary} with the \texttt{times} argument:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
        times = 5)
\end{verbatim}

We find that the 5-year probability of survival in this study is \texttt{\{r\ \#\ \ round(summary(f1,\ times\ =\ 5)\$surv\ *\ 100)}\%. The associated lower and upper bounds of the 95\% confidence interval are also displayed.

\hypertarget{x-year-survival-and-the-survival-curve}{%
\section{\texorpdfstring{\(x\)-year survival and the survival curve}{x-year survival and the survival curve}}\label{x-year-survival-and-the-survival-curve}}

The 5-year survival probability is the point on the y-axis that corresponds to 5 years on the x-axis for the survival curve.

\begin{verbatim}
{r eval=FALSE, message=FALSE, include=FALSE}
survplot1 <- survminer::ggsurvplot(survival::survfit(
    survival::Surv(os_yrs, os) ~ 1, data = df), 
           xlab =  Years ,
           ylab =  Overall survival probability ,
           break.x.by = 5, 
           palette = ezfun::msk_palette( main )) +
    geom_segment(x = 5, xend = 5, y = -1, yend = 0.808, col = 2, lwd = 2) +
    geom_segment(x = 5, xend = -0.7, y = 0.808, yend = 0.808, 
                 arrow = arrow(length = unit(0.3,  inches )), col = 2, 
                 lwd = 2)

survplot1$plot <- survplot1$plot +
    annotate( text , x = 0.2, y = 0.7, label =  81% , size = 6, col = 2)

survplot1
\end{verbatim}

\hypertarget{x-year-survival-is-often-estimated-incorrectly}{%
\section{\texorpdfstring{\(x\)-year survival is often estimated incorrectly}{x-year survival is often estimated incorrectly}}\label{x-year-survival-is-often-estimated-incorrectly}}

What happens if you use a naive estimate?

\texttt{\{r\ \#\ \ table(df\$os{[}df\$os\_yrs\ \textless{}=\ 5{]}){[}2{]}} of the \texttt{\{r\ \#\ \ nrow(df)} patients died by 5 years so:

\[\Big(1 - \frac{297}{2119}\Big) \times 100 = 86\%\]

\begin{itemize}
\item
  You get an \textbf{incorrect} estimate of the 5-year probability of survival when you ignore the fact that \texttt{\{r\ \#\ \ table(df\$os{[}df\$os\_yrs\ \textless{}=\ 5{]}){[}1{]}} patients were censored before 5 years.
\item
  Recall the \textbf{correct} estimate of the 5-year probability of survival was \texttt{\{r\ \#\ \ round(summary(f1,\ times\ =\ 5)\$surv\ *\ 100)}\%.
\end{itemize}

\hypertarget{estimating-median-survival-time}{%
\section{Estimating median survival time}\label{estimating-median-survival-time}}

Another quantity often of interest in a survival analysis is the average survival time, which we quantify using the median (survival times are not expected to be normally distributed so the mean is not an appropriate summary).

We can obtain this directly from our \texttt{survfit} object:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df)
\end{verbatim}

We see the median survival time is \texttt{\{r\ \#\ \ round(summary(f1)\$table{[}\ median\ {]},\ 1)} years. The lower and upper bounds of the 95\% confidence interval are also displayed.

\hypertarget{median-survival-time-and-the-survival-curve}{%
\section{Median survival time and the survival curve}\label{median-survival-time-and-the-survival-curve}}

Median survival is the time corresponding to a survival probability of 0.5:

\begin{verbatim}
{r eval=FALSE, message=FALSE, include=FALSE}
survplot2 <- survminer::ggsurvplot(survival::survfit(
    survival::Surv(os_yrs, os) ~ 1, data = df), 
           xlab =  Years ,
           ylab =  Overall survival probability ,
           break.x.by = 5, 
           palette = ezfun::msk_palette( main )) +
    geom_segment(x = -1, xend = 12.6794, y = 0.5, yend = 0.5, 
                 col = 2, lwd = 2) +
    geom_segment(x = 12.6794, xend = 12.6794, y = 0.5, yend = -0.02, 
                 arrow = arrow(length = unit(0.3,  inches )), col = 2, 
                 lwd = 2)

survplot2$plot <- survplot2$plot +
    annotate( text , x = 9.5, y = 0.02, label =  12.7 years , size = 6, col = 2)

survplot2
\end{verbatim}

\hypertarget{median-survival-is-often-estimated-incorrectly}{%
\section{Median survival is often estimated incorrectly}\label{median-survival-is-often-estimated-incorrectly}}

What happens if you use a naive estimate?

Summarize the median survival time among the \texttt{\{r\ \#\ \ table(df\$os){[}2{]}} patients who died:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df$os_yrs[df$os == 1] %>% 
    median
\end{verbatim}

\begin{itemize}
\item
  You get an \textbf{incorrect} estimate of median survival time of \texttt{\{r\ \#\ \ round(median(df\$os\_yrs{[}df\$os\ ==\ 1{]}),\ 1)} years when you ignore the fact that censored patients also contribute follow-up time.
\item
  Recall the \textbf{correct} estimate of median survival time is \texttt{\{r\ \#\ \ round(summary(f1)\$table{[}\ median\ {]},\ 1)} years.
\end{itemize}

\hypertarget{comparing-survival-times-between-groups}{%
\chapter{Comparing survival times between groups}\label{comparing-survival-times-between-groups}}

\hypertarget{questions-of-interest-with-respect-to-between-group-differences}{%
\section{Questions of interest with respect to between-group differences}\label{questions-of-interest-with-respect-to-between-group-differences}}

Is there a difference in survival probability between groups?

From our example: does the probability of survival differ according to BMI among kidney cancer patients?

\hypertarget{kaplan-meier-plot-by-group}{%
\section{Kaplan-Meier plot by group}\label{kaplan-meier-plot-by-group}}

We can add a covariate to the right-hand side of the \texttt{survival::survfit} object to obtain a stratified Kaplan-Meier plot.

Let's also look at some other customization we can do with \texttt{survminer::ggsurvplot}.

\begin{verbatim}
{r fig.height = 6}
survminer::ggsurvplot(
    fit = survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), 
    xlab =  Years ,
    ylab =  Overall survival probability ,
    legend.title =  BMI ,
    legend.labs = c( Normal ,  Overweight ,  Obese ),
    break.x.by = 5, 
    palette = ezfun::msk_palette( contrast ), 
    censor = FALSE,
    risk.table = TRUE,
    risk.table.y.text = FALSE)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  By looking at the curves, we can see that normal BMI patients have the lowest overall survival probability, followed by overweight BMI patients and obese BMI patients.
\item
  The risk table below the plot shows us the number of patients at risk at certain time points, which can give an idea of how much information is being used to calculate the estimates at each time
\end{itemize}

\hypertarget{x-year-survival-probability-by-group}{%
\section{\texorpdfstring{\(x\)-year survival probability by group}{x-year survival probability by group}}\label{x-year-survival-probability-by-group}}

As before, we can get an estimate of, for example, 5-year survival by using \texttt{summary} with the \texttt{times} argument in our \texttt{survival::survfit} object:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), 
        times = 5)
\end{verbatim}

To summarize:

\begin{verbatim}
{r eval=FALSE, include=FALSE}
library(survival)
tab <- ezfun::uvsurv(NULL,  bmi_cat ,  os ,  os_yrs , 5, df)[-1, c(1, 3)]
colnames(tab) <- c( BMI ,  5-year estimate (95% CI) )
tab[, 1] <- c( Normal ,  Overweight ,  Obese )
kable(tab, row.names = FALSE)
\end{verbatim}

\hypertarget{log-rank-test-for-between-group-significance-test}{%
\section{Log-rank test for between-group significance test}\label{log-rank-test-for-between-group-significance-test}}

\begin{itemize}
\tightlist
\item
  We can conduct between-group significance tests using a log-rank test.
\item
  The log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups.
\item
  There are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question.
\end{itemize}

We get the log-rank p-value using the \texttt{survival::survdiff} function:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::survdiff(survival::Surv(df$os_yrs, df$os) ~ df$bmi_cat)
\end{verbatim}

And we see that the p-value is \textless.001, indicating a significant difference in overall survival according to BMI.

\hypertarget{regression-2}{%
\chapter{Regression}\label{regression-2}}

\hypertarget{the-cox-regression-model}{%
\section{The Cox regression model}\label{the-cox-regression-model}}

We may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables.

The Cox regression model is a semi-parametric model that can be used to fit univariable and multivariable regression models that have survival outcomes.

Some key assumptions of the model:

\begin{itemize}
\tightlist
\item
  non-informative censoring
\item
  proportional hazards
\end{itemize}

\emph{Note}: parametric regression models for survival outcomes are also available, but I won't cover them in detail here.

\hypertarget{cox-regression-example-using-a-single-covariate}{%
\section{Cox regression example using a single covariate}\label{cox-regression-example-using-a-single-covariate}}

We can fit regression models for survival data using the \texttt{survival::coxph} function, which takes a \texttt{survival::Surv} object on the left hand side and has standard syntax for regression formulas in \texttt{R} on the right hand side.

\begin{verbatim}
{r eval = FALSE}
survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), data = df)
\end{verbatim}

We can see a tidy version of the output using the \texttt{tidy} function from the \texttt{broom} package:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
broom::tidy(survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), 
                            data = df))
\end{verbatim}

\hypertarget{hazard-ratios}{%
\section{Hazard ratios}\label{hazard-ratios}}

The quantity of interest from a Cox regression model is a \textbf{hazard ratio (HR)}.

If you have a regression parameter \(\beta\) (from column \texttt{estimate} in our \texttt{survival::coxph}) then HR = \(\exp(\beta)\).

For example, from our example we obtain the regression parameter \(\beta_1=-0.4441733\) for obese vs normal BMI, so we have HR = \(\exp(\beta_1)=0.64\).

A HR \textless{} 1 indicates reduced hazard of death whereas a HR \textgreater{} 1 indicates an increased hazard of death.

So we would say that obese BMI kidney cancer patients have 0.64 times reduced hazard of death as compared to normal BMI kidney cancer patients.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

\begin{itemize}
\tightlist
\item
  Time-to-event data is common
\item
  Survival analysis techniques are required to account for censored data
\item
  The \texttt{survival} package provides tools for survival analysis, including the \texttt{Surv} and \texttt{survfit} functions
\item
  The \texttt{survminer} package allows for customization of Kaplan-Meier plots based on \texttt{ggplot2}
\item
  Between-group comparisons can be made with the log-rank test using \texttt{survival::survdiff}
\item
  Multiavariable Cox regression analysis can be accomplished using \texttt{survival::coxph}
\end{itemize}

\hypertarget{survival-analysis-in-r-2}{%
\chapter{Survival Analysis in R}\label{survival-analysis-in-r-2}}

output:
html\_document:
toc: TRUE
toc\_float: TRUE

This tutorial provides an introduction to survival analysis, and to conducting a survival analysis in R.

This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center R-Presenters series on August 30, 2018.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# load packages
library(knitr)
library(tidyverse)
library(broom)

# load my package to access msk_palette with MSK brand colors
devtools::install_github( zabore/ezfun )
\end{verbatim}

\begin{verbatim}
{r loaddata 2, echo = TRUE}
# load(here::here( data ,  survival_data_example.RData ))
\end{verbatim}

\hypertarget{introduction-4}{%
\chapter{Introduction}\label{introduction-4}}

\hypertarget{what-is-survival-data-1}{%
\section{What is survival data?}\label{what-is-survival-data-1}}

Time-to-event data that consists of a distinct start time and end time.

Examples from cancer:

\begin{itemize}
\tightlist
\item
  Time from surgery to death
\item
  Time from start of treatment to progression
\item
  Time from response to recurrence
\end{itemize}

\hypertarget{examples-from-other-fields-1}{%
\section{Examples from other fields}\label{examples-from-other-fields-1}}

Time-to-event data is common in many fields including, but not limited to:

\begin{itemize}
\tightlist
\item
  Time from HIV infection to development of AIDS
\item
  Time to heart attack
\item
  Time to onset of substance abuse
\item
  Time to initiation of sexual activity
\item
  Time to machine malfunction
\end{itemize}

\hypertarget{aliases-for-survival-analysis-1}{%
\section{Aliases for survival analysis}\label{aliases-for-survival-analysis-1}}

Because survival analysis is common in many other fields, it also goes by other names:

\begin{itemize}
\tightlist
\item
  Reliability analysis
\item
  Duration analysis
\item
  Event history analysis
\item
  Time-to-event analysis
\end{itemize}

\hypertarget{questions-of-interest-2}{%
\section{Questions of interest}\label{questions-of-interest-2}}

The two most common questions I encounter related to survival analysis are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the probability of survival to a certain point in time?
\item
  What is the average survival time?
\end{enumerate}

\hypertarget{censoring-1}{%
\chapter{Censoring}\label{censoring-1}}

\hypertarget{what-is-censoring-1}{%
\section{What is censoring?}\label{what-is-censoring-1}}

In survival analysis it is common for the exact event time to be unknown, or unobserved, which is called censoring. A subject may be censored due to:

\begin{itemize}
\tightlist
\item
  Loss to follow-up
\item
  Withdrawal from study
\item
  No event by end of fixed study period
\end{itemize}

Specifically these are examples of \textbf{right} censoring. Other common types of censoring include:

\begin{itemize}
\tightlist
\item
  Left
\item
  Interval
\end{itemize}

\hypertarget{censored-survival-data-1}{%
\section{Censored survival data}\label{censored-survival-data-1}}

When the exact event time is unknown then some patients are censored, and survival analysis methods are required.

\begin{verbatim}
{r swimmer 2, eval=FALSE, include=FALSE}
# make fake data
set.seed(20180809)
fkdt <- data_frame(Subject = as.factor(1:10), 
                   Years = sample(4:20, 10, replace = T),
                   censor = sample(c( Censor , rep( Event , 2)), 10, 
                                   replace = T)) 
# %>% mutate(Subject = fct_reorder(Subject, Years, desc = TRUE))

# plot with shapes to indicate censoring or event
ggplot(fkdt, aes(Subject, Years)) + 
    geom_bar(stat =  identity , width = 0.5, 
             fill = ezfun::msk_palette( main )[3]) + 
    geom_point(data = fkdt, 
               aes(Subject, Years, color = censor, shape = censor), 
               size = 6) +
    scale_color_manual(values = ezfun::msk_palette( contrast )[2:3]) +
    coord_flip() +
    theme_minimal() + 
    theme(legend.title = element_blank(),
          legend.position =  bottom )
\end{verbatim}

In this example, how would we compute the proportion who are event-free at 10 years?

\begin{itemize}
\tightlist
\item
  Subjects 2, 3, 5, 6, 8, 9, and 10 were all event-free at 10 years.
\item
  Subjects 4 and 7 had the event before 10 years.
\item
  Subject 1 was censored before 10 years, so we don't know whether they had the event or not by 10 years. How do we incorporate this subject into our estimate?
\end{itemize}

\hypertarget{we-can-incorporate-censored-data-using-survival-analysis-techniques-1}{%
\section{We can incorporate censored data using survival analysis techniques}\label{we-can-incorporate-censored-data-using-survival-analysis-techniques-1}}

Toy example of a Kaplan-Meier curve for this simple data (details to follow):

\begin{verbatim}
{r eval=FALSE, include=FALSE}
library(survival)
plot(survfit(Surv(Years, ifelse(censor ==  Event , 1, 0)) ~ 1, data = fkdt), 
     xlab =  Years , 
     ylab =  Survival probability , 
     mark.time = T, 
     conf.int = FALSE)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Horizontal lines represent survival duration for the interval
\item
  An interval is terminated by an event
\item
  The height of vertical lines show the change in cumulative probability
\item
  Censored observations, indicated by tick marks, reduces the cumulative survival between intervals
\end{itemize}

\hypertarget{danger-of-ignoring-censoring-1}{%
\section{Danger of ignoring censoring}\label{danger-of-ignoring-censoring-1}}

\href{https://callingbullshit.org/case_studies/case_study_musician_mortality.html}{Case study: musicians and mortality}

Conclusion: Musical genre is associated with early death among musicians.

Problem: this graph does not account for the right-censored nature of the data.

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# include_graphics( ./img/musician_death_graph.jpg )
\end{verbatim}

\hypertarget{components-of-survival-data-1}{%
\section{Components of survival data}\label{components-of-survival-data-1}}

For subject \(i\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Event time \(T_i\)
\item
  Censoring time \(C_i\)
\item
  Event indicator \(\delta_i\):

  \begin{itemize}
  \tightlist
  \item
    1 if event observed (i.e.~\(T_i \leq C_i\))
  \item
    0 if censored (i.e.~\(T_i > C_i\))
  \end{itemize}
\item
  Observed time \(Y_i = \min(T_i, C_i)\)
\end{enumerate}

\hypertarget{data-example-1}{%
\chapter{Data example}\label{data-example-1}}

\hypertarget{research-question-of-interest-1}{%
\section{Research question of interest}\label{research-question-of-interest-1}}

Investigating the obesity paradox in kidney cancer patients.

\begin{itemize}
\tightlist
\item
  Increased BMI associated with risk of kidney cancer
\item
  Is increased BMI also associated with worse prognosis among kidney cancer patients?
\end{itemize}

\hypertarget{data-structure-1}{%
\section{Data structure}\label{data-structure-1}}

\begin{itemize}
\tightlist
\item
  \texttt{\{r\ \#\ \ nrow(df)} kidney cancer patients
\item
  Outcome: overall survival
\item
  Predictor: BMI
\end{itemize}

\begin{verbatim}
{r peekdata 2, eval=FALSE, include=FALSE}
df[, c( os_yrs ,  os ,  bmi_cat )] %>% 
    head
\end{verbatim}

Variables:

\begin{itemize}
\tightlist
\item
  os\_yrs : the observed time \(Y_i = min(T_i, C_i)\)
\item
  os : the event indicator \(\delta_i\)
\item
  bmi\_cat : 1 = Normal BMI \textless{} 25, 2 = Overweight BMI 25-30, 3 = Obese BMI \textgreater{} 30
\end{itemize}

\hypertarget{preparing-data-for-analysis-1}{%
\chapter{Preparing data for analysis}\label{preparing-data-for-analysis-1}}

\hypertarget{dates-1}{%
\section{Dates}\label{dates-1}}

Data will often come with start and end dates rather than pre-calculated survival times. Our data example includes the following variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  proc\_date : Date of surgery
\item
  last\_status\_date : Date of death or last follow-up
\item
  last\_status : Character variable denoting whether the patient is alive, and the cause of death if dead
\end{enumerate}

The first step is to make sure these are formatted as dates in R.

\hypertarget{formatting-dates---base-r-1}{%
\section{Formatting dates - base R}\label{formatting-dates---base-r-1}}

First let's look at the current format of our surgery date:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date)
\end{verbatim}

We see this is a character variable in a certain format, but we need it to be formatted as a Date.

\begin{verbatim}
{r format_date1 2, eval=FALSE, include=FALSE}
df <- df %>% 
    mutate(proc_date_format1 = as.Date(proc_date, format =  %d%b%Y ))
\end{verbatim}

And after formatting we see that surgery date has Date format now:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date_format1)
\end{verbatim}

\begin{itemize}
\item
  Note that in base R the format must include the separator as well as the symbol. e.g.~if your date is in format m/d/Y then you would need \texttt{format\ =\ \ \%m/\%d/\%Y}
\item
  See a full list of date format symbols at \url{https://www.statmethods.net/input/dates.html}
\end{itemize}

\hypertarget{formatting-dates---lubridate-1}{%
\section{Formatting dates - lubridate}\label{formatting-dates---lubridate-1}}

We can also use the \texttt{lubridate} package to format dates. Again we look at our original surgery date variable:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date)
\end{verbatim}

And now use the \texttt{lubridate::dmy} function to format this into a Date:

\begin{verbatim}
{r format_date2 2}
df <- df %>% 
    mutate(proc_date_format2 = lubridate::dmy(proc_date))
\end{verbatim}

And again we see that \texttt{R} now recognizes surgery date as a Date format:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
str(df$proc_date_format2)
\end{verbatim}

\begin{itemize}
\item
  The help page for \texttt{?ymd} will show all format options.
\item
  Note that unlike the base R option, the separators do not need to be specified
\end{itemize}

\hypertarget{event-indicator-1}{%
\section{Event indicator}\label{event-indicator-1}}

Most functions used in survival analysis will also require a binary indicator of event that is:

\begin{itemize}
\tightlist
\item
  0 for no event
\item
  1 for event
\end{itemize}

Currently our data example contains a character variable indicating whehter the patient is alive, and if not indicating the cause of death, so we must create a binary indicator.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
table(df$last_status, useNA = 'ifany')

df <- df %>% 
    mutate(os_event = ifelse(last_status ==  Alive , 0, 1))

table(df$os_event)
\end{verbatim}

\hypertarget{calculating-survival-times---base-r-1}{%
\section{Calculating survival times - base R}\label{calculating-survival-times---base-r-1}}

Now that we have our dates formatted, we need to calculate the difference between start and end time in some units, usually months or years.

A base \texttt{R} solution to calculate the number of years from surgery to death:

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
# need to actually properly format the real dates for use
df <- df %>% 
    mutate(proc_date = as.Date(proc_date, format =  %d%b%Y ),
           last_status_date = as.Date(last_status_date, format =  %d%b%Y ))
\end{verbatim}

\begin{verbatim}
{r difftime_ex1 2}
df <- df %>% 
    mutate(os_yrs_opt1 = as.numeric(difftime(last_status_date, proc_date, 
                                             units =  days )) / 365.25)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(df$os_yrs_opt1)
\end{verbatim}

\begin{itemize}
\item
  Here we use \texttt{difftime} to calculate the number of days between our two dates and convert it to a numeric value using \texttt{as.numeric}. We then convert to years by dividing by 365.25, the average number of days in a year.
\item
  \emph{Sidenote}: the \textgreater0 nature of survival times is another reason why standard regression techniques such as linear regression would not be an appropriate way to analyze time-to-event data
\end{itemize}

\hypertarget{calculating-survival-times---lubridate-1}{%
\section{Calculating survival times - lubridate}\label{calculating-survival-times---lubridate-1}}

We can also use the \texttt{lubridate} package to calculate the number of years from surgery to death:

\begin{verbatim}
{r difftime_ex2 2, message = FALSE, warning = FALSE}
library(lubridate)

df <- df %>% 
    mutate(os_yrs_opt2 = 
               as.duration(proc_date %--% last_status_date) /
               dyears(1))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(df$os_yrs_opt2)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Here the operator \texttt{\%-\/-\%} is used to designate a time interval, which is then converted to the number of elapsed seconds using \texttt{as.duration} and finally converted to years by dividing by \texttt{dyears(1)}, which gives the number of seconds in a year.
\item
  If you look closely you will see the result differs slightly from the previous result due to rounding differences, but nothing that would impact our results
\item
  \emph{Note}: we need to load the \texttt{lubridate} package using a call to \texttt{library} in order to be able to access the special operators (similar to situation with pipes)
\end{itemize}

\hypertarget{analyzing-survival-data-1}{%
\chapter{Analyzing survival data}\label{analyzing-survival-data-1}}

\hypertarget{questions-of-interest-3}{%
\section{Questions of interest}\label{questions-of-interest-3}}

Recall the questions of interest:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the probability of surviving to a certain point in time?
\item
  What is the average survival time?
\end{enumerate}

\hypertarget{creating-survival-objects-1}{%
\section{Creating survival objects}\label{creating-survival-objects-1}}

The Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs.

\begin{itemize}
\tightlist
\item
  The \texttt{Surv} function from the \texttt{survival} package creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a \texttt{+} if the subject was censored. Let's look at the first 10 observations:
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::Surv(df$os_yrs, df$os)[1:10]
\end{verbatim}

\hypertarget{estimating-survival-curves-with-the-kaplan-meier-method-1}{%
\section{Estimating survival curves with the Kaplan-Meier method}\label{estimating-survival-curves-with-the-kaplan-meier-method-1}}

\begin{itemize}
\tightlist
\item
  The \texttt{survival::survfit} function creates survival curves based on a formula. Let's generate the overall survival curve for the entire cohort, assign it to object \texttt{f1}, and look at the \texttt{names} of that object:
\end{itemize}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
f1 <- survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df)
names(f1)
\end{verbatim}

Some key components of this \texttt{survfit} object that will be used to create survival curves include:

\begin{itemize}
\tightlist
\item
  \texttt{time}, which contains the start and endpoints of each time interval
\item
  \texttt{surv}, which contains the survival probability corresponding to each \texttt{time}
\end{itemize}

\hypertarget{kaplan-meier-plot---base-r-1}{%
\section{Kaplan-Meier plot - base R}\label{kaplan-meier-plot---base-r-1}}

Now we plot the \texttt{survfit} object in base \texttt{R} to get the Kaplan-Meier plot:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
     xlab =  Years , 
     ylab =  Overall survival probability )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The default plot in base \texttt{R} shows the step function (solid line) with associated confidence intervals (dotted lines). Note that the tick marks for censored patients are not shown by default, but could be added using \texttt{mark.time\ =\ TRUE}
\end{itemize}

\hypertarget{kaplan-meier-plot---ggsurvplot-1}{%
\section{Kaplan-Meier plot - ggsurvplot}\label{kaplan-meier-plot---ggsurvplot-1}}

Alternatively, the \texttt{ggsurvplot} function from the \texttt{survminer} package is built on \texttt{ggplot2}, and can be used to create Kaplan-Meier plots:

\begin{verbatim}
{r, message = FALSE, warning = FALSE}
survminer::ggsurvplot(
    fit = survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
    xlab =  Years , 
    ylab =  Overall survival probability )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The default plot using \texttt{survminer::ggsurvplot} shows the step function (solid line) with associated confidence bands (shaded area). The tick marks for censored patients are shown by default, somewhat obscuring the line itself in this example, and could be supressed using \texttt{censor\ =\ FALSE}
\end{itemize}

\hypertarget{estimating-x-year-survival-1}{%
\section{\texorpdfstring{Estimating \(x\)-year survival}{Estimating x-year survival}}\label{estimating-x-year-survival-1}}

One quantity often of interest in a survival analysis is the probability of surviving a certain number (\(x\)) of years.

For example, to estimate the probability of survivng to 5 years, use \texttt{summary} with the \texttt{times} argument:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), 
        times = 5)
\end{verbatim}

We find that the 5-year probability of survival in this study is \texttt{\{r\ \#\ \ round(summary(f1,\ times\ =\ 5)\$surv\ *\ 100)}\%. The associated lower and upper bounds of the 95\% confidence interval are also displayed.

\hypertarget{x-year-survival-and-the-survival-curve-1}{%
\section{\texorpdfstring{\(x\)-year survival and the survival curve}{x-year survival and the survival curve}}\label{x-year-survival-and-the-survival-curve-1}}

The 5-year survival probability is the point on the y-axis that corresponds to 5 years on the x-axis for the survival curve.

\begin{verbatim}
{r, message = FALSE, echo = TRUE}
survplot1 <- survminer::ggsurvplot(survival::survfit(
    survival::Surv(os_yrs, os) ~ 1, data = df), 
           xlab =  Years ,
           ylab =  Overall survival probability ,
           break.x.by = 5, 
           palette = ezfun::msk_palette( main )) +
    geom_segment(x = 5, xend = 5, y = -1, yend = 0.808, col = 2, lwd = 2) +
    geom_segment(x = 5, xend = -0.7, y = 0.808, yend = 0.808, 
                 arrow = arrow(length = unit(0.3,  inches )), col = 2, 
                 lwd = 2)

survplot1$plot <- survplot1$plot +
    annotate( text , x = 0.2, y = 0.7, label =  81% , size = 6, col = 2)

survplot1
\end{verbatim}

\hypertarget{x-year-survival-is-often-estimated-incorrectly-1}{%
\section{\texorpdfstring{\(x\)-year survival is often estimated incorrectly}{x-year survival is often estimated incorrectly}}\label{x-year-survival-is-often-estimated-incorrectly-1}}

What happens if you use a naive estimate?

\texttt{\{r\ \#\ \ table(df\$os{[}df\$os\_yrs\ \textless{}=\ 5{]}){[}2{]}} of the \texttt{\{r\ \#\ \ nrow(df)} patients died by 5 years so:

\[\Big(1 - \frac{297}{2119}\Big) \times 100 = 86\%\]

\begin{itemize}
\item
  You get an \textbf{incorrect} estimate of the 5-year probability of survival when you ignore the fact that \texttt{\{r\ \#\ \ table(df\$os{[}df\$os\_yrs\ \textless{}=\ 5{]}){[}1{]}} patients were censored before 5 years.
\item
  Recall the \textbf{correct} estimate of the 5-year probability of survival was \texttt{\{r\ \#\ \ round(summary(f1,\ times\ =\ 5)\$surv\ *\ 100)}\%.
\end{itemize}

\hypertarget{estimating-median-survival-time-1}{%
\section{Estimating median survival time}\label{estimating-median-survival-time-1}}

Another quantity often of interest in a survival analysis is the average survival time, which we quantify using the median (survival times are not expected to be normally distributed so the mean is not an appropriate summary).

We can obtain this directly from our \texttt{survfit} object:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df)
\end{verbatim}

We see the median survival time is \texttt{\{r\ \#\ \ round(summary(f1)\$table{[}\ median\ {]},\ 1)} years. The lower and upper bounds of the 95\% confidence interval are also displayed.

\hypertarget{median-survival-time-and-the-survival-curve-1}{%
\section{Median survival time and the survival curve}\label{median-survival-time-and-the-survival-curve-1}}

Median survival is the time corresponding to a survival probability of 0.5:

\begin{verbatim}
{r, message = FALSE, echo = TRUE}
survplot2 <- survminer::ggsurvplot(survival::survfit(
    survival::Surv(os_yrs, os) ~ 1, data = df), 
           xlab =  Years ,
           ylab =  Overall survival probability ,
           break.x.by = 5, 
           palette = ezfun::msk_palette( main )) +
    geom_segment(x = -1, xend = 12.6794, y = 0.5, yend = 0.5, 
                 col = 2, lwd = 2) +
    geom_segment(x = 12.6794, xend = 12.6794, y = 0.5, yend = -0.02, 
                 arrow = arrow(length = unit(0.3,  inches )), col = 2, 
                 lwd = 2)

survplot2$plot <- survplot2$plot +
    annotate( text , x = 9.5, y = 0.02, label =  12.7 years , size = 6, col = 2)

survplot2
\end{verbatim}

\hypertarget{median-survival-is-often-estimated-incorrectly-1}{%
\section{Median survival is often estimated incorrectly}\label{median-survival-is-often-estimated-incorrectly-1}}

What happens if you use a naive estimate?

Summarize the median survival time among the \texttt{\{r\ \#\ \ table(df\$os){[}2{]}} patients who died:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df$os_yrs[df$os == 1] %>% 
    median
\end{verbatim}

\begin{itemize}
\item
  You get an \textbf{incorrect} estimate of median survival time of \texttt{\{r\ \#\ \ round(median(df\$os\_yrs{[}df\$os\ ==\ 1{]}),\ 1)} years when you ignore the fact that censored patients also contribute follow-up time.
\item
  Recall the \textbf{correct} estimate of median survival time is \texttt{\{r\ \#\ \ round(summary(f1)\$table{[}\ median\ {]},\ 1)} years.
\end{itemize}

\hypertarget{comparing-survival-times-between-groups-1}{%
\chapter{Comparing survival times between groups}\label{comparing-survival-times-between-groups-1}}

\hypertarget{questions-of-interest-with-respect-to-between-group-differences-1}{%
\section{Questions of interest with respect to between-group differences}\label{questions-of-interest-with-respect-to-between-group-differences-1}}

Is there a difference in survival probability between groups?

From our example: does the probability of survival differ according to BMI among kidney cancer patients?

\hypertarget{kaplan-meier-plot-by-group-1}{%
\section{Kaplan-Meier plot by group}\label{kaplan-meier-plot-by-group-1}}

We can add a covariate to the right-hand side of the \texttt{survival::survfit} object to obtain a stratified Kaplan-Meier plot.

Let's also look at some other customization we can do with \texttt{survminer::ggsurvplot}.

\begin{verbatim}
{r fig.height = 6}
survminer::ggsurvplot(
    fit = survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), 
    xlab =  Years ,
    ylab =  Overall survival probability ,
    legend.title =  BMI ,
    legend.labs = c( Normal ,  Overweight ,  Obese ),
    break.x.by = 5, 
    palette = ezfun::msk_palette( contrast ), 
    censor = FALSE,
    risk.table = TRUE,
    risk.table.y.text = FALSE)
\end{verbatim}

\begin{itemize}
\tightlist
\item
  By looking at the curves, we can see that normal BMI patients have the lowest overall survival probability, followed by overweight BMI patients and obese BMI patients.
\item
  The risk table below the plot shows us the number of patients at risk at certain time points, which can give an idea of how much information is being used to calculate the estimates at each time
\end{itemize}

\hypertarget{x-year-survival-probability-by-group-1}{%
\section{\texorpdfstring{\(x\)-year survival probability by group}{x-year survival probability by group}}\label{x-year-survival-probability-by-group-1}}

As before, we can get an estimate of, for example, 5-year survival by using \texttt{summary} with the \texttt{times} argument in our \texttt{survival::survfit} object:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), 
        times = 5)
\end{verbatim}

To summarize:

\begin{verbatim}
{r eval=FALSE, include=FALSE}
library(survival)
tab <- ezfun::uvsurv(NULL,  bmi_cat ,  os ,  os_yrs , 5, df)[-1, c(1, 3)]
colnames(tab) <- c( BMI ,  5-year estimate (95% CI) )
tab[, 1] <- c( Normal ,  Overweight ,  Obese )
kable(tab, row.names = FALSE)
\end{verbatim}

\hypertarget{log-rank-test-for-between-group-significance-test-1}{%
\section{Log-rank test for between-group significance test}\label{log-rank-test-for-between-group-significance-test-1}}

\begin{itemize}
\tightlist
\item
  We can conduct between-group significance tests using a log-rank test.
\item
  The log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups.
\item
  There are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question.
\end{itemize}

We get the log-rank p-value using the \texttt{survival::survdiff} function:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
survival::survdiff(survival::Surv(df$os_yrs, df$os) ~ df$bmi_cat)
\end{verbatim}

And we see that the p-value is \textless.001, indicating a significant difference in overall survival according to BMI.

\hypertarget{regression-3}{%
\chapter{Regression}\label{regression-3}}

\hypertarget{the-cox-regression-model-1}{%
\section{The Cox regression model}\label{the-cox-regression-model-1}}

We may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables.

The Cox regression model is a semi-parametric model that can be used to fit univariable and multivariable regression models that have survival outcomes.

Some key assumptions of the model:

\begin{itemize}
\tightlist
\item
  non-informative censoring
\item
  proportional hazards
\end{itemize}

\emph{Note}: parametric regression models for survival outcomes are also available, but I won't cover them in detail here.

\hypertarget{cox-regression-example-using-a-single-covariate-1}{%
\section{Cox regression example using a single covariate}\label{cox-regression-example-using-a-single-covariate-1}}

We can fit regression models for survival data using the \texttt{survival::coxph} function, which takes a \texttt{survival::Surv} object on the left hand side and has standard syntax for regression formulas in \texttt{R} on the right hand side.

\begin{verbatim}
{r eval = FALSE}
survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), data = df)
\end{verbatim}

We can see a tidy version of the output using the \texttt{tidy} function from the \texttt{broom} package:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
broom::tidy(survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), 
                            data = df))
\end{verbatim}

\hypertarget{hazard-ratios-1}{%
\section{Hazard ratios}\label{hazard-ratios-1}}

The quantity of interest from a Cox regression model is a \textbf{hazard ratio (HR)}.

If you have a regression parameter \(\beta\) (from column \texttt{estimate} in our \texttt{survival::coxph}) then HR = \(\exp(\beta)\).

For example, from our example we obtain the regression parameter \(\beta_1=-0.4441733\) for obese vs normal BMI, so we have HR = \(\exp(\beta_1)=0.64\).

A HR \textless{} 1 indicates reduced hazard of death whereas a HR \textgreater{} 1 indicates an increased hazard of death.

So we would say that obese BMI kidney cancer patients have 0.64 times reduced hazard of death as compared to normal BMI kidney cancer patients.

\hypertarget{summary-1}{%
\section{Summary}\label{summary-1}}

\begin{itemize}
\tightlist
\item
  Time-to-event data is common
\item
  Survival analysis techniques are required to account for censored data
\item
  The \texttt{survival} package provides tools for survival analysis, including the \texttt{Surv} and \texttt{survfit} functions
\item
  The \texttt{survminer} package allows for customization of Kaplan-Meier plots based on \texttt{ggplot2}
\item
  Between-group comparisons can be made with the log-rank test using \texttt{survival::survdiff}
\item
  Multiavariable Cox regression analysis can be accomplished using \texttt{survival::coxph}
\end{itemize}

\hypertarget{survival-analysis-in-r-3}{%
\section{Survival Analysis in R}\label{survival-analysis-in-r-3}}

\url{https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(survival)
library(ranger)
library(ggplot2)
library(dplyr)
library(ggfortify)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(veteran)
head(veteran)
\end{verbatim}

\hypertarget{censored-data}{%
\subsection{Censored Data}\label{censored-data}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
km <- with(veteran, Surv(time, status))

head(km,80)
\end{verbatim}

\hypertarget{kaplan-meier-1}{%
\subsection{Kaplan Meier}\label{kaplan-meier-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
km_fit <- survfit(Surv(time, status) ~ 1, data = veteran)

km_fit
\end{verbatim}

\hypertarget{life-table}{%
\subsection{Life Table}\label{life-table}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(km_fit, times = c(1,30,60,90*(1:10)))
\end{verbatim}

\hypertarget{km-graph-overall}{%
\subsection{KM Graph Overall}\label{km-graph-overall}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
plot(km_fit, xlab= Days , main = 'Kaplan Meyer Plot') #base graphics is always ready
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
autoplot(km_fit)
\end{verbatim}

\hypertarget{km-per-treatment-group}{%
\subsection{KM per treatment group}\label{km-per-treatment-group}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
km_trt_fit <- survfit(Surv(time, status) ~ trt, data = veteran)
km_trt_fit
\end{verbatim}

\hypertarget{km-graph-per-treatment-group}{%
\subsection{KM Graph per treatment group}\label{km-graph-per-treatment-group}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
autoplot(km_trt_fit)
\end{verbatim}

\hypertarget{survminer-2}{%
\chapter{survminer}\label{survminer-2}}

\url{http://www.sthda.com/english/rpkgs/survminer/\#uber-platinum-customized-survival-curves}

\hypertarget{openintro-statistics}{%
\chapter{OpenIntro Statistics}\label{openintro-statistics}}

\url{https://www.openintro.org/stat/surv.php}

\url{https://www.openintro.org/download.php?file=survival_analysis_in_R\&referrer=/stat/surv.php}

\url{https://www.openintro.org/download.php?file=survival_analysis_in_R_code\&referrer=/stat/surv.php}

\url{https://www.openintro.org/download.php?file=survival_analysis_in_R_code_df-cp\&referrer=/stat/surv.php}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( OIsurv )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# library(OIsurv)
library(survival)
library(splines)
library(KMsurv)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(help=KMsurv)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(aids)
aids
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
 data(tongue)
tongue
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
my.surv.object <- Surv(tongue$time[tongue$type==1], tongue$delta[tongue$type==1])
my.surv.object
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data(psych)
psych
my.surv.object <- Surv(psych$age, psych$age + psych$time, psych$death)
my.surv.object
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rm(list=ls())

#===> loading packages and such <===#
#install.packages( OIsurv )
library(OIsurv)
data(aids)
aids
attach(aids)
infect
detach(aids)
aids$infect

#===> survival object <===#
data(tongue); attach(tongue)   # the following will not affect computations
# create a subset for just the first group by using [type==1]
my.surv.object <- Surv(time[type==1], delta[type==1])
my.surv.object
detach(tongue)

data(psych); attach(psych)
my.surv.object <- Surv(age, age+time, death)
my.surv.object
detach(psych)

#===> K-M Estimate <===#
data(tongue); attach(tongue)
my.surv <- Surv(time[type==1], delta[type==1])
survfit(my.surv ~ 1)
my.fit <- survfit(my.surv ~ 1)
summary(my.fit)$surv     # returns the Kaplan-Meier estimate at each t_i
summary(my.fit)$time     # {t_i}
summary(my.fit)$n.risk   # {Y_i}
summary(my.fit)$n.event  # {d_i}
summary(my.fit)$std.err  # standard error of the K-M estimate at {t_i}
summary(my.fit)$lower    # lower pointwise estimates (alternatively, $upper)
str(my.fit)              # full summary of the my.fit object
str(summary(my.fit))     # full summary of the my.fit object
pdf( ../figures/kmPlot.pdf , 7, 4.5)
plot(my.fit, main= Kaplan-Meier estimate with 95% confidence bounds ,
   xlab= time , ylab= survival function )
dev.off()
my.fit1 <- survfit( Surv(time, delta) ~ type )   # here the key is  type 
detach(tongue)

#===> confidence bands <===#
data(bmt); attach(bmt)
my.surv <- Surv(t2[group==1], d3[group==1])
my.cb <- confBands(my.surv, confLevel=0.95, type= hall )
pdf( ../figures/confBand.pdf , 8, 5)
plot(survfit(my.surv ~ 1), xlim=c(100, 600), xlab= time ,
  ylab= Estimated Survival Function ,
  main= Reproducing Confidence Bands for Example 4.2 in Klein/Moeschberger )

lines(my.cb$time, my.cb$lower, lty=3, type= s )
lines(my.cb$time, my.cb$upper, lty=3, type= s )
legend(100, 0.3, legend=c( K-M survival estimate ,
   pointwise intervals , confidence bands ), lty=1:3)
dev.off()
detach(bmt)


#===> cumulative hazard <===#
data(tongue); attach(tongue)
my.surv <- Surv(time[type==1], delta[type==1])
my.fit  <- summary(survfit(my.surv ~ 1))
H.hat   <- -log(my.fit$surv)
H.hat   <- c(H.hat, tail(H.hat, 1))
h.sort.of <- my.fit$n.event / my.fit$n.risk
H.tilde   <- cumsum(h.sort.of)
H.tilde   <- c(H.tilde, tail(H.tilde, 1))
pdf( ../figures/cumHazard.pdf , 6, 4)
plot(c(my.fit$time, 250), H.hat, xlab= time , ylab= cumulative hazard ,
  main= comparing cumulative hazards , ylim=range(c(H.hat, H.tilde)), type= s )
points(c(my.fit$time, 250), H.tilde, lty=2, type= s )
legend( topleft , legend=c( H.hat , H.tilde ), lty=1:2)
dev.off()
detach(tongue)


#===> mean/median <===#
data(drug6mp); attach(drug6mp)
my.surv <- Surv(t1, rep(1, 21))   # all placebo patients observed
survfit(my.surv ~ 1)
print(survfit(my.surv ~ 1), print.rmean=TRUE)
detach(drug6mp)

#===> test for 2+ samples <===#
data(btrial); attach(btrial)
survdiff(Surv(time, death) ~ im)   # output omitted
survdiff(Surv(time, death) ~ im, rho=1)   # output omitted
detach(btrial)

#===> coxph, time-independent <===#
data(burn); attach(burn)
my.surv   <- Surv(T1, D1)
coxph.fit <- coxph(my.surv ~ Z1 + as.factor(Z11), method= breslow )
coxph.fit
co <- coxph.fit$coefficients  # may use coxph.fit$coeff instead
va <- coxph.fit$var           # I^(-1), estimated cov matrix of the estimates
ll <- coxph.fit$loglik        # log-likelihood for alt and null MLEs, resp.
my.survfit.object <- survfit(coxph.fit)
hold <- survfit(my.surv ~ 1)
#source( http://www.stat.ucla.edu/~david/teac/surv/local-coxph-test.R )
coxph.fit
C   <- matrix(c(0, 1, 0, 0,
                0, 0, 1, 0,
                0, 0, 0, 1), nrow=3, byrow=TRUE)
d   <- rep(0, 3)
t1  <- C %*% co - d
t2  <- C %*% va %*% t(C)
XW2 <- c(t(t1) %*% solve(t2) %*% t1)
pchisq(XW2, 3, lower.tail=FALSE)
#local.coxph.test(coxph.fit, 2:4)
my.survfit.object <- survfit(coxph.fit)
detach(burn)


#===> coxph, time-dependent <===#
data(relapse)
relapse

N  <- dim(relapse)[1]
t1 <- rep(0, N+sum(!is.na(relapse$int)))  # initialize start time at 0
t2 <- rep(-1, length(t1))                 # build vector for end times
d  <- rep(-1, length(t1))                 # whether event was censored
g  <- rep(-1, length(t1))                 # gender covariate
i  <- rep(FALSE, length(t1))              # initialize intervention at FALSE

j  <- 1
for(ii in 1:dim(relapse)[1]){
  if(is.na(relapse$int[ii])){      # no intervention, copy survival record
    t2[j] <- relapse$event[ii]
    d[j]  <- relapse$delta[ii]
    g[j]  <- relapse$gender[ii]
    j <- j+1
  } else {                         # intervention, split records
    g[j+0:1] <- relapse$gender[ii] # gender is same for each time
    d[j]     <- 0                  # no relapse observed pre-intervention
    d[j+1]   <- relapse$delta[ii]  # relapse occur post-intervention?
    i[j+1]   <- TRUE               # intervention covariate, post-intervention
    t2[j]    <- relapse$int[ii]-1  # end of pre-intervention
    t1[j+1]  <- relapse$int[ii]-1  # start of post-intervention
    t2[j+1]  <- relapse$event[ii]  # end of post-intervention
    j <- j+2                       # two records added
  }
}

mySurv <- Surv(t1, t2, d)        # pg 3 discusses left-trunc. right-cens. data
myCPH  <- coxph(mySurv ~ g + i)

#data(burn); attach(burn)
##source( http://www.stat.ucla.edu/~david/teac/surv/time-dep-coxph.R )
#td.coxph <- timeDepCoxph(burn,  T1 ,  D1 , 2:4,  Z1 , verbose=FALSE)
#td.coxph   # some model output is omitted for brevity
#detach(burn)

#===> AFT models <===#
data(larynx)
attach(larynx)
srFit <- survreg(Surv(time, delta) ~ as.factor(stage) + age, dist= weibull )
summary(srFit)
srFitExp <- survreg(Surv(time, delta) ~ as.factor(stage) + age, dist= exponential )
summary(srFitExp)
srFitExp$coeff    # covariate coefficients
srFitExp$icoef    # intercept and scale coefficients
srFitExp$var      # variance-covariance matrix
srFitExp$loglik   # log-likelihood
srFit$scale       # not using srFitExp (defaulted to 1)
detach(larynx)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

# Posted with permission of the code author:
# Beau Benjamin Bruce
# Author email: bbbruce@emory.edu
# 
# This code is available under GPL-2
# For license information, see
# http://cran.r-project.org/web/licenses/GPL-2

library(KMsurv)
data(burn)

#=====> Convert a data frame to a counting process version <=====#
#=====> Allows for time dependent variables to be introduced <=====#
df.cp = function(data,t.var,status.var,covars=setdiff(names(data),c(t.var,status.var))) {
  # data: data frame that represents the dataset
  # t.var: the column name of  data  that represents the survival time variable
  # status.var: the column name of  data  that represents the status variable
  # covars: list other covariates to retain
  
  # Returned object: a data frame that breaks each event down to a counting process
  
  # sorted times, append to 0
  t.sort <- c(0,sort(unlist(unique(data[t.var]))))
  
  # for each data point find times less than or equal to the obs' time
  t.list <- lapply(unlist(data[t.var]),function(x) t.sort[t.sort<=x])
  
  # create a list of datasets with covariates and all relevant start/stop times
  # use with to set the environment to the correct list item
  df.list <- lapply(seq_along(t.list),function(i) cbind(with(list(x=t.list[[i]]),
                     # start by removing one from end of x, stop by removing first of x
                     # include the status variable in the dataframe - helpful later                                        
                     data.frame(start=head(x,-1),stop=tail(x,-1),data[i,c(status.var,covars)]))))

  # do.call uses df.list as the argument for rbind
  df <- do.call(rbind,df.list)

  # create the correct status need last time for each
  # subject with status=1 to to be status=1 but all others status=0
  #
  # the lapply creates vectors 0,0,0,...,1 based on length of t.list
  # need to substract 2 because the lag takes one away, then need one for the 1 at end
  # do.call with c binds them together into a single vector
  # this is then multiplied by status to correct it
  keep.status <- do.call(c,lapply(t.list,function(x) c(rep(0,length(x)-2),1)))
  df[status.var] <- df[status.var] * keep.status
  df
}


#=====> Create the counting process data frame <=====#
burn.cp <- df.cp(burn,'T1','D1')
burn.cp <- within(burn.cp,{ T1Z1 <- log(stop)*Z1; }) 

#=====> Apply the Cox Proportional Hazards model <=====#
coxph(Surv(start,stop,D1) ~ Z1+Z2+Z3+T1Z1,data=burn.cp)

\end{verbatim}

\hypertarget{survsup}{%
\chapter{survsup}\label{survsup}}

\begin{itemize}
\tightlist
\item
  Plotting survival curves with the survsup package
\end{itemize}

\url{https://cran.r-project.org/web/packages/survsup/vignettes/survsup_intro.html}

\url{http://github.com/dlindholm/survsup/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( survsup )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(survsup)
library(ggplot2)
library(survival)
library(dplyr)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fit <- survfit(Surv(time, status) ~ 1, data = lung)
plot_survfit(fit)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ 1, data = .) %>%
  plot_survfit()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ 1, data = .) %>%
  plot_survfit(cuminc = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit(cuminc = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit(cuminc = FALSE, ci = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit(cuminc = FALSE, ci = TRUE) + # < NOTE!
  labs(x =  Time (days) , y =  Survival (%) )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit(cuminc = FALSE) %>%
  nar()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lung %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit(cuminc = FALSE) %>%
  nar(size = 3)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ rx, data = .) %>%
  plot_survfit() %>%
  nar() +
  scale_color_manual(values = c( darkorange ,  steelblue ,  darkred ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit() %>%
  nar() %>%
  skislopes()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit() %>%
  nar() %>%
  skislopes(reverse = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit() %>%
  nar() %>%
  cat4()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit() %>%
  nar() %>%
  hcl_rainbow()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit() %>%
  nar() %>%
  hcl_rainbow(reverse = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(lwd = 2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(lwd = 0.5)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(legend.title =  Extent of disease )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(ylim = c(0, 100)) %>%
  nar()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(xmax = 2000) %>%
  nar()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ extent, data = .) %>%
  plot_survfit(xmax = 2000, xbreaks = c(0, 1000, 2000)) %>%
  nar()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(flip = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(size = 5, flip = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(size = 2, flip = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(y_offset = 0.1, flip = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(y_offset = 0.03, flip = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(separator = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colon %>%
  survfit(Surv(time, status) ~ sex, data = .) %>%
  plot_survfit() %>%
  nar(sep_color =  grey90 , sep_lwd = 1.5)
\end{verbatim}

\url{https://cran.r-project.org/package=gridExtra}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(gridExtra)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
p <- list(
  p1 = colon %>%
    survfit(Surv(time, status) ~ sex, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar() +
    labs(tag =  A ),

  p2 = colon %>%
    survfit(Surv(time, status) ~ node4, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar() +
    labs(tag =  B )
)

grid.arrange(grobs = p, ncol = 2)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Store plots in a list
p <- list(
  p1 = colon %>%
    survfit(Surv(time, status) ~ 1, data = .) %>%
    plot_survfit(ylim = c(0, 100)) +
    labs(tag =  A ),

  p2 = colon %>%
    survfit(Surv(time, status) ~ rx, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar(2, separator = FALSE) +
    labs(tag =  B ),

  p3 = colon %>%
    survfit(Surv(time, status) ~ extent, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar(2, separator = FALSE) +
    labs(tag =  C ),

  p4 = colon %>%
    survfit(Surv(time, status) ~ sex, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar(2, separator = FALSE) +
    labs(tag =  D ),

  p5 = colon %>%
    survfit(Surv(time, status) ~ node4, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar(2, separator = FALSE) +
    labs(tag =  E ),

  p6 = colon %>%
    survfit(Surv(time, status) ~ surg, data = .) %>%
    plot_survfit(ylim = c(0, 100)) %>%
    nar(2, separator = FALSE) +
    labs(tag =  F )

)

#Define layout matrix
lay <- rbind(c(1,1,2),
             c(1,1,3),
             c(4,5,6))

#Plot it all!
grid.arrange(grobs = p, layout_matrix = lay)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
p[[ p3 ]]
\end{verbatim}

\hypertarget{survivalanalysis}{%
\chapter{survivalAnalysis}\label{survivalanalysis}}

\hypertarget{univariate-survival-analysis}{%
\section{Univariate Survival Analysis}\label{univariate-survival-analysis}}

\url{https://cran.r-project.org/web/packages/survivalAnalysis/vignettes/univariate.html}

\hypertarget{breast-cancer-wisconsin}{%
\chapter{breast cancer wisconsin}\label{breast-cancer-wisconsin}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
UCI_data_URL <- RCurl::getURL('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data')



\end{verbatim}

\hypertarget{lung-cancer}{%
\chapter{Lung Cancer}\label{lung-cancer}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(survival)
km_fit <- survfit(Surv(time, status) ~ sex, data = lung)
km_fit
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(km_fit, times = c(12,36,60))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# View fit
View(km_fit)

# Get formula
km_fit[[ call ]][[ formula ]]

# Get formula 2
km_fit[[ call ]]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)
# make a dataframe from fit list
fitDF <- bind_cols(
time = km_fit[[ time ]],
n.risk = km_fit[[ n.risk ]],
n.event = km_fit[[ n.event ]],
n.censor = km_fit[[ n.censor ]],
surv = km_fit[[ surv ]],
lower = km_fit[[ lower ]],
upper = km_fit[[ upper ]],
) %>% 
  mutate(
    timeyear = time / 365.25
  )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# this gives the result for the time = 0.5
fitDF[which.min(abs(fitDF$timeyear - 0.5)),]

# this gives the result for the time = 1
fitDF[which.min(abs(fitDF$timeyear - 1)),]

# this gives the result for the time = 2
fitDF[which.min(abs(fitDF$timeyear - 2)),]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
fitDF[which.min(abs(fitDF$timeyear - 0.5)),]

fitDF[which.min(abs(fitDF$timeyear - 1)),]

fitDF[which.min(abs(fitDF$timeyear - 2)),]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# https://stackoverflow.com/questions/43419385/how-to-export-survfit-output-as-a-csv-table
res <- summary(km_fit, times = c(12,36,60))
save.df <- as.data.frame(res[c( strata ,  time ,  n.risk ,  n.event ,  surv ,  std.err ,  lower ,  upper )])
# write.csv(save.df, file =  ./file.csv )
\end{verbatim}

\hypertarget{syncing-a-github-fork}{%
\chapter{Syncing a GitHub Fork}\label{syncing-a-github-fork}}

\hypertarget{configuring-a-remote-for-a-fork}{%
\chapter{Configuring a remote for a fork}\label{configuring-a-remote-for-a-fork}}

\url{https://help.github.com/articles/configuring-a-remote-for-a-fork/}

\hypertarget{open-terminal.}{%
\section{Open Terminal.}\label{open-terminal.}}

\hypertarget{list-the-current-configured-remote-repository-for-your-fork.}{%
\section{List the current configured remote repository for your fork.}\label{list-the-current-configured-remote-repository-for-your-fork.}}

\begin{verbatim}
{bash}
git remote -v
\end{verbatim}

\begin{verbatim}
origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)
origin  https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)
\end{verbatim}

\hypertarget{specify-a-new-remote-upstream-repository-that-will-be-synced-with-the-fork.}{%
\section{Specify a new remote upstream repository that will be synced with the fork.}\label{specify-a-new-remote-upstream-repository-that-will-be-synced-with-the-fork.}}

\begin{verbatim}
{bash}
git remote add upstream https://github.com/BIOP/IPA4LSx.git
\end{verbatim}

\begin{verbatim}
git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git

git remote add upstream https://github.com/BIOP/IPA4LSx.git
\end{verbatim}

\hypertarget{verify-the-new-upstream-repository-youve-specified-for-your-fork.}{%
\section{Verify the new upstream repository you've specified for your fork.}\label{verify-the-new-upstream-repository-youve-specified-for-your-fork.}}

\begin{verbatim}
{bash}
git remote -v
\end{verbatim}

\begin{verbatim}
origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)
origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)
upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch)
upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push)
\end{verbatim}

\hypertarget{syncing-a-fork}{%
\chapter{Syncing a fork}\label{syncing-a-fork}}

\url{https://help.github.com/articles/syncing-a-fork/}

\hypertarget{open-terminal.-1}{%
\section{Open Terminal.}\label{open-terminal.-1}}

\hypertarget{change-the-current-working-directory-to-your-local-project.}{%
\section{Change the current working directory to your local project.}\label{change-the-current-working-directory-to-your-local-project.}}

\hypertarget{fetch-the-branches-and-their-respective-commits-from-the-upstream-repository.-commits-to-master-will-be-stored-in-a-local-branch-upstreammaster.}{%
\section{Fetch the branches and their respective commits from the upstream repository. Commits to master will be stored in a local branch, upstream/master.}\label{fetch-the-branches-and-their-respective-commits-from-the-upstream-repository.-commits-to-master-will-be-stored-in-a-local-branch-upstreammaster.}}

\begin{verbatim}
{bash}
git fetch upstream
\end{verbatim}

\begin{verbatim}
git fetch upstream
remote: Counting objects: 75, done.
remote: Compressing objects: 100% (53/53), done.
remote: Total 62 (delta 27), reused 44 (delta 9)
Unpacking objects: 100% (62/62), done.
From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY
 * [new branch]      master     -> upstream/master
\end{verbatim}

\hypertarget{check-out-your-forks-local-master-branch.}{%
\section{Check out your fork's local master branch.}\label{check-out-your-forks-local-master-branch.}}

\begin{verbatim}
{bash}
git checkout master
\end{verbatim}

\begin{verbatim}
git checkout master
Switched to branch 'master'
\end{verbatim}

\hypertarget{merge-the-changes-from-upstreammaster-into-your-local-master-branch.-this-brings-your-forks-master-branch-into-sync-with-the-upstream-repository-without-losing-your-local-changes.}{%
\section{Merge the changes from upstream/master into your local master branch. This brings your fork's master branch into sync with the upstream repository, without losing your local changes.}\label{merge-the-changes-from-upstreammaster-into-your-local-master-branch.-this-brings-your-forks-master-branch-into-sync-with-the-upstream-repository-without-losing-your-local-changes.}}

\begin{verbatim}
{bash}
git merge upstream/master
\end{verbatim}

\begin{verbatim}
git merge upstream/master
Updating a422352..5fdff0f
Fast-forward
 README                    |    9 -
 README.md                 |    7 ++++++
 2 files changed, 7 insertions(+), 9 deletions(-)
 delete mode 100644 README
 create mode 100644 README.md
\end{verbatim}

\hypertarget{if-your-local-branch-didnt-have-any-unique-commits-git-will-instead-perform-a-fast-forward}{%
\section{If your local branch didn't have any unique commits, Git will instead perform a fast-forward :}\label{if-your-local-branch-didnt-have-any-unique-commits-git-will-instead-perform-a-fast-forward}}

\begin{verbatim}
{bash}
git merge upstream/master
\end{verbatim}

\begin{verbatim}
git merge upstream/master
Updating 34e91da..16c56ad
Fast-forward
 README.md                 |    5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)
\end{verbatim}

\textbf{Tip: Syncing your fork only updates your local copy of the repository. To update your fork on GitHub, you must push your changes.}

\hypertarget{my-r-codes-for-data-analysis-8}{%
\chapter{My R Codes For Data Analysis}\label{my-r-codes-for-data-analysis-8}}

\begin{itemize}
\tightlist
\item
  finalfit
\end{itemize}

\url{http://www.datasurg.net/2018/07/12/finalfit-now-includes-bootstrap-simulation-for-model-prediction/}

\begin{itemize}
\item
\end{itemize}

\url{https://kbroman.org/knitr_knutshell/pages/figs_tables.html}

\hypertarget{tables-4}{%
\section{Tables}\label{tables-4}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(xtable)
xtable(BMT)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(kableExtra)
kable(BMT)
\end{verbatim}

\begin{verbatim}
{r display results as table, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}

require(rhandsontable)
rhandsontable(BMT)
\end{verbatim}

\hypertarget{tttable}{%
\section{tttable}\label{tttable}}

\url{https://github.com/leeper/tttable}

\hypertarget{renderers}{%
\subsection{- renderers}\label{renderers}}

\hypertarget{xtable-2}{%
\subsubsection{- xtable}\label{xtable-2}}

\url{https://rdrr.io/cran/xtable/man/xtable.html}

\hypertarget{flextable-1}{%
\subsubsection{- flextable}\label{flextable-1}}

\url{https://davidgohel.github.io/flextable/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\url{https://cran.r-project.org/web/packages/flextable/vignettes/overview.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(flextable)
library(officer)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
data <- iris[c(1:3, 51:53, 101:104),]

data
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
flextable::regulartable(data)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- regulartable(
  head(mtcars), 
  col_keys = c( am ,  carb ,  gear ,  mpg ,  drat  ))
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- theme_vanilla(myft)
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- merge_v(myft, j = c( am ,  carb ) )
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- set_header_labels( myft, carb =  # carb.  )
myft <- width(myft, width = .75) # set width of all columns to .75 in
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- autofit(myft)
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- italic(myft, j = 1)
myft <- bg(myft, bg =  #C90000 , part =  header )
myft <- color(myft, color =  white , part =  header )
myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
myft <- color(myft, ~ drat > 3.5, ~ drat, color =  red )
myft <- bold(myft, ~ drat > 3.5, ~ drat, bold = TRUE)
myft <- autofit(myft)

myft
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(officer)


ft <- regulartable(head(mtcars))
ft <- theme_booktabs(ft)
ft <- autofit(ft)

ppt <- read_pptx()
ppt <- add_slide(ppt, layout =  Title and Content , master =  Office Theme )
ppt <- ph_with_flextable(ppt, value = ft, type =  body ) 

print(ppt, target =  output/example.pptx )

# https://view.officeapps.live.com/op/view.aspx?src=https://davidgohel.github.io/flextable/articles/assets/pptx/example.pptx
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
doc <- read_docx()
doc <- body_add_flextable(doc, value = ft)
print(doc, target =  output/example.docx )
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Make Beautiful Tables with the Formattable Package
\end{itemize}

\url{https://www.displayr.com/formattable/?utm_medium=Feed\&utm_source=Syndication}

\hypertarget{knitrkable}{%
\subsubsection{- knitr::kable()}\label{knitrkable}}

\hypertarget{formatttable}{%
\subsubsection{- formatttable}\label{formatttable}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(formattable)

p <- percent(c(0.1, 0.02, 0.03, 0.12))
p
p + 0.05
max(p)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
balance <- accounting(c(1000, 500, 200, -150, 0, 1200))
balance

balance + 1000
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
p <- data.frame(
  id = c(1, 2, 3, 4, 5), 
  name = c( A1 ,  A2 ,  B1 ,  B2 ,  C1 ),
  balance = accounting(c(52500, 36150, 25000, 18300, 7600), format =  d ),
  growth = percent(c(0.3, 0.3, 0.1, 0.15, 0.15), format =  d ),
  ready = formattable(c(TRUE, TRUE, FALSE, FALSE, TRUE),  yes ,  no ))
p
print.AsIs(p)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
df <- data.frame(
  id = 1:10,
  name = c( Bob ,  Ashley ,  James ,  David ,  Jenny , 
     Hans ,  Leo ,  John ,  Emily ,  Lee ), 
  age = c(28, 27, 30, 28, 29, 29, 27, 27, 31, 30),
  grade = c( C ,  A ,  A ,  C ,  B ,  B ,  B ,  A ,  C ,  C ),
  test1_score = c(8.9, 9.5, 9.6, 8.9, 9.1, 9.3, 9.3, 9.9, 8.5, 8.6),
  test2_score = c(9.1, 9.1, 9.2, 9.1, 8.9, 8.5, 9.2, 9.3, 9.1, 8.8),
  final_score = c(9, 9.3, 9.4, 9, 9, 8.9, 9.25, 9.6, 8.8, 8.7),
  registered = c(TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE),
  stringsAsFactors = FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}


library(formattable)

formattable(df, list(
  age = color_tile( white ,  orange ),
  grade = formatter( span , style = x ~ ifelse(x ==  A , 
    style(color =  green , font.weight =  bold ), NA)),
  area(col = c(test1_score, test2_score)) ~ normalize_bar( pink , 0.2),
  final_score = formatter( span ,
    style = x ~ style(color = ifelse(rank(-x) <= 3,  green ,  gray )),
    x ~ sprintf( %.2f (rank: %02d) , x, rank(-x))),
  registered = formatter( span ,
    style = x ~ style(color = ifelse(x,  green ,  red )),
    x ~ icontext(ifelse(x,  ok ,  remove ), ifelse(x,  Yes ,  No )))
))
\end{verbatim}

\hypertarget{knitlatex}{%
\subsubsection{- knitLatex}\label{knitlatex}}

\hypertarget{htmltable-3}{%
\subsubsection{- htmlTable}\label{htmltable-3}}

\hypertarget{psytabs}{%
\subsubsection{- psytabs}\label{psytabs}}

\hypertarget{sortablehtmltables-1}{%
\subsubsection{- SortableHTMLTables}\label{sortablehtmltables-1}}

\hypertarget{tablaxlsx}{%
\subsubsection{- tablaxlsx}\label{tablaxlsx}}

\hypertarget{table1xls}{%
\subsubsection{- table1xls}\label{table1xls}}

\hypertarget{tablehtml}{%
\subsubsection{- tableHTML}\label{tablehtml}}

\hypertarget{tablemonster}{%
\subsubsection{- TableMonster}\label{tablemonster}}

\hypertarget{texreg-1}{%
\subsubsection{- texreg}\label{texreg-1}}

\hypertarget{ztable-1}{%
\subsubsection{- ztable}\label{ztable-1}}

\hypertarget{apastyle}{%
\subsubsection{- apaStyle}\label{apastyle}}

\hypertarget{apatables-1}{%
\subsubsection{- apaTables}\label{apatables-1}}

\hypertarget{apsrtable}{%
\subsubsection{- apsrtable}\label{apsrtable}}

\hypertarget{dt-2}{%
\subsubsection{- DT}\label{dt-2}}

\url{https://www.infoworld.com/video/91607/r-tip-quick-interactive-tables}

\url{https://rstudio.github.io/DT/}

\url{https://datatables.net/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages('DT')
\end{verbatim}

\hypertarget{gtsummary}{%
\subsubsection{- gtsummary}\label{gtsummary}}

\url{https://github.com/vincentarelbundock/gtsummary}

\hypertarget{higher-level-functionality}{%
\subsection{- higher-level functionality}\label{higher-level-functionality}}

\hypertarget{finalfit-5}{%
\subsubsection{- finalfit}\label{finalfit-5}}

\url{https://github.com/ewenharrison/finalfit}

\url{http://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( ewenharrison/finalfit )
# install.packages( rstan )
# install.packages( boot )

library(tidyverse)
library(finalfit)
library(rstan)
library(boot)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Load example dataset, modified version of survival::colon
data(colon_s)



colon_s2$age <- as.numeric(colon_s$age)
colon_s2$age.factor <- as_factor(colon_s$age.factor)
colon_s2$sex.factor <- as_factor(colon_s$sex.factor)
colon_s2$obstruct.factor <- as_factor(colon_s$obstruct.factor)
colon_s2$perfor.factor <- as_factor(colon_s$perfor.factor)
colon_s2$mort_5yr <- as_factor(colon_s$mort_5yr)
colon_s2$hospital <- as_factor(colon_s$hospital)
colon_s2$status <- as.numeric(colon_s$status)
colon_s2$time <- as.numeric(colon_s$time)
colon_s2

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Table 1 - Patient demographics by variable of interest -
explanatory = c( age ,  age.factor , 
   sex.factor ,  obstruct.factor )
dependent =  perfor.factor  # Bowel perforation
table <- colon_s2 %>%
  summary_factorlist(dependent, explanatory,
  p=TRUE, add_dependent_label=TRUE, total_col = TRUE)

print.AsIs(table)


\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Table 2 - 5 yr mortality -
explanatory = c( age.factor , 
   sex.factor ,
   obstruct.factor )
dependent = 'mort_5yr'
table <- colon_s %>%
  summary_factorlist(dependent, explanatory, 
  p=TRUE, add_dependent_label=TRUE)

print.AsIs(table)
\end{verbatim}

\begin{verbatim}
{r results='asis', eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(table, row.names=FALSE, 
    align=c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
dependent = 'mort_5yr'
table_surv <- colon_s2 %>%
  finalfit(dependent, explanatory)
\end{verbatim}

\begin{verbatim}
{r results='asis', eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(table_surv, row.names = FALSE, 
    align = c( l ,  l ,  r ,  r ,  r ,  r ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
explanatory_multi = c( age.factor , 
   obstruct.factor )
dependent = 'mort_5yr'
colon_s2 %>%
  finalfit(dependent, explanatory, 
  explanatory_multi)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
explanatory_multi = c( age.factor ,  obstruct.factor )
random_effect =  hospital 
dependent = 'mort_5yr'
colon_s2 %>%
  finalfit(dependent, explanatory, 
  explanatory_multi, random_effect)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

explanatory = c( age.factor ,  sex.factor , 
 obstruct.factor ,  perfor.factor )
dependent =  Surv(time, status) 
colon_s2 %>%
  finalfit(dependent, explanatory)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
dependent = 'mort_5yr'
table7 <- colon_s2 %>%
  finalfit(dependent, explanatory, 
  metrics=TRUE)
\end{verbatim}

\begin{verbatim}
{r, eval=FALSE, include=FALSE, echo=TRUE, results= asis }
knitr::kable(table7[[1]], row.names=FALSE, align=c( l ,  l ,  r ,  r ,  r ))
knitr::kable(table7[[2]], row.names=FALSE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
explanatory_multi = c( age.factor ,  obstruct.factor )
random_effect =  hospital 
dependent = 'mort_5yr'

# Separate tables
colon_s2 %>%
  summary_factorlist(dependent, 
  explanatory, fit_id=TRUE) -> example.summary

colon_s2 %>%
  glmuni(dependent, explanatory) %>%
  fit2df(estimate_suffix=  (univariable) ) -> example.univariable

colon_s2 %>%
  glmmulti(dependent, explanatory) %>%
  fit2df(estimate_suffix=  (multivariable) ) -> example.multivariable

colon_s2 %>%
  glmmixed(dependent, explanatory, random_effect) %>%
  fit2df(estimate_suffix=  (multilevel) ) -> example.multilevel

# Pipe together
example.summary %>%
  finalfit_merge(example.univariable) %>%
  finalfit_merge(example.multivariable) %>%
  finalfit_merge(example.multilevel) %>%
  select(-c(fit_id, index)) %>% # remove unnecessary columns
  dependent_label(colon_s2, dependent, prefix=  ) # place dependent variable label
\end{verbatim}

\begin{verbatim}
{r fig.height=5, fig.width=6, eval=FALSE, include=FALSE, echo=TRUE, warning=FALSE, message=FALSE}
# OR plot
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
dependent = 'mort_5yr'
colon_s2 %>%
  or_plot(dependent, explanatory)
# Previously fitted models (`glmmulti()` or 
# `glmmixed()`) can be provided directly to `glmfit`
\end{verbatim}

\begin{verbatim}
{r fig.height=5, fig.width=6, eval=FALSE, include=FALSE, echo=TRUE}
# HR plot
explanatory = c( age.factor ,  sex.factor , 
   obstruct.factor ,  perfor.factor )
dependent =  Surv(time, status) 
colon_s2 %>%
  hr_plot(dependent, explanatory, dependent_label =  Survival )
# Previously fitted models (`coxphmulti`) can be provided directly using `coxfit`
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# KM plot
explanatory = c( perfor.factor )
dependent =  Surv(time, status) 

plotKM <- colon_s2 %>%
  surv_plot(dependent, explanatory, 
  xlab =  Time (days) , pval = TRUE, legend =  none )

plotKM
\end{verbatim}

\hypertarget{janitor}{%
\subsubsection{- janitor}\label{janitor}}

\hypertarget{huxtable-1}{%
\subsubsection{- huxtable}\label{huxtable-1}}

\url{https://hughjonesd.github.io/huxtable/design-principles.html}

\hypertarget{tables-5}{%
\subsubsection{- tables}\label{tables-5}}

\hypertarget{stargazer-3}{%
\subsubsection{- stargazer}\label{stargazer-3}}

\hypertarget{pixiedust}{%
\subsubsection{- pixiedust}\label{pixiedust}}

pixiedust: Tables so Beautifully Fine-Tuned You Will Believe It's Magic

\url{https://cran.r-project.org/web/packages/pixiedust/vignettes/pixiedust.html}

\url{https://cran.r-project.org/web/packages/pixiedust/vignettes/advancedMagic.html}

\hypertarget{reporttools}{%
\subsubsection{- reporttools}\label{reporttools}}

\hypertarget{rtable}{%
\subsubsection{- rtable}\label{rtable}}

\hypertarget{summarytools-6}{%
\subsubsection{- summarytools}\label{summarytools-6}}

\hypertarget{tab}{%
\subsubsection{- tab}\label{tab}}

\hypertarget{tableone-1}{%
\subsubsection{- tableone}\label{tableone-1}}

\hypertarget{carpenter}{%
\subsubsection{- carpenter}\label{carpenter}}

\url{https://cran.r-project.org/web/packages/carpenter/vignettes/carpenter.html}

\hypertarget{dtables}{%
\subsubsection{- dtables}\label{dtables}}

\hypertarget{etable}{%
\subsubsection{- etable}\label{etable}}

\hypertarget{tangram-1}{%
\subsubsection{- tangram}\label{tangram-1}}

tangram (grammar of tables)

\url{https://github.com/spgarbet/tangram}
\url{http://htmlpreview.github.io/?https://github.com/spgarbet/tg/blob/master/vignettes/example.html}

\url{https://github.com/spgarbet/tangram/issues/36}

\hypertarget{pivots}{%
\subsection{- pivots}\label{pivots}}

\hypertarget{rpivotttable}{%
\subsubsection{- rpivotttable}\label{rpivotttable}}

\hypertarget{other}{%
\subsection{- other}\label{other}}

\hypertarget{gtable-2}{%
\subsubsection{- gtable}\label{gtable-2}}

\hypertarget{sjtlm}{%
\subsubsection{- sjtlm}\label{sjtlm}}

\url{https://strengejacke.github.io/sjPlot/articles/sjtlm.html}

\hypertarget{arsenal-2}{%
\subsubsection{- arsenal}\label{arsenal-2}}

to compare data frames: \url{https://cran.r-project.org/web/packages/arsenal/vignettes/compare.html}

\hypertarget{arsenalpaired}{%
\paragraph{- arsenal::paired}\label{arsenalpaired}}

summary statistics for a set of variables paired across two time points:

\url{https://cran.r-project.org/web/packages/arsenal/vignettes/paired.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(arsenal)
dat <- data.frame(
  tp = paste0( Time Point  , c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)),
  id = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 6),
  Cat = c( A ,  A ,  A ,  B ,  B ,  B ,  B ,  A , NA,  B ),
  Fac = factor(c( A ,  B ,  C ,  A ,  B ,  C ,  A ,  B ,  C ,  A )),
  Num = c(1, 2, 3, 4, 4, 3, 3, 4, 0, NA),
  Ord = ordered(c( I ,  II ,  II ,  III ,  III ,  III ,  I ,  III ,  II ,  I )),
  Lgl = c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE),
  Dat = as.Date( 2018-05-01 ) + c(1, 1, 2, 2, 3, 4, 5, 6, 3, 4),
  stringsAsFactors = FALSE
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dat
\end{verbatim}

\begin{verbatim}
{r include=FALSE, eval=FALSE, comment=NA, prompt=FALSE, cache=FALSE, echo=TRUE, results='asis'}
p <- paired(tp ~ Cat + Fac + Num + Ord + Lgl + Dat, data = dat, id = id, signed.rank.exact = FALSE)
summary(p)
\end{verbatim}

\hypertarget{arsenalfreqlist}{%
\paragraph{- arsenal::freqlist}\label{arsenalfreqlist}}

\url{https://cran.r-project.org/web/packages/arsenal/vignettes/freqlist.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
require(arsenal)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# load the data
data(mockstudy)

# retain NAs when creating the table using the useNA argument
tab.ex <- table(mockstudy[, c( arm ,  sex ,  mdquality.s )], useNA =  ifany )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tab.ex
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
noby <- freqlist(tab.ex)

str(noby)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# view the data frame portion of freqlist output
head(noby[[ freqlist ]])  ## or use as.data.frame(noby)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
summary(noby)
\end{verbatim}

summary(noby, title = Basic freqlist output )

summary(freqlist(\textasciitilde{} arm + sex + mdquality.s, data = mockstudy, addNA = TRUE))

summary(freqlist(\textasciitilde arm + sex + addNA(mdquality.s), data = mockstudy))

summary(freqlist(\textasciitilde arm + sex + includeNA(mdquality.s, Missing ), data = mockstudy))

\begin{verbatim}
withnames <- freqlist(tab.ex, labelTranslations = c( Treatment Arm ,  Gender ,  LASA QOL ), digits = 0)
summary(withnames)
\end{verbatim}

\hypertarget{arsenaltableby}{%
\paragraph{- arsenal::tableby}\label{arsenaltableby}}

\url{https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html}

\hypertarget{arsenalmodelsum}{%
\paragraph{- arsenal::modelsum}\label{arsenalmodelsum}}

\url{https://cran.r-project.org/web/packages/arsenal/vignettes/modelsum.html}

\hypertarget{desctable}{%
\subsubsection{- desctable}\label{desctable}}

\url{https://cran.r-project.org/web/packages/desctable/vignettes/desctable.html}

\hypertarget{gt}{%
\chapter{GT}\label{gt}}

\url{https://github.com/rstudio/gt}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( devtools )
remotes::install_github( rstudio/gt )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(gt)
library(tidyverse)
library(glue)

# Define the start and end dates for the data range
start_date <-  2010-06-07 
end_date <-  2010-06-14 

# Create a gt table based on preprocessed
# `sp500` table data
sp500 %>%
  dplyr::filter(date >= start_date & date <= end_date) %>%
  dplyr::select(-adj_close) %>%
  dplyr::mutate(date = as.character(date)) %>%
  gt() %>%
  tab_header(
    title =  S&P 500 ,
    subtitle = glue::glue( {start_date} to {end_date} )
  ) %>%
  fmt_date(
    columns = vars(date),
    date_style = 3
  ) %>%
  fmt_currency(
    columns = vars(open, high, low, close),
    currency =  USD 
  ) %>%
  fmt_number(
    columns = vars(volume),
    scale_by = 1 / 1E9,
    pattern =  {x}B 
  )
\end{verbatim}

\hypertarget{sparklines}{%
\chapter{sparklines}\label{sparklines}}

R tip: Sparklines in HTML tables\\
\url{https://www.infoworld.com/video/91867/r-tip-sparklines-in-html-tables}

\hypertarget{tensorflow}{%
\chapter{Tensorflow}\label{tensorflow}}

\url{https://ai.google/education/}

\url{https://github.com/tensorflow/workshops}

\url{https://experiments.withgoogle.com/collection/ai}

\url{https://developers.google.com/machine-learning/crash-course/}

\url{https://ai.google/education/responsible-ai-practices}

\url{https://research.google.com/seedbank/}

\url{https://codelabs.developers.google.com/codelabs/end-to-end-ml/index.html\#0}

\hypertarget{text-mining}{%
\chapter{Text Mining}\label{text-mining}}

\url{https://regexr.com/}

\url{https://regex101.com/}

\hypertarget{read-text-files-with-readtext}{%
\chapter{Read text files with readtext()}\label{read-text-files-with-readtext}}

\url{https://cran.r-project.org/web/packages/readtext/vignettes/readtext_vignette.html}

\hypertarget{qdapregex}{%
\chapter{qdapRegex}\label{qdapregex}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(qdapRegex)
\end{verbatim}

\url{https://github.com/trinker/qdapRegex}

\url{http://trinker.github.io/qdapRegex_dev/index.html}

\hypertarget{stringr-2}{%
\chapter{stringr}\label{stringr-2}}

\url{https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html}

\begin{verbatim}
stringr::str_view()
\end{verbatim}

\hypertarget{regexplain}{%
\chapter{RegExplain}\label{regexplain}}

\url{https://www.garrickadenbuie.com/project/regexplain/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( gadenbuie/regexplain )
# source( https://install-github.me/gadenbuie/regexplain )
\end{verbatim}

\hypertarget{a-tidy-text-analysis-of-my-google-search-history}{%
\chapter{A Tidy Text Analysis of My Google Search History}\label{a-tidy-text-analysis-of-my-google-search-history}}

\url{https://www.r-bloggers.com/a-tidy-text-analysis-of-my-google-search-history/}

\hypertarget{text-mining-with-r-a-tidy-approach}{%
\chapter{Text Mining with R A Tidy Approach}\label{text-mining-with-r-a-tidy-approach}}

\url{https://www.tidytextmining.com/}

\hypertarget{pride-and-prejudice}{%
\chapter{Pride and Prejudice}\label{pride-and-prejudice}}

\url{https://juliasilge.com/blog/tidy-text-classification/}

\url{https://juliasilge.com/blog/if-i-loved-nlp-less/}

\hypertarget{cleannlp}{%
\chapter{cleanNLP}\label{cleannlp}}

\url{https://statsmaths.github.io/cleanNLP/}

\hypertarget{text-analysis-of-holy-books}{%
\chapter{Text analysis of holy books}\label{text-analysis-of-holy-books}}

\hypertarget{quran}{%
\section{quRan}\label{quran}}

\url{https://github.com/andrewheiss/quRan}

\url{https://github.com/andrewheiss/quRan/blob/master/data-raw/clean_data.R}

\hypertarget{tidy-text-parts-of-speech-and-unique-words-in-the-quran}{%
\subsection{Tidy text, parts of speech, and unique words in the Qur'an}\label{tidy-text-parts-of-speech-and-unique-words-in-the-quran}}

\url{https://www.andrewheiss.com/blog/2018/12/28/tidytext-pos-arabic/}

\hypertarget{sacred}{%
\section{sacred}\label{sacred}}

\url{http://sacred.john-coene.com/}

\url{https://github.com/JohnCoene/sacred}

\hypertarget{scripturs}{%
\section{scriptuRs}\label{scripturs}}

\url{https://github.com/andrewheiss/scriptuRs}

\hypertarget{tidy-text-parts-of-speech-and-unique-words-in-the-bible}{%
\subsection{Tidy text, parts of speech, and unique words in the Bible}\label{tidy-text-parts-of-speech-and-unique-words-in-the-bible}}

\url{https://www.andrewheiss.com/blog/2018/12/26/tidytext-pos-john/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# devtools::install_github( andrewheiss/scriptuRs )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tidyverse)  # For dplyr, ggplot2, and friends
library(scriptuRs)  # For full text of bible
library(tidytext)   # For analyzing text
library(cleanNLP)   # For fancier natural language processing

# Load data
gospels <- kjv_bible() %>% 
  filter(book_title %in% c( Matthew ,  Mark ,  Luke ,  John ))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Set up NLP backend
# reticulate::use_python( /Users/serdarbalciold/.conda )  # I use homebrew python3
# reticulate::use_condaenv(condaenv =  /anaconda3/envs , conda =  auto , required = FALSE)
# cnlp_init_spacy()  # Use spaCy
cnlp_init_udpipe()  # Or use this R-only one without external dependencies
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# Determine the parts of speech of the  text  column and use  verse_title  as the id
gospels_annotated <- cnlp_annotate(gospels, as_strings = TRUE,
                                   text_var =  text , doc_var =  verse_title )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gospels_annotated
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
glimpse(gospels_annotated)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gospel_terms <- gospels_annotated %>% 
  cnlp_get_token()
head(gospel_terms)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gospels_lookup <- gospels %>% 
  select(verse_title, book_title, chapter_number, verse_number)

gospel_terms <- gospel_terms %>% 
  left_join(gospels_lookup, by = c( id  =  verse_title ))

glimpse(gospel_terms)
\end{verbatim}

\hypertarget{word-associations-from-the-small-world-of-words}{%
\chapter{WORD ASSOCIATIONS FROM THE SMALL WORLD OF WORDS}\label{word-associations-from-the-small-world-of-words}}

\url{https://juliasilge.com/blog/word-associations/}

\hypertarget{section-1}{%
\chapter{}\label{section-1}}

\hypertarget{the-lesser-known-stars-of-the-tidyverse}{%
\chapter{The Lesser Known Stars of the Tidyverse}\label{the-lesser-known-stars-of-the-tidyverse}}

\begin{verbatim}
slug: the-lesser-known-stars-of-the-tidyverse
tags:
- tidyverse
- R
- Code
categories: []
\end{verbatim}

\emph{I copied this code just to learn myself. See original links below:}

\hypertarget{webinar-tidyverse-exploratory-analysis-emily-robinson-1}{%
\chapter{Webinar: Tidyverse Exploratory Analysis (Emily Robinson)}\label{webinar-tidyverse-exploratory-analysis-emily-robinson-1}}

\textless iframe width= 560 height= 315 src= \url{https://www.youtube.com/embed/uG3igAGX7UE} frameborder= 0 allow= accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture allowfullscreen\textgreater{}

\textless iframe width= 560 height= 315 src= \url{https://www.youtube.com/embed/ax4LXQ5t38k} frameborder= 0 allow= accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture allowfullscreen\textgreater{}

\url{https://hookedondata.org/the-lesser-known-stars-of-the-tidyverse/}

\url{https://www.rstudio.com/resources/videos/the-lesser-known-stars-of-the-tidyverse/}

\url{https://github.com/robinsones/robinsones_blog/blob/master/content/post/multipleChoiceResponses.csv}

\url{https://github.com/robinsones/robinsones_blog/blob/master/content/post/2018-11-16-the-lesser-known-stars-of-the-tidyverse.Rmd}

\hypertarget{reading-in-the-data}{%
\section{Reading in the data}\label{reading-in-the-data}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE, error = TRUE)

library(tidyverse)
library(magrittr)
theme_set(theme_bw())
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses_base <- read.csv( data/multipleChoiceResponses.csv )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# for one column
sum(is.na(multiple_choice_responses_base$Country))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# for five columns
multiple_choice_responses_base %>%
  summarise_at(1:5, ~sum(is.na(.))) 

multiple_choice_responses_base %>%
  summarise_at(vars(GenderSelect:StudentStatus), ~sum(is.na(.))) 

multiple_choice_responses_base %>%
  summarise_at(vars(GenderSelect, Age), ~sum(is.na(.))) 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses_base %>%
  count(StudentStatus) 
\end{verbatim}

Yep. We see here we have a lot of \texttt{} entries instead of NAs. We can correct this with \texttt{na\_if} from \texttt{dplyr}, which takes as an argument what we want to turn into NAs. We can also use \texttt{\%\textless{}\textgreater{}\%}, which is a reassignment pipe. While this is nice to save some typing, it can make it confusing when reading a script, so use with caution.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses_base %<>%
  na_if(  )

## is the same as: 

multiple_choice_responses_base <- multiple_choice_responses_base %>%
  na_if(  )
\end{verbatim}

Now let's count the NAs again.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses_base %>%
  summarise_at(1:5, ~sum(is.na(.))) 
\end{verbatim}

And it's fixed!

How could we have avoided this all in the first place? By using \texttt{\{r\ \#\ eadr::read\_csv} instead of \texttt{\{r\ \#\ ead.csv}.

If you're not familiar with \texttt{::}, it's for explicitly setting what package you're getting the function on the right from. This is helpful in three ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  There can be name conflicts, where two packages have functions with the same name. Using \texttt{::} ensures you're getting the function you want.
\item
  if you only want to use one function from a package, you can use \texttt{::} to skip the library call. As long as you've installed the package, you don't need to have loaded it to get the function.
\item
  For teaching purposes, it's nice to remind people where the function is coming from.
\end{enumerate}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses <- readr::read_csv( multipleChoiceResponses.csv )
\end{verbatim}

It's definitely faster, but it seems we have some errors. Let's inspect them.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
problems(multiple_choice_responses)
\end{verbatim}

We see each row and column where a problem occurs. What's happening is that \texttt{\{r\ \#\ ead\_csv} uses the first 1000 rows of a column to guess its type. But in some cases, it's guessing the column is an integer, because the first 1000 rows are whole numbers, when actually it should be double, as some entries have decimal points. We can fix this by changing the number of rows \texttt{\{r\ \#\ ead\_csv} uses to guess the column type (with the \texttt{guess\_max} argument) to the number of rows in the data set.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses <- readr::read_csv( multipleChoiceResponses.csv , 
                                             guess_max = nrow(multiple_choice_responses))
\end{verbatim}

Error-free!

\hypertarget{initial-examination}{%
\section{Initial examination}\label{initial-examination}}

Let's see what we can glean from the column names themselves. I'll only look at the first 20 since there are so many.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
colnames(multiple_choice_responses) %>%
  head(20)
\end{verbatim}

We can see that there were categories of questions, like LearningPlatform, with each platform having its own column.

Now let's take a look at our numeric columns with \href{https://github.com/ropensci/skimr}{skimr}. Skimr is a package from \href{https://ropensci.org/}{rOpenSci} that allows you to quickly view summaries of your data. We can use \texttt{select\_if} to select only columns where a certain condition, in this case whether it's a numeric column, is true.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses %>%
  select_if(is.numeric) %>%
  skimr::skim()
\end{verbatim}

I love the histograms. We can quickly see from them that people self teach a lot and spend a good amount of time building models and gathering data, compared to visualizing data or working in production.

Let's see how many distinct answers we have for each question. We can use \texttt{n\_distinct()}, a shorter and faster version of \texttt{length(unique())}. We'll use \texttt{summarise\_all}, which is the same as \texttt{summarise\_at} except that you don't select a group of columns and so it applies to every one in the dataset.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses %>%
  summarise_all(n_distinct) %>%
  select(1:10)
\end{verbatim}

This data would be more helpful if it was tidy and had two columns, \texttt{question} and \texttt{num\_distinct\_answers}. We can use \texttt{tidyr::gather} to change our data from wide to long format and then \texttt{arrange} it so we can see the columns with the most distinct answers first. If you've used (or are still using!) reshape2, check out tidyr; reshape2 is retired and is only updated with changes necessary for it to remain on CRAN. While not exactly equivalent, \texttt{tidyr::spread} replaces \texttt{\{r\ \#\ eshape2::dcast}, \texttt{tidyr::separate} \texttt{\{r\ \#\ eshape2::colsplit}, and \texttt{tidyr::gather} \texttt{\{r\ \#\ eshape2::melt}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses %>%
  summarise_all(n_distinct) %>%
  tidyr::gather(question, num_distinct_answers) %>%
  arrange(desc(num_distinct_answers))
\end{verbatim}

Let's take a look at the question with the most distinct answers, WorkMethodsSelect.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
multiple_choice_responses %>%
  count(WorkMethodsSelect, sort = TRUE)
\end{verbatim}

We can see this is a multiple select question, where if a person selected multiple answers they're listed as one entry, separated by commas. Let's tidy it up.

First, let's get rid of the NAs. We can use \texttt{!is.na(WorkMethodsSelect)}, short for \texttt{is.na(WorkMethodsSelect)\ ==\ FALSE}, to filter out NAs. We then use \texttt{str\_split}, from stringr, to divide the entries up. \texttt{str\_split(WorkMethodsSelect,\ \ ,\ )} says Take this string and split it into a list by dividing it where there are \texttt{,}s.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
nested_workmethods <- multiple_choice_responses %>%
  select(WorkMethodsSelect) %>%
  filter(!is.na(WorkMethodsSelect)) %>%
  mutate(work_method = str_split(WorkMethodsSelect,  , )) 

nested_workmethods %>%
  select(work_method)
\end{verbatim}

Now we have a list column, with each entry in the list being one work method. We can \texttt{unnest} this so we can get back a tidy dataframe.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
unnested_workmethods <- nested_workmethods %>%
  tidyr::unnest(work_method) %>%
  select(work_method)

unnested_workmethods
\end{verbatim}

Great! As a last step, let's \texttt{count} this data so we can find which are the most common work methods people use.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
unnested_workmethods %>%
  count(work_method, sort = TRUE)
\end{verbatim}

We see the classic methods of data visualization, logistic regression, and cross-validation lead the pack.

\hypertarget{graphing-frequency-of-different-work-challenges}{%
\subsection{Graphing Frequency of Different Work Challenges}\label{graphing-frequency-of-different-work-challenges}}

Now let's move on to understanding what challenges people face at work. This was one of those categories where there were multiple questions asked, all having names starting with \texttt{WorkChallengeFrequency} and ending with the challenge (e.g DirtyData ).

We can find the relevant columns by using the dplyr \texttt{select} helper \texttt{contains}. We then use \texttt{gather} to tidy the data for analysis, filter for only the non-NAs, and remove the \texttt{WorkChallengeFrequency} from each question using \texttt{stringr::str\_remove}.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
WorkChallenges <- multiple_choice_responses %>%
  select(contains( WorkChallengeFrequency )) %>%
  gather(question, response) %>%
  filter(!is.na(response)) %>%
  mutate(question = stringr::str_remove(question,  WorkChallengeFrequency )) 

WorkChallenges
\end{verbatim}

Let's make a facet bar plot, one for each question with the frequency of responses.To make the x-axis tick labels readable, we'll change them to be vertical instead of horizontal.

\begin{verbatim}
{r WorkChallenges_graph1, fig.width = 9, fig.height = 6}
ggplot(WorkChallenges, aes(x = response)) + 
  geom_bar() + 
  facet_wrap(~question) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
\end{verbatim}

This graph has two main problems. First, there are too many histograms for it to be really useful. But second, the order of the x-axis is wrong. We want it to go from least often to most, but instead \texttt{\{r\ \#\ arely} is in the middle. We can manually reorder the level of this variable using \texttt{forcats::fct\_relevel}.

\begin{verbatim}
{r WorkChallenges_graph2, fig.width = 9, fig.height = 6}
WorkChallenges %>%
  mutate(response = fct_relevel(response,  Rarely ,  Sometimes , 
                                 Often ,  Most of the time )) %>%
  ggplot(aes(x = response)) + 
  geom_bar() + 
  facet_wrap(~question) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
\end{verbatim}

Now we've got the x-axis in the order we want it. Let's try dichotomizing the variable by grouping most of the time and often together as the person considering something a challenge. We can use \texttt{if\_else} and \texttt{\%in\%}. \texttt{\%in\%} is equivalent to \texttt{\{r\ \#\ esponse\ ==\ \ Most\ of\ the\ time\ \ \textbar{}\ response\ ==\ \ Often} and can save you a lot of typing if you have a bunch of variables to match.

Grouping by the question, we can use \texttt{summarise} to reduce the dataset to one row per question, adding the variable \texttt{perc\_problem} for the percentage of responses that thought something was a challenge often or most of the time. This way, we can make one graph with data for all the questions and easily compare them.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
perc_problem_work_challenge <- WorkChallenges %>%
  mutate(response = if_else(response %in% c( Most of the time ,  Often ), 1, 0)) %>%
  group_by(question) %>%
  summarise(perc_problem = mean(response)) 
\end{verbatim}

\begin{verbatim}
{r perc_problem_work_challenge_graph, fig.width = 8, fig.height = 5}
ggplot(perc_problem_work_challenge, aes(x = question, y = perc_problem)) + 
  geom_point() +
  coord_flip()
\end{verbatim}

This is better, but it's hard to read because the points are scattered all over the place. Although you can spot the highest one, you then have to track it back to the correct variable. And it's also hard to tell the order of the ones in the middle.

We can use \texttt{forcats:fct\_reorder} to change the x-axis to be ordered by another variable, in this case the y-axis. While we're at it, we can use \texttt{scale\_y\_continuous} and\texttt{scales::percent} to update our axis to display in percent and \texttt{labs} to change our axis labels.

\begin{verbatim}
{r perc_problem_work_challenge_graph2, fig.width = 8, fig.height = 5}
ggplot(perc_problem_work_challenge, 
       aes(x = perc_problem, 
           y = fct_reorder(question, perc_problem))) + 
  geom_point() +
  scale_x_continuous(labels = scales::percent) + 
  labs(y =  Work Challenge , 
       x =  Percentage of people encountering challenge frequently )
\end{verbatim}

Much better! You can now easily tell which work challenges are encountered most frequently.

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

I'm a big advocate of using and teaching the tidyverse for data analysis and visualization in R (it runs \href{http://varianceexplained.org/r/teach-tidyverse/}{in the family}). In addition to doing these talks, I've released a course on \href{https://www..com/courses/categorical-data-in-the-tidyverse}{Categorical Data in the Tidyverse}. I walk through some of the functions in this course and more from forcats. It's part of the new \href{https://www..com/tracks/tidyverse-fundamentals}{Tidyverse Fundamentals skill track}, which is suitable for people are new to R or those looking to switch to the tidyverse. Check it out and let us know what you think.

Some other good resources for learning the tidyverse are Hadley Wickham and Garrett Grolemund's free \href{http://r4ds.had.co.nz/}{R for Data Science book} and \href{https://www.rstudio.com/resources/cheatsheets/}{RStudio's cheat sheets}. If you have questions, I recommend using the \href{https://community.rstudio.com/c/tidyverse}{tidyverse section of RStudio community} and/or the \#rstats hashtag on Twitter. If you do, make sure you include a reproducible example (see best practices \href{https://reprex.tidyverse.org/articles/reprex-dos-and-donts.html}{here}) with the \href{https://reprex.tidyverse.org/articles/articles/magic-reprex.html}{reprex package}!

\hypertarget{tidycells}{%
\chapter{tidycells}\label{tidycells}}

\hypertarget{tidyxl}{%
\chapter{tidyxl}\label{tidyxl}}

\url{https://github.com/nacnudus/tidyxl}

\hypertarget{tidycells-1}{%
\chapter{tidycells}\label{tidycells-1}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# remotes::install_github( nacnudus/tidyxl )
# remotes::install_github( r-rudra/tidycells )
# install.packages( tidycells )
# install.packages( tidyxl )
library(tidycells)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
system.file( extdata ,  marks.xlsx , package =  tidycells , mustWork = TRUE)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# you should have tidyxl installed
system.file( extdata ,  marks.xlsx , package =  tidycells , mustWork = TRUE) %>% 
  read_cells()
\end{verbatim}

\hypertarget{tufte-handout}{%
\chapter{Tufte Handout}\label{tufte-handout}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
\end{verbatim}

\hypertarget{introduction-5}{%
\chapter{Introduction}\label{introduction-5}}

The Tufte handout style is a style that Edward Tufte uses in his books and handouts. Tufte's style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography. This style has been implemented in LaTeX and HTML/CSS\footnote{See Github repositories \href{https://github.com/tufte-latex/tufte-latex}{tufte-latex} and \href{https://github.com/edwardtufte/tufte-css}{tufte-css}}, respectively. We have ported both implementations into the \href{https://github.com/rstudio/tufte}{\textbf{tufte} package}. If you want LaTeX/PDF output, you may use the \texttt{tufte\_handout} format for handouts, and \texttt{tufte\_book} for books. For HTML output, use \texttt{tufte\_html}. These formats can be either specified in the YAML metadata at the beginning of an R Markdown document (see an example below), or passed to the \texttt{\{r\ \#\ markdown::render()} function. See \citet{R-rmarkdown} for more information about \textbf{rmarkdown}.

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{# An Example Using the Tufte Style }
\FunctionTok{author}\KeywordTok{:}\AttributeTok{  John Smith }
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  tufte:}\FunctionTok{:tufte_handout}\KeywordTok{:}\AttributeTok{ default}
\AttributeTok{  tufte:}\FunctionTok{:tufte_html}\KeywordTok{:}\AttributeTok{ default}
\end{Highlighting}
\end{Shaded}

There are two goals of this package:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  To produce both PDF and HTML output with similar styles from the same R Markdown document;
\item
  To provide simple syntax to write elements of the Tufte style such as side notes and margin figures, e.g.~when you want a margin figure, all you need to do is the chunk option \texttt{fig.margin\ =\ TRUE}, and we will take care of the details for you, so you never need to think about \texttt{\textbackslash{}begin\{marginfigure\}\ \textbackslash{}end\{marginfigure\}} or \texttt{\textless{}span\ class=\ marginfigure\ \textgreater{}\ \textless{}/span\textgreater{}}; the LaTeX and HTML code under the hood may be complicated, but you never need to learn or write such code.
\end{enumerate}

If you have any feature requests or find bugs in \textbf{tufte}, please do not hesitate to file them to \url{https://github.com/rstudio/tufte/issues}. For general questions, you may ask them on StackOverflow: \url{http://stackoverflow.com/tags/rmarkdown}.

\hypertarget{headings}{%
\chapter{Headings}\label{headings}}

This style provides first and second-level headings (that is, \texttt{\#} and \texttt{\#\#}), demonstrated in the next section. You may get unexpected output if you try to use \texttt{\#\#\#} and smaller headings.

\texttt{\{r\ \#\ \ newthought(\textquotesingle{}In\ his\ later\ books\textquotesingle{})}\footnote{\href{http://www.edwardtufte.com/tufte/books_be}{Beautiful Evidence}}, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and sets the first few words of the sentence in small caps. To accomplish this using this style, call the \texttt{newthought()} function in \textbf{tufte} in an \emph{inline R expression} \texttt{\textasciigrave{}\{r\ \#\ \ \textasciigrave{}} as demonstrated at the beginning of this paragraph.\footnote{Note you should not assume \textbf{tufte} has been attached to your R session. You should either \texttt{library(tufte)} in your R Markdown document before you call \texttt{newthought()}, or use \texttt{tufte::newthought()}.}

\hypertarget{figures}{%
\chapter{Figures}\label{figures}}

\hypertarget{margin-figures}{%
\section{Margin Figures}\label{margin-figures}}

Images and graphics play an integral role in Tufte's work. To place figures in the margin you can use the \textbf{knitr} chunk option \texttt{fig.margin\ =\ TRUE}. For example:

\begin{verbatim}
{r fig-margin, fig.margin = TRUE, fig.cap =  MPG vs horsepower, colored by transmission. , fig.width=3.5, fig.height=3.5, cache=TRUE, message=FALSE}
library(ggplot2)
mtcars2 <- mtcars
mtcars2$am <- factor(
  mtcars$am, labels = c('automatic', 'manual')
)
ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point() + geom_smooth() +
  theme(legend.position = 'bottom')
\end{verbatim}

Note the use of the \texttt{fig.cap} chunk option to provide a figure caption. You can adjust the proportions of figures using the \texttt{fig.width} and \texttt{fig.height} chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin.

\hypertarget{arbitrary-margin-content}{%
\section{Arbitrary Margin Content}\label{arbitrary-margin-content}}

In fact, you can include anything in the margin using the \textbf{knitr} engine named \texttt{marginfigure}. Unlike R code chunks \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\ \{r\ eval=FALSE,\ include=FALSE,\ echo=TRUE\}}, you write a chunk starting with \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\ \{marginfigure\}} instead, then put the content in the chunk. See an example on the right about the first fundamental theorem of calculus.

\begin{verbatim}
{marginfigure}
We know from _the first fundamental theorem of calculus_ that for $x$ in $[a, b]$:
$$\frac{d}{dx}\left( \int_{a}^{x} f(u)\,du\right)=f(x).$$
\end{verbatim}

For the sake of portability between LaTeX and HTML, you should keep the margin content as simple as possible (syntax-wise) in the \texttt{marginefigure} blocks. You may use simple Markdown syntax like \texttt{**bold**} and \texttt{\_italic\_} text, but please refrain from using footnotes, citations, or block-level elements (e.g.~blockquotes and lists) there.

Note: if you set \texttt{echo\ =\ TRUE} in your global chunk options, you will have to add \texttt{echo\ =\ TRUE} to the chunk to display a margin figure, for example \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\ \{marginfigure,\ echo\ =\ TRUE\}}.

\hypertarget{full-width-figures}{%
\section{Full Width Figures}\label{full-width-figures}}

You can arrange for figures to span across the entire page by using the chunk option \texttt{fig.fullwidth\ =\ TRUE}.

\begin{verbatim}
{r fig-fullwidth, fig.width = 10, fig.height = 2, fig.fullwidth = TRUE, fig.cap =  A full width figure. , warning=FALSE, message=FALSE, cache=TRUE}
ggplot(diamonds, aes(carat, price)) + geom_smooth() +
  facet_grid(~ cut)
\end{verbatim}

Other chunk options related to figures can still be used, such as \texttt{fig.width}, \texttt{fig.cap}, \texttt{out.width}, and so on. For full width figures, usually \texttt{fig.width} is large and \texttt{fig.height} is small. In the above example, the plot size is \(10 \times 2\).

\hypertarget{main-column-figures}{%
\section{Main Column Figures}\label{main-column-figures}}

Besides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output.

\begin{verbatim}
{r fig-main, fig.cap =  A figure in the main column. , cache=TRUE}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
\end{verbatim}

\hypertarget{sidenotes}{%
\chapter{Sidenotes}\label{sidenotes}}

One of the most prominent and distinctive features of this style is the extensive use of sidenotes. There is a wide margin to provide ample room for sidenotes and small figures. Any use of a footnote will automatically be converted to a sidenote. \footnote{This is a sidenote that was entered using a footnote.}

If you'd like to place ancillary information in the margin without the sidenote mark (the superscript number), you can use the \texttt{margin\_note()} function from \textbf{tufte} in an inline R expression. \texttt{\{r\ \#\ \ margin\_note(\ This\ is\ a\ margin\ note.\ \ Notice\ that\ there\ is\ no\ number\ preceding\ the\ note.\ )} This function does not process the text with Pandoc, so Markdown syntax will not work here. If you need to write anything in Markdown syntax, please use the \texttt{marginfigure} block described previously.

\hypertarget{references}{%
\chapter{References}\label{references}}

References can be displayed as margin notes for HTML output. For example, we can cite R here \citep{R-base}. To enable this feature, you must set \texttt{link-citations:\ yes} in the YAML metadata, and the version of \texttt{pandoc-citeproc} should be at least 0.7.2. You can always install your own version of Pandoc from \url{http://pandoc.org/installing.html} if the version is not sufficient. To check the version of \texttt{pandoc-citeproc} in your system, you may run this in R:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
system2('pandoc-citeproc', '--version')
\end{verbatim}

If your version of \texttt{pandoc-citeproc} is too low, or you did not set \texttt{link-citations:\ yes} in YAML, references in the HTML output will be placed at the end of the output document.

\hypertarget{tables-6}{%
\chapter{Tables}\label{tables-6}}

You can use the \texttt{kable()} function from the \textbf{knitr} package to format tables that integrate well with the rest of the Tufte handout style. The table captions are placed in the margin like figures in the HTML output.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(
  mtcars[1:6, 1:6], caption = 'A subset of mtcars.'
)
\end{verbatim}

\hypertarget{block-quotes}{%
\chapter{Block Quotes}\label{block-quotes}}

We know from the Markdown syntax that paragraphs that start with \texttt{\textgreater{}} are converted to block quotes. If you want to add a right-aligned footer for the quote, you may use the function \texttt{quote\_footer()} from \textbf{tufte} in an inline R expression. Here is an example:

\begin{quote}
If it weren't for my lawyer, I'd still be in prison. It went a lot faster with two people digging.

\texttt{\{r\ \#\ \ tufte::quote\_footer(\textquotesingle{}\ Joe\ Martin\textquotesingle{})}
\end{quote}

Without using \texttt{quote\_footer()}, it looks like this (the second line is just a normal paragraph):

\begin{quote}
Great people talk about ideas, average people talk about things, and small people talk about wine.

Fran Lebowitz
\end{quote}

\hypertarget{responsiveness}{%
\chapter{Responsiveness}\label{responsiveness}}

The HTML page is responsive in the sense that when the page width is smaller than 760px, sidenotes and margin notes will be hidden by default. For sidenotes, you can click their numbers (the superscripts) to toggle their visibility. For margin notes, you may click the circled plus signs to toggle visibility.

\hypertarget{more-examples}{%
\chapter{More Examples}\label{more-examples}}

The rest of this document consists of a few test cases to make sure everything still works well in slightly more complicated scenarios. First we generate two plots in one figure environment with the chunk option \texttt{fig.show\ =\ \textquotesingle{}hold\textquotesingle{}}:

\begin{verbatim}
{r fig-two-together, fig.cap= Two plots in one figure environment. , fig.show='hold', cache=TRUE, message=FALSE}
p <- ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point()
p
p + geom_smooth()
\end{verbatim}

Then two plots in separate figure environments (the code is identical to the previous code chunk, but the chunk option is the default \texttt{fig.show\ =\ \textquotesingle{}asis\textquotesingle{}} now):

\begin{verbatim}
{r fig-two-separate, ref.label='fig-two-together', fig.cap=sprintf( Two plots in separate figure environments (the %s plot). , c( first ,  second )), cache=TRUE, message=FALSE}
\end{verbatim}

You may have noticed that the two figures have different captions, and that is because we used a character vector of length 2 for the chunk option \texttt{fig.cap} (something like \texttt{fig.cap\ =\ c(\textquotesingle{}first\ plot\textquotesingle{},\ \textquotesingle{}second\ plot\textquotesingle{})}).

Next we show multiple plots in margin figures. Similarly, two plots in the same figure environment in the margin:

\begin{verbatim}
{r fig-margin-together, fig.margin=TRUE, fig.show='hold', fig.cap= Two plots in one figure environment in the margin. , fig.width=3.5, fig.height=2.5, cache=TRUE}
p
p + geom_smooth(method = 'lm')
\end{verbatim}

Then two plots from the same code chunk placed in different figure environments:

\begin{verbatim}
{r fig-margin-separate, fig.margin=TRUE, fig.cap=sprintf( Two plots in separate figure environments in the margin (the %s plot). , c( first ,  second )), fig.width=3.5, fig.height=2.5, cache=TRUE}
knitr::kable(head(iris, 15))
p
knitr::kable(head(iris, 12))
p + geom_smooth(method = 'lm')
knitr::kable(head(iris, 5))
\end{verbatim}

We blended some tables in the above code chunk only as \emph{placeholders} to make sure there is enough vertical space among the margin figures, otherwise they will be stacked tightly together. For a practical document, you should not insert too many margin figures consecutively and make the margin crowded.

You do not have to assign captions to figures. We show three figures with no captions below in the margin, in the main column, and in full width, respectively.

\begin{verbatim}
{r fig-nocap-margin, fig.margin=TRUE, fig.width=3.5, fig.height=2, cache=TRUE}
# a boxplot of weight vs transmission; this figure
# will be placed in the margin
ggplot(mtcars2, aes(am, wt)) + geom_boxplot() +
  coord_flip()
\end{verbatim}

\begin{verbatim}
{r fig-nocap-main, cache=TRUE}
# a figure in the main column
p <- ggplot(mtcars, aes(wt, hp)) + geom_point()
p
\end{verbatim}

\begin{verbatim}
{r fig-nocap-fullwidth, fig.fullwidth=TRUE, fig.width=10, fig.height=3, cache=TRUE}
# a fullwidth figure
p + geom_smooth(method = 'lm') + facet_grid(~ gear)
\end{verbatim}

\hypertarget{some-notes-on-tufte-css}{%
\chapter{Some Notes on Tufte CSS}\label{some-notes-on-tufte-css}}

There are a few other things in Tufte CSS that we have not mentioned so far. If you prefer \texttt{\{r\ \#\ \ sans\_serif(\textquotesingle{}sans-serif\ fonts\textquotesingle{})}, use the function \texttt{sans\_serif()} in \textbf{tufte}. For epigraphs, you may use a pair of underscores to make the paragraph italic in a block quote, e.g.

\begin{quote}
\emph{I can win an argument on any topic, against any opponent. People know this, and steer clear of me at parties. Often, as a sign of their great respect, they don't even invite me.}

\texttt{\{r\ \#\ \ quote\_footer(\textquotesingle{}\ Dave\ Barry\textquotesingle{})}
\end{quote}

We hope you will enjoy the simplicity of R Markdown and this R package, and we sincerely thank the authors of the Tufte-CSS and Tufte-LaTeX projects for developing the beautiful CSS and LaTeX classes. Our \textbf{tufte} package would not have been possible without their heavy lifting.

You can turn on/off some features of the Tufte style in HTML output. The default features enabled are:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  tufte:}\FunctionTok{:tufte_html}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{tufte_features}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{ fonts }\KeywordTok{,}\AttributeTok{  background }\KeywordTok{,}\AttributeTok{  italics }\KeywordTok{]}
\end{Highlighting}
\end{Shaded}

If you do not want the page background to be lightyellow, you can remove \texttt{background} from \texttt{tufte\_features}. You can also customize the style of the HTML page via a CSS file. For example, if you do not want the subtitle to be italic, you can define

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h3}\FunctionTok{.subtitle}\NormalTok{ em \{}
  \KeywordTok{font-style}\NormalTok{: }\DecValTok{normal}\OperatorTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

in, say, a CSS file \texttt{my\_style.css} (under the same directory of your Rmd document), and apply it to your HTML output via the \texttt{css} option, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  tufte:}\FunctionTok{:tufte_html}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{tufte_features}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{ fonts }\KeywordTok{,}\AttributeTok{  background }\KeywordTok{]}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{  my_style.css }
\end{Highlighting}
\end{Shaded}

There is also a variant of the Tufte style in HTML/CSS named \href{http://nogginfuel.com/envisioned-css/}{Envisoned CSS} . This style can be used by specifying the argument \texttt{tufte\_variant\ =\ \textquotesingle{}envisioned\textquotesingle{}} in \texttt{tufte\_html()}\footnote{The actual Envisioned CSS was not used in the \textbf{tufte} package. We only changed the fonts, background color, and text color based on the default Tufte style.}, e.g.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  tufte:}\FunctionTok{:tufte_html}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{tufte_variant}\KeywordTok{:}\AttributeTok{  envisioned }
\end{Highlighting}
\end{Shaded}

To see the R Markdown source of this example document, you may follow \href{https://github.com/rstudio/tufte/raw/master/inst/rmarkdown/templates/tufte_html/skeleton/skeleton.Rmd}{this link to Github}, use the wizard in RStudio IDE (\texttt{File\ -\textgreater{}\ New\ File\ -\textgreater{}\ R\ Markdown\ -\textgreater{}\ From\ Template}), or open the Rmd file in the package:

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
file.edit(
  tufte:::template_resources(
    'tufte_html', '..', 'skeleton', 'skeleton.Rmd'
  )
)
\end{verbatim}

This document is also available in \href{http://rstudio.github.io/tufte/cn/}{Chinese}, and its \texttt{envisioned} style can be found \href{http://rstudio.github.io/tufte/envisioned/}{here}.

\begin{verbatim}
{r bib, include=FALSE}
# create a bib file for the R packages used in this document
knitr::write_bib(c('base', 'rmarkdown'), file = 'skeleton.bib')
\end{verbatim}

\hypertarget{tutorials}{%
\chapter{Tutorials}\label{tutorials}}

\begin{itemize}
\tightlist
\item
  Exploratory Data Analysis \& Data Preparation with `funModeling'
\end{itemize}

\url{https://blog.datascienceheroes.com/exploratory-data-analysis-data-preparation-with-funmodeling/}

\begin{itemize}
\tightlist
\item
  Content for Wrangling data in the Tidyverse - a tutorial given at useR! 2018
\end{itemize}

\url{https://github.com/drsimonj/tidyverse_tutorial-useR2018}

\begin{itemize}
\tightlist
\item
  Teaching R to New Users - From tapply to the Tidyverse
\end{itemize}

\url{https://simplystatistics.org/2018/07/12/use-r-keynote-2018/}

\begin{itemize}
\tightlist
\item
  jstor
\end{itemize}

An R Package for Analysing Scientific Articles

\url{https://speakerdeck.com/tklebel/jstor-an-r-package-for-analysing-scientific-articles?slide=25}

\begin{itemize}
\tightlist
\item
  workshop in survival analysis using R
\end{itemize}

\url{https://github.com/dave-harrington/survival_workshop}

\url{https://github.com/dave-harrington/eventtimedata}

\begin{itemize}
\tightlist
\item
  Teaching R to New Users - From tapply to the Tidyverse
\end{itemize}

\url{https://simplystatistics.org/2018/07/12/use-r-keynote-2018/}

\begin{itemize}
\tightlist
\item
  Data Driven Decision Making (D3M)
\end{itemize}

\url{http://www.vishalsingh.org/teaching/\#content}

\begin{itemize}
\tightlist
\item
  Tidymodeling Titanic Tragedy
\end{itemize}

\url{https://cdn.rawgit.com/ClaytonJY/tidymodels-talk/145e6574/slides.html\#1}

\begin{itemize}
\tightlist
\item
  Disease risk modelling and visualization using R
\end{itemize}

\url{https://paula-moraga.github.io/teaching/}

\begin{itemize}
\tightlist
\item
  Creating a Geodemographic Classification Using K-means Clustering in R
\end{itemize}

\url{https://data.cdrc.ac.uk/tutorial/creating-a-geodemographic-classification-using-k-means-clustering-in-r}

\begin{itemize}
\tightlist
\item
  Advanced R
\end{itemize}

\url{http://adv-r.had.co.nz/}

\begin{itemize}
\tightlist
\item
  How to use R for matching samples (propensity score)
\end{itemize}

\url{https://datascienceplus.com/how-to-use-r-for-matching-samples-propensity-score/}

\hypertarget{tweetbook1}{%
\chapter{tweetbook1}\label{tweetbook1}}

\url{https://rtweet.info/}

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
library(tidyverse)
library(rtweet)
\end{verbatim}

\hypertarget{get-data}{%
\chapter{get data}\label{get-data}}

\begin{verbatim}
{r include=FALSE, eval=FALSE, echo = TRUE}
gipath <- rtweet::search_tweets(q =  #gipath ,
                                n = 18000,
                                include_rts = FALSE,
                                # retryonratelimit = TRUE
                                )

# gipath %>% 
#   select(user_id,status_id, contains( url )) %>%
#   filter(!is.na(ext_media_url)) %>% 
# View()
\end{verbatim}

\hypertarget{filter-tweet}{%
\chapter{filter tweet}\label{filter-tweet}}

\begin{verbatim}
{r filter tweet}

for (i in 1:dim(gipath)[1]) {
  nam <- paste0( gitweetid , i)
  assign(nam, gipath$status_id[i])
  nam2 <- paste0( gitweet , i)
  assign(nam2, gipath[gipath$status_id==gitweetid1, ])
}
\end{verbatim}

\hypertarget{tweet-owner}{%
\chapter{tweet owner}\label{tweet-owner}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$screen_name
\end{verbatim}

\hypertarget{tweet-time}{%
\chapter{tweet time}\label{tweet-time}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$created_at
\end{verbatim}

\hypertarget{tweet-text}{%
\chapter{tweet text}\label{tweet-text}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$text
\end{verbatim}

\hypertarget{tweet-media}{%
\chapter{tweet media}\label{tweet-media}}

\begin{verbatim}
{r tweet media}
unlist(gitweet2$ext_media_url)
\end{verbatim}

\begin{verbatim}
{r tweet media length}
length(unlist(gitweet2$ext_media_url))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
\end{verbatim}

\hypertarget{download-image-read-image}{%
\chapter{download image, read image}\label{download-image-read-image}}

\begin{verbatim}
{r download image read image, error=FALSE, comment=FALSE}
for (i in 1:length(unlist(gitweet2$ext_media_url))) {
    urls <- unlist(gitweet2$ext_media_url)[i]
    dest <- paste0( twfigure/jpeg ,i, .jpg , collapse =   )
    download.file(url = urls, destfile = dest, mode = 'wb')
}

images <- capture.output(
    cat(
        for (i in 1:length(unlist(gitweet2$ext_media_url))) {
            cat(
                paste0( ![](twfigure/jpeg ,
                       i,
                        .jpg){width=30%} , 
                       collapse =   
                ),
                 \n 
            )
        }
        , 
        sep =  \n )
)
\end{verbatim}

\hypertarget{auto-output}{%
\chapter{Auto Output}\label{auto-output}}

Tweet by: \textbf{\texttt{\{r\ \#\ \ gitweet2\$screen\_name}}

Tweet Time: \textbf{\texttt{\{r\ \#\ \ gitweet2\$created\_at}}

\emph{\texttt{\{r\ \#\ \ gitweet2\$text}}

\texttt{\{r\ \#\ \ unlist(gitweet2\$hashtags)}

\texttt{\{r\ \#\ \ unlist(gitweet2\$symbols)}

\texttt{\{r\ \#\ \ unlist(gitweet2\$urls\_expanded\_url)}

\texttt{\{r\ \#\ \ images}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweetbody1 <-  gitweet1$screen_name; gitweet1$created_at; gitweet1$text; unlist(gitweet1$hashtags); unlist(gitweet1$symbols); unlist(gitweet1$urls_expanded_url) 

evaluate::replay(evaluate::evaluate(tweetbody1))

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(evaluate)
s <-  paste(capture.output(replay(evaluate::evaluate(tweetbody1))), collapse= \n )
cat(s)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
dont_print_source = function(x){
    if (class(x)!= source ){
        cat(x)
    }
}

L <-  evaluate::evaluate(tweetbody1)

# library(R.utils)
# s3 <-  paste(captureOutput(
# for(i in 1:length(L)) dont_print_source(L[[i]])  
# ), collapse= \n )

s3 <- gsub( \\[1]|\  ,   , paste(capture.output(
for(i in 1:length(L)) dont_print_source(L[[i]])
), collapse= \n ))
\end{verbatim}

\texttt{\{r\ \#\ \ s3}

\url{https://community.rstudio.com/t/how-to-use-an-object-rather-than-a-file-as-source-for-knitting-resolved/3057/6}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweetAutoOutput <- function(x) {
  
  
  
}
\end{verbatim}

Tweet by: \textbf{\texttt{\{r\ \#\ \ gitweet2\$screen\_name}}

Tweet Time: \textbf{\texttt{\{r\ \#\ \ gitweet2\$created\_at}}

\emph{\texttt{\{r\ \#\ \ gitweet2\$text}}

\texttt{\{r\ \#\ \ unlist(gitweet2\$hashtags)}

\texttt{\{r\ \#\ \ unlist(gitweet2\$symbols)}

\texttt{\{r\ \#\ \ unlist(gitweet2\$urls\_expanded\_url)}

\texttt{\{r\ \#\ \ images}

\hypertarget{olders}{%
\chapter{olders}\label{olders}}

rtweet::get\_collections( serdarbalci )

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1 <- gipath %>%
  filter(user_id == 3011337389)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$user_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$status_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$created_at
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$screen_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$ext_media_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
length(gitweet1$ext_media_url)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
imageurl1 <- gitweet1$ext_media_url[[1]][1]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
imageurl1
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
imageurl2 <- gitweet1$ext_media_url[[1]][2]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
imageurl2
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$text
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$source
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$display_text_width
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$reply_to_status_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$reply_to_status_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$reply_to_user_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$reply_to_screen_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$is_quote
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$is_retweet
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$favorite_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$hashtags
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$symbols
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$urls_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$urls_t.co
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$urls_expanded_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$media_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$media_t.co
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$media_expanded_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$media_type
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$ext_media_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$ext_media_t.co
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$ext_media_expanded_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$ext_media_type
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$mentions_user_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$mentions_screen_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$lang
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_status_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_text
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_created_at
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_source
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_favorite_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_retweet_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_user_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_screen_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_followers_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_friends_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_statuses_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_location
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_description
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$quoted_verified
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_status_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_text
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_created_at
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_source
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_favorite_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_retweet_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_user_id
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_screen_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_followers_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_friends_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_statuses_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_location
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_description
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$retweet_verified
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$place_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$place_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$place_full_name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$place_type
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$country
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$country_code
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$geo_coords
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$coords_coords
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$bbox_coords
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$status_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$name
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$location
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$description
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$protected
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$followers_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$friends_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$listed_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$statuses_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$favourites_count
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$account_created_at
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$verified
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$profile_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$profile_expanded_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$account_lang
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$profile_banner_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$profile_background_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet1$profile_image_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# gipath %>%
#   select(user_id,status_id, contains( url )) %>%
#   filter(!is.na(ext_media_url)) %>%
#   select(status_id, contains( media_url )) %>%
# View()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet2 <- gipath %>% 
  filter(status_id ==1096465400848699392)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
gitweet2$ext_media_url
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
unlist(gitweet2$ext_media_url)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
length(unlist(gitweet2$ext_media_url))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# jpeg1 <- paste0( \  , unlist(gitweet2$ext_media_url)[1],  \  )

# jpeg1 <- unlist(gitweet2$ext_media_url)[1]
# jpeg2 <- unlist(gitweet2$ext_media_url)[2]
# jpeg3 <- unlist(gitweet2$ext_media_url)[3]
# jpeg4 <- unlist(gitweet2$ext_media_url)[4]

# <center><img src= `{r #  jpeg1` ><img src= `{r #  jpeg2` ></center>
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
for (i in 1:length(unlist(gitweet2$ext_media_url))) {
  nam <- paste0( jpeg , i)
  assign(nam, unlist(gitweet2$ext_media_url)[i])
}
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
download.file(url = jpeg1, destfile = 'twfigure/jpeg1.jpg', mode = 'wb')
\end{verbatim}

dene1

dene2

image 0

\includegraphics{`\{r \# jpeg1`} \includegraphics{`\{r \# jpeg2`} \includegraphics{`\{r \# jpeg3`}

image 1

\textless img src= \texttt{\{r\ \#\ \ jpeg1} \textgreater{}

image 2

\textless img src= \texttt{\{r\ \#\ \ jpeg1} \textgreater\textless img src= \texttt{\{r\ \#\ \ jpeg2} \textgreater\textless img src= \texttt{\{r\ \#\ \ jpeg3} \textgreater{}

image 3

\textless img src= \texttt{\{r\ \#\ \ jpeg1} \textgreater\textless img src= \texttt{\{r\ \#\ \ jpeg2} \textgreater\textless img src= \texttt{\{r\ \#\ \ jpeg3} \textgreater{}

\hypertarget{tweetrmd}{%
\chapter{tweetrmd}\label{tweetrmd}}

\url{https://github.com/gadenbuie/tweetrmd}

\hypertarget{tweetrmd-1}{%
\chapter{tweetrmd}\label{tweetrmd-1}}

Easily embed Tweets anywhere R Markdown turns plain text into HTML.

\hypertarget{installation-1}{%
\section{Installation}\label{installation-1}}

You can install the released version of \textbf{tweetrmd} from GitHub:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# install.packages( devtools )}
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{( gadenbuie}\OperatorTok{/}\NormalTok{tweetrmd )}
\end{Highlighting}
\end{Shaded}

\hypertarget{embed-a-tweet}{%
\section{Embed a Tweet}\label{embed-a-tweet}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(tweetrmd)

tweet_embed( https://twitter.com/alexpghayes/status/1211748406730706944 )
\end{verbatim}

Or if you would rather use the screen name and status id.

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweet_embed(tweet_url( alexpghayes ,  1211748406730706944 ))
\end{verbatim}

\hypertarget{take-a-screenshot-of-a-tweet}{%
\section{Take a screenshot of a tweet}\label{take-a-screenshot-of-a-tweet}}

Screenshots are automatically embedded in R Markdown documents,
or you can save the screenshot as a \texttt{.png} or \texttt{.pdf} file.
Uses the \href{https://github.com/rstudio/webshot2}{rstudio/webshot2} package.

\begin{verbatim}
{r screenshot, out.width= 400px }
tweet_screenshot(tweet_url( alexpghayes ,  1211748406730706944 ))
\end{verbatim}

\hypertarget{customize-tweet-appearance}{%
\section{Customize tweet appearance}\label{customize-tweet-appearance}}

Twitter's \href{https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-statuses-oembed}{oembed API}
provides a number of options,
all of which are made available for customization in \texttt{tweet\_embed()} and \texttt{tweet\_screenshot()}.

\begin{verbatim}
{r screenshot-customized, out.width= 300px }
tweet_screenshot(
  tweet_url( alexpghayes ,  1211748406730706944 ),
  maxwidth = 300,
  hide_media = TRUE,
  theme =  dark 
)
\end{verbatim}

Note: When using \texttt{tweet\_embed()},
you may need to add the following line to your YAML header
for strict markdown output formats.

\hypertarget{r-notebook-5}{%
\chapter{R Notebook}\label{r-notebook-5}}

\hypertarget{api-connection}{%
\subsection{API connection}\label{api-connection}}

\url{http://rtweet.info/}
\url{https://apps.twitter.com/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( rtweet )
library(rtweet)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# web browser method: create token and save it as an environment variable
create_token(
    app =   ,
     consumer_key =   ,
     consumer_secret =   )


# ## authenticate via access token
# token <- create_token(
#   app =   ,
#   consumer_key =   ,
#   acess_token =   ,
#   access_secret =   )

# 
# 
# ## create token and save it as an environment variable
# twitter_token <- create_token(
#   app = appname,
#   consumer_key = key,
#   consumer_secret = secret,
#   access_token = access_token,
#   access_secret = access_secret
# )
# 
# 
# ## check to see if the token is loaded
# identical(twitter_token, get_token())

\end{verbatim}

\hypertarget{search-tweets}{%
\subsection{Search Tweets}\label{search-tweets}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## search for 18000 tweets using the hashtag
rt <- search_tweets(
     #GIpath , n = 18000, include_rts = FALSE
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## preview tweets data
head(rt)
dplyr::glimpse(rt)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## preview users data
users_data(rt)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## plot time series (if ggplot2 is installed)
ts_plot(rt)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## plot time series of tweets
ts_plot(rt,  3 hours ) +
    ggplot2::theme_minimal() +
    ggplot2::theme(plot.title = ggplot2::element_text(face =  bold )) +
    ggplot2::labs(
        x = NULL, y = NULL,
        title =  Frequency of #pathologists Twitter statuses from past 9 days ,
        subtitle =  Twitter status (tweet) counts aggregated using three-hour intervals ,
        caption =  \nSource: Data collected from Twitter's REST API via rtweet 
    )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## search for 250,000 tweets containing the word data
rt1 <- search_tweets(
     USCAP , n = 250000, retryonratelimit = TRUE
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## search for 10,000 tweets sent from the US
rt1 <- search_tweets(
     lang:en , geocode = lookup_coords( usa ), n = 10000
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

## create lat/lng variables using all available tweet and profile geo-location data
rt1 <- lat_lng(rt1)

## plot state boundaries
par(mar = c(0, 0, 0, 0))
maps::map( state , lwd = .25)

## plot lat and lng points onto state map
with(rt1, points(lng, lat, pch = 20, cex = .75, col = rgb(0, .3, .7, .75)))
\end{verbatim}

\hypertarget{stream-tweets}{%
\subsection{Stream Tweets}\label{stream-tweets}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## random sample for 30 seconds (default)
rt3 <- stream_tweets(  )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
rt3
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## stream tweets from london for 60 seconds
rt <- stream_tweets(lookup_coords( london, uk ), timeout = 60)

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## stream london tweets for a week (60 secs x 60 mins * 24 hours *  7 days)
# stream_tweets(
#      realdonaldtrump,trump ,
#     timeout = 60 * 60 * 24 * 7,
#     file_name =  tweetsabouttrump.json ,
#     parse = FALSE
# )


stream_tweets(
     realdonaldtrump,trump ,
    timeout = 60 * 60 * 1 * 1,
    file_name =  tweetsabouttrump.json ,
    parse = FALSE
)

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## read in the data as a tidy tbl data frame
djt <- parse_stream( tweetsabouttrump.json )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
djt
\end{verbatim}

\hypertarget{twitter-connections-and-user-information}{%
\subsection{Twitter connections and user information}\label{twitter-connections-and-user-information}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## get user IDs of accounts followed by CNN
# cnn_fds <- get_friends( cnn )

sb_fds <- get_friends( serdarbalci )

sb_fds
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## lookup data on those accounts
# cnn_fds_data <- lookup_users(cnn_fds$user_id)

sb_fds_data <- lookup_users(sb_fds$user_id)
sb_fds_data
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
sb_follows <- sb_fds_data$screen_name
sb_follows[1:50]
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## get user IDs of accounts following CNN
# cnn_flw <- get_followers( cnn , n = 75000)

sb_flw <- get_followers( serdarbalci )
sb_flw
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## lookup data on those accounts
# cnn_flw_data <- lookup_users(cnn_flw$user_id)

sb_flw_data <- lookup_users(sb_flw$user_id[1:10])

sb_flw_data
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# ## how many total follows does cnn have?
# cnn <- lookup_users( cnn )
# 
# ## get them all (this would take a little over 5 days)
# cnn_flw <- get_followers(
#      cnn , n = cnn$followers_count, retryonratelimit = TRUE
# )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## get user IDs of accounts followed by CNN
tmls <- get_timelines(c( cnn ,  BBCWorld ,  foxnews ), n = 3200)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## plot the frequency of tweets for each user over time
tmls %>%
    dplyr::filter(created_at >  2017-10-29 ) %>%
    dplyr::group_by(screen_name) %>%
    ts_plot( days , trim = 1L) +
    ggplot2::geom_point() +
    ggplot2::theme_minimal() +
    ggplot2::theme(
        legend.title = ggplot2::element_blank(),
        legend.position =  bottom ,
        plot.title = ggplot2::element_text(face =  bold )) +
    ggplot2::labs(
        x = NULL, y = NULL,
        title =  Frequency of Twitter statuses posted by news organization ,
        subtitle =  Twitter status (tweet) counts aggregated by day from October/November 2017 ,
        caption =  \nSource: Data collected from Twitter's REST API via rtweet 
    )

\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# jkr <- get_favorites( jk_rowling , n = 3000)

sbf <- get_favorites( serdarbalci , n = 3000)
sbf
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## search for users with #rstats in their profiles
# usrs <- search_users( #rstats , n = 1000)

path_usrs <- search_users( pathology , n = 1000)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
head(path_usrs)
\end{verbatim}

\hypertarget{twitter-trends}{%
\subsection{Twitter Trends}\label{twitter-trends}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
sf <- get_trends( san francisco )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
sf
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## lookup users by screen_name or user_id
users <- c( KimKardashian ,  justinbieber ,  taylorswift13 ,
            espn ,  JoelEmbiid ,  cstonehoops ,  KUHoops ,
            upshotnyt ,  fivethirtyeight ,  hadleywickham ,
            cnn ,  foxnews ,  msnbc ,  maddow ,  seanhannity ,
            potus ,  epa ,  hillaryclinton ,  realdonaldtrump ,
            natesilver538 ,  ezraklein ,  annecoulter )
famous_tweeters <- lookup_users(users)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## preview users data
famous_tweeters
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# extract most recent tweets data from the famous tweeters
tweets_data(famous_tweeters)
\end{verbatim}

\hypertarget{post-tweet-via-r}{%
\subsection{Post tweet via R}\label{post-tweet-via-r}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# post_tweet( my first rtweet #rstats, let us see if it works :) http://rtweet.info/ )
\end{verbatim}

\hypertarget{follow-via-r}{%
\subsection{Follow via R}\label{follow-via-r}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}

## ty for the follow ;)
post_follow( kearneymw )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## quick overview of rtweet functions
vignette( auth , package =  rtweet )

## quick overview of rtweet functions
vignette( intro , package =  rtweet )


## working with the stream
vignette( stream , package =  rtweet )


## working with the stream
vignette( FAQ , package =  rtweet )
\end{verbatim}

\hypertarget{election-analysis-on-twitter}{%
\subsection{Election Analysis on Twitter}\label{election-analysis-on-twitter}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Stream keywords used to filter tweets
q <-  hillaryclinton,imwithher,realdonaldtrump,maga,electionday 

## Stream time in seconds so for one minute set timeout = 60
## For larger chunks of time, I recommend multiplying 60 by the number
## of desired minutes. This method scales up to hours as well
## (x * 60 = x mins, x * 60 * 60 = x hours)
## Stream for 30 minutes
# streamtime <- 30 * 60
streamtime <- 3 * 60


## Filename to save json data (backup)
filename <-  rtelect.json 
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Stream election tweets
rt_election <- stream_tweets(q = q, timeout = streamtime, file_name = filename)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## No upfront-parse save as json file instead method
stream_tweets(
  q = q,
  parse = FALSE,
  timeout = streamtime,
  file_name = filename
)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Parse from json file
rt_election <- parse_stream(filename)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## stream_tweets2 method
# twoweeks <- 60L * 60L * 24L * 7L * 2L
# congress <-  congress,senate,house of representatives,representatives,senators,legislative 
# stream_tweets2(
#   q = congress,
#   parse = FALSE,
#   timeout = twoweeks,
#   dir =  congress-stream 
# )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Parse from json file
rt <- parse_stream( congress-stream.json )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Preview tweets data
rt
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Preview users data
users_data(rt)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## Plot time series of all tweets aggregated by second
ts_plot(rt, by =  secs )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
## plot multiple time series by first grouping the data by screen name
rt %>%
  dplyr::group_by(screen_name) %>%
  ts_plot() +
  ggplot2::labs(
    title =  Tweets during election day for the 2016 U.S. election ,
    subtitle =  Tweets collected, parsed, and plotted using `{r # tweet` 
  )
\end{verbatim}

\hypertarget{graphing-tweets}{%
\subsection{Graphing Tweets}\label{graphing-tweets}}

\url{http://graphtweets.john-coene.com/index.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( graphTweets ) # CRAN release v0.4
library(graphTweets)
library(igraph) # for plot
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# tweets <- rtweet::search_tweets( rstats )

tweets <- rtweet::search_tweets( #pathologists )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
    gt_edges(text, screen_name, status_id) %>% 
    gt_graph() %>% 
    plot()
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id) %>% 
  gt_graph() -> graph

class(graph)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
graph
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id) %>% 
  gt_collect() -> edges

names(edges)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
edges
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id) %>% 
  gt_nodes() %>% 
  gt_collect() -> graph

graph
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lapply(graph, nrow) # number of edges and nodes
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
lapply(graph, names) # names of data.frames returned
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id) %>% 
  gt_nodes(meta = TRUE) %>% 
  gt_collect() -> graph

graph

# lapply(graph, names) # names of data.frames returned
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id, datetime =  created_at ) %>% 
  gt_nodes(meta = TRUE) %>% 
  gt_collect() -> graph

graph
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
# install.packages( sigmajs )
library(dplyr)
library(sigmajs) # for plots

tweets %>% 
  gt_edges(text, screen_name, status_id, datetime =  created_at ) %>% 
  gt_nodes(meta = TRUE) %>% 
  gt_collect() -> gt

nodes <- gt$nodes %>% 
  mutate(
    id = nodes,
    label = ifelse(is.na(name), nodes, name),
    size = n_edges,
    color =  #1967be 
  ) 

edges <- gt$edges %>% 
  mutate(
    id = 1:n()
  )

sigmajs() %>% 
  sg_force_start() %>% 
  sg_nodes(nodes, id, label, size, color) %>% 
  sg_edges(edges, id, source, target) %>% 
  sg_force_stop(10000)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(igraph)

tweets %>% 
  gt_edges(text, screen_name, status_id) %>% 
  gt_graph() -> g

# communities
wc <- walktrap.community(g)
V(g)$color <- membership(wc)

# plot
# tons of arrguments because defaults are awful
plot(g, 
     layout = igraph::layout.fruchterman.reingold(g), 
     vertex.color = V(g)$color,
     vertex.label.family =  sans ,
     vertex.label.color = hsv(h = 0, s = 0, v = 0, alpha = 0.0),
     vertex.size = igraph::degree(g), 
     edge.arrow.size = 0.2, 
     edge.arrow.width = 0.3, edge.width = 1,
     edge.color = hsv(h = 1, s = .59, v = .91, alpha = 0.7),
     vertex.frame.color= #fcfcfc )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
tweets %>% 
  gt_edges(text, screen_name, status_id,  created_at ) %>% 
  gt_nodes() %>% 
  gt_dyn() %>% 
  gt_collect() -> net
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(head(net$edges))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
knitr::kable(head(net$nodes))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(sigmajs)

# convert to numeric & rescale
edges <- net$edges %>% 
  dplyr::mutate( 
    id = 1:n(),
    created_at = as.numeric(created_at),
    created_at = (created_at - min(created_at)) / (max(created_at) - min(created_at)),
    created_at = created_at * 5000
  )

nodes <- net$nodes %>% 
  dplyr::mutate(
    id = source,
    size = n_edges
  )

mx <- max(edges$created_at) + 500

sigmajs() %>% 
  sg_force_start() %>% 
  sg_nodes(nodes, id, size) %>% 
  sg_add_edges(edges, created_at, id, source, target, 
               cumsum = FALSE, refresh = FALSE) %>% 
  sg_force_stop(delay = mx) %>% 
  sg_settings(defaultNodeColor =  #1967be )
\end{verbatim}

\hypertarget{a-shiny-app-with-rtweet}{%
\chapter{A Shiny App with rtweet}\label{a-shiny-app-with-rtweet}}

\url{https://aj17.shinyapps.io/twitteranalytics/}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(blogdown)
blogdown::shortcode('tweet', '1014492923981803521')
\end{verbatim}

\hypertarget{conference-tweets}{%
\chapter{Conference tweets}\label{conference-tweets}}

\url{https://twitter.com/APo_ORV/status/1016412207867973632}

\url{https://twitter.com/grrrck/status/959137137118646272}

\url{https://gadenbuie.shinyapps.io/rsconf_tweets/}

\url{https://github.com/gadenbuie/rsconf_tweets}

\url{https://behindbars.shinyapps.io/user2018/}

\url{https://github.com/oliviergimenez/isec2018_tweet_analysis}

\hypertarget{twitter-article-mentions-and-citations}{%
\chapter{Twitter Article Mentions and Citations}\label{twitter-article-mentions-and-citations}}

\url{https://github.com/dsquintana/ajp}

\hypertarget{twitterreport}{%
\chapter{twitterreport}\label{twitterreport}}

\url{https://github.com/gvegayon/twitterreport}

\hypertarget{streamr}{%
\chapter{streamR}\label{streamr}}

\url{https://cran.r-project.org/web/packages/streamR/}

\begin{itemize}
\tightlist
\item
  Retweet count for specific tweet
\end{itemize}

\url{https://stackoverflow.com/questions/10427147/retweet-count-for-specific-tweet}

\hypertarget{statquotes}{%
\chapter{statquotes}\label{statquotes}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( statquotes )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
statquotes::statquote()
\end{verbatim}

\hypertarget{rtweet-workshop}{%
\chapter{rtweet-workshop}\label{rtweet-workshop}}

\url{https://github.com/mkearney/rtweet-workshop}

\url{https://rtweet-workshop.mikewk.com/}

\hypertarget{twitter-dashboard}{%
\chapter{twitter dashboard}\label{twitter-dashboard}}

\hypertarget{making-a-twitter-dashboard-with-r}{%
\chapter{Making a twitter dashboard with R}\label{making-a-twitter-dashboard-with-r}}

\url{https://jsta.rbind.io/blog/making-a-twitter-dashboard-with-r/}

\url{https://jsta.rbind.io/tweets}

\url{http://rtweet.info/articles/auth.html}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(rtweet)
library(magrittr)
library(dplyr)
library(DT)
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
user_name <-  serdarbalci 
my_likes  <- get_favorites(user_name, n = 100) %>% 
  select( created_at ,  screen_name ,  text ,  urls_expanded_url ) %>%
  arrange(desc(created_at))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
my_likes$created_at <- strptime(as.POSIXct(my_likes$created_at), 
                                format =  %Y-%m-%d )
my_likes$created_at <- format(my_likes$created_at,  %Y-%m-%d )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
createLink <- function(x) {
  if(is.na(x)){
    return(  )
  }else{
    sprintf(paste0('<a href= ', URLdecode(x),'  target= _blank >', 
                   substr(x, 1, 25) ,'</a>'))
  }
}

my_likes$urls_expanded_url <- lapply(my_likes$urls_expanded_url, 
                                     function(x) sapply(x, createLink))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
my_table <- datatable(my_likes, 
                      options = list(scrollX = TRUE, autoWidth = TRUE,
                                     columnDefs = list(list(
                                           width = '70%', 
                                           targets = c(2)))), 
                      rownames = FALSE,
                      fillContainer = TRUE,
                      width =  100% , 
                      height =  100% ,  
                      colnames = c( Date ,  Handle ,  Text ,  URL ))

my_table <- formatStyle(my_table, columns = 1:4, fontSize = '70%')
my_table <- formatStyle(my_table, columns = 3, width = '500px')
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
my_table
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
library(widgetframe)

frameWidget(my_table, width =  100% , height = 800,
            options = frameOptions(allowfullscreen = TRUE))
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
frameableWidget(my_table)
\end{verbatim}

\hypertarget{visualisation-graphs-plots}{%
\chapter{Visualisation: Graphs \& Plots}\label{visualisation-graphs-plots}}

\begin{itemize}
\tightlist
\item
  Visualization of Biomedical Data
\end{itemize}

\url{https://www.annualreviews.org/doi/10.1146/annurev-biodatasci-080917-013424}

\begin{itemize}
\tightlist
\item
  Regional population structures at a glance
\end{itemize}

\url{https://ikashnitsky.github.io/2018/the-lancet-paper/}

\begin{itemize}
\tightlist
\item
  Global Migration, animated with R
\end{itemize}

\url{http://blog.revolutionanalytics.com/2018/06/global-migration-animated-with-r.html}

\begin{itemize}
\tightlist
\item
  Creating a Geodemographic Classification Using K-means Clustering in R
\end{itemize}

\url{https://data.cdrc.ac.uk/tutorial/creating-a-geodemographic-classification-using-k-means-clustering-in-r}

\begin{itemize}
\tightlist
\item
  Tidy Eval Meets ggplot2
\end{itemize}

\url{http://www.onceupondata.com/2018/07/06/ggplot-tidyeval/}

\begin{itemize}
\item
  \url{http://serialmentor.com/dataviz/}
\item
  You Can Design a Good Chart with R
\end{itemize}

\url{https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e}

\begin{itemize}
\tightlist
\item
  Data to Viz
\end{itemize}

\url{https://www.data-to-viz.com/}

\href{https://www.data-to-viz.com/}{\includegraphics{https://www.data-to-viz.com/img/poster/poster_big.png}}

\begin{itemize}
\item
  ggpubr
  ggpubr: `ggplot2' Based Publication Ready Plots
  \url{http://www.sthda.com/english/rpkgs/ggpubr/}
\item
  R Graph Gallery
\end{itemize}

\url{https://www.r-graph-gallery.com/}

\begin{itemize}
\tightlist
\item
  The Data Visualisation Catalogue
\end{itemize}

\url{https://datavizcatalogue.com/}

\begin{itemize}
\tightlist
\item
  Dataviz Project
\end{itemize}

\url{http://datavizproject.com/}

\begin{itemize}
\tightlist
\item
  Python Graph Gallery
\end{itemize}

\url{https://python-graph-gallery.com/}

\begin{itemize}
\tightlist
\item
  Financial Times Visual Vocabulary
\end{itemize}

\url{https://github.com/ft-interactive/chart-doctor/tree/master/visual-vocabulary}

\begin{itemize}
\tightlist
\item
  Xenographics Weird but (sometimes) useful charts
\end{itemize}

\url{https://xeno.graphics/}

\begin{itemize}
\item
\end{itemize}

\url{https://vis.design/}

\begin{itemize}
\tightlist
\item
  Show Me Shiny Gallery of R Web Apps
\end{itemize}

\url{https://www.showmeshiny.com/}

\begin{itemize}
\tightlist
\item
  Where Work Pays: Occupations \& Earnings across the United States
\end{itemize}

\url{http://www.hamiltonproject.org/charts/where_work_pays_interactive}

\begin{itemize}
\tightlist
\item
  You Can Design a Good Chart with R But do R users invest in design?
\end{itemize}

\url{https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e}

\begin{itemize}
\tightlist
\item
  Machine Learning Results in R: one plot to rule them all!
\end{itemize}

\url{https://datascienceplus.com/machine-learning-results-one-plot-to-rule-them-all/}

\begin{itemize}
\tightlist
\item
  data visualisation applications, tools and libraries
\end{itemize}

\url{http://www.visualisingdata.com/resources/}

\hypertarget{r-notebook-6}{%
\chapter{R Notebook}\label{r-notebook-6}}

\begin{itemize}
\tightlist
\item
  The ultimate online collection toolbox: Combining RSelenium and Rvest - Part 1
\end{itemize}

\url{https://www.youtube.com/watch?v=OxbvFiYxEzI}

\url{https://gist.github.com/HanjoStudy/aeb331b7a277be9639f3cfb3bf875ba2}

\url{https://hanjostudy.github.io/Presentations/UseR2018/RSelenium/rselenium.html\#1}

\url{https://hanjostudy.github.io/Presentations/UseR2018/Rvest/rvest.html\#1}

\begin{itemize}
\tightlist
\item
  Automated Text Feature Engineering using textfeatures in R
\end{itemize}

\url{https://www.r-bloggers.com/automated-text-feature-engineering-using-textfeatures-in-r/}

\hypertarget{selectorgadget}{%
\chapter{Selectorgadget}\label{selectorgadget}}

\url{https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html}

\hypertarget{polite}{%
\chapter{polite}\label{polite}}

\url{https://github.com/dmi3kno/polite}

\hypertarget{where-to-learn-r}{%
\chapter{Where to learn R}\label{where-to-learn-r}}

\hypertarget{introduction-to-data-science}{%
\chapter{Introduction to Data Science}\label{introduction-to-data-science}}

\url{https://rafalab.github.io/dsbook/}

\hypertarget{rstudio-education}{%
\chapter{RStudio Education}\label{rstudio-education}}

\url{https://education.rstudio.com/}

\hypertarget{statistics-in-action-with-r}{%
\chapter{Statistics in Action with R}\label{statistics-in-action-with-r}}

\url{http://sia.webpopix.org/index.html}

\hypertarget{swirlstats}{%
\chapter{swirlstats}\label{swirlstats}}

\url{https://swirlstats.com/}

\hypertarget{data-skills-for-reproducible-science}{%
\chapter{Data Skills for Reproducible Science}\label{data-skills-for-reproducible-science}}

\url{https://gupsych.github.io/data_skills/index.html}

\hypertarget{rstats-ed}{%
\chapter{rstats-ed}\label{rstats-ed}}

\url{https://github.com/rstudio-education/rstats-ed}

\hypertarget{new-online-courses-psu}{%
\chapter{new online courses psu}\label{new-online-courses-psu}}

\url{https://newonlinecourses.science.psu.edu/statprogram/}

\hypertarget{think-stats}{%
\chapter{Think Stats}\label{think-stats}}

\url{https://greenteapress.com/wp/think-stats-2e/}

\hypertarget{statsthinking21}{%
\chapter{statsthinking21}\label{statsthinking21}}

\url{http://statsthinking21.org/index.html}

\hypertarget{rstudio-8}{%
\chapter{RStudio}\label{rstudio-8}}

\url{https://www.rstudio.com/online-learning/}

\hypertarget{r-statistics}{%
\chapter{r-statistics}\label{r-statistics}}

\url{http://r-statistics.co/R-Tutorial.html}

\hypertarget{advanced-data-science}{%
\chapter{Advanced Data Science}\label{advanced-data-science}}

\url{https://jhu-advdatasci.github.io/2018/}

\hypertarget{how-do-i}{%
\chapter{How Do I? \ldots{}}\label{how-do-i}}

\url{https://smach.github.io/R4JournalismBook/HowDoI.html}

\hypertarget{data-management-and-manipulation-using-r}{%
\chapter{Data management and manipulation using R}\label{data-management-and-manipulation-using-r}}

\url{https://ozanj.github.io/rclass/resources/}

\hypertarget{teaching-reproducible-data-analysis-in-r}{%
\chapter{Teaching Reproducible Data Analysis in R}\label{teaching-reproducible-data-analysis-in-r}}

\url{https://gupsych.github.io/trdair_workshop/}

\hypertarget{academic-websites}{%
\chapter{Academic Websites}\label{academic-websites}}

\url{https://gupsych.github.io/acadweb/}

\hypertarget{data-skills-for-reproducible-science-1}{%
\chapter{Data Skills for Reproducible Science}\label{data-skills-for-reproducible-science-1}}

\url{https://gupsych.github.io/data_skills/}

\hypertarget{methodology-metascience}{%
\chapter{Methodology \& Metascience}\label{methodology-metascience}}

\url{https://gupsych.github.io/mms/}

\hypertarget{causal-inference-book}{%
\chapter{Causal Inference Book}\label{causal-inference-book}}

\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\hypertarget{introtor}{%
\chapter{IntroToR}\label{introtor}}

\url{https://github.com/sbalci/IntroToR.git}

\hypertarget{youtube-collections}{%
\chapter{YouTube Collections}\label{youtube-collections}}

\textless iframe width= 560 height= 315 src= \url{https://www.youtube.com/embed/videoseries?list=PLxRBOaoEoP4KUSgmcNjSGBFu7PYipGVrX} frameborder= 0 allow= accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture allowfullscreen\textgreater{}

\begin{itemize}
\item
  Jamovi\\
  \url{https://www.youtube.com/playlist?list=PLkk92zzyru5OAtc_ItUubaSSq6S_TGfRn}
\item
  Do More with R
\end{itemize}

\url{https://www.youtube.com/playlist?list=PL7D2RMSmRO9JOvPC1gbA8Mc3azvSfm8Vv}

\url{https://www.youtube.com/playlist?list=PLYaGSokOr0MPz1tgwTW4JKcelhdJyUIrb}

\begin{itemize}
\tightlist
\item
  Neat proofs/perspectives
\end{itemize}

\url{https://www.youtube.com/playlist?list=PLZHQObOWTQDPSKntUcMArGheySM4gL7wS}

\begin{itemize}
\tightlist
\item
  Learning medical statistics with python and Jupyter notebooks
\end{itemize}

\url{https://www.youtube.com/playlist?list=PLsu0TcgLDUiIueDMfTX3322AZhdGb0_zm}

\begin{itemize}
\tightlist
\item
  Data Visualization and R
\end{itemize}

\url{https://www.youtube.com/playlist?list=PLCj1LhGni3hPGy6Kj1AFxHYkKklxenO9D}

\hypertarget{what-they-forgot-to-teach-you-about-r}{%
\chapter{What They Forgot to Teach You About R}\label{what-they-forgot-to-teach-you-about-r}}

\url{https://whattheyforgot.org/}

\hypertarget{keeping-up-to-date-with-r-news}{%
\chapter{Keeping up to date with R news}\label{keeping-up-to-date-with-r-news}}

\url{https://masalmon.eu/2019/01/25/uptodate/}

\hypertarget{advanced-r-markdown-workshop}{%
\chapter{Advanced R Markdown Workshop}\label{advanced-r-markdown-workshop}}

\url{https://arm.rbind.io/days/day1/learnr/}

\hypertarget{cran-task-views}{%
\chapter{CRAN Task Views}\label{cran-task-views}}

\url{https://cran.r-project.org/web/views/}

\hypertarget{wikibook-r-programming}{%
\chapter{WikiBook R Programming}\label{wikibook-r-programming}}

\url{https://en.wikibooks.org/wiki/R_Programming}

\hypertarget{happy-git-and-github-for-the-user-1}{%
\chapter{Happy Git and GitHub for the useR}\label{happy-git-and-github-for-the-user-1}}

\url{https://happygitwithr.com}

\url{https://r-bootcamp.netlify.com/}

\hypertarget{how-i-use-r}{%
\chapter{How I Use R}\label{how-i-use-r}}

\url{https://howiuser.com}

\hypertarget{r-pirate-yarrr}{%
\chapter{R Pirate YaRrr}\label{r-pirate-yarrr}}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
install.packages( yarrr )
library( yarrr )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
pirateplot(formula = weight ~ Time,
data = ChickWeight,
pal =  xmen )
\end{verbatim}

\begin{verbatim}
{r eval=FALSE, include=FALSE, echo=TRUE}
yarrr::pirateplot(formula = weight ~ Diet,
                  data = ChickWeight)
\end{verbatim}

  \bibliography{bib/book.bib,bib/packages.bib}

\end{document}
