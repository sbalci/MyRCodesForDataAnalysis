[["index.html", "My R Codes for Data Analysis Articles per journals per country Chapter 1 Prerequisites", " My R Codes for Data Analysis Articles per journals per country Serdar Balcı {r # Sys.Date() Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 5. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure ??. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table ??. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],["literature.html", "Chapter 3 Literature", " Chapter 3 Literature Here is a review of existing methods. "],["literature-1.html", "Chapter 4 Literature", " Chapter 4 Literature Here is a review of existing methods. "],["methods.html", "Chapter 5 Methods", " Chapter 5 Methods We describe our methods in this chapter. "],["applications.html", "Chapter 6 Applications 6.1 Example one 6.2 Example two", " Chapter 6 Applications Some significant applications are demonstrated in this chapter. 6.1 Example one 6.2 Example two "],["final-words.html", "Chapter 7 Final Words", " Chapter 7 Final Words We have finished a nice book. {r # if (knitr::is_html_output()) ' # References {-} ' output: html_notebook: code_folding: hide fig_caption: yes highlight: kate number_sections: yes theme: cerulean toc: yes toc_float: yes html_document: code_folding: hide df_print: kable keep_md: yes number_sections: yes theme: cerulean toc: yes toc_float: yes highlight: kate If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page. "],["analysis.html", "Chapter 8 Analysis 8.1 Articles per journals per country", " Chapter 8 Analysis 8.1 Articles per journals per country Aim: In the previous analysis we have observed that Japanese researchers have much more articles than German and Turkish researchers. Here we will look at the distribution of articles per journals per country. Methods: Pathology Journal ISSN List was retrieved from In Cites Clarivate, and Journal Data Filtered as follows: JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'PATHOLOGY' Selected Category Scheme: WoS Data is retrieved from PubMed via RISmed package. PubMed collection from National Library of Medicine (https://www.ncbi.nlm.nih.gov/pubmed/), has the most comprehensive information about peer reviewed articles in medicine. The API (https://dataguide.nlm.nih.gov/), and R packages are available for getting and fetching data from the server. The search formula for PubMed is generated as “ISSN List AND Country[Affiliation]” like done in advanced search of PubMed. Articles from Japan, German and Turkey are retrieved limiting the search with pathology journals, affiliation and last 10 years. The retrieved information was compiled in a table. Result: In this graph x-axis is the list of journals with decreasing impact factor, and y-axis is the number of articles published in that journal. The colors and shapes are showing the country of affiliation. We see that in one journal articles from Japan is more than 800. Comment: It is seen that one of the journals ISSN: 1440-1827 has more than 800 articles from Japan. This journal is also from Japan. Here we wonder if there is an editorial preference for articles from their home country. We sometimes observe this situation if there is a conference in that country, and the conference abstracts are indexed. This may also be a clue that if a country has a journal listed in indexes, than it is more easy for the researchers in that country to publish their results. Future Work: Whether this observation is a unique situation, or there is a tendency in the journals to publish article from their country of origin, merits further investigation. "],["feedback.html", "Chapter 9 Feedback", " Chapter 9 Feedback Serdar Balcı, MD, Pathologist would like to hear your feedback: https://goo.gl/forms/YjGZ5DHgtPlR1RnB3 This document will be continiously updated and the last update was on {r # Sys.Date(). "],["back-to-main-menu.html", "Chapter 10 Back to Main Menu", " Chapter 10 Back to Main Menu Main Page for Bibliographic Analysis output: html_notebook: code_folding: hide fig_caption: yes highlight: kate number_sections: yes theme: cerulean toc: yes toc_float: yes html_document: code_folding: hide df_print: kable keep_md: yes number_sections: yes theme: cerulean toc: yes toc_float: yes highlight: kate "],["analysis-1.html", "Chapter 11 Analysis 11.1 PubMed Indexed Peer Reviewed Articles in Pathology Journals: A country based comparison", " Chapter 11 Analysis 11.1 PubMed Indexed Peer Reviewed Articles in Pathology Journals: A country based comparison Aim: Here, we are going to compare 3 countries (German, Japan and Turkey), in terms of number of articles in pathology journals during the last decade. Methods: If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page. Pathology Journal ISSN List was retrieved from In Cites Clarivate, and Journal Data Filtered as follows: JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'PATHOLOGY' Selected Category Scheme: WoS Data is retrieved from PubMed via RISmed package. PubMed collection from National Library of Medicine (https://www.ncbi.nlm.nih.gov/pubmed/), has the most comprehensive information about peer reviewed articles in medicine. The API (https://dataguide.nlm.nih.gov/), and R packages are available for getting and fetching data from the server. The search formula for PubMed is generated as “ISSN List AND Country[Affiliation]” like done in advanced search of PubMed. From the fetched data the year of articles are grouped and counted by country. Result: In the below table we see the number of articles per country in the last decade. And the figure below shows this data in a line graph. Comment: We see that Japan has much more articles than German and Turkey. Turkey has a small increase in number of articles. Future Work: Indentify why Japan has too much articles. Compare Japan with other countries. Compare Turkey with neighbours, EU, OECD &amp; Middle East countries. Analyse multinational studies. Analyse adding journal impact as a factor. "],["feedback-1.html", "Chapter 12 Feedback", " Chapter 12 Feedback Serdar Balcı, MD, Pathologist would like to hear your feedback: https://goo.gl/forms/YjGZ5DHgtPlR1RnB3 This document will be continiously updated and the last update was on {r # Sys.Date(). "],["back-to-main-menu-1.html", "Chapter 13 Back to Main Menu", " Chapter 13 Back to Main Menu Main Page for Bibliographic Analysis output: html_notebook: code_folding: hide highlight: kate number_sections: yes theme: cerulean toc: yes toc_float: yes fig_caption: yes html_document: df_print: kable number_sections: yes toc: yes "],["analysis-of-recent-pancreas-related-articles.html", "Chapter 14 Analysis of Recent Pancreas Related Articles", " Chapter 14 Analysis of Recent Pancreas Related Articles Pancreas Journals https://www.ncbi.nlm.nih.gov/nlmcatalog/?term=pancreas Pathology Journals Member List DOI Link PubMed Link Journal Link Altmetric API Dimensions API USCAP abstracts vs publication Member list vs worldmap Pathology Journal ISSN List was retrieved from In Cites Clarivate, and Journal Data Filtered as follows: JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: 'PATHOLOGY' Selected Category Scheme: WoS Data is retrieved from PubMed via E-direct. PubMed collection from National Library of Medicine (https://www.ncbi.nlm.nih.gov/pubmed/), has the most comprehensive information about peer reviewed articles in medicine. The API (https://dataguide.nlm.nih.gov/) is available for getting and fetching data from the server. The query for PubMed is generated as “ISSN List AND keywords” like done in advanced search of PubMed. From the fetched data articles are grouped by country and keywords. Result: mapgraph And the figure below shows this data in a line graph. "],["feedback-2.html", "Chapter 15 Feedback", " Chapter 15 Feedback Serdar Balcı, MD, Pathologist would like to hear your feedback: https://goo.gl/forms/YjGZ5DHgtPlR1RnB3 This document will be continiously updated and the last update was on {r # Sys.Date(). "],["back-to-main-menu-2.html", "Chapter 16 Back to Main Menu", " Chapter 16 Back to Main Menu Main Page for Bibliographic Analysis output: html_notebook: code_folding: hide fig_caption: yes highlight: kate number_sections: yes theme: cerulean toc: yes toc_float: yes html_document: code_folding: hide df_print: kable keep_md: yes number_sections: yes theme: cerulean toc: yes toc_float: yes highlight: kate If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page. "],["analysis-2.html", "Chapter 17 Analysis 17.1 MeSH Terms In Pathology Articles From Turkey", " Chapter 17 Analysis 17.1 MeSH Terms In Pathology Articles From Turkey Background PubMed collection from National Library of Medicine, has the most comprehensive information about peer reviewed articles in medicine. MeSH Terms is a controlled vocabulary that is used to label PubMed articles according to their content. It is done by experts in National Library of Medicine. Keywords are lables that are given by authors of the article. Both are included in a PubMed record of an article. Aim: In this analysis we aimed to identify the common research topics Turkish pathologists are interested. We extracted most common MeSH terms and keywords from PubMed articles using EDirect: MeSH Terms Pathology Articles From Turkey Methods: Packages used for analysis. Tidyverse is used for data manipulation, and rstudioapi to run e-utilities commands from RStudio. Pathology Journal ISSN List was retrieved from In Cites Clarivate, and Journal Data Filtered as follows: JCR Year: 2016 Selected Editions: SCIE,SSCI Selected Categories: &#39;PATHOLOGY&#39; Selected Category Scheme: WoS Data is retrieved from PubMed via e-Utilities. The search formula for PubMed is generated as “ISSN List AND Country[Affiliation]” like done in advanced search of PubMed. Articles are downloaded as xml. MeSH terms are extracted from xml. Common terms are excluded and major topics are selected. Keywords are extracted from xml. Result: The retrieved information was compiled in a table. Comment: Future Work: "],["feedback-3.html", "Chapter 18 Feedback", " Chapter 18 Feedback Serdar Balcı, MD, Pathologist would like to hear your feedback: https://goo.gl/forms/YjGZ5DHgtPlR1RnB3 This document will be continiously updated and the last update was on {r # Sys.Date(). "],["back-to-main-menu-3.html", "Chapter 19 Back to Main Menu", " Chapter 19 Back to Main Menu Main Page for Bibliographic Analysis Several packages support making beautiful tables with R, such as xtable stargazer pander tables ascii etc. It is also very easy to make tables with knitr’s kable function: library(knitr) kable(mtcars[1:5, ], caption = &quot;A knitr kable.&quot;) Table 19.1: A knitr kable. mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Analysing the HIV pandemic https://rviews.rstudio.com/2019/04/30/analysing-hiv-pandemic-part-1/ "],["arsenal.html", "Chapter 20 arsenal 20.1 The compare function 20.2 Row 20.3 Row 20.4 Describe results of analysis", " Chapter 20 arsenal 20.1 The compare function https://cran.r-project.org/web/packages/arsenal/vignettes/compare.html Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer x arm 3 character x fu.time 6 integer x fu.stat 7 integer y fu_time 11 integer y fu stat 12 integer y Arm 13 character Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor ast 12 integer ast 8 numeric Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs sex sex 1495 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1741 differences not shown) var.x var.y case values.x values.y row.x row.y sex sex 76170 Male Male 26 20 sex sex 76240 Male Male 27 21 sex sex 76431 Female Female 28 22 sex sex 76712 Male Male 29 23 sex sex 76780 Female Female 30 24 sex sex 77066 Female Female 31 25 sex sex 77316 Male Male 32 26 sex sex 77355 Male Male 33 27 sex sex 77591 Male Male 34 28 sex sex 77851 Male Male 35 29 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 Non-identical attributes var.x var.y name sex sex label sex sex levels race race class race race label race race levels bmi bmi label Column name comparison options It is possible to change which column names are considered “the same variable”. Ignoring case For example, to ignore case in variable names (so that Arm and arm are considered the same), pass tol.vars = &quot;case&quot;. You can do this using comparison.control() summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, control = comparison.control(tol.vars = &quot;case&quot;))) or pass it through the ... arguments. summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = &quot;case&quot;)) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer x fu.time 6 integer x fu.stat 7 integer y fu_time 11 integer y fu stat 12 integer Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor ast 12 integer ast 8 numeric Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 1495 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1741 differences not shown) var.x var.y case values.x values.y row.x row.y sex sex 76170 Male Male 26 20 sex sex 76240 Male Male 27 21 sex sex 76431 Female Female 28 22 sex sex 76712 Male Male 29 23 sex sex 76780 Female Female 30 24 sex sex 77066 Female Female 31 25 sex sex 77316 Male Male 32 26 sex sex 77355 Male Male 33 27 sex sex 77591 Male Male 34 28 sex sex 77851 Male Male 35 29 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Treating dots and underscores the same (equivalence classes) It is possible to treat certain characters or sets of characters as the same by passing a character vector of equivalence classes to the tol.vars= argument. In short, each string in the vector is split into single characters, and the resulting set of characters is replaced by the first character in the string. For example, passing c(&quot;._&quot;) would replace all underscores with dots in the column names of both datasets. Similarly, passing c(&quot;aA&quot;, &quot;BbCc&quot;) would replace all instances of &quot;A&quot; with &quot;a&quot; and all instances of &quot;b&quot;, &quot;C&quot;, or &quot;c&quot; with &quot;B&quot;. This is one way to ignore case for certain letters. Otherwise, it’s possible to combine the equivalence classes with ignoring case, by passing (e.g.) c(&quot;._&quot;, &quot;case&quot;). Passing a single character as an element this vector will replace that character with the empty string. For example, passing c(&quot; “,”.“) would remove all spaces and dots from the column names. For mockstudy, let’s treat dots, underscores, and spaces as the same, and ignore case: summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;) # dots=underscores=spaces, ignore case )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor ast 12 integer ast 8 numeric Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 1495 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1741 differences not shown) var.x var.y case values.x values.y row.x row.y sex sex 76170 Male Male 26 20 sex sex 76240 Male Male 27 21 sex sex 76431 Female Female 28 22 sex sex 76712 Male Male 29 23 sex sex 76780 Female Female 30 24 sex sex 77066 Female Female 31 25 sex sex 77316 Male Male 32 26 sex sex 77355 Male Male 33 27 sex sex 77591 Male Male 34 28 sex sex 77851 Male Male 35 29 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Column comparison options Logical tolerance Use the tol.logical= argument to change how logicals are compared. By default, they’re expected to be equal to each other. Numeric tolerance To allow numeric differences of a certain tolerance, use the tol.num= and tol.num.val= options. tol.num.val= determines the maximum (unsigned) difference tolerated if tol.num=&quot;absolute&quot; (default), and determines the maximum (unsigned) percent difference tolerated if tol.num=&quot;percent&quot;. Also note the option int.as.num=, which determines whether integers and numerics should be compared despite their class difference. If TRUE, the integers are coerced to numeric. Note that mockstudy$ast is integer, while mockstudy2$ast is numeric: summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE # compare integers and numerics )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 1495 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 3 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1741 differences not shown) var.x var.y case values.x values.y row.x row.y sex sex 76170 Male Male 26 20 sex sex 76240 Male Male 27 21 sex sex 76431 Female Female 28 22 sex sex 76712 Male Male 29 23 sex sex 76780 Female Female 30 24 sex sex 77066 Female Female 31 25 sex sex 77316 Male Male 32 26 sex sex 77355 Male Male 33 27 sex sex 77591 Male Male 34 28 sex sex 77851 Male Male 35 29 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 ast ast 86205 27 36 6 3 ast ast 105271 100 36 3 2 ast ast 110754 35 36 1 1 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Suppose a tolerance of up to 10 is allowed for ast: summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE, # compare integers and numerics tol.num.val = 10 # allow absolute differences &lt;= 10 )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 1495 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 1 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1741 differences not shown) var.x var.y case values.x values.y row.x row.y sex sex 76170 Male Male 26 20 sex sex 76240 Male Male 27 21 sex sex 76431 Female Female 28 22 sex sex 76712 Male Male 29 23 sex sex 76780 Female Female 30 24 sex sex 77066 Female Female 31 25 sex sex 77316 Male Male 32 26 sex sex 77355 Male Male 33 27 sex sex 77591 Male Male 34 28 sex sex 77851 Male Male 35 29 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 ast ast 105271 100 36 3 2 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Factor tolerance By default, factors are compared to each other based on both the labels and the underlying numeric levels. Set tol.factor=&quot;levels&quot; to match only the numeric levels, or set tol.factor=&quot;labels&quot; to match only the labels. summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE, # compare integers and numerics tol.num.val = 10, # allow absolute differences &lt;= 10 tol.factor = &quot;labels&quot; # match only factor labels )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared var.x pos.x class.x var.y pos.y class.y race 5 character race 3 factor Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 0 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 1 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (256 differences not shown) var.x var.y case values.x values.y row.x row.y ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 ast ast 105271 100 36 3 2 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Also note the option factor.as.char=, which determines whether factors and characters should be compared despite their class difference. If TRUE, the factors are coerced to characters. Note that mockstudy$race is a character, while mockstudy2$race is a factor: summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE, # compare integers and numerics tol.num.val = 10, # allow absolute differences &lt;= 10 tol.factor = &quot;labels&quot;, # match only factor labels factor.as.char = TRUE # compare factors and characters )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared No other variables not compared Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 0 0 race race 1285 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 1 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (1531 differences not shown) var.x var.y case values.x values.y row.x row.y race race 76170 Caucasian caucasian 26 20 race race 76240 Caucasian caucasian 27 21 race race 76431 Caucasian caucasian 28 22 race race 76712 Caucasian caucasian 29 23 race race 76780 Caucasian caucasian 30 24 race race 77066 Caucasian caucasian 31 25 race race 77316 Caucasian caucasian 32 26 race race 77591 Caucasian caucasian 34 28 race race 77851 Caucasian caucasian 35 29 race race 77956 Caucasian caucasian 36 30 ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 ast ast 105271 100 36 3 2 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Character tolerance Use the tol.char= argument to change how character variables are compared. By default, they are compared as-is, but they can be compared after ignoring case or trimming whitespace or both. summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE, # compare integers and numerics tol.num.val = 10, # allow absolute differences &lt;= 10 tol.factor = &quot;labels&quot;, # match only factor labels factor.as.char = TRUE, # compare factors and characters tol.char = &quot;case&quot; # ignore case in character vectors )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared No other variables not compared Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 0 0 race race 0 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 266 266 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 1 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable (256 differences not shown) var.x var.y case values.x values.y row.x row.y ps ps 86205 0 NA 6 3 hgb hgb 88714 NA -9 192 186 hgb hgb 88955 NA -9 204 198 hgb hgb 89549 NA -9 229 223 hgb hgb 89563 NA -9 231 225 hgb hgb 89584 NA -9 237 231 hgb hgb 89591 NA -9 238 232 hgb hgb 89595 NA -9 239 233 hgb hgb 89647 NA -9 243 237 hgb hgb 89665 NA -9 244 238 hgb hgb 89827 NA -9 255 249 ast ast 105271 100 36 3 2 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Date tolerance Use the tol.date= argument to change how dates are compared. By default, they’re expected to be equal to each other. Other data type tolerances Use the tol.other= argument to change how other objects are compared. By default, they’re expected to be identical(). User-defined tolerance functions Details The comparison.control() function accepts functions for any of the tolerance arguments in addition to the short-hand character strings. This allows the user to create custom tolerance functions to suit his/her needs. Any custom tolerance function must accept two vectors as arguments and return a logical vector of the same length. The TRUEs in the results should correspond to elements which are deemed “different”. Note that the numeric and date tolerance functions should also include a third argument for tolerance size (even if it’s not used). CAUTION: the results should not include NAs, since the logical vector is used to subset the input data.frames. The tol.NA() function is useful for considering any NAs in the two vectors (but not both) as differences, in addition to other criteria. tol.NA function (x, y, idx) { (is.na(x) &amp; !is.na(y)) | (is.na(y) &amp; !is.na(x)) | (!is.na(x) &amp; !is.na(y) &amp; idx) } &lt;environment: namespace:arsenal&gt; The tol.NA() function is used in all default tolerance functions to help handle NAs. Example 1 Suppose we want to ignore any dates which are later in the second dataset than the first. We define a custom tolerance function. my.tol &lt;- function(x, y, tol) { tol.NA(x, y, x &gt; y) } date.df1 &lt;- data.frame(dt = as.Date(c(&quot;2017-09-07&quot;, &quot;2017-08-08&quot;, &quot;2017-07-09&quot;, NA))) date.df2 &lt;- data.frame(dt = as.Date(c(&quot;2017-10-01&quot;, &quot;2017-08-08&quot;, &quot;2017-07-10&quot;, &quot;2017-01-01&quot;))) n.diffs(compare(date.df1, date.df2)) # default finds any differences [1] 3 n.diffs(compare(date.df1, date.df2, tol.date = my.tol)) # our function identifies only the NA as different... [1] 1 n.diffs(compare(date.df2, date.df1, tol.date = my.tol)) # ... until we change the argument order [1] 3 Example 2 (Continuing our mockstudy example) Suppose we’re okay with NAs getting replaced by -9. tol.minus9 &lt;- function(x, y, tol) { idx1 &lt;- is.na(x) &amp; !is.na(y) &amp; y == -9 idx2 &lt;- tol.num.absolute(x, y, tol) # find other absolute differences return(!idx1 &amp; idx2) } summary(compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), # dots=underscores=spaces, ignore case int.as.num = TRUE, # compare integers and numerics tol.num.val = 10, # allow absolute differences &lt;= 10 tol.factor = &quot;labels&quot;, # match only factor labels factor.as.char = TRUE, # compare factors and characters tol.char = &quot;case&quot;, # ignore case in character vectors tol.num = tol.minus9 # ignore NA -&gt; -9 changes )) Summary of data.frames version arg ncol nrow x mockstudy 14 1499 y mockstudy2 13 1495 Variables not shared version variable position class x age 2 integer Other variables not compared No other variables not compared Observations not shared version case observation x 88989 9 x 90158 8 x 99508 7 x 112263 5 Differences detected by variable var.x var.y n NAs arm Arm 0 0 sex sex 0 0 race race 0 0 fu.time fu_time 0 0 fu.stat fu stat 0 0 ps ps 1 1 hgb hgb 0 0 bmi bmi 0 0 alk.phos alk.phos 0 0 ast ast 1 0 mdquality.s mdquality.s 0 0 age.ord age.ord 0 0 First 10 differences detected per variable var.x var.y case values.x values.y row.x row.y ps ps 86205 0 NA 6 3 ast ast 105271 100 36 3 2 Non-identical attributes var.x var.y name arm Arm label sex sex label sex sex levels race race class race race label race race levels bmi bmi label Extract Differences Differences can be easily extracted using the diffs() function. If you only want to determine how many differences were found, use the n.diffs() function. cmp &lt;- compare(mockstudy, mockstudy2, by = &quot;case&quot;, tol.vars = c(&quot;._ &quot;, &quot;case&quot;), int.as.num = TRUE) n.diffs(cmp) [1] 1765 head(diffs(cmp)) var.x var.y case values.x values.y row.x row.y 1 sex sex 76170 Male Male 26 20 2 sex sex 76240 Male Male 27 21 3 sex sex 76431 Female Female 28 22 4 sex sex 76712 Male Male 29 23 5 sex sex 76780 Female Female 30 24 6 sex sex 77066 Female Female 31 25 Differences can also be summarized by variable. diffs(cmp, by.var = TRUE) var.x var.y n NAs 1 arm Arm 0 0 2 sex sex 1495 0 3 fu.time fu_time 0 0 4 fu.stat fu stat 0 0 5 ps ps 1 1 6 hgb hgb 266 266 7 bmi bmi 0 0 8 alk.phos alk.phos 0 0 9 ast ast 3 0 10 mdquality.s mdquality.s 0 0 11 age.ord age.ord 0 0 To report differences from only a few variables, one can pass a list of variable names to diffs(). diffs(cmp, vars = c(&quot;ps&quot;, &quot;ast&quot;), by.var = TRUE) var.x var.y n NAs 5 ps ps 1 1 9 ast ast 3 0 diffs(cmp, vars = c(&quot;ps&quot;, &quot;ast&quot;)) var.x var.y case values.x values.y row.x row.y 1496 ps ps 86205 0 NA 6 3 1763 ast ast 86205 27 36 6 3 1764 ast ast 105271 100 36 3 2 1765 ast ast 110754 35 36 1 1 Appendix Stucture of the Object (This section is just as much for my use as for yours!) obj &lt;- compare(mockstudy, mockstudy2, by = &quot;case&quot;) There are two main objects in the &quot;compare.data.frame&quot; object, each with its own print method. The frame.summary contains: the substituted-deparsed arguments information about the number of columns and rows in each dataset the by-variables for each dataset (which may not be the same) the attributes for each dataset (which get counted in the print method) a data.frame of by-variables and row numbers of observations not shared between datasets the number of shared observations print(obj$frame.summary) version arg ncol nrow by attrs unique n.shared 1 x mockstudy 14 1499 case 3 attributes 4 unique obs 1495 2 y mockstudy2 13 1495 case 3 attributes 0 unique obs 1495 The vars.summary contains: variable name, column number, and class vector (with possibly more than one element) for each x and y. These are all NA if there isn’t a match in both datasets. values, a list-column of the text string &quot;by-variable&quot; for the by-variables, NULL for columns that aren’t compared, or a data.frame containing: The by-variables for differences found The values which are different for x and y The row numbers for differences found attrs, a list-column of NULL if there are no attributes, or a data.frame containing: The name of the attributes The attributes for x and y, set to NA if non-existant The actual attributes (if show.attr=TRUE). print(obj$vars.summary) var.x pos.x class.x var.y pos.y class.y values attrs 8 case 1 integer case 1 integer by-variable 0 attributes 17 sex 4 factor sex 2 factor 1495 differences 2 attributes 16 race 5 character race 3 factor Not compared 3 attributes 15 ps 8 integer ps 4 integer 1 differences 0 attributes 13 hgb 9 numeric hgb 5 numeric 266 differences 0 attributes 7 bmi 10 numeric bmi 6 numeric 0 differences 1 attributes 4 alk.phos 11 integer alk.phos 7 integer 0 differences 0 attributes 6 ast 12 integer ast 8 numeric Not compared 0 attributes 14 mdquality.s 13 integer mdquality.s 9 integer 0 differences 0 attributes 3 age.ord 14 ordered, factor age.ord 10 ordered, factor 0 differences 0 attributes 2 age 2 integer &lt;NA&gt; NA NA Not compared 0 attributes 5 arm 3 character &lt;NA&gt; NA NA Not compared 0 attributes 11 fu.time 6 integer &lt;NA&gt; NA NA Not compared 0 attributes 10 fu.stat 7 integer &lt;NA&gt; NA NA Not compared 0 attributes 12 &lt;NA&gt; NA NA fu_time 11 integer Not compared 0 attributes 9 &lt;NA&gt; NA NA fu stat 12 integer Not compared 0 attributes 1 &lt;NA&gt; NA NA Arm 13 character Not compared 0 attributes --- ## The freqlist function https://cran.r-project.org/web/packages/arsenal/vignettes/freqlist.html The freqlist function Tina Gunderson and Ethan Heinzen 09 November, 2018 Overview Sample dataset The freqlist object Basic output using summary() Using a formula with freqlist Rounding percentage digits or changing variable names for printing Additional examples Including combinations with frequencies of zero Options for NA handling Frequency counts and percentages subset by factor levels Change labels on the fly Using xtable() to format and print freqlist() results Use freqlist in bookdown Appendix: Notes regarding table options in R NAs Table dimname names (dnn) Overview freqlist() is a function meant to produce output similar to SAS’s PROC FREQ procedure when using the /list option of the TABLE statement. freqlist() provides options for handling missing or sparse data and can provide cumulative counts and percentages based on subgroups. It depends on the knitr package for printing. require(arsenal) Sample dataset For our examples, we’ll load the mockstudy data included with this package and use it to create a basic table. Because they have fewer levels, for brevity, we’ll use the variables arm, sex, and mdquality.s to create the example table. We’ll retain NAs in the table creation. See the appendix for notes regarding default NA handling and other useful information regarding tables in R. # load the data data(mockstudy) # retain NAs when creating the table using the useNA argument tab.ex &lt;- table(mockstudy[, c(&quot;arm&quot;, &quot;sex&quot;, &quot;mdquality.s&quot;)], useNA = &quot;ifany&quot;) The freqlist object The freqlist() function returns an object of class &quot;freqlist&quot;, which has three parts: freqlist, byVar, and labels. freqlist is a single data frame containing all contingency tables with calculated frequencies, cumulative frequencies, percentages, and cumulative percentages. byVar and labels are used in the summary method for subgroups and variable names, which will be covered in later examples. Note that freqlist() is an S3 generic, with methods for tables and formulas. noby &lt;- freqlist(tab.ex) str(noby) List of 3 $ freqlist:&#39;data.frame&#39;: 18 obs. of 7 variables: ..$ arm : Factor w/ 3 levels &quot;A: IFL&quot;,&quot;F: FOLFOX&quot;,..: 1 1 1 1 1 1 2 2 2 2 ... ..$ sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 1 1 1 2 2 2 1 1 1 2 ... ..$ mdquality.s: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 2 NA 1 2 NA 1 2 NA 1 ... ..$ Freq : int [1:18] 29 214 34 12 118 21 31 285 95 21 ... ..$ cumFreq : int [1:18] 29 243 277 289 407 428 459 744 839 860 ... ..$ freqPercent: num [1:18] 1.93 14.28 2.27 0.8 7.87 ... ..$ cumPercent : num [1:18] 1.93 16.21 18.48 19.28 27.15 ... $ byVar : NULL $ labels : NULL - attr(*, &quot;class&quot;)= chr &quot;freqlist&quot; # view the data frame portion of freqlist output head(noby[[&quot;freqlist&quot;]]) ## or use as.data.frame(noby) arm sex mdquality.s Freq cumFreq freqPercent cumPercent 1 A: IFL Male 0 29 29 1.93 1.93 2 A: IFL Male 1 214 243 14.28 16.21 3 A: IFL Male &lt;NA&gt; 34 277 2.27 18.48 4 A: IFL Female 0 12 289 0.80 19.28 5 A: IFL Female 1 118 407 7.87 27.15 6 A: IFL Female &lt;NA&gt; 21 428 1.40 28.55 Basic output using summary() The summary method for freqlist() relies on the kable() function (in the knitr package) for printing. knitr::kable() converts the output to markdown which can be printed in the console or easily rendered in Word, PDF, or HTML documents. Note that you must supply results=&quot;asis&quot; to properly format the markdown output. summary(noby) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 You can print a title for the table using the title= argument. summary(noby, title = &quot;Basic freqlist output&quot;) Basic freqlist output arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 You can also easily pull out the freqlist data frame for more complicated formatting or manipulation (e.g. with another function such as xtable() or pander()) using as.data.frame(): head(as.data.frame(noby)) arm sex mdquality.s Freq cumFreq freqPercent cumPercent 1 A: IFL Male 0 29 29 1.93 1.93 2 A: IFL Male 1 214 243 14.28 16.21 3 A: IFL Male &lt;NA&gt; 34 277 2.27 18.48 4 A: IFL Female 0 12 289 0.80 19.28 5 A: IFL Female 1 118 407 7.87 27.15 6 A: IFL Female &lt;NA&gt; 21 428 1.40 28.55 Using a formula with freqlist Instead of passing a pre-computed table to freqlist(), you can instead pass a formula, which will be in turn passed to the xtabs() function. Additional freqlist() arguments are passed through the ... to the freqlist() table method. Note that the addNA= argument was added to xtabs() in R 3.4.0. In previous versions, NAs have to be added to relevant columns using addNA(). ### this works in R &gt;= 3.4.0 summary(freqlist(~ arm + sex + mdquality.s, data = ### mockstudy, addNA = TRUE)) ### This one is backwards-compatible summary(freqlist(~arm + sex + addNA(mdquality.s), data = mockstudy)) |arm |sex |addNA.mdquality.s. | Freq| cumFreq| freqPercent| cumPercent| |:---------|:------|:------------------|----:|-------:|-----------:|----------:| |A: IFL |Male |0 | 29| 29| 1.93| 1.93| | | |1 | 214| 243| 14.28| 16.21| | | |NA | 34| 277| 2.27| 18.48| | |Female |0 | 12| 289| 0.80| 19.28| | | |1 | 118| 407| 7.87| 27.15| | | |NA | 21| 428| 1.40| 28.55| |F: FOLFOX |Male |0 | 31| 459| 2.07| 30.62| | | |1 | 285| 744| 19.01| 49.63| | | |NA | 95| 839| 6.34| 55.97| | |Female |0 | 21| 860| 1.40| 57.37| | | |1 | 198| 1058| 13.21| 70.58| | | |NA | 61| 1119| 4.07| 74.65| |G: IROX |Male |0 | 17| 1136| 1.13| 75.78| | | |1 | 187| 1323| 12.47| 88.26| | | |NA | 24| 1347| 1.60| 89.86| | |Female |0 | 14| 1361| 0.93| 90.79| | | |1 | 121| 1482| 8.07| 98.87| | | |NA | 17| 1499| 1.13| 100.00| One can also set NAs to an explicit value using includeNA(). summary(freqlist(~arm + sex + includeNA(mdquality.s, &quot;Missing&quot;), data = mockstudy)) |arm |sex |includeNA.mdquality.s...Missing.. | Freq| cumFreq| freqPercent| cumPercent| |:---------|:------|:---------------------------------|----:|-------:|-----------:|----------:| |A: IFL |Male |0 | 29| 29| 1.93| 1.93| | | |1 | 214| 243| 14.28| 16.21| | | |Missing | 34| 277| 2.27| 18.48| | |Female |0 | 12| 289| 0.80| 19.28| | | |1 | 118| 407| 7.87| 27.15| | | |Missing | 21| 428| 1.40| 28.55| |F: FOLFOX |Male |0 | 31| 459| 2.07| 30.62| | | |1 | 285| 744| 19.01| 49.63| | | |Missing | 95| 839| 6.34| 55.97| | |Female |0 | 21| 860| 1.40| 57.37| | | |1 | 198| 1058| 13.21| 70.58| | | |Missing | 61| 1119| 4.07| 74.65| |G: IROX |Male |0 | 17| 1136| 1.13| 75.78| | | |1 | 187| 1323| 12.47| 88.26| | | |Missing | 24| 1347| 1.60| 89.86| | |Female |0 | 14| 1361| 0.93| 90.79| | | |1 | 121| 1482| 8.07| 98.87| | | |Missing | 17| 1499| 1.13| 100.00| Rounding percentage digits or changing variable names for printing The digits= argument takes a single numeric value and controls the rounding of percentages in the output. The labelTranslations= argument is a character vector or list whose length must be equal to the number of factors used in the table. Note: this does not change the names of the data frame in the freqlist object, only those used in printing. Both options are applied in the following example. withnames &lt;- freqlist(tab.ex, labelTranslations = c(&quot;Treatment Arm&quot;, &quot;Gender&quot;, &quot;LASA QOL&quot;), digits = 0) summary(withnames) Treatment Arm Gender LASA QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 2 2 1 214 243 14 16 NA 34 277 2 18 Female 0 12 289 1 19 1 118 407 8 27 NA 21 428 1 29 F: FOLFOX Male 0 31 459 2 31 1 285 744 19 50 NA 95 839 6 56 Female 0 21 860 1 57 1 198 1058 13 71 NA 61 1119 4 75 G: IROX Male 0 17 1136 1 76 1 187 1323 12 88 NA 24 1347 2 90 Female 0 14 1361 1 91 1 121 1482 8 99 NA 17 1499 1 100 Additional examples Including combinations with frequencies of zero The sparse= argument takes a single logical value as input. The default option is FALSE. If set to TRUE, the sparse option will include combinations with frequencies of zero in the list of results. As our initial table did not have any such levels, we create a second table to use in our example. summary(freqlist(~race + sex + arm, data = mockstudy, sparse = TRUE, digits = 1)) race sex arm Freq cumFreq freqPercent cumPercent African-Am Male A: IFL 25 25 1.7 1.7 F: FOLFOX 24 49 1.6 3.3 G: IROX 16 65 1.1 4.4 Female A: IFL 14 79 0.9 5.3 F: FOLFOX 25 104 1.7 7.0 G: IROX 11 115 0.7 7.7 Asian Male A: IFL 0 115 0.0 7.7 F: FOLFOX 10 125 0.7 8.4 G: IROX 1 126 0.1 8.4 Female A: IFL 1 127 0.1 8.5 F: FOLFOX 4 131 0.3 8.8 G: IROX 2 133 0.1 8.9 Caucasian Male A: IFL 240 373 16.1 25.0 F: FOLFOX 352 725 23.6 48.6 G: IROX 195 920 13.1 61.7 Female A: IFL 131 1051 8.8 70.4 F: FOLFOX 234 1285 15.7 86.1 G: IROX 136 1421 9.1 95.2 Hawaii/Pacific Male A: IFL 1 1422 0.1 95.3 F: FOLFOX 1 1423 0.1 95.4 G: IROX 0 1423 0.0 95.4 Female A: IFL 0 1423 0.0 95.4 F: FOLFOX 2 1425 0.1 95.5 G: IROX 1 1426 0.1 95.6 Hispanic Male A: IFL 8 1434 0.5 96.1 F: FOLFOX 17 1451 1.1 97.3 G: IROX 12 1463 0.8 98.1 Female A: IFL 4 1467 0.3 98.3 F: FOLFOX 11 1478 0.7 99.1 G: IROX 2 1480 0.1 99.2 Native-Am/Alaska Male A: IFL 1 1481 0.1 99.3 F: FOLFOX 0 1481 0.0 99.3 G: IROX 2 1483 0.1 99.4 Female A: IFL 1 1484 0.1 99.5 F: FOLFOX 1 1485 0.1 99.5 G: IROX 0 1485 0.0 99.5 Other Male A: IFL 2 1487 0.1 99.7 F: FOLFOX 2 1489 0.1 99.8 G: IROX 1 1490 0.1 99.9 Female A: IFL 0 1490 0.0 99.9 F: FOLFOX 2 1492 0.1 100.0 G: IROX 0 1492 0.0 100.0 Options for NA handling The various na.options= allow you to include or exclude data with missing values for one or more factor levels in the counts and percentages, as well as show the missing data but exclude it from the cumulative counts and percentages. The default option is to include all combinations with missing values. summary(freqlist(tab.ex, na.options = &quot;include&quot;)) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 summary(freqlist(tab.ex, na.options = &quot;showexclude&quot;)) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 2.33 2.33 1 214 243 17.16 19.49 NA 34 NA NA NA Female 0 12 255 0.96 20.45 1 118 373 9.46 29.91 NA 21 NA NA NA F: FOLFOX Male 0 31 404 2.49 32.40 1 285 689 22.85 55.25 NA 95 NA NA NA Female 0 21 710 1.68 56.94 1 198 908 15.88 72.81 NA 61 NA NA NA G: IROX Male 0 17 925 1.36 74.18 1 187 1112 15.00 89.17 NA 24 NA NA NA Female 0 14 1126 1.12 90.30 1 121 1247 9.70 100.00 NA 17 NA NA NA summary(freqlist(tab.ex, na.options = &quot;remove&quot;)) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 2.33 2.33 1 214 243 17.16 19.49 Female 0 12 255 0.96 20.45 1 118 373 9.46 29.91 F: FOLFOX Male 0 31 404 2.49 32.40 1 285 689 22.85 55.25 Female 0 21 710 1.68 56.94 1 198 908 15.88 72.81 G: IROX Male 0 17 925 1.36 74.18 1 187 1112 15.00 89.17 Female 0 14 1126 1.12 90.30 1 121 1247 9.70 100.00 Frequency counts and percentages subset by factor levels The groupBy= argument internally subsets the data by the specified factor prior to calculating cumulative counts and percentages. By default, when used each subset will print in a separate table. Using the single = TRUE option when printing will collapse the subsetted result into a single table. withby &lt;- freqlist(tab.ex, groupBy = c(&quot;arm&quot;, &quot;sex&quot;)) summary(withby) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 10.47 10.47 1 214 243 77.26 87.73 NA 34 277 12.27 100.00 arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Female 0 12 12 7.95 7.95 1 118 130 78.15 86.09 NA 21 151 13.91 100.00 arm sex mdquality.s Freq cumFreq freqPercent cumPercent F: FOLFOX Male 0 31 31 7.54 7.54 1 285 316 69.34 76.89 NA 95 411 23.11 100.00 arm sex mdquality.s Freq cumFreq freqPercent cumPercent F: FOLFOX Female 0 21 21 7.50 7.50 1 198 219 70.71 78.21 NA 61 280 21.79 100.00 arm sex mdquality.s Freq cumFreq freqPercent cumPercent G: IROX Male 0 17 17 7.46 7.46 1 187 204 82.02 89.47 NA 24 228 10.53 100.00 arm sex mdquality.s Freq cumFreq freqPercent cumPercent G: IROX Female 0 14 14 9.21 9.21 1 121 135 79.61 88.82 NA 17 152 11.18 100.00 # using the single = TRUE argument will collapse results into a single table for # printing summary(withby, single = TRUE) arm sex mdquality.s Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 10.47 10.47 1 214 243 77.26 87.73 NA 34 277 12.27 100.00 Female 0 12 12 7.95 7.95 1 118 130 78.15 86.09 NA 21 151 13.91 100.00 F: FOLFOX Male 0 31 31 7.54 7.54 1 285 316 69.34 76.89 NA 95 411 23.11 100.00 Female 0 21 21 7.50 7.50 1 198 219 70.71 78.21 NA 61 280 21.79 100.00 G: IROX Male 0 17 17 7.46 7.46 1 187 204 82.02 89.47 NA 24 228 10.53 100.00 Female 0 14 14 9.21 9.21 1 121 135 79.61 88.82 NA 17 152 11.18 100.00 Change labels on the fly At this time, the labels can be changed just for the variables (e.g. not the frequency columns). labels(noby) &lt;- c(&quot;Arm&quot;, &quot;Sex&quot;, &quot;QOL&quot;) summary(noby) Arm Sex QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 You can also supply labelTranslations= to summary(). summary(noby, labelTranslations = c(&quot;Arm&quot;, &quot;Sex&quot;, &quot;QOL&quot;)) Arm Sex QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 Using xtable() to format and print freqlist() results Fair warning: xtable() has kind of a steep learning curve. These examples are given without explanation, for more advanced users. require(xtable) Loading required package: xtable # set up custom function for xtable text italic &lt;- function(x) { paste0(&quot;&lt;i&gt;&quot;, x, &quot;&lt;/i&gt;&quot;) } xftbl &lt;- xtable(noby[[&quot;freqlist&quot;]], caption = &quot;xtable formatted output of freqlist data frame&quot;, align = &quot;|r|r|r|r|c|c|c|r|&quot;) # change the column names names(xftbl)[1:3] &lt;- c(&quot;Arm&quot;, &quot;Gender&quot;, &quot;LASA QOL&quot;) print(xftbl, sanitize.colnames.function = italic, include.rownames = FALSE, type = &quot;html&quot;, comment = FALSE) xtable formatted output of freqlist data frame Arm Gender LASA QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 A: IFL Male 1 214 243 14.28 16.21 A: IFL Male 34 277 2.27 18.48 A: IFL Female 0 12 289 0.80 19.28 A: IFL Female 1 118 407 7.87 27.15 A: IFL Female 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 F: FOLFOX Male 1 285 744 19.01 49.63 F: FOLFOX Male 95 839 6.34 55.97 F: FOLFOX Female 0 21 860 1.40 57.37 F: FOLFOX Female 1 198 1058 13.21 70.58 F: FOLFOX Female 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 G: IROX Male 1 187 1323 12.47 88.26 G: IROX Male 24 1347 1.60 89.86 G: IROX Female 0 14 1361 0.93 90.79 G: IROX Female 1 121 1482 8.07 98.87 G: IROX Female 17 1499 1.13 100.00 Use freqlist in bookdown Since the backbone of freqlist() is knitr::kable(), tables still render well in bookdown. However, print.summary.freqlist() doesn’t use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID. summary(freqlist(~sex + age, data = mockstudy), title = &quot;(\\\\#tab:mytableby) Caption here&quot;) Appendix: Notes regarding table options in R NAs There are several widely used options for basic tables in R. The table() function in base R is probably the most common; by default it excludes NA values. You can change NA handling in base::table() using the useNA= or exclude= arguments. # base table default removes NAs tab.d1 &lt;- base::table(mockstudy[, c(&quot;arm&quot;, &quot;sex&quot;, &quot;mdquality.s&quot;)], useNA = &quot;ifany&quot;) tab.d1 , , mdquality.s = 0 sex arm Male Female A: IFL 29 12 F: FOLFOX 31 21 G: IROX 17 14 , , mdquality.s = 1 sex arm Male Female A: IFL 214 118 F: FOLFOX 285 198 G: IROX 187 121 , , mdquality.s = NA sex arm Male Female A: IFL 34 21 F: FOLFOX 95 61 G: IROX 24 17 xtabs() is similar to table(), but uses a formula-based syntax. However, there is not an option for retaining NAs in the xtabs() function; instead, NAs must be added to each level of the factor where present using the addNA() function, or (in R &gt;= 3.4.0) using the argument addNA = TRUE. # without specifying addNA tab.d2 &lt;- xtabs(formula = ~arm + sex + mdquality.s, data = mockstudy) tab.d2 , , mdquality.s = 0 sex arm Male Female A: IFL 29 12 F: FOLFOX 31 21 G: IROX 17 14 , , mdquality.s = 1 sex arm Male Female A: IFL 214 118 F: FOLFOX 285 198 G: IROX 187 121 # now with addNA tab.d3 &lt;- xtabs(~arm + sex + addNA(mdquality.s), data = mockstudy) tab.d3 , , addNA(mdquality.s) = 0 sex arm Male Female A: IFL 29 12 F: FOLFOX 31 21 G: IROX 17 14 , , addNA(mdquality.s) = 1 sex arm Male Female A: IFL 214 118 F: FOLFOX 285 198 G: IROX 187 121 , , addNA(mdquality.s) = NA sex arm Male Female A: IFL 34 21 F: FOLFOX 95 61 G: IROX 24 17 Since the formula method of freqlist() uses xtabs(), NAs should be treated in the same way. includeNA() can also be helpful here for setting explicit NA values. Table dimname names (dnn) Supplying a data.frame to the table() function without giving columns individually will create a contingency table using all variables in the data.frame. However, if the columns of a data.frame or matrix are supplied separately (i.e., as vectors), column names will not be preserved. # providing variables separately (as vectors) drops column names tab.d4 &lt;- base::table(mockstudy$arm, mockstudy$sex, mockstudy$mdquality.s) tab.d4 , , = 0 Male Female A: IFL 29 12 F: FOLFOX 31 21 G: IROX 17 14 , , = 1 Male Female A: IFL 214 118 F: FOLFOX 285 198 G: IROX 187 121 If desired, you can use the dnn= argument to pass variable names. # add the column name labels back using dnn option in base::table tab.dnn &lt;- base::table(mockstudy$arm, mockstudy$sex, mockstudy$mdquality.s, dnn = c(&quot;Arm&quot;, &quot;Sex&quot;, &quot;QOL&quot;)) tab.dnn , , QOL = 0 Sex Arm Male Female A: IFL 29 12 F: FOLFOX 31 21 G: IROX 17 14 , , QOL = 1 Sex Arm Male Female A: IFL 214 118 F: FOLFOX 285 198 G: IROX 187 121 If using freqlist(), you can provide the labels directly to freqlist() or to summary() using labelTranslations=. --- ## A Few Notes on Labels https://cran.r-project.org/web/packages/arsenal/vignettes/labels.html A Few Notes on Labels Ethan Heinzen 09 November, 2018 Introduction Examples Set labels in the function call Modify labels after the fact Add labels to a data.frame Introduction The arsenal package relies somewhat heavily on variable labels to make output more “pretty”. A label here is understood to be a single character string with “pretty” text (i.e., not an “ugly” variable name). Three of the main arsenal function use labels in their summary() output. There are several ways to set these labels. We’ll use the mockstudy dataset for all examples here: library(arsenal) data(mockstudy) library(magrittr) # for &#39;freqlist&#39; examples tab.ex &lt;- table(mockstudy[, c(&quot;arm&quot;, &quot;sex&quot;, &quot;mdquality.s&quot;)], useNA=&quot;ifany&quot;) Examples Set labels in the function call The summary() method for tableby(), modelsum(), and freqlist() objects contains a labelTranslations = argument to specify labels in the function call. Note that the freqlist() function matches labels in order, whereas the other two match labels by name. The labels can be input as a list or a character vector. summary(freqlist(tab.ex), labelTranslations = c(&quot;Treatment Arm&quot;, &quot;Gender&quot;, &quot;LASA QOL&quot;)) Treatment Arm Gender LASA QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 summary(tableby(arm ~ sex + age, data = mockstudy), labelTranslations = c(sex = &quot;SEX&quot;, age = &quot;Age, yrs&quot;)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value SEX 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 summary(modelsum(bmi ~ age, adjust = ~sex, data = mockstudy), labelTranslations = list(sexFemale = &quot;Female&quot;, age = &quot;Age, yrs&quot;)) estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 Female -0.718 0.291 0.014 Modify labels after the fact Another option is to add labels after you have created the object. To do this, you can use the form labels(x) &lt;- value or use the pipe-able version, set_labels(). # the non-pipe version; somewhat clunky tmp &lt;- freqlist(tab.ex) labels(tmp) &lt;- c(&quot;Treatment Arm&quot;, &quot;Gender&quot;, &quot;LASA QOL&quot;) summary(tmp) Treatment Arm Gender LASA QOL Freq cumFreq freqPercent cumPercent A: IFL Male 0 29 29 1.93 1.93 1 214 243 14.28 16.21 NA 34 277 2.27 18.48 Female 0 12 289 0.80 19.28 1 118 407 7.87 27.15 NA 21 428 1.40 28.55 F: FOLFOX Male 0 31 459 2.07 30.62 1 285 744 19.01 49.63 NA 95 839 6.34 55.97 Female 0 21 860 1.40 57.37 1 198 1058 13.21 70.58 NA 61 1119 4.07 74.65 G: IROX Male 0 17 1136 1.13 75.78 1 187 1323 12.47 88.26 NA 24 1347 1.60 89.86 Female 0 14 1361 0.93 90.79 1 121 1482 8.07 98.87 NA 17 1499 1.13 100.00 # piped--much cleaner mockstudy %&gt;% tableby(arm ~ sex + age, data = .) %&gt;% set_labels(c(sex = &quot;SEX&quot;, age = &quot;Age, yrs&quot;)) %&gt;% summary() A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value SEX 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 mockstudy %&gt;% modelsum(bmi ~ age, adjust = ~ sex, data = .) %&gt;% set_labels(list(sexFemale = &quot;Female&quot;, age = &quot;Age, yrs&quot;)) %&gt;% summary() estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 Female -0.718 0.291 0.014 Add labels to a data.frame tableby() and modelsum() also allow you to have label attributes on the data. Note that by default these attributes usually get dropped upon subsetting, but tableby() and modelsum() use the keep.labels() function to retain them. mockstudy.lab &lt;- keep.labels(mockstudy) You can set attributes one at a time in two ways: attr(mockstudy.lab$sex, &quot;label&quot;) &lt;- &quot;Sex&quot; labels(mockstudy.lab$age) &lt;- &quot;Age, yrs&quot; …or all at once: labels(mockstudy.lab) &lt;- list(sex = &quot;Sex&quot;, age = &quot;Age, yrs&quot;) summary(tableby(arm ~ sex + age, data = mockstudy.lab)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Sex 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 You can pipe this, too. mockstudy %&gt;% set_labels(list(sex = &quot;SEX&quot;, age = &quot;Age, yrs&quot;)) %&gt;% modelsum(bmi ~ age, adjust = ~ sex, data = .) %&gt;% summary() estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 SEX Female -0.718 0.291 0.014 To extract labels from a data.frame, simply use the labels() function: labels(mockstudy.lab) ## $case ## NULL ## ## $age ## [1] &quot;Age, yrs&quot; ## ## $arm ## [1] &quot;Treatment Arm&quot; ## ## $sex ## [1] &quot;Sex&quot; ## ## $race ## [1] &quot;Race&quot; ## ## $fu.time ## NULL ## ## $fu.stat ## NULL ## ## $ps ## NULL ## ## $hgb ## NULL ## ## $bmi ## [1] &quot;Body Mass Index (kg/m^2)&quot; ## ## $alk.phos ## NULL ## ## $ast ## NULL ## ## $mdquality.s ## NULL ## ## $age.ord ## NULL --- ## The modelsum function https://cran.r-project.org/web/packages/arsenal/vignettes/modelsum.html The modelsum function Beth Atkinson, Ethan Heinzen, Pat Votruba, Jason Sinnwell, Shannon McDonnell and Greg Dougherty 09 November, 2018 Introduction Simple Example Pretty text version of table Pretty Rmarkdown version of table Data frame version of table Add an adjustor to the model Models for each endpoint type Gaussian Fit and summarize linear regression model Extract data using the broom package Create a summary table using modelsum Binomial Fit and summarize logistic regression model Extract data using broom package Create a summary table using modelsum Survival Fit and summarize a Cox regression model Extract data using broom package Create a summary table using modelsum Poisson Example 1: fit and summarize a Poisson regression model Extract data using broom package Create a summary table using modelsum Example 2: fit and summarize a Poisson regression model Extract data using broom package Create a summary table using modelsum Additional Examples 1. Change summary statistics globally 2. Add labels to independent variables 3. Don’t show intercept values 4. Don’t show results for adjustment variables 5. Summarize multiple variables without typing them out 6. Subset the dataset used in the analysis 7. Create combinations of variables on the fly 8. Transform variables on the fly 9. Change the ordering of the variables or delete a variable 10. Merge two modelsum objects together 11. Add a title to the table 12. Modify how missing values are treated 13. Modify the number of digits used 14. Use case-weights in the models 15. Use modelsum within an Sweave document 16. Export modelsum results to a .CSV file 17. Write modelsum object to a separate Word or HTML file 18. Use modelsum in R Shiny 23. Use modelsum in bookdown Available Function Options Summary statistics modelsum.control settings summary.modelsum settings Introduction Very often we are asked to summarize model results from multiple fits into a nice table. The endpoint might be of different types (e.g., survival, case/control, continuous) and there may be several independent variables that we want to examine univariately or adjusted for certain variables such as age and sex. Locally at Mayo, the SAS macros %modelsum, %glmuniv, and %logisuni were written to create such summary tables. With the increasing interest in R, we have developed the function modelsum to create similar tables within the R environment. In developing the modelsum function, the goal was to bring the best features of these macros into an R function. However, the task was not simply to duplicate all the functionality, but rather to make use of R’s strengths (modeling, method dispersion, flexibility in function definition and output format) and make a tool that fits the needs of R users. Additionally, the results needed to fit within the general reproducible research framework so the tables could be displayed within an R markdown report. This report provides step-by-step directions for using the functions associated with modelsum. All functions presented here are available within the arsenal package. An assumption is made that users are somewhat familiar with R markdown documents. For those who are new to the topic, a good initial resource is available at rmarkdown.rstudio.com. Simple Example The first step when using the modelsum function is to load the arsenal package. All the examples in this report use a dataset called mockstudy made available by Paul Novotny which includes a variety of types of variables (character, numeric, factor, ordered factor, survival) to use as examples. &gt; require(arsenal) &gt; data(mockstudy) # load data &gt; dim(mockstudy) # look at how many subjects and variables are in the dataset [1] 1499 14 &gt; # help(mockstudy) # learn more about the dataset and variables &gt; str(mockstudy) # quick look at the data &#39;data.frame&#39;: 1499 obs. of 14 variables: $ case : int 110754 99706 105271 105001 112263 86205 99508 90158 88989 90515 ... $ age : atomic 67 74 50 71 69 56 50 57 51 63 ... ..- attr(*, &quot;label&quot;)= chr &quot;Age in Years&quot; $ arm : atomic F: FOLFOX A: IFL A: IFL G: IROX ... ..- attr(*, &quot;label&quot;)= chr &quot;Treatment Arm&quot; $ sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 1 2 2 2 2 1 1 1 2 1 ... $ race : atomic Caucasian Caucasian Caucasian Caucasian ... ..- attr(*, &quot;label&quot;)= chr &quot;Race&quot; $ fu.time : int 922 270 175 128 233 120 369 421 387 363 ... $ fu.stat : int 2 2 2 2 2 2 2 2 2 2 ... $ ps : int 0 1 1 1 0 0 0 0 1 1 ... $ hgb : num 11.5 10.7 11.1 12.6 13 10.2 13.3 12.1 13.8 12.1 ... $ bmi : atomic 25.1 19.5 NA 29.4 26.4 ... ..- attr(*, &quot;label&quot;)= chr &quot;Body Mass Index (kg/m^2)&quot; $ alk.phos : int 160 290 700 771 350 569 162 152 231 492 ... $ ast : int 35 52 100 68 35 27 16 12 25 18 ... $ mdquality.s: int NA 1 1 1 NA 1 1 1 1 1 ... $ age.ord : Ord.factor w/ 8 levels &quot;10-19&quot;&lt;&quot;20-29&quot;&lt;..: 6 7 4 7 6 5 4 5 5 6 ... To create a simple linear regression table (the default), use a formula statement to specify the variables that you want summarized. The example below predicts BMI with the variables sex and age. &gt; tab1 &lt;- modelsum(bmi ~ sex + age, data=mockstudy) If you want to take a quick look at the table, you can use summary on your modelsum object and the table will print out as text in your R console window. If you use summary without any options you will see a number of &amp;nbsp; statements which translates to “space” in HTML. Pretty text version of table If you want a nicer version in your console window then adding the text=TRUE option. &gt; summary(tab1, text=TRUE) | |estimate |std.error |p.value |adj.r.squared | |:------------|:--------|:---------|:-------|:-------------| |(Intercept) |27.491 |0.181 |&lt; 0.001 |0.004 | |sex Female |-0.731 |0.290 |0.012 | | |(Intercept) |26.424 |0.752 |&lt; 0.001 |0.000 | |Age in Years |0.013 |0.012 |0.290 | | Pretty Rmarkdown version of table In order for the report to look nice within an R markdown (knitr) report, you just need to specify results=&quot;asis&quot; when creating the r chunk. This changes the layout slightly (compresses it) and bolds the variable names. &gt; summary(tab1) estimate std.error p.value adj.r.squared (Intercept) 27.491 0.181 &lt; 0.001 0.004 sex Female -0.731 0.290 0.012 (Intercept) 26.424 0.752 &lt; 0.001 0.000 Age in Years 0.013 0.012 0.290 Data frame version of table If you want a data.frame version, simply use as.data.frame. &gt; as.data.frame(tab1) model term label term.type estimate std.error 1 1 (Intercept) (Intercept) Intercept 27.49147713 0.18134740 2 1 sexFemale sex Female Term -0.73105055 0.29032223 3 2 (Intercept) (Intercept) Intercept 26.42372272 0.75211474 4 2 age Age in Years Term 0.01304859 0.01231653 p.value adj.r.squared 1 0.000000e+00 3.632258e-03 2 1.190605e-02 3.632258e-03 3 1.279109e-196 8.354809e-05 4 2.895753e-01 8.354809e-05 Add an adjustor to the model The argument adjust allows the user to indicate that all the variables should be adjusted for these terms. &gt; tab2 &lt;- modelsum(alk.phos ~ arm + ps + hgb, adjust= ~age + sex, data=mockstudy) &gt; summary(tab2) estimate std.error p.value adj.r.squared Nmiss (Intercept) 175.548 20.587 &lt; 0.001 -0.001 0 Treatment Arm F: FOLFOX -13.701 8.730 0.117 Treatment Arm G: IROX -2.245 9.860 0.820 Age in Years -0.017 0.319 0.956 sex Female 3.016 7.521 0.688 (Intercept) 148.391 19.585 &lt; 0.001 0.045 266 ps 46.721 5.987 &lt; 0.001 Age in Years -0.084 0.311 0.787 sex Female 1.169 7.343 0.874 (Intercept) 336.554 32.239 &lt; 0.001 0.031 266 hgb -13.845 2.137 &lt; 0.001 Age in Years 0.095 0.314 0.763 sex Female -5.980 7.516 0.426 Models for each endpoint type To make sure the correct model is run you need to specify “family”. The options available right now are : gaussian, binomial, survival, and poisson. If there is enough interest, additional models can be added. Gaussian Fit and summarize linear regression model Look at whether there is any evidence that AlkPhos values vary by study arm after adjusting for sex and age (assuming a linear age relationship). &gt; fit &lt;- lm(alk.phos ~ arm + age + sex, data=mockstudy) &gt; summary(fit) Call: lm(formula = alk.phos ~ arm + age + sex, data = mockstudy) Residuals: Min 1Q Median 3Q Max -168.80 -81.45 -47.17 37.39 853.56 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 175.54808 20.58665 8.527 &lt;2e-16 *** armF: FOLFOX -13.70062 8.72963 -1.569 0.117 armG: IROX -2.24498 9.86004 -0.228 0.820 age -0.01741 0.31878 -0.055 0.956 sexFemale 3.01598 7.52097 0.401 0.688 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 128.5 on 1228 degrees of freedom (266 observations deleted due to missingness) Multiple R-squared: 0.002552, Adjusted R-squared: -0.0006969 F-statistic: 0.7855 on 4 and 1228 DF, p-value: 0.5346 &gt; plot(fit) The results suggest that the endpoint may need to be transformed. Calculating the Box-Cox transformation suggests a log transformation. &gt; require(MASS) &gt; boxcox(fit) &gt; fit2 &lt;- lm(log(alk.phos) ~ arm + age + sex, data=mockstudy) &gt; summary(fit2) Call: lm(formula = log(alk.phos) ~ arm + age + sex, data = mockstudy) Residuals: Min 1Q Median 3Q Max -3.0098 -0.4470 -0.1065 0.4205 2.0620 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.9692474 0.1025239 48.469 &lt;2e-16 *** armF: FOLFOX -0.0766798 0.0434746 -1.764 0.078 . armG: IROX -0.0192828 0.0491041 -0.393 0.695 age -0.0004058 0.0015876 -0.256 0.798 sexFemale 0.0179253 0.0374553 0.479 0.632 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.6401 on 1228 degrees of freedom (266 observations deleted due to missingness) Multiple R-squared: 0.003121, Adjusted R-squared: -0.0001258 F-statistic: 0.9613 on 4 and 1228 DF, p-value: 0.4278 &gt; plot(fit2) Finally, look to see whether there there is a non-linear relationship with age. &gt; require(gam) &gt; fit3 &lt;- lm(log(alk.phos) ~ arm + ns(age, df=2) + sex, data=mockstudy) &gt; &gt; # test whether there is a difference between models &gt; stats::anova(fit2,fit3) Analysis of Variance Table Model 1: log(alk.phos) ~ arm + age + sex Model 2: log(alk.phos) ~ arm + ns(age, df = 2) + sex Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 1228 503.19 2 1227 502.07 1 1.1137 2.7218 0.09924 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; &gt; # look at functional form of age &gt; termplot(fit3, term=2, se=T, rug=T) In this instance it looks like there isn’t enough evidence to say that the relationship is non-linear. Extract data using the broom package The broom package makes it easy to extract information from the fit. &gt; tmp &lt;- tidy(fit3) # coefficients, p-values &gt; class(tmp) [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; &gt; tmp # A tibble: 6 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 4.76 0.141 33.8 1.93e-177 2 armF: FOLFOX -0.0767 0.0434 -1.77 7.78e- 2 3 armG: IROX -0.0195 0.0491 -0.396 6.92e- 1 4 ns(age, df = 2)1 0.330 0.260 1.27 2.04e- 1 5 ns(age, df = 2)2 -0.101 0.0935 -1.08 2.82e- 1 6 sexFemale 0.0183 0.0374 0.489 6.25e- 1 &gt; &gt; glance(fit3) # A tibble: 1 x 11 r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0.00533 0.00127 0.640 1.31 0.255 6 -1196. 2405. 2441. # ... with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt; Create a summary table using modelsum &gt; ms.logy &lt;- modelsum(log(alk.phos) ~ arm + ps + hgb, data=mockstudy, adjust= ~age + sex, + family=gaussian, + gaussian.stats=c(&quot;estimate&quot;,&quot;CI.lower.estimate&quot;,&quot;CI.upper.estimate&quot;,&quot;p.value&quot;)) &gt; summary(ms.logy) estimate CI.lower.estimate CI.upper.estimate p.value (Intercept) 4.969 4.768 5.170 &lt; 0.001 Treatment Arm F: FOLFOX -0.077 -0.162 0.009 0.078 Treatment Arm G: IROX -0.019 -0.116 0.077 0.695 Age in Years -0.000 -0.004 0.003 0.798 sex Female 0.018 -0.056 0.091 0.632 (Intercept) 4.832 4.640 5.023 &lt; 0.001 ps 0.226 0.167 0.284 &lt; 0.001 Age in Years -0.001 -0.004 0.002 0.636 sex Female 0.009 -0.063 0.081 0.814 (Intercept) 5.765 5.450 6.080 &lt; 0.001 hgb -0.069 -0.090 -0.048 &lt; 0.001 Age in Years 0.000 -0.003 0.003 0.925 sex Female -0.027 -0.101 0.046 0.468 Binomial Fit and summarize logistic regression model &gt; boxplot(age ~ mdquality.s, data=mockstudy, ylab=attr(mockstudy$age,&#39;label&#39;), xlab=&#39;mdquality.s&#39;) &gt; &gt; fit &lt;- glm(mdquality.s ~ age + sex, data=mockstudy, family=binomial) &gt; summary(fit) Call: glm(formula = mdquality.s ~ age + sex, family = binomial, data = mockstudy) Deviance Residuals: Min 1Q Median 3Q Max -2.1832 0.4500 0.4569 0.4626 0.4756 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 2.329442 0.514684 4.526 6.01e-06 *** age -0.002353 0.008256 -0.285 0.776 sexFemale 0.039227 0.195330 0.201 0.841 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 807.68 on 1246 degrees of freedom Residual deviance: 807.55 on 1244 degrees of freedom (252 observations deleted due to missingness) AIC: 813.55 Number of Fisher Scoring iterations: 4 &gt; &gt; # create Odd&#39;s ratio w/ confidence intervals &gt; tmp &lt;- data.frame(summary(fit)$coef) &gt; tmp Estimate Std..Error z.value Pr...z.. (Intercept) 2.329441734 0.514683688 4.5259677 6.011977e-06 age -0.002353404 0.008255814 -0.2850602 7.755980e-01 sexFemale 0.039227292 0.195330166 0.2008256 8.408350e-01 &gt; &gt; tmp$OR &lt;- round(exp(tmp[,1]),2) &gt; tmp$lower.CI &lt;- round(exp(tmp[,1] - 1.96* tmp[,2]),2) &gt; tmp$upper.CI &lt;- round(exp(tmp[,1] + 1.96* tmp[,2]),2) &gt; names(tmp)[4] &lt;- &#39;P-value&#39; &gt; &gt; kable(tmp[,c(&#39;OR&#39;,&#39;lower.CI&#39;,&#39;upper.CI&#39;,&#39;P-value&#39;)]) OR lower.CI upper.CI P-value (Intercept) 10.27 3.75 28.17 0.000006 age 1.00 0.98 1.01 0.775598 sexFemale 1.04 0.71 1.53 0.840835 &gt; &gt; # Assess the predictive ability of the model &gt; &gt; # code using the pROC package &gt; require(pROC) &gt; pred &lt;- predict(fit, type=&#39;response&#39;) &gt; tmp &lt;- pROC::roc(mockstudy$mdquality.s[!is.na(mockstudy$mdquality.s)]~ pred, plot=TRUE, percent=TRUE) &gt; tmp$auc Area under the curve: 50.69% Extract data using broom package The broom package makes it easy to extract information from the fit. &gt; tidy(fit, exp=T, conf.int=T) # coefficients, p-values, conf.intervals # A tibble: 3 x 7 term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 10.3 0.515 4.53 0.00000601 3.83 28.9 2 age 0.998 0.00826 -0.285 0.776 0.981 1.01 3 sexFemale 1.04 0.195 0.201 0.841 0.712 1.53 &gt; &gt; glance(fit) # model summary statistics # A tibble: 1 x 7 null.deviance df.null logLik AIC BIC deviance df.residual &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 808. 1246 -404. 814. 829. 808. 1244 Create a summary table using modelsum &gt; summary(modelsum(mdquality.s ~ age + bmi, data=mockstudy, adjust=~sex, family=binomial)) OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 10.272 3.831 28.876 &lt; 0.001 0.507 0 Age in Years 0.998 0.981 1.014 0.776 sex Female 1.040 0.712 1.534 0.841 (Intercept) 4.814 1.709 13.221 0.003 0.550 33 Body Mass Index (kg/m^2) 1.023 0.987 1.063 0.220 sex Female 1.053 0.717 1.561 0.794 &gt; &gt; fitall &lt;- modelsum(mdquality.s ~ age, data=mockstudy, family=binomial, + binomial.stats=c(&quot;Nmiss2&quot;,&quot;OR&quot;,&quot;p.value&quot;)) &gt; summary(fitall) OR p.value Nmiss2 (Intercept) 10.493 &lt; 0.001 0 Age in Years 0.998 0.766 Survival Fit and summarize a Cox regression model &gt; require(survival) Loading required package: survival Attaching package: &#39;survival&#39; The following object is masked from &#39;package:rpart&#39;: solder &gt; &gt; # multivariable model with all 3 terms &gt; fit &lt;- coxph(Surv(fu.time, fu.stat) ~ age + sex + arm, data=mockstudy) &gt; summary(fit) Call: coxph(formula = Surv(fu.time, fu.stat) ~ age + sex + arm, data = mockstudy) n= 1499, number of events= 1356 coef exp(coef) se(coef) z Pr(&gt;|z|) age 0.004600 1.004611 0.002501 1.839 0.0659 . sexFemale 0.039893 1.040699 0.056039 0.712 0.4765 armF: FOLFOX -0.454650 0.634670 0.064878 -7.008 2.42e-12 *** armG: IROX -0.140785 0.868676 0.072760 -1.935 0.0530 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 exp(coef) exp(-coef) lower .95 upper .95 age 1.0046 0.9954 0.9997 1.0095 sexFemale 1.0407 0.9609 0.9324 1.1615 armF: FOLFOX 0.6347 1.5756 0.5589 0.7207 armG: IROX 0.8687 1.1512 0.7532 1.0018 Concordance= 0.563 (se = 0.009 ) Rsquare= 0.037 (max possible= 1 ) Likelihood ratio test= 56.21 on 4 df, p=2e-11 Wald test = 56.26 on 4 df, p=2e-11 Score (logrank) test = 56.96 on 4 df, p=1e-11 &gt; &gt; # check proportional hazards assumption &gt; fit.z &lt;- cox.zph(fit) &gt; fit.z rho chisq p age -0.0311 1.46 0.226 sexFemale -0.0325 1.44 0.230 armF: FOLFOX 0.0343 1.61 0.205 armG: IROX 0.0337 1.54 0.214 GLOBAL NA 4.59 0.332 &gt; plot(fit.z[1], resid=FALSE) # makes for a cleaner picture in this case &gt; abline(h=coef(fit)[1], col=&#39;red&#39;) &gt; &gt; # check functional form for age using pspline (penalized spline) &gt; # results are returned for the linear and non-linear components &gt; fit2 &lt;- coxph(Surv(fu.time, fu.stat) ~ pspline(age) + sex + arm, data=mockstudy) &gt; fit2 Call: coxph(formula = Surv(fu.time, fu.stat) ~ pspline(age) + sex + arm, data = mockstudy) coef se(coef) se2 Chisq DF p pspline(age), linear 0.00443 0.00237 0.00237 3.48989 1.00 0.0617 pspline(age), nonlin 13.11270 3.08 0.0047 sexFemale 0.03993 0.05610 0.05607 0.50663 1.00 0.4766 armF: FOLFOX -0.46240 0.06494 0.06493 50.69608 1.00 1.1e-12 armG: IROX -0.15243 0.07301 0.07299 4.35876 1.00 0.0368 Iterations: 6 outer, 16 Newton-Raphson Theta= 0.954 Degrees of freedom for terms= 4.1 1.0 2.0 Likelihood ratio test=70.1 on 7.08 df, p=2e-12 n= 1499, number of events= 1356 &gt; &gt; # plot smoothed age to visualize why significant &gt; termplot(fit2, se=T, terms=1) &gt; abline(h=0) &gt; &gt; # The c-statistic comes out in the summary of the fit &gt; summary(fit2)$concordance C se(C) 0.5684325 0.5684325 &gt; &gt; # It can also be calculated using the survConcordance function &gt; survConcordance(Surv(fu.time, fu.stat) ~ predict(fit2), data=mockstudy) Call: survConcordance(formula = Surv(fu.time, fu.stat) ~ predict(fit2), data = mockstudy) n= 1499 Concordance= 0.5684325 se= 0.008779125 concordant discordant tied.risk tied.time std(c-d) 620221.00 470282.00 5021.00 766.00 19235.49 Extract data using broom package The broom package makes it easy to extract information from the fit. &gt; tidy(fit) # coefficients, p-values # A tibble: 4 x 7 term estimate std.error statistic p.value conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 age 0.00460 0.00250 1.84 6.59e- 2 -0.000302 0.00950 2 sexFemale 0.0399 0.0560 0.712 4.77e- 1 -0.0699 0.150 3 armF: FOLFOX -0.455 0.0649 -7.01 2.42e-12 -0.582 -0.327 4 armG: IROX -0.141 0.0728 -1.93 5.30e- 2 -0.283 0.00182 &gt; &gt; glance(fit) # model summary statistics # A tibble: 1 x 15 n nevent statistic.log p.value.log statistic.sc p.value.sc &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1499 1356 56.2 1.81e-11 57.0 1.26e-11 # ... with 9 more variables: statistic.wald &lt;dbl&gt;, p.value.wald &lt;dbl&gt;, # r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;, # std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt; Create a summary table using modelsum &gt; ##Note: You must use quotes when specifying family=&quot;survival&quot; &gt; ## family=survival will not work &gt; summary(modelsum(Surv(fu.time, fu.stat) ~ arm, + adjust=~age + sex, data=mockstudy, family=&quot;survival&quot;)) HR CI.lower.HR CI.upper.HR p.value concordance Treatment Arm F: FOLFOX 0.635 0.559 0.721 &lt; 0.001 0.563 Treatment Arm G: IROX 0.869 0.753 1.002 0.053 Age in Years 1.005 1.000 1.010 0.066 sex Female 1.041 0.932 1.162 0.477 &gt; &gt; ##Note: the pspline term is not working yet &gt; #summary(modelsum(Surv(fu.time, fu.stat) ~ arm, &gt; # adjust=~pspline(age) + sex, data=mockstudy, family=&#39;survival&#39;)) Poisson Poisson regression is useful when predicting an outcome variable representing counts. It can also be useful when looking at survival data. Cox models and Poisson models are very closely related and survival data can be summarized using Poisson regression. If you have overdispersion (see if the residual deviance is much larger than degrees of freedom), you may want to use quasipoisson() instead of poisson(). Some of these diagnostics need to be done outside of modelsum. Example 1: fit and summarize a Poisson regression model For the first example, use the solder dataset available in the rpart package. The endpoint skips has a definite Poisson look. &gt; require(rpart) ##just to get access to solder dataset &gt; data(solder) &gt; hist(solder$skips) &gt; &gt; fit &lt;- glm(skips ~ Opening + Solder + Mask , data=solder, family=poisson) &gt; stats::anova(fit, test=&#39;Chi&#39;) Analysis of Deviance Table Model: poisson, link: log Response: skips Terms added sequentially (first to last) Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) NULL 899 8788.2 Opening 2 2920.5 897 5867.7 &lt; 2.2e-16 *** Solder 1 1168.4 896 4699.3 &lt; 2.2e-16 *** Mask 4 2015.7 892 2683.7 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; summary(fit) Call: glm(formula = skips ~ Opening + Solder + Mask, family = poisson, data = solder) Deviance Residuals: Min 1Q Median 3Q Max -6.1251 -1.4720 -0.7826 0.5986 6.6031 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -1.12220 0.07742 -14.50 &lt; 2e-16 *** OpeningM 0.57161 0.05707 10.02 &lt; 2e-16 *** OpeningS 1.81475 0.05044 35.98 &lt; 2e-16 *** SolderThin 0.84682 0.03327 25.45 &lt; 2e-16 *** MaskA3 0.51315 0.07098 7.23 4.83e-13 *** MaskA6 1.81103 0.06609 27.40 &lt; 2e-16 *** MaskB3 1.20225 0.06697 17.95 &lt; 2e-16 *** MaskB6 1.86648 0.06310 29.58 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 8788.2 on 899 degrees of freedom Residual deviance: 2683.7 on 892 degrees of freedom AIC: 4802.2 Number of Fisher Scoring iterations: 5 Overdispersion is when the Residual deviance is larger than the degrees of freedom. This can be tested, approximately using the following code. The goal is to have a p-value that is &gt;0.05. &gt; 1-pchisq(fit$deviance, fit$df.residual) [1] 0 One possible solution is to use the quasipoisson family instead of the poisson family. This adjusts for the overdispersion. &gt; fit2 &lt;- glm(skips ~ Opening + Solder + Mask, data=solder, family=quasipoisson) &gt; summary(fit2) Call: glm(formula = skips ~ Opening + Solder + Mask, family = quasipoisson, data = solder) Deviance Residuals: Min 1Q Median 3Q Max -6.1251 -1.4720 -0.7826 0.5986 6.6031 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.12220 0.13483 -8.323 3.19e-16 *** OpeningM 0.57161 0.09939 5.751 1.22e-08 *** OpeningS 1.81475 0.08784 20.660 &lt; 2e-16 *** SolderThin 0.84682 0.05794 14.615 &lt; 2e-16 *** MaskA3 0.51315 0.12361 4.151 3.62e-05 *** MaskA6 1.81103 0.11510 15.735 &lt; 2e-16 *** MaskB3 1.20225 0.11663 10.308 &lt; 2e-16 *** MaskB6 1.86648 0.10989 16.984 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasipoisson family taken to be 3.033198) Null deviance: 8788.2 on 899 degrees of freedom Residual deviance: 2683.7 on 892 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 5 Extract data using broom package The broom package makes it easy to extract information from the fit. &gt; tidy(fit) # coefficients, p-values # A tibble: 8 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) -1.12 0.0774 -14.5 1.29e- 47 2 OpeningM 0.572 0.0571 10.0 1.29e- 23 3 OpeningS 1.81 0.0504 36.0 1.66e-283 4 SolderThin 0.847 0.0333 25.5 6.47e-143 5 MaskA3 0.513 0.0710 7.23 4.83e- 13 6 MaskA6 1.81 0.0661 27.4 2.45e-165 7 MaskB3 1.20 0.0670 18.0 4.55e- 72 8 MaskB6 1.87 0.0631 29.6 2.71e-192 &gt; &gt; glance(fit) # model summary statistics # A tibble: 1 x 7 null.deviance df.null logLik AIC BIC deviance df.residual &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 8788. 899 -2393. 4802. 4841. 2684. 892 Create a summary table using modelsum &gt; summary(modelsum(skips~Opening + Solder + Mask, data=solder, family=&quot;quasipoisson&quot;)) RR CI.lower.RR CI.upper.RR p.value (Intercept) 1.533 1.179 1.952 &lt; 0.001 Opening M 2.328 1.733 3.167 &lt; 0.001 Opening S 7.491 5.780 9.888 &lt; 0.001 (Intercept) 2.904 2.423 3.446 &lt; 0.001 Solder Thin 2.808 2.295 3.458 &lt; 0.001 (Intercept) 1.611 1.135 2.204 0.005 Mask A3 1.469 0.995 2.214 0.059 Mask A6 8.331 5.839 12.222 &lt; 0.001 Mask B3 3.328 2.309 4.920 &lt; 0.001 Mask B6 6.466 4.598 9.378 &lt; 0.001 &gt; summary(modelsum(skips~Opening + Solder + Mask, data=solder, family=&quot;poisson&quot;)) RR CI.lower.RR CI.upper.RR p.value (Intercept) 1.533 1.397 1.678 &lt; 0.001 Opening M 2.328 2.089 2.599 &lt; 0.001 Opening S 7.491 6.805 8.267 &lt; 0.001 (Intercept) 2.904 2.750 3.065 &lt; 0.001 Solder Thin 2.808 2.637 2.992 &lt; 0.001 (Intercept) 1.611 1.433 1.804 &lt; 0.001 Mask A3 1.469 1.280 1.690 &lt; 0.001 Mask A6 8.331 7.341 9.487 &lt; 0.001 Mask B3 3.328 2.923 3.800 &lt; 0.001 Mask B6 6.466 5.724 7.331 &lt; 0.001 Example 2: fit and summarize a Poisson regression model This second example uses the survival endpoint available in the mockstudy dataset. There is a close relationship between survival and Poisson models, and often it is easier to fit the model using Poisson regression, especially if you want to present absolute risk. &gt; # add .01 to the follow-up time (.01*1 day) in order to keep everyone in the analysis &gt; fit &lt;- glm(fu.stat ~ offset(log(fu.time+.01)) + age + sex + arm, data=mockstudy, family=poisson) &gt; summary(fit) Call: glm(formula = fu.stat ~ offset(log(fu.time + 0.01)) + age + sex + arm, family = poisson, data = mockstudy) Deviance Residuals: Min 1Q Median 3Q Max -3.1188 -0.4041 0.3242 0.9727 4.3588 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -5.875627 0.108984 -53.913 &lt; 2e-16 *** age 0.003724 0.001705 2.184 0.0290 * sexFemale 0.027321 0.038575 0.708 0.4788 armF: FOLFOX -0.335141 0.044600 -7.514 5.72e-14 *** armG: IROX -0.107776 0.050643 -2.128 0.0333 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for poisson family taken to be 1) Null deviance: 2113.5 on 1498 degrees of freedom Residual deviance: 2048.0 on 1494 degrees of freedom AIC: 5888.2 Number of Fisher Scoring iterations: 5 &gt; 1-pchisq(fit$deviance, fit$df.residual) [1] 0 &gt; &gt; coef(coxph(Surv(fu.time,fu.stat) ~ age + sex + arm, data=mockstudy)) age sexFemale armF: FOLFOX armG: IROX 0.004600011 0.039892735 -0.454650445 -0.140784996 &gt; coef(fit)[-1] age sexFemale armF: FOLFOX armG: IROX 0.003723763 0.027320917 -0.335141090 -0.107775577 &gt; &gt; # results from the Poisson model can then be described as risk ratios (similar to the hazard ratio) &gt; exp(coef(fit)[-1]) age sexFemale armF: FOLFOX armG: IROX 1.0037307 1.0276976 0.7152372 0.8978291 &gt; &gt; # As before, we can model the dispersion which alters the standard error &gt; fit2 &lt;- glm(fu.stat ~ offset(log(fu.time+.01)) + age + sex + arm, + data=mockstudy, family=quasipoisson) &gt; summary(fit2) Call: glm(formula = fu.stat ~ offset(log(fu.time + 0.01)) + age + sex + arm, family = quasipoisson, data = mockstudy) Deviance Residuals: Min 1Q Median 3Q Max -3.1188 -0.4041 0.3242 0.9727 4.3588 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -5.875627 0.566666 -10.369 &lt;2e-16 *** age 0.003724 0.008867 0.420 0.675 sexFemale 0.027321 0.200572 0.136 0.892 armF: FOLFOX -0.335141 0.231899 -1.445 0.149 armG: IROX -0.107776 0.263318 -0.409 0.682 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for quasipoisson family taken to be 27.03493) Null deviance: 2113.5 on 1498 degrees of freedom Residual deviance: 2048.0 on 1494 degrees of freedom AIC: NA Number of Fisher Scoring iterations: 5 Extract data using broom package The broom package makes it easy to extract information from the fit. &gt; tidy(fit) ##coefficients, p-values # A tibble: 5 x 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) -5.88 0.109 -53.9 0. 2 age 0.00372 0.00171 2.18 2.90e- 2 3 sexFemale 0.0273 0.0386 0.708 4.79e- 1 4 armF: FOLFOX -0.335 0.0446 -7.51 5.72e-14 5 armG: IROX -0.108 0.0506 -2.13 3.33e- 2 &gt; &gt; glance(fit) ##model summary statistics # A tibble: 1 x 7 null.deviance df.null logLik AIC BIC deviance df.residual &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 2114. 1498 -2939. 5888. 5915. 2048. 1494 Create a summary table using modelsum Remember that the result from modelsum is different from the fit above. The modelsum summary shows the results for age + offset(log(fu.time+.01)) then sex + offset(log(fu.time+.01)) instead of age + sex + arm + offset(log(fu.time+.01)). &gt; summary(modelsum(fu.stat ~ age, adjust=~offset(log(fu.time+.01))+ sex + arm, + data=mockstudy, family=poisson)) RR CI.lower.RR CI.upper.RR p.value (Intercept) 0.003 0.002 0.003 &lt; 0.001 Age in Years 1.004 1.000 1.007 0.029 sexFemale 1.028 0.953 1.108 0.479 armF: FOLFOX 0.715 0.656 0.781 &lt; 0.001 armG: IROX 0.898 0.813 0.991 0.033 Additional Examples Here are multiple examples showing how to use some of the different options. 1. Change summary statistics globally There are standard settings for each type of model regarding what information is summarized in the table. This behavior can be modified using the modelsum.control function. In fact, you can save your standard settings and use that for future tables. &gt; mycontrols &lt;- modelsum.control(gaussian.stats=c(&quot;estimate&quot;,&quot;std.error&quot;,&quot;adj.r.squared&quot;,&quot;Nmiss&quot;), + show.adjust=FALSE, show.intercept=FALSE) &gt; tab2 &lt;- modelsum(bmi ~ age, adjust=~sex, data=mockstudy, control=mycontrols) &gt; summary(tab2) estimate std.error adj.r.squared Age in Years 0.012 0.012 0.004 You can also change these settings directly in the modelsum call. &gt; tab3 &lt;- modelsum(bmi ~ age, adjust=~sex, data=mockstudy, + gaussian.stats=c(&quot;estimate&quot;,&quot;std.error&quot;,&quot;adj.r.squared&quot;,&quot;Nmiss&quot;), + show.intercept=FALSE, show.adjust=FALSE) &gt; summary(tab3) estimate std.error adj.r.squared Age in Years 0.012 0.012 0.004 2. Add labels to independent variables In the above example, age is shown with a label (Age in Years), but sex is listed “as is”. This is because the data was created in SAS and in the SAS dataset, age had a label but sex did not. The label is stored as an attribute within R. &gt; ## Look at one variable&#39;s label &gt; attr(mockstudy$age,&#39;label&#39;) [1] &quot;Age in Years&quot; &gt; &gt; ## See all the variables with a label &gt; unlist(lapply(mockstudy,&#39;attr&#39;,&#39;label&#39;)) age arm &quot;Age in Years&quot; &quot;Treatment Arm&quot; race bmi &quot;Race&quot; &quot;Body Mass Index (kg/m^2)&quot; &gt; &gt; ## or &gt; cbind(sapply(mockstudy,attr,&#39;label&#39;)) [,1] case NULL age &quot;Age in Years&quot; arm &quot;Treatment Arm&quot; sex NULL race &quot;Race&quot; fu.time NULL fu.stat NULL ps NULL hgb NULL bmi &quot;Body Mass Index (kg/m^2)&quot; alk.phos NULL ast NULL mdquality.s NULL age.ord NULL If you want to add labels to other variables, there are a couple of options. First, you could add labels to the variables in your dataset. &gt; attr(mockstudy$age,&#39;label&#39;) &lt;- &#39;Age, yrs&#39; &gt; &gt; tab1 &lt;- modelsum(bmi ~ age, adjust=~sex, data=mockstudy) &gt; summary(tab1) estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 sex Female -0.718 0.291 0.014 You can also use the built-in data.frame method for labels&lt;-: &gt; labels(mockstudy) &lt;- c(age = &#39;Age, yrs&#39;) &gt; &gt; tab1 &lt;- modelsum(bmi ~ age, adjust=~sex, data=mockstudy) &gt; summary(tab1) estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 sex Female -0.718 0.291 0.014 Another option is to add labels after you have created the table &gt; mylabels &lt;- list(sexFemale = &quot;Female&quot;, age =&quot;Age, yrs&quot;) &gt; summary(tab1, labelTranslations = mylabels) estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Age, yrs 0.012 0.012 0.348 Female -0.718 0.291 0.014 Alternatively, you can check the variable labels and manipulate them with a function called labels, which works on the modelsum object. &gt; labels(tab1) bmi age &quot;Body Mass Index (kg/m^2)&quot; &quot;Age, yrs&quot; sexFemale &quot;sex Female&quot; &gt; labels(tab1) &lt;- c(sexFemale=&quot;Female&quot;, age=&quot;Baseline Age (yrs)&quot;) &gt; labels(tab1) bmi age &quot;Body Mass Index (kg/m^2)&quot; &quot;Baseline Age (yrs)&quot; sexFemale &quot;Female&quot; &gt; summary(tab1) estimate std.error p.value adj.r.squared (Intercept) 26.793 0.766 &lt; 0.001 0.004 Baseline Age (yrs) 0.012 0.012 0.348 Female -0.718 0.291 0.014 3. Don’t show intercept values &gt; summary(modelsum(age~mdquality.s+sex, data=mockstudy), show.intercept=FALSE) estimate std.error p.value adj.r.squared Nmiss mdquality.s -0.326 1.093 0.766 -0.001 252 sex Female -1.208 0.610 0.048 0.002 0 4. Don’t show results for adjustment variables &gt; summary(modelsum(mdquality.s ~ age + bmi, data=mockstudy, adjust=~sex, family=binomial), + show.adjust=FALSE) OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 10.272 3.831 28.876 &lt; 0.001 0.507 0 Age, yrs 0.998 0.981 1.014 0.776 (Intercept) 4.814 1.709 13.221 0.003 0.550 33 Body Mass Index (kg/m^2) 1.023 0.987 1.063 0.220 5. Summarize multiple variables without typing them out Often one wants to summarize a number of variables. Instead of typing by hand each individual variable, an alternative approach is to create a formula using the paste command with the collapse=&quot;+&quot; option. &gt; # create a vector specifying the variable names &gt; myvars &lt;- names(mockstudy) &gt; &gt; # select the 8th through the 12th &gt; # paste them together, separated by the + sign &gt; RHS &lt;- paste(myvars[8:12], collapse=&quot;+&quot;) &gt; RHS [1] “ps+hgb+bmi+alk.phos+ast” &gt; &gt; # create a formula using the as.formula function &gt; as.formula(paste(&#39;mdquality.s ~ &#39;, RHS)) mdquality.s ~ ps + hgb + bmi + alk.phos + ast &gt; &gt; # use the formula in the modelsum function &gt; summary(modelsum(as.formula(paste(&#39;mdquality.s ~&#39;, RHS)), family=binomial, data=mockstudy)) OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 14.628 10.755 20.399 &lt; 0.001 0.620 266 ps 0.461 0.332 0.639 &lt; 0.001 (Intercept) 1.236 0.272 5.560 0.783 0.573 266 hgb 1.176 1.040 1.334 0.011 (Intercept) 4.963 1.818 13.292 0.002 0.549 33 Body Mass Index (kg/m^2) 1.023 0.987 1.062 0.225 (Intercept) 10.622 7.687 14.794 &lt; 0.001 0.552 266 alk.phos 0.999 0.998 1.000 0.159 (Intercept) 10.936 7.912 15.232 &lt; 0.001 0.545 266 ast 0.995 0.988 1.001 0.099 These steps can also be done using the formulize function. &gt; ## The formulize function does the paste and as.formula steps &gt; tmp &lt;- formulize(&#39;mdquality.s&#39;,myvars[8:10]) &gt; tmp mdquality.s ~ ps + hgb + bmi &gt; &gt; ## More complex formulas could also be written using formulize &gt; tmp2 &lt;- formulize(&#39;mdquality.s&#39;,c(&#39;ps&#39;,&#39;hgb&#39;,&#39;sqrt(bmi)&#39;)) &gt; &gt; ## use the formula in the modelsum function &gt; summary(modelsum(tmp, data=mockstudy, family=binomial)) OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 14.628 10.755 20.399 &lt; 0.001 0.620 266 ps 0.461 0.332 0.639 &lt; 0.001 (Intercept) 1.236 0.272 5.560 0.783 0.573 266 hgb 1.176 1.040 1.334 0.011 (Intercept) 4.963 1.818 13.292 0.002 0.549 33 Body Mass Index (kg/m^2) 1.023 0.987 1.062 0.225 6. Subset the dataset used in the analysis Here are two ways to get the same result (limit the analysis to subjects age&gt;50 and in the F: FOLFOX treatment group). The first approach uses the subset function applied to the dataset mockstudy. This example also selects a subset of variables. The modelsum function is then applied to this subsetted data. &gt; newdata &lt;- subset(mockstudy, subset=age&gt;50 &amp; arm==&#39;F: FOLFOX&#39;, select = c(age,sex, bmi:alk.phos)) &gt; dim(mockstudy) [1] 1499 14 &gt; table(mockstudy$arm) A: IFL F: FOLFOX G: IROX 428 691 380 &gt; dim(newdata) [1] 557 4 &gt; names(newdata) [1] &quot;age&quot; &quot;sex&quot; &quot;bmi&quot; &quot;alk.phos&quot; &gt; summary(modelsum(alk.phos ~ ., data=newdata)) estimate std.error p.value adj.r.squared Nmiss (Intercept) 122.577 46.924 0.009 -0.001 0 age 0.619 0.719 0.390 (Intercept) 164.814 7.673 &lt; 0.001 -0.002 0 sex Female -5.497 12.118 0.650 (Intercept) 238.658 33.705 &lt; 0.001 0.010 15 bmi -2.776 1.207 0.022 The second approach does the same analysis but uses the subset argument within modelsum to subset the data. &gt; summary(modelsum(log(alk.phos) ~ sex + ps + bmi, subset=age&gt;50 &amp; arm==&quot;F: FOLFOX&quot;, data=mockstudy)) estimate std.error p.value adj.r.squared Nmiss (Intercept) 4.872 0.039 &lt; 0.001 -0.002 0 sex Female -0.005 0.062 0.931 (Intercept) 4.770 0.040 &lt; 0.001 0.027 108 ps 0.183 0.050 &lt; 0.001 (Intercept) 5.207 0.172 &lt; 0.001 0.007 15 Body Mass Index (kg/m^2) -0.012 0.006 0.044 &gt; summary(modelsum(alk.phos ~ ps + bmi, adjust=~sex, subset = age&gt;50 &amp; bmi&lt;24, data=mockstudy)) estimate std.error p.value adj.r.squared Nmiss (Intercept) 178.812 14.550 &lt; 0.001 0.007 77 ps 20.834 13.440 0.122 sex Female -17.542 16.656 0.293 (Intercept) 373.008 104.272 &lt; 0.001 0.009 24 Body Mass Index (kg/m^2) -8.239 4.727 0.083 sex Female -24.058 16.855 0.155 &gt; summary(modelsum(alk.phos ~ ps + bmi, adjust=~sex, subset=1:30, data=mockstudy)) estimate std.error p.value adj.r.squared Nmiss (Intercept) 169.112 57.013 0.006 0.294 0 ps 254.901 68.100 &lt; 0.001 sex Female 49.566 67.643 0.470 (Intercept) 453.070 200.651 0.033 -0.049 1 Body Mass Index (kg/m^2) -5.993 7.408 0.426 sex Female -22.308 79.776 0.782 7. Create combinations of variables on the fly &gt; ## create a variable combining the levels of mdquality.s and sex &gt; with(mockstudy, table(interaction(mdquality.s,sex))) 0.Male 1.Male 0.Female 1.Female 77 686 47 437 &gt; summary(modelsum(age ~ interaction(mdquality.s,sex), data=mockstudy)) estimate std.error p.value adj.r.squared Nmiss (Intercept) 59.714 1.314 &lt; 0.001 0.003 252 interaction(mdquality.s, sex) 1.Male 0.730 1.385 0.598 interaction(mdquality.s, sex) 0.Female 0.988 2.134 0.643 interaction(mdquality.s, sex) 1.Female -1.021 1.425 0.474 8. Transform variables on the fly Certain transformations need to be surrounded by I() so that R knows to treat it as a variable transformation and not some special model feature. If the transformation includes any of the symbols / - + ^ * then surround the new variable by I(). &gt; summary(modelsum(arm==&quot;F: FOLFOX&quot; ~ I(age/10) + log(bmi) + mdquality.s, + data=mockstudy, family=binomial)) OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 0.656 0.382 1.124 0.126 0.514 0 Age, yrs 1.045 0.957 1.142 0.326 (Intercept) 0.633 0.108 3.698 0.611 0.508 33 Body Mass Index (kg/m^2) 1.092 0.638 1.867 0.748 (Intercept) 0.722 0.503 1.029 0.074 0.502 252 mdquality.s 1.045 0.719 1.527 0.819 9. Change the ordering of the variables or delete a variable &gt; mytab &lt;- modelsum(bmi ~ sex + alk.phos + age, data=mockstudy) &gt; mytab2 &lt;- mytab[c(&#39;age&#39;,&#39;sex&#39;,&#39;alk.phos&#39;)] &gt; summary(mytab2) estimate std.error p.value adj.r.squared Nmiss (Intercept) 26.424 0.752 &lt; 0.001 0.000 0 Age, yrs 0.013 0.012 0.290 (Intercept) 27.491 0.181 &lt; 0.001 0.004 0 sex Female -0.731 0.290 0.012 (Intercept) 27.944 0.253 &lt; 0.001 0.011 266 alk.phos -0.005 0.001 &lt; 0.001 &gt; summary(mytab[c(&#39;age&#39;,&#39;sex&#39;)]) estimate std.error p.value adj.r.squared (Intercept) 26.424 0.752 &lt; 0.001 0.000 Age, yrs 0.013 0.012 0.290 (Intercept) 27.491 0.181 &lt; 0.001 0.004 sex Female -0.731 0.290 0.012 &gt; summary(mytab[c(3,1)]) estimate std.error p.value adj.r.squared (Intercept) 26.424 0.752 &lt; 0.001 0.000 Age, yrs 0.013 0.012 0.290 (Intercept) 27.491 0.181 &lt; 0.001 0.004 sex Female -0.731 0.290 0.012 10. Merge two modelsum objects together It is possible to combine two modelsum objects so that they print out together, however you need to pay attention to the columns that are being displayed. It is easier to combine two models of the same family (such as two sets of linear models). If you want to combine linear and logistic model results then you would want to display the beta coefficients for the logistic model. &gt; ## demographics &gt; tab1 &lt;- modelsum(bmi ~ sex + age, data=mockstudy) &gt; ## lab data &gt; tab2 &lt;- modelsum(mdquality.s ~ hgb + alk.phos, data=mockstudy, family=binomial) &gt; &gt; tab12 &lt;- merge(tab1,tab2) &gt; class(tab12) [1] “modelsumList” &gt; &gt; ##ERROR: The merge works, but not the summary &gt; #summary(tab12) 11. Add a title to the table When creating a pdf the tables are automatically numbered and the title appears below the table. In Word and HTML, the titles appear un-numbered and above the table. &gt; t1 &lt;- modelsum(bmi ~ sex + age, data=mockstudy) &gt; summary(t1, title=&#39;Demographics&#39;) Demographics estimate std.error p.value adj.r.squared (Intercept) 27.491 0.181 &lt; 0.001 0.004 sex Female -0.731 0.290 0.012 (Intercept) 26.424 0.752 &lt; 0.001 0.000 Age, yrs 0.013 0.012 0.290 12. Modify how missing values are treated Depending on the report you are writing you have the following options: Use all values available for each variable Use only those subjects who have measurements available for all the variables &gt; ## look at how many missing values there are for each variable &gt; apply(is.na(mockstudy),2,sum) case age arm sex race fu.time 0 0 0 0 7 0 fu.stat ps hgb bmi alk.phos ast 0 266 266 33 266 266 mdquality.s age.ord 252 0 &gt; ## Show how many subjects have each variable (non-missing) &gt; summary(modelsum(bmi ~ ast + age, data=mockstudy, + control=modelsum.control(gaussian.stats=c(&quot;N&quot;,&quot;estimate&quot;)))) estimate N (Intercept) 27.331 1233 ast -0.005 (Intercept) 26.424 1499 Age, yrs 0.013 &gt; &gt; ## Always list the number of missing values &gt; summary(modelsum(bmi ~ ast + age, data=mockstudy, + control=modelsum.control(gaussian.stats=c(&quot;Nmiss2&quot;,&quot;estimate&quot;)))) estimate Nmiss2 (Intercept) 27.331 266 ast -0.005 (Intercept) 26.424 0 Age, yrs 0.013 &gt; &gt; ## Only show the missing values if there are some (default) &gt; summary(modelsum(bmi ~ ast + age, data=mockstudy, + control=modelsum.control(gaussian.stats=c(&quot;Nmiss&quot;,&quot;estimate&quot;)))) estimate Nmiss (Intercept) 27.331 266 ast -0.005 (Intercept) 26.424 0 Age, yrs 0.013 &gt; &gt; ## Don&#39;t show N at all &gt; summary(modelsum(bmi ~ ast + age, data=mockstudy, + control=modelsum.control(gaussian.stats=c(&quot;estimate&quot;)))) estimate (Intercept) 27.331 ast -0.005 (Intercept) 26.424 Age, yrs 0.013 13. Modify the number of digits used Within modelsum.control function there are 3 options for controlling the number of significant digits shown. digits: controls the number of digits after the decimal point for continuous values digits.ratio: controls the number of digits after the decimal point for continuous values digits.p: controls the number of digits after the decimal point for continuous values &gt; summary(modelsum(bmi ~ sex + age + fu.time, data=mockstudy), digits=4, digits.test=2) Warning: Using &#39;digits.test = &#39; is deprecated. Use &#39;digits.p = &#39; instead. estimate std.error p.value adj.r.squared (Intercept) 27.4915 0.1813 &lt; 0.001 0.0036 sex Female -0.7311 0.2903 0.012 (Intercept) 26.4237 0.7521 &lt; 0.001 0.0001 Age, yrs 0.0130 0.0123 0.290 (Intercept) 26.4937 0.2447 &lt; 0.001 0.0079 fu.time 0.0011 0.0003 &lt; 0.001 14. Use case-weights in the models Occasionally it is of interest to fit models using case weights. The modelsum function allows you to pass on the weights to the models and it will do the appropriate fit. &gt; mockstudy$agegp &lt;- cut(mockstudy$age, breaks=c(18,50,60,70,90), right=FALSE) &gt; &gt; ## create weights based on agegp and sex distribution &gt; tab1 &lt;- with(mockstudy,table(agegp, sex)) &gt; tab1 sex agegp Male Female [18,50) 152 110 [50,60) 258 178 [60,70) 295 173 [70,90) 211 122 &gt; tab2 &lt;- with(mockstudy, table(agegp, sex, arm)) &gt; gpwts &lt;- rep(tab1, length(unique(mockstudy$arm)))/tab2 &gt; &gt; ## apply weights to subjects &gt; index &lt;- with(mockstudy, cbind(as.numeric(agegp), as.numeric(sex), as.numeric(as.factor(arm)))) &gt; mockstudy$wts &lt;- gpwts[index] &gt; &gt; ## show weights by treatment arm group &gt; tapply(mockstudy$wts,mockstudy$arm, summary) $`A: IFL` Min. 1st Qu. Median Mean 3rd Qu. Max. 2.923 3.225 3.548 3.502 3.844 4.045 $`F: FOLFOX` Min. 1st Qu. Median Mean 3rd Qu. Max. 2.033 2.070 2.201 2.169 2.263 2.303 $`G: IROX` Min. 1st Qu. Median Mean 3rd Qu. Max. 3.667 3.734 4.023 3.945 4.031 4.471 &gt; mockstudy$newvarA &lt;- as.numeric(mockstudy$arm==&#39;A: IFL&#39;) &gt; tab1 &lt;- modelsum(newvarA ~ ast + bmi + hgb, data=mockstudy, subset=(arm !=&#39;G: IROX&#39;), + family=binomial) &gt; summary(tab1, title=&#39;No Case Weights used&#39;) No Case Weights used OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 0.590 0.473 0.735 &lt; 0.001 0.550 210 ast 1.003 0.998 1.008 0.258 (Intercept) 0.578 0.306 1.093 0.091 0.500 29 Body Mass Index (kg/m^2) 1.003 0.980 1.026 0.808 (Intercept) 1.006 0.386 2.631 0.990 0.514 210 hgb 0.965 0.894 1.043 0.372 &gt; &gt; suppressWarnings({ + tab2 &lt;- modelsum(newvarA ~ ast + bmi + hgb, data=mockstudy, subset=(arm !=&#39;G: IROX&#39;), + weights=wts, family=binomial) + summary(tab2, title=&#39;Case Weights used&#39;) + }) Case Weights used OR CI.lower.OR CI.upper.OR p.value concordance Nmiss (Intercept) 0.956 0.837 1.091 0.504 0.550 210 ast 1.003 1.000 1.006 0.068 (Intercept) 0.957 0.658 1.393 0.820 0.500 29 Body Mass Index (kg/m^2) 1.002 0.988 1.016 0.780 (Intercept) 1.829 1.031 3.248 0.039 0.514 210 hgb 0.956 0.913 1.001 0.058 15. Use modelsum within an Sweave document For those users who wish to create tables within an Sweave document, the following code seems to work. \\documentclass{article} \\usepackage{longtable} \\usepackage{pdfpages} \\begin{document} \\section{Read in Data} &lt;&lt;echo=TRUE&gt;&gt;= require(arsenal) require(knitr) require(rmarkdown) data(mockstudy) tab1 &lt;- modelsum(bmi~sex+age, data=mockstudy) @ \\section{Convert Summary.modelsum to LaTeX} &lt;&lt;echo=TRUE, results=&#39;hide&#39;, message=FALSE&gt;&gt;= capture.output(summary(tab1), file=&quot;Test.md&quot;) ## Convert R Markdown Table to LaTeX render(&quot;Test.md&quot;, pdf_document(keep_tex=TRUE)) @ \\includepdf{Test.pdf} \\end{document} 16. Export modelsum results to a .CSV file When looking at multiple variables it is sometimes useful to export the results to a csv file. The as.data.frame function creates a data frame object that can be exported or further manipulated within R. &gt; summary(tab2, text=T) | |OR |CI.lower.OR |CI.upper.OR |p.value |concordance |Nmiss | |:------------------------|:-----|:-----------|:-----------|:-------|:-----------|:-----| |(Intercept) |0.956 |0.837 |1.091 |0.504 |0.550 |210 | |ast |1.003 |1.000 |1.006 |0.068 | | | |(Intercept) |0.957 |0.658 |1.393 |0.820 |0.500 |29 | |Body Mass Index (kg/m^2) |1.002 |0.988 |1.016 |0.780 | | | |(Intercept) |1.829 |1.031 |3.248 |0.039 |0.514 |210 | |hgb |0.956 |0.913 |1.001 |0.058 | | | &gt; tmp &lt;- as.data.frame(tab2) &gt; tmp model term label term.type OR 1 1 (Intercept) (Intercept) Intercept 0.9559704 2 1 ast ast Term 1.0027311 3 2 (Intercept) (Intercept) Intercept 0.9573694 4 2 bmi Body Mass Index (kg/m^2) Term 1.0019251 5 3 (Intercept) (Intercept) Intercept 1.8287083 6 3 hgb hgb Term 0.9563507 CI.lower.OR CI.upper.OR p.value concordance Nmiss 1 0.8373522 1.090904 0.50443340 0.5499494 210 2 0.9998110 1.005696 0.06813456 0.5499494 210 3 0.6579225 1.392859 0.81981779 0.5002561 29 4 0.9884804 1.015561 0.78019163 0.5002561 29 5 1.0311954 3.247941 0.03911088 0.5138162 210 6 0.9132041 1.001419 0.05770821 0.5138162 210 &gt; # write.csv(tmp, &#39;/my/path/here/mymodel.csv&#39;) 17. Write modelsum object to a separate Word or HTML file &gt; ## write to an HTML document &gt; write2html(tab2, &quot;~/ibm/trash.html&quot;) &gt; &gt; ## write to a Word document &gt; write2word(tab2, &quot;~/ibm/trash.doc&quot;, title=&quot;My table in Word&quot;) 18. Use modelsum in R Shiny The easiest way to output a modelsum() object in an R Shiny app is to use the tableOutput() UI in combination with the renderTable() server function and as.data.frame(summary(modelsum())): &gt; # A standalone shiny app &gt; library(shiny) &gt; library(arsenal) &gt; data(mockstudy) &gt; &gt; shinyApp( + ui = fluidPage(tableOutput(&quot;table&quot;)), + server = function(input, output) { + output$table &lt;- renderTable({ + as.data.frame(summary(modelsum(age ~ sex, data = mockstudy), text = &quot;html&quot;)) + }, sanitize.text.function = function(x) x) + } + ) This can be especially powerful if you feed the selections from a selectInput(multiple = TRUE) into formulize() to make the table dynamic! 23. Use modelsum in bookdown Since the backbone of modelsum() is knitr::kable(), tables still render well in bookdown. However, print.summary.modelsum() doesn’t use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID. &gt; summary(modelsum(age ~ sex, data = mockstudy), title=&quot;(\\\\#tab:mytableby) Caption here&quot;) Available Function Options Summary statistics The available summary statistics, by varible type, are: ordinal: Ordinal logistic regression models default: Nmiss, OR, CI.lower.OR, CI.upper.OR, p.value optional: estimate, CI.OR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, endpoint, std.error, statistic, logLik, AIC, BIC, edf, deviance, df.residual binomial,quasibinomial: Logistic regression models default: OR, CI.lower.OR, CI.upper.OR, p.value, concordance, Nmiss optional: estimate, CI.OR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, endpoint, std.error, statistic, logLik, AIC, BIC, null.deviance, deviance, df.residual, df.null gaussian: Linear regression models default: estimate, std.error, p.value, adj.r.squared, Nmiss optional: CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, statistic, standard.estimate, endpoint, r.squared, AIC, BIC, logLik, statistic.F, p.value.F poisson, quasipoisson: Poisson regression models default: RR, CI.lower.RR, CI.upper.RR, p.value, Nmiss optional: CI.RR, CI.estimate, CI.lower.estimate, CI.upper.estimate, CI.RR, Nmiss2, std.error, estimate, statistic, endpoint, AIC, BIC, logLik, dispersion, null.deviance, deviance, df.residual, df.null negbin: Negative binomial regression models default: RR, CI.lower.RR, CI.upper.RR, p.value, Nmiss optional: CI.RR, CI.estimate, CI.lower.estimate, CI.upper.estimate, CI.RR, Nmiss2, std.error, estimate, statistic, endpoint, AIC, BIC, logLik, dispersion, null.deviance, deviance, df.residual, df.null, theta, SE.theta survival: Cox models default: HR, CI.lower.HR, CI.upper.HR, p.value, concordance, Nmiss optional: CI.HR, CI.estimate, CI.lower.estimate, CI.upper.estimate, N, Nmiss2, estimate, std.error, endpoint, Nevents, statistic, r.squared, logLik, AIC, BIC, statistic.sc, p.value.sc, p.value.log, p.value.wald, N, std.error.concordance The full description of these parameters that can be shown for models include: N: a count of the number of observations used in the analysis Nmiss: only show the count of the number of missing values if there are some missing values Nmiss2: always show a count of the number of missing values for a model endpoint: dependent variable used in the model std.err: print the standard error statistic: test statistic statistic.F: test statistic (F test) p.value: print the p-value r.squared: print the model R-square adj.r.squared: print the model adjusted R-square r.squared: print the model R-square concordance: print the model C statistic (which is the AUC for logistic models) logLik: print the loglikelihood value p.value.log: print the p-value for the overall model likelihood test p.value.wald: print the p-value for the overall model wald test p.value.sc: print the p-value for overall model score test AIC: print the Akaike information criterion BIC: print the Bayesian information criterion null.deviance: null deviance deviance: model deviance df.residual: degrees of freedom for the residual df.null: degrees of freedom for the null model dispersion: This is used in Poisson models and is defined as the deviance/df.residual statistic.sc: overall model score statistic std.error.concordance: standard error for the C statistic HR: print the hazard ratio (for survival models), i.e. exp(beta) CI.lower.HR, CI.upper.HR: print the confidence interval for the HR OR: print the odd’s ratio (for logistic models), i.e. exp(beta) CI.lower.OR, CI.upper.OR: print the confidence interval for the OR RR: print the risk ratio (for poisson models), i.e. exp(beta) CI.lower.RR, CI.upper.RR: print the confidence interval for the RR estimate: print beta coefficient standardized.estimate: print the standardized beta coefficient CI.lower.estimate, CI.upper.estimate: print the confidence interval for the beta coefficient edf: print the effective degrees of freedom. theta: print the estimate of theta. SE.theta: print the estimate of theta’s standard error. modelsum.control settings A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in modelsum.control or in summary.modelsum. &gt; args(modelsum.control) function (digits = 3L, digits.ratio = 3L, digits.p = 3L, format.p = TRUE, show.adjust = TRUE, show.intercept = TRUE, conf.level = 0.95, ordinal.stats = c(&quot;OR&quot;, &quot;CI.lower.OR&quot;, &quot;CI.upper.OR&quot;, &quot;p.value&quot;, &quot;Nmiss&quot;), binomial.stats = c(&quot;OR&quot;, &quot;CI.lower.OR&quot;, &quot;CI.upper.OR&quot;, &quot;p.value&quot;, &quot;concordance&quot;, &quot;Nmiss&quot;), gaussian.stats = c(&quot;estimate&quot;, &quot;std.error&quot;, &quot;p.value&quot;, &quot;adj.r.squared&quot;, &quot;Nmiss&quot;), poisson.stats = c(&quot;RR&quot;, &quot;CI.lower.RR&quot;, &quot;CI.upper.RR&quot;, &quot;p.value&quot;, &quot;Nmiss&quot;), negbin.stats = c(&quot;RR&quot;, &quot;CI.lower.RR&quot;, &quot;CI.upper.RR&quot;, &quot;p.value&quot;, &quot;Nmiss&quot;), survival.stats = c(&quot;HR&quot;, &quot;CI.lower.HR&quot;, &quot;CI.upper.HR&quot;, &quot;p.value&quot;, &quot;concordance&quot;, &quot;Nmiss&quot;), stat.labels = list(), ...) NULL summary.modelsum settings The summary.modelsum function has options that modify how the table appears (such as adding a title or modifying labels). &gt; args(arsenal:::summary.modelsum) function (object, ..., labelTranslations = NULL, text = FALSE, title = NULL, term.name = &quot;&quot;) NULL --- ## The paired function https://cran.r-project.org/web/packages/arsenal/vignettes/paired.html The paired function Ethan Heinzen, Beth Atkinson, Jason Sinnwell 09 November, 2018 Introduction Simple Example NAs Available Function Options Testing options paired.control settings summary.tableby settings Introduction Another one of the most common tables in medical literature includes summary statistics for a set of variables paired across two time points. Locally at Mayo, the SAS macro %paired was written to create summary tables with a single call. With the increasing interest in R, we have developed the function paired() to create similar tables within the R environment. This vignette is light on purpose; paired() piggybacks off of tableby, so most documentation there applies here, too. Simple Example The first step when using the paired() function is to load the arsenal package. We can’t use mockstudy here because we need a dataset with paired observations, so we’ll create our own dataset. library(arsenal) dat &lt;- data.frame( tp = paste0(&quot;Time Point &quot;, c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)), id = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 6), Cat = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;A&quot;, NA, &quot;B&quot;), Fac = factor(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;)), Num = c(1, 2, 3, 4, 4, 3, 3, 4, 0, NA), Ord = ordered(c(&quot;I&quot;, &quot;II&quot;, &quot;II&quot;, &quot;III&quot;, &quot;III&quot;, &quot;III&quot;, &quot;I&quot;, &quot;III&quot;, &quot;II&quot;, &quot;I&quot;)), Lgl = c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE), Dat = as.Date(&quot;2018-05-01&quot;) + c(1, 1, 2, 2, 3, 4, 5, 6, 3, 4), stringsAsFactors = FALSE ) To create a simple table stratified by time point, use a formula= statement to specify the variables that you want summarized and the id= argument to specify the paired observations. p &lt;- paired(tp ~ Cat + Fac + Num + Ord + Lgl + Dat, data = dat, id = id, signed.rank.exact = FALSE) summary(p) Time Point 1 (N=4) Time Point 2 (N=4) Difference (N=4) p value Cat 1.000 A 2 (50.0%) 2 (50.0%) 1 (50.0%) B 2 (50.0%) 2 (50.0%) 1 (50.0%) Fac 0.261 A 2 (50.0%) 1 (25.0%) 2 (100.0%) B 1 (25.0%) 2 (50.0%) 1 (100.0%) C 1 (25.0%) 1 (25.0%) 1 (100.0%) Num 0.391 Mean (SD) 2.750 (1.258) 3.250 (0.957) 0.500 (1.000) Range 1.000 - 4.000 2.000 - 4.000 -1.000 - 1.000 Ord 0.174 I 2 (50.0%) 0 (0.0%) 2 (100.0%) II 1 (25.0%) 1 (25.0%) 1 (100.0%) III 1 (25.0%) 3 (75.0%) 0 (0.0%) Lgl 1.000 FALSE 2 (50.0%) 1 (25.0%) 2 (100.0%) TRUE 2 (50.0%) 3 (75.0%) 1 (50.0%) Dat 0.182 median 2018-05-03 2018-05-04 0.500 Range 2018-05-02 - 2018-05-06 2018-05-02 - 2018-05-07 0.000 - 1.000 The third column shows the difference between time point 1 and time point 2. For categorical variables, it reports the percent of observations from time point 1 which changed in time point 2. NAs Note that by default, observations which do not have both timepoints are removed. This is easily changed using the na.action = na.paired(&quot;&lt;arg&gt;&quot;) argument. For example: p &lt;- paired(tp ~ Cat + Fac + Num + Ord + Lgl + Dat, data = dat, id = id, signed.rank.exact = FALSE, na.action = na.paired(&quot;fill&quot;)) summary(p) Time Point 1 (N=6) Time Point 2 (N=6) Difference (N=6) p value Cat 1.000 N-Miss 2 1 2 A 2 (50.0%) 2 (40.0%) 1 (50.0%) B 2 (50.0%) 3 (60.0%) 1 (50.0%) Fac 0.261 N-Miss 1 1 2 A 2 (40.0%) 2 (40.0%) 2 (100.0%) B 1 (20.0%) 2 (40.0%) 1 (100.0%) C 2 (40.0%) 1 (20.0%) 1 (100.0%) Num 0.391 N-Miss 1 2 2 Mean (SD) 2.200 (1.643) 3.250 (0.957) 0.500 (1.000) Range 0.000 - 4.000 2.000 - 4.000 -1.000 - 1.000 Ord 0.174 N-Miss 1 1 2 I 2 (40.0%) 1 (20.0%) 2 (100.0%) II 2 (40.0%) 1 (20.0%) 1 (100.0%) III 1 (20.0%) 3 (60.0%) 0 (0.0%) Lgl 1.000 N-Miss 1 1 2 FALSE 3 (60.0%) 2 (40.0%) 2 (100.0%) TRUE 2 (40.0%) 3 (60.0%) 1 (50.0%) Dat 0.182 N-Miss 1 1 2 median 2018-05-04 2018-05-05 0.500 Range 2018-05-02 - 2018-05-06 2018-05-02 - 2018-05-07 0.000 - 1.000 For more details, see the help page for na.paired(). Available Function Options Testing options The tests used to calculate p-values differ by the variable type, but can be specified explicitly in the formula statement or in the control function. The following tests are accepted: paired.t: A paired t-test. mcnemar: McNemar’s test. signed.rank: the signed-rank test. sign.test: the sign test. notest: Don’t perform a test. paired.control settings A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in paired.control or in summary.tableby. args(paired.control) ## function (test = TRUE, diff = TRUE, test.pname = NULL, numeric.test = &quot;paired.t&quot;, ## cat.test = &quot;mcnemar&quot;, ordered.test = &quot;signed.rank&quot;, date.test = &quot;paired.t&quot;, ## numeric.stats = c(&quot;Nmiss&quot;, &quot;meansd&quot;, &quot;range&quot;), cat.stats = c(&quot;Nmiss&quot;, ## &quot;countpct&quot;), ordered.stats = c(&quot;Nmiss&quot;, &quot;countpct&quot;), ## date.stats = c(&quot;Nmiss&quot;, &quot;median&quot;, &quot;range&quot;), stats.labels = list(Nmiss = &quot;N-Miss&quot;, ## Nmiss2 = &quot;N-Miss&quot;, meansd = &quot;Mean (SD)&quot;, medianq1q3 = &quot;Median (Q1, Q3)&quot;, ## q1q3 = &quot;Q1, Q3&quot;, range = &quot;Range&quot;, countpct = &quot;Count (Pct)&quot;), ## digits = 3L, digits.count = 0L, digits.p = 3L, format.p = TRUE, ## conf.level = 0.95, mcnemar.correct = TRUE, signed.rank.exact = NULL, ## signed.rank.correct = TRUE, ...) ## NULL summary.tableby settings Since the “paired” object inherits “tableby”, the summary.tableby function is what’s actually used to format and print the table. args(arsenal:::summary.tableby) ## function (object, ..., labelTranslations = NULL, text = FALSE, ## title = NULL, pfootnote = FALSE, term.name = &quot;&quot;) ## NULL --- ## The tableby function https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html The tableby function Beth Atkinson, Ethan Heinzen, Jason Sinnwell, Shannon McDonnell and Greg Dougherty 09 November, 2018 Introduction Simple Example Pretty text version of table Pretty Rmarkdown version of table Data frame version of table Summaries using standard R code Modifying Output Add labels Change summary statistics globally Change summary statistics within the formula Controlling Options for Categorical Tests (Chisq and Fisher’s) Modifying the look &amp; feel in Word documents Additional Examples 1. Summarize without a group/by variable 2. Display footnotes indicating which “test” was used 3. Summarize an ordered factor 4. Summarize a survival variable 5. Summarize date variables 6. Summarize multiple variables without typing them out 7. Subset the dataset used in the analysis 8. Create combinations of variables on the fly 9. Transform variables on the fly 10. Subsetting (change the ordering of the variables, delete a variable, sort by p-value, filter by p-value) 11. Merge two tableby objects together 12. Add a title to the table 13. Modify how missing values are displayed 14. Modify the number of digits used 15. Create a user-defined summary statistic 16. Use case-weights for creating summary statistics 17. Create your own p-value and add it to the table 18. For two-level categorical variables or one-line numeric variables, simplify the output. 19. Use tableby within an Sweave document 20. Export tableby object to a .CSV file 21. Write tableby object to a separate Word or HTML file 22. Use tableby in R Shiny 23. Use tableby in bookdown 24. Adjust tableby for multiple p-values Available Function Options Summary statistics Testing options tableby.control settings summary.tableby settings Introduction One of the most common tables in medical literature includes summary statistics for a set of variables, often stratified by some group (e.g. treatment arm). Locally at Mayo, the SAS macros %table and %summary were written to create summary tables with a single call. With the increasing interest in R, we have developed the function tableby to create similar tables within the R environment. In developing the tableby() function, the goal was to bring the best features of these macros into an R function. However, the task was not simply to duplicate all the functionality, but rather to make use of R’s strengths (modeling, method dispersion, flexibility in function definition and output format) and make a tool that fits the needs of R users. Additionally, the results needed to fit within the general reproducible research framework so the tables could be displayed within an R markdown report. This report provides step-by-step directions for using the functions associated with tableby(). All functions presented here are available within the arsenal package. An assumption is made that users are somewhat familiar with R Markdown documents. For those who are new to the topic, a good initial resource is available at rmarkdown.rstudio.com. Simple Example The first step when using the tableby function is to load the arsenal package. All the examples in this report use a dataset called mockstudy made available by Paul Novotny which includes a variety of types of variables (character, numeric, factor, ordered factor, survival) to use as examples. require(arsenal) require(knitr) require(survival) data(mockstudy) ##load data dim(mockstudy) ##look at how many subjects and variables are in the dataset ## [1] 1499 14 # help(mockstudy) ##learn more about the dataset and variables str(mockstudy) ##quick look at the data ## &#39;data.frame&#39;: 1499 obs. of 14 variables: ## $ case : int 110754 99706 105271 105001 112263 86205 99508 90158 88989 90515 ... ## $ age : atomic 67 74 50 71 69 56 50 57 51 63 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Age in Years&quot; ## $ arm : atomic F: FOLFOX A: IFL A: IFL G: IROX ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Treatment Arm&quot; ## $ sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 1 2 2 2 2 1 1 1 2 1 ... ## $ race : atomic Caucasian Caucasian Caucasian Caucasian ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Race&quot; ## $ fu.time : int 922 270 175 128 233 120 369 421 387 363 ... ## $ fu.stat : int 2 2 2 2 2 2 2 2 2 2 ... ## $ ps : int 0 1 1 1 0 0 0 0 1 1 ... ## $ hgb : num 11.5 10.7 11.1 12.6 13 10.2 13.3 12.1 13.8 12.1 ... ## $ bmi : atomic 25.1 19.5 NA 29.4 26.4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Body Mass Index (kg/m^2)&quot; ## $ alk.phos : int 160 290 700 771 350 569 162 152 231 492 ... ## $ ast : int 35 52 100 68 35 27 16 12 25 18 ... ## $ mdquality.s: int NA 1 1 1 NA 1 1 1 1 1 ... ## $ age.ord : Ord.factor w/ 8 levels &quot;10-19&quot;&lt;&quot;20-29&quot;&lt;..: 6 7 4 7 6 5 4 5 5 6 ... To create a simple table stratified by treament arm, use a formula statement to specify the variables that you want summarized. The example below uses age (a continuous variable) and sex (a factor). tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy) If you want to take a quick look at the table, you can use summary() on your tableby object and the table will print out as text in your R console window. If you use summary() without any options you will see a number of &amp;nbsp; statements which translates to “space” in HTML. Pretty text version of table If you want a nicer version in your console window then add the text=TRUE option. summary(tab1, text=TRUE) ## ## ## | | A: IFL (N=428) | F: FOLFOX (N=691) | G: IROX (N=380) | Total (N=1499) | p value| ## |:------------|:---------------:|:-----------------:|:---------------:|:---------------:|-------:| ## |sex | | | | | 0.190| ## |- Male | 277 (64.7%) | 411 (59.5%) | 228 (60.0%) | 916 (61.1%) | | ## |- Female | 151 (35.3%) | 280 (40.5%) | 152 (40.0%) | 583 (38.9%) | | ## |Age in Years | | | | | 0.614| ## |- Mean (SD) | 59.673 (11.365) | 60.301 (11.632) | 59.763 (11.499) | 59.985 (11.519) | | ## |- Range | 27.000 - 88.000 | 19.000 - 88.000 | 26.000 - 85.000 | 19.000 - 88.000 | | Pretty Rmarkdown version of table In order for the report to look nice within an R markdown (knitr) report, you just need to specify results=&quot;asis&quot; when creating the r chunk. This changes the layout slightly (compresses it) and bolds the variable names. summary(tab1) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value sex 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age in Years 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Data frame version of table If you want a data.frame version, simply use as.data.frame. as.data.frame(tab1) ## variable term label variable.type A: IFL F: FOLFOX ## 1 sex sex sex categorical ## 2 sex countpct Male categorical 277.00000, 64.71963 411.00000, 59.47902 ## 3 sex countpct Female categorical 151.00000, 35.28037 280.00000, 40.52098 ## 4 age age Age in Years numeric ## 5 age meansd Mean (SD) numeric 59.67290, 11.36454 60.30101, 11.63225 ## 6 age range Range numeric 27, 88 19, 88 ## G: IROX Total test p.value ## 1 Pearson&#39;s Chi-squared test 0.1904388 ## 2 228, 60 916.0000, 61.1074 Pearson&#39;s Chi-squared test 0.1904388 ## 3 152, 40 583.0000, 38.8926 Pearson&#39;s Chi-squared test 0.1904388 ## 4 Linear Model ANOVA 0.6143859 ## 5 59.76316, 11.49930 59.98532, 11.51877 Linear Model ANOVA 0.6143859 ## 6 26, 85 19, 88 Linear Model ANOVA 0.6143859 Summaries using standard R code ## base R frequency example tmp &lt;- table(Gender=mockstudy$sex, &quot;Study Arm&quot;=mockstudy$arm) tmp ## Study Arm ## Gender A: IFL F: FOLFOX G: IROX ## Male 277 411 228 ## Female 151 280 152 # Note: The continuity correction is applied by default in R (not used in %table) chisq.test(tmp) ## ## Pearson&#39;s Chi-squared test ## ## data: tmp ## X-squared = 3.3168, df = 2, p-value = 0.1904 ## base R numeric summary example tapply(mockstudy$age, mockstudy$arm, summary) ## $`A: IFL` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 27.00 53.00 61.00 59.67 68.00 88.00 ## ## $`F: FOLFOX` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 19.0 52.0 61.0 60.3 69.0 88.0 ## ## $`G: IROX` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 26.00 52.00 61.00 59.76 68.00 85.00 summary(aov(age ~ arm, data=mockstudy)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## arm 2 129 64.7 0.487 0.614 ## Residuals 1496 198628 132.8 Modifying Output Add labels In the above example, age is shown with a label (Age in Years), but sex is listed “as is” with lower case letters. This is because the data was created in SAS and in the SAS dataset, age had a label but sex did not. The label is stored as an attribute within R. ## Look at one variable&#39;s label attr(mockstudy$age,&#39;label&#39;) ## [1] &quot;Age in Years&quot; ## See all the variables with a label unlist(lapply(mockstudy,&#39;attr&#39;,&#39;label&#39;)) ## age arm race ## &quot;Age in Years&quot; &quot;Treatment Arm&quot; &quot;Race&quot; ## bmi ## &quot;Body Mass Index (kg/m^2)&quot; # Can also use labels(mockstudy) If you want to add labels to other variables, there are a couple of options. First, you could add labels to the variables in your dataset. attr(mockstudy$sex,&#39;label&#39;) &lt;- &#39;Gender&#39; tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy) summary(tab1) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age in Years 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 You can also use the built-in data.frame method for labels&lt;-: labels(mockstudy) &lt;- c(age = &#39;Age, yrs&#39;, sex = &quot;Gender&quot;) tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy) summary(tab1) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Another option is to add labels after you have created the table mylabels &lt;- list(sex = &quot;SEX&quot;, age = &quot;Age, yrs&quot;) summary(tab1, labelTranslations = mylabels) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value SEX 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Alternatively, you can check the variable labels and manipulate them with a function called labels, which works on the tableby object. labels(tab1) ## arm sex age ## &quot;arm&quot; &quot;Gender&quot; &quot;Age, yrs&quot; labels(tab1) &lt;- c(arm=&quot;Treatment Assignment&quot;, age=&quot;Baseline Age (yrs)&quot;) labels(tab1) ## arm sex age ## &quot;Treatment Assignment&quot; &quot;Gender&quot; &quot;Baseline Age (yrs)&quot; summary(tab1) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Baseline Age (yrs) 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Change summary statistics globally Currently the default behavior is to summarize continuous variables with: Number of missing values, Mean (SD), 25th - 75th quantiles, and Minimum-Maximum values with an ANOVA (t-test with equal variances) p-value. For categorical variables the default is to show: Number of missing values and count (column percent) with a chi-square p-value. This behavior can be modified using the tableby.control function. In fact, you can save your standard settings and use that for future tables. Note that test=FALSE and total=FALSE results in the total column and p-value column not being printed. mycontrols &lt;- tableby.control(test=FALSE, total=FALSE, numeric.test=&quot;kwt&quot;, cat.test=&quot;chisq&quot;, numeric.stats=c(&quot;N&quot;, &quot;median&quot;, &quot;q1q3&quot;), cat.stats=c(&quot;countpct&quot;), stats.labels=list(N=&#39;Count&#39;, median=&#39;Median&#39;, q1q3=&#39;Q1,Q3&#39;)) tab2 &lt;- tableby(arm ~ sex + age, data=mockstudy, control=mycontrols) summary(tab2) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Gender Male 277 (64.7%) 411 (59.5%) 228 (60.0%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) Age, yrs Count 428 691 380 Median 61.000 61.000 61.000 Q1,Q3 53.000, 68.000 52.000, 69.000 52.000, 68.000 You can also change these settings directly in the tableby call. tab3 &lt;- tableby(arm ~ sex + age, data=mockstudy, test=FALSE, total=FALSE, numeric.stats=c(&quot;median&quot;,&quot;q1q3&quot;), numeric.test=&quot;kwt&quot;) summary(tab3) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Gender Male 277 (64.7%) 411 (59.5%) 228 (60.0%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) Age, yrs Median 61.000 61.000 61.000 Q1, Q3 53.000, 68.000 52.000, 69.000 52.000, 68.000 Change summary statistics within the formula In addition to modifying summary options globally, it is possible to modify the test and summary statistics for specific variables within the formula statement. For example, both the kwt (Kruskal-Wallis rank-based) and anova (asymptotic analysis of variance) tests apply to numeric variables, and we can use one for the variable “age”, another for the variable “bmi”, and no test for the variable “ast”. A list of all the options is shown at the end of the vignette. The tests function can do a quick check on what tests were performed on each variable in tableby. tab.test &lt;- tableby(arm ~ kwt(age) + anova(bmi) + notest(ast), data=mockstudy) tests(tab.test) ## Variable p.value Method ## age Age, yrs 0.6390614 Kruskal-Wallis rank sum test ## bmi Body Mass Index (kg/m^2) 0.8916552 Linear Model ANOVA ## ast ast NA No test summary(tab.test) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.639 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Body Mass Index (kg/m^2) 0.892 N-Miss 9 20 4 33 Mean (SD) 27.290 (5.552) 27.210 (5.173) 27.106 (5.751) 27.206 (5.432) Range 14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 ast N-Miss 69 141 56 266 Mean (SD) 37.292 (28.036) 35.202 (26.659) 35.670 (25.807) 35.933 (26.843) Range 10.000 - 205.000 7.000 - 174.000 5.000 - 176.000 5.000 - 205.000 Summary statistics for any individual variable can also be modified, but it must be done as secondary arguments to the test function. The function names must be strings that are functions already written for tableby, built-in R functions like mean and range, or user-defined functions. tab.test &lt;- tableby(arm ~ kwt(ast, &quot;Nmiss2&quot;,&quot;median&quot;) + anova(age, &quot;N&quot;,&quot;mean&quot;) + notest(bmi, &quot;Nmiss&quot;,&quot;median&quot;), data=mockstudy) summary(tab.test) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value ast 0.039 N-Miss 69 141 56 266 Median 29.000 25.500 27.000 27.000 Age, yrs 0.614 N 428 691 380 1499 mean 59.7 60.3 59.8 60 Body Mass Index (kg/m^2) N-Miss 9 20 4 33 Median 26.234 26.525 25.978 26.325 Controlling Options for Categorical Tests (Chisq and Fisher’s) The formal tests for categorical variables against the levels of the by variable, chisq and fe, have options to simulate p-values. We show how to turn on the simulations for these with 500 replicates for the Fisher’s test (fe). set.seed(100) tab.catsim &lt;- tableby(arm ~ sex + race, cat.test=&quot;fe&quot;, simulate.p.value=TRUE, B=500, data=mockstudy) tests(tab.catsim) Variable p.value sex Gender 0.2195609 race Race 0.3093812 Method sex Fisher’s Exact Test for Count Data with simulated p-value(based on 500 replicates) race Fisher’s Exact Test for Count Data with simulated p-value(based on 500 replicates) The chis-square test on 2x2 tables applies Yates’ continuity correction by default, so we provide an option to turn off the correction. We show the results with and without the correction that is applied to treatment arm by sex, if we use subset to ignore one of the three treatment arms. cat.correct &lt;- tableby(arm ~ sex + race, cat.test=&quot;chisq&quot;, subset = !grepl(&quot;^F&quot;, arm), data=mockstudy) tests(cat.correct) Variable p.value Method sex Gender 0.1666280 Pearson’s Chi-squared test race Race 0.8108543 Pearson’s Chi-squared test cat.nocorrect &lt;- tableby(arm ~ sex + race, cat.test=&quot;chisq&quot;, subset = !grepl(&quot;^F&quot;, arm), chisq.correct=FALSE, data=mockstudy) tests(cat.nocorrect) Variable p.value Method sex Gender 0.1666280 Pearson’s Chi-squared test race Race 0.8108543 Pearson’s Chi-squared test Modifying the look &amp; feel in Word documents You can easily create Word versions of tableby output via an Rmarkdown report and the default options will give you a reasonable table in Word - just select the “Knit Word” option in RStudio. The functionality listed in this next paragraph is coming soon but needs an upgraded version of RStudio If you want to modify fonts used for the table, then you’ll need to add an extra line to your header at the beginning of your file. You can take the WordStylesReference01.docx file and modify the fonts (storing the format preferences in your project directory). To see how this works, run your report once using WordStylesReference01.docx and then WordStylesReference02.docx. output: word_document reference_docx: /projects/bsi/gentools/R/lib320/arsenal/doc/WordStylesReference01.docx For more informating on changing the look/feel of your Word document, see the Rmarkdown documentation website. Additional Examples Here are multiple examples showing how to use some of the different options. 1. Summarize without a group/by variable tab.noby &lt;- tableby(~ bmi + sex + age, data=mockstudy) summary(tab.noby) Overall (N=1499) Body Mass Index (kg/m^2) N-Miss 33 Mean (SD) 27.206 (5.432) Range 14.053 - 60.243 Gender Male 916 (61.1%) Female 583 (38.9%) Age, yrs Mean (SD) 59.985 (11.519) Range 19.000 - 88.000 2. Display footnotes indicating which “test” was used summary(tab.test) #, pfootnote=TRUE) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value ast 0.039 N-Miss 69 141 56 266 Median 29.000 25.500 27.000 27.000 Age, yrs 0.614 N 428 691 380 1499 mean 59.7 60.3 59.8 60 Body Mass Index (kg/m^2) N-Miss 9 20 4 33 Median 26.234 26.525 25.978 26.325 3. Summarize an ordered factor When comparing groups of ordered data there are a couple of options. The default uses a general independence test available from the coin package. For two-group comparisons, this is essentially the Armitage trend test. The other option is to specify the Kruskal Wallis test. The example below shows both options. mockstudy$age.ordnew &lt;- ordered(c(&quot;a&quot;,NA,as.character(mockstudy$age.ord[-(1:2)]))) table(mockstudy$age.ord, mockstudy$sex) ## ## Male Female ## 10-19 1 0 ## 20-29 8 11 ## 30-39 37 30 ## 40-49 127 83 ## 50-59 257 179 ## 60-69 298 170 ## 70-79 168 101 ## 80-89 20 9 table(mockstudy$age.ordnew, mockstudy$sex) ## ## Male Female ## 10-19 1 0 ## 20-29 8 11 ## 30-39 37 30 ## 40-49 127 83 ## 50-59 257 179 ## 60-69 297 170 ## 70-79 168 100 ## 80-89 20 9 ## a 1 0 class(mockstudy$age.ord) ## [1] &quot;ordered&quot; &quot;factor&quot; summary(tableby(sex ~ age.ordnew, data = mockstudy)) #, pfootnote = TRUE) Male (N=916) Female (N=583) Total (N=1499) p value age.ordnew 0.040 N-Miss 0 1 1 10-19 1 (0.1%) 0 (0.0%) 1 (0.1%) 20-29 8 (0.9%) 11 (1.9%) 19 (1.3%) 30-39 37 (4.0%) 30 (5.2%) 67 (4.5%) 40-49 127 (13.9%) 83 (14.3%) 210 (14.0%) 50-59 257 (28.1%) 179 (30.8%) 436 (29.1%) 60-69 297 (32.4%) 170 (29.2%) 467 (31.2%) 70-79 168 (18.3%) 100 (17.2%) 268 (17.9%) 80-89 20 (2.2%) 9 (1.5%) 29 (1.9%) a 1 (0.1%) 0 (0.0%) 1 (0.1%) summary(tableby(sex ~ kwt(age.ord), data = mockstudy)) #) #, pfootnote = TRUE) Male (N=916) Female (N=583) Total (N=1499) p value age.ord 0.067 10-19 1 (0.1%) 0 (0.0%) 1 (0.1%) 20-29 8 (0.9%) 11 (1.9%) 19 (1.3%) 30-39 37 (4.0%) 30 (5.1%) 67 (4.5%) 40-49 127 (13.9%) 83 (14.2%) 210 (14.0%) 50-59 257 (28.1%) 179 (30.7%) 436 (29.1%) 60-69 298 (32.5%) 170 (29.2%) 468 (31.2%) 70-79 168 (18.3%) 101 (17.3%) 269 (17.9%) 80-89 20 (2.2%) 9 (1.5%) 29 (1.9%) 4. Summarize a survival variable First look at the information that is presented by the survfit() function, then see how the same results can be seen with tableby. The default is to show the median survival (time at which the probability of survival = 50%). survfit(Surv(fu.time, fu.stat)~sex, data=mockstudy) ## Call: survfit(formula = Surv(fu.time, fu.stat) ~ sex, data = mockstudy) ## ## n events median 0.95LCL 0.95UCL ## sex=Male 916 829 550 515 590 ## sex=Female 583 527 543 511 575 survdiff(Surv(fu.time, fu.stat)~sex, data=mockstudy) ## Call: ## survdiff(formula = Surv(fu.time, fu.stat) ~ sex, data = mockstudy) ## ## N Observed Expected (O-E)^2/E (O-E)^2/V ## sex=Male 916 829 830 0.000370 0.000956 ## sex=Female 583 527 526 0.000583 0.000956 ## ## Chisq= 0 on 1 degrees of freedom, p= 1 summary(tableby(sex ~ Surv(fu.time, fu.stat), data=mockstudy)) Male (N=916) Female (N=583) Total (N=1499) p value Surv(fu.time, fu.stat) 0.975 Events 829 527 1356 Median Survival 550.000 543.000 546.000 It is also possible to obtain summaries of the % survival at certain time points (say the probability of surviving 1-year). summary(survfit(Surv(fu.time/365.25, fu.stat)~sex, data=mockstudy), times=1:5) ## Call: survfit(formula = Surv(fu.time/365.25, fu.stat) ~ sex, data = mockstudy) ## ## sex=Male ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 626 286 0.6870 0.0153 0.6576 0.7177 ## 2 309 311 0.3437 0.0158 0.3142 0.3761 ## 3 152 151 0.1748 0.0127 0.1516 0.2015 ## 4 57 61 0.0941 0.0104 0.0759 0.1168 ## 5 24 16 0.0628 0.0095 0.0467 0.0844 ## ## sex=Female ## time n.risk n.event survival std.err lower 95% CI upper 95% CI ## 1 380 202 0.6531 0.0197 0.6155 0.693 ## 2 190 189 0.3277 0.0195 0.2917 0.368 ## 3 95 90 0.1701 0.0157 0.1420 0.204 ## 4 51 32 0.1093 0.0133 0.0861 0.139 ## 5 18 12 0.0745 0.0126 0.0534 0.104 summary(tableby(sex ~ Surv(fu.time/365.25, fu.stat), data=mockstudy, times=1:5, surv.stats=c(&quot;NeventsSurv&quot;,&quot;NriskSurv&quot;))) Male (N=916) Female (N=583) Total (N=1499) p value Surv(fu.time/365.25, fu.stat) 0.975 time = 1 286 (68.7) 202 (65.3) 488 (67.4) time = 2 597 (34.4) 391 (32.8) 988 (33.7) time = 3 748 (17.5) 481 (17.0) 1229 (17.3) time = 4 809 (9.4) 513 (10.9) 1322 (10.1) time = 5 825 (6.3) 525 (7.4) 1350 (6.8) time = 1 626 380 1006 time = 2 309 190 499 time = 3 152 95 247 time = 4 57 51 108 time = 5 24 18 42 5. Summarize date variables Date variables by default are summarized with the number of missing values, the median, and the range. For example purposes we’ve created a random date. Missing values are introduced for impossible February dates. set.seed(100) N &lt;- nrow(mockstudy) mockstudy$dtentry &lt;- mdy.Date(month=sample(1:12,N,replace=T), day=sample(1:29,N,replace=T), year=sample(2005:2009,N,replace=T)) summary(tableby(sex ~ dtentry, data=mockstudy)) Male (N=916) Female (N=583) Total (N=1499) p value dtentry 0.554 N-Miss 3 2 5 Median 2007-06-16 2007-06-15 2007-06-15 Range 2005-01-03 - 2009-12-27 2005-01-01 - 2009-12-28 2005-01-01 - 2009-12-28 6. Summarize multiple variables without typing them out Often one wants to summarize a number of variables. Instead of typing by hand each individual variable, an alternative approach is to create a formula using the paste command with the collapse=&quot;+&quot; option. ## create a vector specifying the variable names myvars &lt;- names(mockstudy) ## select the 8th through the last variables ## paste them together, separated by the + sign RHS &lt;- paste(myvars[8:10], collapse=&quot;+&quot;) RHS [1] “ps+hgb+bmi” ## create a formula using the as.formula function as.formula(paste(&#39;arm ~ &#39;, RHS)) arm ~ ps + hgb + bmi ## use the formula in the tableby function summary(tableby(as.formula(paste(&#39;arm ~&#39;, RHS)), data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value ps 0.903 N-Miss 69 141 56 266 Mean (SD) 0.529 (0.597) 0.547 (0.595) 0.537 (0.606) 0.539 (0.598) Range 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 hgb 0.639 N-Miss 69 141 56 266 Mean (SD) 12.276 (1.686) 12.381 (1.763) 12.373 (1.680) 12.348 (1.719) Range 9.060 - 17.300 9.000 - 18.200 9.000 - 17.000 9.000 - 18.200 Body Mass Index (kg/m^2) 0.892 N-Miss 9 20 4 33 Mean (SD) 27.290 (5.552) 27.210 (5.173) 27.106 (5.751) 27.206 (5.432) Range 14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 These steps can also be done using the formulize function. ## The formulize function does the paste and as.formula steps tmp &lt;- formulize(&#39;arm&#39;,myvars[8:10]) tmp arm ~ ps + hgb + bmi ## More complex formulas could also be written using formulize tmp2 &lt;- formulize(&#39;arm&#39;,c(&#39;ps&#39;,&#39;hgb^2&#39;,&#39;bmi&#39;)) ## use the formula in the tableby function summary(tableby(tmp, data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value ps 0.903 N-Miss 69 141 56 266 Mean (SD) 0.529 (0.597) 0.547 (0.595) 0.537 (0.606) 0.539 (0.598) Range 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 hgb 0.639 N-Miss 69 141 56 266 Mean (SD) 12.276 (1.686) 12.381 (1.763) 12.373 (1.680) 12.348 (1.719) Range 9.060 - 17.300 9.000 - 18.200 9.000 - 17.000 9.000 - 18.200 Body Mass Index (kg/m^2) 0.892 N-Miss 9 20 4 33 Mean (SD) 27.290 (5.552) 27.210 (5.173) 27.106 (5.751) 27.206 (5.432) Range 14.053 - 53.008 16.649 - 49.130 15.430 - 60.243 14.053 - 60.243 7. Subset the dataset used in the analysis Here are two ways to get the same result (limit the analysis to subjects age&gt;5 and in the F: FOLFOX treatment group). The first approach uses the subset function applied to the dataset mockstudy. This example also selects a subset of variables. The tableby function is then applied to this subsetted data. newdata &lt;- subset(mockstudy, subset=age&gt;50 &amp; arm==&#39;F: FOLFOX&#39;, select = c(sex,ps:bmi)) dim(mockstudy) ## [1] 1499 16 table(mockstudy$arm) ## ## A: IFL F: FOLFOX G: IROX ## 428 691 380 dim(newdata) ## [1] 557 4 names(newdata) ## [1] &quot;sex&quot; &quot;ps&quot; &quot;hgb&quot; &quot;bmi&quot; summary(tableby(sex ~ ., data=newdata)) Male (N=333) Female (N=224) Total (N=557) p value ps 0.652 N-Miss 64 44 108 Mean (SD) 0.554 (0.600) 0.528 (0.602) 0.543 (0.600) Range 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 hgb &lt; 0.001 N-Miss 64 44 108 Mean (SD) 12.720 (1.925) 12.063 (1.395) 12.457 (1.760) Range 9.000 - 18.200 9.100 - 15.900 9.000 - 18.200 bmi 0.650 N-Miss 9 6 15 Mean (SD) 27.539 (4.780) 27.337 (5.508) 27.458 (5.081) Range 17.927 - 47.458 16.649 - 49.130 16.649 - 49.130 The second approach does the same analysis but uses the subset argument within tableby to subset the data. summary(tableby(sex ~ ps + hgb + bmi, subset=age&gt;50 &amp; arm==&quot;F: FOLFOX&quot;, data=mockstudy)) Male (N=333) Female (N=224) Total (N=557) p value ps 0.652 N-Miss 64 44 108 Mean (SD) 0.554 (0.600) 0.528 (0.602) 0.543 (0.600) Range 0.000 - 2.000 0.000 - 2.000 0.000 - 2.000 hgb &lt; 0.001 N-Miss 64 44 108 Mean (SD) 12.720 (1.925) 12.063 (1.395) 12.457 (1.760) Range 9.000 - 18.200 9.100 - 15.900 9.000 - 18.200 Body Mass Index (kg/m^2) 0.650 N-Miss 9 6 15 Mean (SD) 27.539 (4.780) 27.337 (5.508) 27.458 (5.081) Range 17.927 - 47.458 16.649 - 49.130 16.649 - 49.130 8. Create combinations of variables on the fly ## create a variable combining the levels of mdquality.s and sex with(mockstudy, table(interaction(mdquality.s,sex))) ## ## 0.Male 1.Male 0.Female 1.Female ## 77 686 47 437 summary(tableby(arm ~ interaction(mdquality.s,sex), data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value interaction(mdquality.s, sex) 0.493 N-Miss 55 156 41 252 0.Male 29 (7.8%) 31 (5.8%) 17 (5.0%) 77 (6.2%) 1.Male 214 (57.4%) 285 (53.3%) 187 (55.2%) 686 (55.0%) 0.Female 12 (3.2%) 21 (3.9%) 14 (4.1%) 47 (3.8%) 1.Female 118 (31.6%) 198 (37.0%) 121 (35.7%) 437 (35.0%) ## create a new grouping variable with combined levels of arm and sex summary(tableby(interaction(mdquality.s, sex) ~ age + bmi, data=mockstudy, subset=arm==&quot;F: FOLFOX&quot;)) 0.Male (N=31) 1.Male (N=285) 0.Female (N=21) 1.Female (N=198) Total (N=535) p value Age, yrs 0.190 Mean (SD) 63.065 (11.702) 60.653 (11.833) 60.810 (10.103) 58.924 (11.366) 60.159 (11.612) Range 41.000 - 82.000 19.000 - 88.000 42.000 - 81.000 29.000 - 83.000 19.000 - 88.000 Body Mass Index (kg/m^2) 0.894 N-Miss 0 6 1 5 12 Mean (SD) 26.633 (5.094) 27.387 (4.704) 27.359 (4.899) 27.294 (5.671) 27.307 (5.100) Range 20.177 - 41.766 17.927 - 47.458 19.801 - 39.369 16.799 - 44.841 16.799 - 47.458 9. Transform variables on the fly Certain transformations need to be surrounded by I() so that R knows to treat it as a variable transformation and not some special model feature. If the transformation includes any of the symbols / - + ^ * then surround the new variable by I(). trans &lt;- tableby(arm ~ I(age/10) + log(bmi) + factor(mdquality.s, levels=0:1, labels=c(&#39;N&#39;,&#39;Y&#39;)), data=mockstudy) summary(trans) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.614 Mean (SD) 5.967 (1.136) 6.030 (1.163) 5.976 (1.150) 5.999 (1.152) Range 2.700 - 8.800 1.900 - 8.800 2.600 - 8.500 1.900 - 8.800 Body Mass Index (kg/m^2) 0.811 N-Miss 9 20 4 33 Mean (SD) 3.287 (0.197) 3.286 (0.183) 3.279 (0.200) 3.285 (0.192) Range 2.643 - 3.970 2.812 - 3.894 2.736 - 4.098 2.643 - 4.098 factor(mdquality.s, levels = 0:1, labels = c(“N”, “Y”)) 0.694 N-Miss 55 156 41 252 N 41 (11.0%) 52 (9.7%) 31 (9.1%) 124 (9.9%) Y 332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%) The labels for these variables isn’t exactly what we’d like so we can change modify those after the fact. Instead of typing out the very long variable names you can modify specific labels by position. labels(trans) ## arm ## &quot;arm&quot; ## I(age/10) ## &quot;Age, yrs&quot; ## log(bmi) ## &quot;Body Mass Index (kg/m^2)&quot; ## factor(mdquality.s, levels = 0:1, labels = c(&quot;N&quot;, &quot;Y&quot;)) ## &quot;factor(mdquality.s, levels = 0:1, labels = c(\\&quot;N\\&quot;, \\&quot;Y\\&quot;))&quot; labels(trans)[2:4] &lt;- c(&#39;Age per 10 yrs&#39;, &#39;log(BMI)&#39;, &#39;MD Quality&#39;) labels(trans) ## arm ## &quot;arm&quot; ## I(age/10) ## &quot;Age per 10 yrs&quot; ## log(bmi) ## &quot;log(BMI)&quot; ## factor(mdquality.s, levels = 0:1, labels = c(&quot;N&quot;, &quot;Y&quot;)) ## &quot;MD Quality&quot; summary(trans) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age per 10 yrs 0.614 Mean (SD) 5.967 (1.136) 6.030 (1.163) 5.976 (1.150) 5.999 (1.152) Range 2.700 - 8.800 1.900 - 8.800 2.600 - 8.500 1.900 - 8.800 log(BMI) 0.811 N-Miss 9 20 4 33 Mean (SD) 3.287 (0.197) 3.286 (0.183) 3.279 (0.200) 3.285 (0.192) Range 2.643 - 3.970 2.812 - 3.894 2.736 - 4.098 2.643 - 4.098 MD Quality 0.694 N-Miss 55 156 41 252 N 41 (11.0%) 52 (9.7%) 31 (9.1%) 124 (9.9%) Y 332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%) Note that if we had not changed mdquality.s to a factor, it would have been summarized as though it were a continuous variable. class(mockstudy$mdquality.s) [1] “integer” summary(tableby(arm~mdquality.s, data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value mdquality.s 0.695 N-Miss 55 156 41 252 Mean (SD) 0.890 (0.313) 0.903 (0.297) 0.909 (0.289) 0.901 (0.299) Range 0.000 - 1.000 0.000 - 1.000 0.000 - 1.000 0.000 - 1.000 Another option would be to specify the test and summary statistics. In fact, if I had a set of variables coded 0/1 and that was all I was summarizing, then I could change the global option for continuous variables to use the chi-square test and show countpct. summary(tableby(arm ~ chisq(mdquality.s, &quot;Nmiss&quot;,&quot;countpct&quot;), data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value mdquality.s 0.694 N-Miss 55 156 41 252 0 41 (11.0%) 52 (9.7%) 31 (9.1%) 124 (9.9%) 1 332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%) 10. Subsetting (change the ordering of the variables, delete a variable, sort by p-value, filter by p-value) mytab &lt;- tableby(arm ~ sex + alk.phos + age, data=mockstudy) mytab2 &lt;- mytab[c(&#39;age&#39;,&#39;sex&#39;,&#39;alk.phos&#39;)] summary(mytab2) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) alk.phos 0.226 N-Miss 69 141 56 266 Mean (SD) 175.577 (128.608) 161.984 (121.978) 173.506 (138.564) 168.969 (128.492) Range 11.000 - 858.000 10.000 - 1014.000 7.000 - 982.000 7.000 - 1014.000 summary(mytab[c(&#39;age&#39;,&#39;sex&#39;)], digits = 2) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.614 Mean (SD) 59.67 (11.36) 60.30 (11.63) 59.76 (11.50) 59.99 (11.52) Range 27.00 - 88.00 19.00 - 88.00 26.00 - 85.00 19.00 - 88.00 Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) summary(mytab[c(3,1)], digits = 3) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) summary(sort(mytab, decreasing = TRUE)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 alk.phos 0.226 N-Miss 69 141 56 266 Mean (SD) 175.577 (128.608) 161.984 (121.978) 173.506 (138.564) 168.969 (128.492) Range 11.000 - 858.000 10.000 - 1014.000 7.000 - 982.000 7.000 - 1014.000 Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) summary(mytab[mytab &lt; 0.5]) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) alk.phos 0.226 N-Miss 69 141 56 266 Mean (SD) 175.577 (128.608) 161.984 (121.978) 173.506 (138.564) 168.969 (128.492) Range 11.000 - 858.000 10.000 - 1014.000 7.000 - 982.000 7.000 - 1014.000 head(mytab, 1) # can also use tail() Tableby Object Function Call: tableby(formula = arm ~ sex + alk.phos + age, data = mockstudy) y variable: [1] “arm” x variables: [1] “sex” 11. Merge two tableby objects together It is possible to combine two tableby objects so that they print out together. ## demographics tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;Nmiss&quot;,&quot;meansd&quot;), total=FALSE)) ## lab data tab2 &lt;- tableby(arm ~ hgb + alk.phos, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;Nmiss&quot;,&quot;median&quot;,&quot;q1q3&quot;), numeric.test=&quot;kwt&quot;, total=FALSE)) names(tab1$x) [1] “sex” “age” names(tab2$x) [1] “hgb” “alk.phos” tab12 &lt;- merge(tab1,tab2) class(tab12) [1] “tableby” names(tab12$x) [1] “sex” “age” “hgb” “alk.phos” summary(tab12) #, pfootnote=TRUE) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) hgb 0.570 N-Miss 69 141 56 Median 12.100 12.200 12.400 Q1, Q3 11.000, 13.450 11.100, 13.600 11.175, 13.625 alk.phos 0.104 N-Miss 69 141 56 Median 133.000 116.000 122.000 Q1, Q3 89.000, 217.000 85.000, 194.750 87.750, 210.250 12. Add a title to the table When creating a pdf the tables are automatically numbered and the title appears below the table. In Word and HTML, the titles appear un-numbered and above the table. t1 &lt;- tableby(arm ~ sex + age, data=mockstudy) summary(t1, title=&#39;Demographics&#39;) Demographics A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) Range 27.000 - 88.000 19.000 - 88.000 26.000 - 85.000 19.000 - 88.000 13. Modify how missing values are displayed Depending on the report you are writing you have the following options: Show how many subjects have each variable Show how many subjects are missing each variable Show how many subjects are missing each variable only if there are any missing values Don’t indicate missing values at all ## look at how many missing values there are for each variable apply(is.na(mockstudy),2,sum) ## case age arm sex race fu.time fu.stat ps ## 0 0 0 0 7 0 0 266 ## hgb bmi alk.phos ast mdquality.s age.ord age.ordnew dtentry ## 266 33 266 266 252 0 1 5 ## Show how many subjects have each variable (non-missing) summary(tableby(sex ~ ast + age, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;N&quot;,&quot;median&quot;), total=FALSE))) Male (N=916) Female (N=583) p value ast 0.921 N 754 479 Median 27.000 27.000 Age, yrs 0.048 N 916 583 Median 61.000 60.000 ## Always list the number of missing values summary(tableby(sex ~ ast + age, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;Nmiss2&quot;,&quot;median&quot;), total=FALSE))) Male (N=916) Female (N=583) p value ast 0.921 N-Miss 162 104 Median 27.000 27.000 Age, yrs 0.048 N-Miss 0 0 Median 61.000 60.000 ## Only show the missing values if there are some (default) summary(tableby(sex ~ ast + age, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;Nmiss&quot;,&quot;mean&quot;),total=FALSE))) Male (N=916) Female (N=583) p value ast 0.921 N-Miss 162 104 mean 35.9 36 Age, yrs 0.048 mean 60.5 59.2 ## Don&#39;t show N at all summary(tableby(sex ~ ast + age, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;mean&quot;),total=FALSE))) Male (N=916) Female (N=583) p value ast 0.921 mean 35.9 36 Age, yrs 0.048 mean 60.5 59.2 One might also consider the use of includeNA() to include NAs in the counts and percents for categorical variables. mockstudy$ps.cat &lt;- factor(mockstudy$ps) attr(mockstudy$ps.cat, &quot;label&quot;) &lt;- &quot;ps&quot; summary(tableby(sex ~ includeNA(ps.cat), data = mockstudy, cat.stats = &quot;countpct&quot;)) Male (N=916) Female (N=583) Total (N=1499) p value ps 0.354 0 391 (42.7%) 244 (41.9%) 635 (42.4%) 1 329 (35.9%) 202 (34.6%) 531 (35.4%) 2 34 (3.7%) 33 (5.7%) 67 (4.5%) (Missing) 162 (17.7%) 104 (17.8%) 266 (17.7%) 14. Modify the number of digits used Within tableby.control function there are 4 options for controlling the number of significant digits shown. digits: controls the number of digits after the decimal place for continuous values digits.count: controls the number of digits after the decimal point for counts digits.pct: controls the number of digits after the decimal point for percents digits.p: controls the number of digits after the decimal point for p-values summary(tableby(arm ~ sex + age + fu.time, data=mockstudy), digits=4, digits.p=2, digits.pct=1) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.19 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.61 Mean (SD) 59.6729 (11.3645) 60.3010 (11.6323) 59.7632 (11.4993) 59.9853 (11.5188) Range 27.0000 - 88.0000 19.0000 - 88.0000 26.0000 - 85.0000 19.0000 - 88.0000 fu.time &lt; 0.01 Mean (SD) 553.5841 (419.6065) 731.2460 (487.7443) 607.2421 (435.5092) 649.0841 (462.5109) Range 9.0000 - 2170.0000 0.0000 - 2472.0000 17.0000 - 2118.0000 0.0000 - 2472.0000 With the exception of digits.p, all of these can be specified on a per-variable basis using the in-formula functions that specify which tests are run: summary(tableby(arm ~ chisq(sex, digits.pct=1) + anova(age, digits=4) + anova(fu.time, digits = 1), data=mockstudy)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Gender 0.190 Male 277 (64.7%) 411 (59.5%) 228 (60.0%) 916 (61.1%) Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) Age, yrs 0.614 Mean (SD) 59.6729 (11.3645) 60.3010 (11.6323) 59.7632 (11.4993) 59.9853 (11.5188) Range 27.0000 - 88.0000 19.0000 - 88.0000 26.0000 - 85.0000 19.0000 - 88.0000 fu.time &lt; 0.001 Mean (SD) 553.6 (419.6) 731.2 (487.7) 607.2 (435.5) 649.1 (462.5) Range 9.0 - 2170.0 0.0 - 2472.0 17.0 - 2118.0 0.0 - 2472.0 15. Create a user-defined summary statistic For purposes of this example, the code below creates a trimmed mean function (trims 10%) and use that to summarize the data. Note the use of the ... which tells R to pass extra arguments on - this is required for user-defined functions. In this case, na.rm=T is passed to myfunc. The weights argument is also required, even though it isn’t passed on to the internal function in this particular example. myfunc &lt;- function(x, weights=rep(1,length(x)), ...){ mean(x, trim=.1, ...) } summary(tableby(sex ~ hgb, data=mockstudy, control=tableby.control(numeric.stats=c(&quot;Nmiss&quot;,&quot;myfunc&quot;), numeric.test=&quot;kwt&quot;, stats.labels=list(Nmiss=&#39;Missing values&#39;, myfunc=&quot;Trimmed Mean, 10%&quot;)))) Male (N=916) Female (N=583) Total (N=1499) p value hgb &lt; 0.001 Missing values 162 104 266 Trimmed Mean, 10% 12.6 11.9 NA 16. Use case-weights for creating summary statistics When comparing groups, they are often unbalanced when it comes to nuisances such as age and sex. The tableby function allows you to create weighted summary statistics. If this option us used then p-values are not calculated (test=FALSE). ##create fake group that is not balanced by age/sex set.seed(200) mockstudy$fake_arm &lt;- ifelse(mockstudy$age&gt;60 &amp; mockstudy$sex==&#39;Female&#39;,sample(c(&#39;A&#39;,&#39;B&#39;),replace=T, prob=c(.2,.8)), sample(c(&#39;A&#39;,&#39;B&#39;),replace=T, prob=c(.8,.4))) mockstudy$agegp &lt;- cut(mockstudy$age, breaks=c(18,50,60,70,90), right=FALSE) ## create weights based on agegp and sex distribution tab1 &lt;- with(mockstudy,table(agegp, sex)) tab2 &lt;- with(mockstudy, table(agegp, sex, fake_arm)) tab2 ## , , fake_arm = A ## ## sex ## agegp Male Female ## [18,50) 73 62 ## [50,60) 128 94 ## [60,70) 139 7 ## [70,90) 102 0 ## ## , , fake_arm = B ## ## sex ## agegp Male Female ## [18,50) 79 48 ## [50,60) 130 84 ## [60,70) 156 166 ## [70,90) 109 122 gpwts &lt;- rep(tab1, length(unique(mockstudy$fake_arm)))/tab2 gpwts[gpwts&gt;50] &lt;- 30 ## apply weights to subjects index &lt;- with(mockstudy, cbind(as.numeric(agegp), as.numeric(sex), as.numeric(as.factor(fake_arm)))) mockstudy$wts &lt;- gpwts[index] ## show weights by treatment arm group tapply(mockstudy$wts,mockstudy$fake_arm, summary) ## $A ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.774 1.894 2.069 2.276 2.082 24.714 ## ## $B ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.042 1.924 1.677 1.985 2.292 orig &lt;- tableby(fake_arm ~ age + sex + Surv(fu.time/365, fu.stat), data=mockstudy, test=FALSE) summary(orig, title=&#39;No Case Weights used&#39;) No Case Weights used A (N=605) B (N=894) Total (N=1499) Age, yrs Mean (SD) 57.413 (11.618) 61.726 (11.125) 59.985 (11.519) Range 22.000 - 85.000 19.000 - 88.000 19.000 - 88.000 Gender Male 442 (73.1%) 474 (53.0%) 916 (61.1%) Female 163 (26.9%) 420 (47.0%) 583 (38.9%) Surv(fu.time/365, fu.stat) Events 554 802 1356 Median Survival 1.504 1.493 1.496 tab1 &lt;- tableby(fake_arm ~ age + sex + Surv(fu.time/365, fu.stat), data=mockstudy, weights=wts) summary(tab1, title=&#39;Case Weights used&#39;) Case Weights used A (N=605) B (N=894) Total (N=1499) Age, yrs Mean (SD) 58.009 (10.925) 60.151 (11.428) 59.126 (11.235) Range 22.000 - 85.000 19.000 - 88.000 19.000 - 88.000 Gender Male 916 (66.5%) 916 (61.1%) 1832 (63.7%) Female 461 (33.5%) 583 (38.9%) 1044 (36.3%) Surv(fu.time/365, fu.stat) Events 1252 1348 2599 Median Survival 1.534 1.496 1.532 17. Create your own p-value and add it to the table When using weighted summary statistics, it is often desirable to then show a p-value from a model that corresponds to the weighted analysis. It is possible to add your own p-value and modify the column title for that new p-value. Another use for this would be to add standardized differences or confidence intervals instead of a p-value. To add the p-value you simply need to create a data frame and use the function modpval.tableby. The first 2 columns in the dataframe are required and are the variable name and the new p-value. The third column can be used to indicate what method was used to calculate the p-value. If you specify use.pname=TRUE then the column name indicating the p-value will be also be used in the tableby summary. mypval &lt;- data.frame(variable=c(&#39;age&#39;,&#39;sex&#39;,&#39;Surv(fu.time/365, fu.stat)&#39;), adj.pvalue=c(.953,.811,.01), method=c(&#39;Age/Sex adjusted model results&#39;)) tab2 &lt;- modpval.tableby(tab1, mypval, use.pname=TRUE) summary(tab2, title=&#39;Case Weights used, p-values added&#39;) #, pfootnote=TRUE) Case Weights used, p-values added A (N=605) B (N=894) Total (N=1499) adj.pvalue Age, yrs 0.953 Mean (SD) 58.009 (10.925) 60.151 (11.428) 59.126 (11.235) Range 22.000 - 85.000 19.000 - 88.000 19.000 - 88.000 Gender 0.811 Male 916 (66.5%) 916 (61.1%) 1832 (63.7%) Female 461 (33.5%) 583 (38.9%) 1044 (36.3%) Surv(fu.time/365, fu.stat) 0.010 Events 1252 1348 2599 Median Survival 1.534 1.496 1.532 18. For two-level categorical variables or one-line numeric variables, simplify the output. If the cat.simplify option is set to TRUE, then only the second level of two-level categorical varialbes is shown. In the example below, sex has two levels, and “Female” is the second level, hence only the counts and percents for Female are shown. Similarly, “mdquality.s” was turned to a factor, and “1” is the second level, but since there are missings, the table ignores cat.simplify and displays all levels (since the output can no longer be displayed on one line). table2 &lt;- tableby(arm~sex + factor(mdquality.s), data=mockstudy, cat.simplify=TRUE) summary(table2, labelTranslations=c(sex=&quot;Female&quot;, &quot;factor(mdquality.s)&quot;=&quot;MD Quality&quot;)) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Female 151 (35.3%) 280 (40.5%) 152 (40.0%) 583 (38.9%) 0.190 MD Quality 0.694 N-Miss 55 156 41 252 0 41 (11.0%) 52 (9.7%) 31 (9.1%) 124 (9.9%) 1 332 (89.0%) 483 (90.3%) 308 (90.9%) 1123 (90.1%) Similarly, if numeric.simplify is set to TRUE, then any numerics which only have one row of summary statistics are simplified into a single row. Note again that ast has missing values and so is not simplified to a single row. summary(tableby(arm ~ age + ast, data = mockstudy, numeric.simplify=TRUE, numeric.stats=c(&quot;Nmiss&quot;, &quot;meansd&quot;))) A: IFL (N=428) F: FOLFOX (N=691) G: IROX (N=380) Total (N=1499) p value Age, yrs 59.673 (11.365) 60.301 (11.632) 59.763 (11.499) 59.985 (11.519) 0.614 ast 0.507 N-Miss 69 141 56 266 Mean (SD) 37.292 (28.036) 35.202 (26.659) 35.670 (25.807) 35.933 (26.843) The in-formula functions to change which tests are run can also be used to specify these options for each variable at a time. summary(tableby(arm ~ anova(age, &quot;meansd&quot;, numeric.simplify=TRUE) + chisq(sex, cat.simplify=TRUE), data = mockstudy)) ## ## ## | | A: IFL (N=428) | F: FOLFOX (N=691) | G: IROX (N=380) | Total (N=1499) | p value| ## |:------------|:---------------:|:-----------------:|:---------------:|:---------------:|-------:| ## |**Age, yrs** | 59.673 (11.365) | 60.301 (11.632) | 59.763 (11.499) | 59.985 (11.519) | 0.614| ## |**Gender** | 151 (35.3%) | 280 (40.5%) | 152 (40.0%) | 583 (38.9%) | 0.190| 19. Use tableby within an Sweave document For those users who wish to create tables within an Sweave document, the following code seems to work. \\documentclass{article} \\usepackage{longtable} \\usepackage{pdfpages} \\begin{document} \\section{Read in Data} &lt;&lt;echo=TRUE&gt;&gt;= require(arsenal) require(knitr) require(rmarkdown) data(mockstudy) tab1 &lt;- tableby(arm~sex+age, data=mockstudy) @ \\section{Convert Summary.Tableby to LaTeX} &lt;&lt;echo=TRUE, results=&#39;hide&#39;, message=FALSE&gt;&gt;= capture.output(summary(tab1), file=&quot;Test.md&quot;) ## Convert R Markdown Table to LaTeX render(&quot;Test.md&quot;, pdf_document(keep_tex=TRUE)) @ \\includepdf{Test.pdf} \\end{document} 20. Export tableby object to a .CSV file When looking at multiple variables it is sometimes useful to export the results to a csv file. The as.data.frame function creates a data frame object that can be exported or further manipulated within R. tab1 &lt;- tableby(arm~sex+age, data=mockstudy) as.data.frame(tab1) ## variable term label variable.type A: IFL F: FOLFOX ## 1 sex sex Gender categorical ## 2 sex countpct Male categorical 277.00000, 64.71963 411.00000, 59.47902 ## 3 sex countpct Female categorical 151.00000, 35.28037 280.00000, 40.52098 ## 4 age age Age, yrs numeric ## 5 age meansd Mean (SD) numeric 59.67290, 11.36454 60.30101, 11.63225 ## 6 age range Range numeric 27, 88 19, 88 ## G: IROX Total test p.value ## 1 Pearson&#39;s Chi-squared test 0.1904388 ## 2 228, 60 916.0000, 61.1074 Pearson&#39;s Chi-squared test 0.1904388 ## 3 152, 40 583.0000, 38.8926 Pearson&#39;s Chi-squared test 0.1904388 ## 4 Linear Model ANOVA 0.6143859 ## 5 59.76316, 11.49930 59.98532, 11.51877 Linear Model ANOVA 0.6143859 ## 6 26, 85 19, 88 Linear Model ANOVA 0.6143859 # write.csv(tmp, &#39;/my/path/here/mymodel.csv&#39;) 21. Write tableby object to a separate Word or HTML file ## write to an HTML document tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy) write2html(tab1, &quot;~/trash.html&quot;) ## write to a Word document write2word(tab1, &quot;~/trash.doc&quot;, title=&quot;My table in Word&quot;) 22. Use tableby in R Shiny The easiest way to output a tableby() object in an R Shiny app is to use the tableOutput() UI in combination with the renderTable() server function and as.data.frame(summary(tableby())): # A standalone shiny app library(shiny) library(arsenal) data(mockstudy) shinyApp( ui = fluidPage(tableOutput(&quot;table&quot;)), server = function(input, output) { output$table &lt;- renderTable({ as.data.frame(summary(tableby(sex ~ age, data = mockstudy), text = &quot;html&quot;)) }, sanitize.text.function = function(x) x) } ) This can be especially powerful if you feed the selections from a selectInput(multiple = TRUE) into formulize() to make the table dynamic! 23. Use tableby in bookdown Since the backbone of tableby() is knitr::kable(), tables still render well in bookdown. However, print.summary.tableby() doesn’t use the caption= argument of kable(), so some tables may not have a properly numbered caption. To fix this, use the method described on the bookdown site to give the table a tag/ID. summary(tableby(sex ~ age, data = mockstudy), title=&quot;(\\\\#tab:mytableby) Caption here&quot;) 24. Adjust tableby for multiple p-values The padjust() function is a new S3 generic piggybacking off of p.adjust(). It works on both tableby and summary.tableby objects: tab &lt;- summary(tableby(sex ~ age + fu.time + bmi + mdquality.s, data = mockstudy)) tab ## ## ## | | Male (N=916) | Female (N=583) | Total (N=1499) | p value| ## |:----------------------------|:-----------------:|:-----------------:|:-----------------:|-------:| ## |**Age, yrs** | | | | 0.048| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 60.455 (11.369) | 59.247 (11.722) | 59.985 (11.519) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 19.000 - 88.000 | 22.000 - 88.000 | 19.000 - 88.000 | | ## |**fu.time** | | | | 0.978| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 649.345 (454.332) | 648.674 (475.472) | 649.084 (462.511) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 2472.000 | 9.000 - 2441.000 | 0.000 - 2472.000 | | ## |**Body Mass Index (kg/m^2)** | | | | 0.012| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;N-Miss | 22 | 11 | 33 | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 27.491 (5.030) | 26.760 (5.984) | 27.206 (5.432) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 14.053 - 60.243 | 15.430 - 53.008 | 14.053 - 60.243 | | ## |**mdquality.s** | | | | 0.827| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;N-Miss | 153 | 99 | 252 | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 0.899 (0.301) | 0.903 (0.296) | 0.901 (0.299) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 1.000 | 0.000 - 1.000 | 0.000 - 1.000 | | padjust(tab, method = &quot;bonferroni&quot;) ## ## ## | | Male (N=916) | Female (N=583) | Total (N=1499) | p value| ## |:----------------------------|:-----------------:|:-----------------:|:-----------------:|-------:| ## |**Age, yrs** | | | | 0.191| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 60.455 (11.369) | 59.247 (11.722) | 59.985 (11.519) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 19.000 - 88.000 | 22.000 - 88.000 | 19.000 - 88.000 | | ## |**fu.time** | | | | 1.000| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 649.345 (454.332) | 648.674 (475.472) | 649.084 (462.511) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 2472.000 | 9.000 - 2441.000 | 0.000 - 2472.000 | | ## |**Body Mass Index (kg/m^2)** | | | | 0.048| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;N-Miss | 22 | 11 | 33 | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 27.491 (5.030) | 26.760 (5.984) | 27.206 (5.432) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 14.053 - 60.243 | 15.430 - 53.008 | 14.053 - 60.243 | | ## |**mdquality.s** | | | | 1.000| ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;N-Miss | 153 | 99 | 252 | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Mean (SD) | 0.899 (0.301) | 0.903 (0.296) | 0.901 (0.299) | | ## |&amp;nbsp;&amp;nbsp;&amp;nbsp;Range | 0.000 - 1.000 | 0.000 - 1.000 | 0.000 - 1.000 | | Available Function Options Summary statistics The default summary statistics, by varible type, are: numeric.stats: Continuous variables will show by default Nmiss, meansd, range cat.stats: Categorical and factor variables will show by default Nmiss, countpct ordered.stats: Ordered factors will show by default Nmiss, countpct surv.stats: Survival variables will show by default Nmiss, Nevents, medsurv date.stats: Date variables will show by default Nmiss, median, range Any summary statistics standardly defined in R (e.g. mean, median, sd, med, range) can be specified, however there are a number of extra functions defined specifically for the tableby function. N: a count of the number of observations for a particular group Nmiss: only show the count of the number of missing values if there are some missing values Nmiss2: always show a count of the number of missing values for a variable within each group meansd: print the mean and standard deviation in the format mean(sd) countpct: print the number of values in a category plus the column-percentage in the format N (%) countrowpct: print the number of values in a category plus the row-percentage in the format N (%) countcellpct: print the number of values in a category plus the cell-percentage in the format N (%) binomCI: print the proportion in a category plus a binomial confidence interval. rowbinomCI: print the row proportion in a category plus a binomial confidence interval. medianq1q3: print the median, 25th, and 75th quantiles median (Q1, Q3) q1q3: print the 25th and 75th quantiles Q1, Q3 iqr: print the inter-quartile range. medianrange: print the median, minimum and maximum values median (minimum, maximum) Nevents: print number of events for a survival object within each grouping level medsurv: print the median survival NeventsSurv: print number of events and survival at given times NriskSurv: print the number still at risk at given times medTime: print the median follow-up time Testing options The tests used to calculate p-values differ by the variable type, but can be specified explicitly in the formula statement or in the control function. The following tests are accepted: anova: analysis of variance test; the default test for continuous variables. When the grouping variable has two levels, it is equivalent to the two-sample t-test with equal variance. kwt: Kruskal-Wallis test, optional test for continuous variables. When the grouping variable has two levels, it is equivalent to the Wilcoxon Rank Sum test. chisq: chi-square goodness of fit test for equal counts of a categorical variable across categories; the default for categorical or factor variables fe: Fisher’s exact test for categorical variables; optional logrank: log-rank test, the default test for time-to-event variables trend: The independence_test function from the coin is used to test for trends. Whenthe grouping variable has two levels, it is equivalent to the Armitage trend test. This is the default for ordered factors notest: Don’t perform a test. tableby.control settings A quick way to see what arguments are possible to utilize in a function is to use the args() command. Settings involving the number of digits can be set in tableby.control or in summary.tableby. args(tableby.control) ## function (test = TRUE, total = TRUE, test.pname = NULL, cat.simplify = FALSE, ## numeric.simplify = FALSE, numeric.test = &quot;anova&quot;, cat.test = &quot;chisq&quot;, ## ordered.test = &quot;trend&quot;, surv.test = &quot;logrank&quot;, date.test = &quot;kwt&quot;, ## numeric.stats = c(&quot;Nmiss&quot;, &quot;meansd&quot;, &quot;range&quot;), cat.stats = c(&quot;Nmiss&quot;, ## &quot;countpct&quot;), ordered.stats = c(&quot;Nmiss&quot;, &quot;countpct&quot;), ## surv.stats = c(&quot;Nevents&quot;, &quot;medSurv&quot;), date.stats = c(&quot;Nmiss&quot;, ## &quot;median&quot;, &quot;range&quot;), stats.labels = list(Nmiss = &quot;N-Miss&quot;, ## Nmiss2 = &quot;N-Miss&quot;, meansd = &quot;Mean (SD)&quot;, medianrange = &quot;Median (Range)&quot;, ## median = &quot;Median&quot;, medianq1q3 = &quot;Median (Q1, Q3)&quot;, q1q3 = &quot;Q1, Q3&quot;, ## iqr = &quot;IQR&quot;, range = &quot;Range&quot;, countpct = &quot;Count (Pct)&quot;, ## Nevents = &quot;Events&quot;, medSurv = &quot;Median Survival&quot;, medTime = &quot;Median Follow-Up&quot;), ## digits = 3L, digits.count = 0L, digits.pct = 1L, digits.p = 3L, ## format.p = TRUE, conf.level = 0.95, chisq.correct = FALSE, ## simulate.p.value = FALSE, B = 2000, ...) ## NULL summary.tableby settings The summary.tableby function has options that modify how the table appears (such as adding a title or modifying labels). args(arsenal:::summary.tableby) ## function (object, ..., labelTranslations = NULL, text = FALSE, ## title = NULL, pfootnote = FALSE, term.name = &quot;&quot;) ## NULL --- ## The write2 function https://cran.r-project.org/web/packages/arsenal/vignettes/write2.html The write2 function Ethan Heinzen 09 November, 2018 Introduction A note on piping Examples Using arsenal Objects tableby modelsum freqlist compare Examples Using Other Objects knitr::kable() xtable::xtable() pander::pander_return() Output Multiple Tables to One Document Output Other Objects Monospaced (as if in a terminal) Add a YAML Header to the Output FAQs How do I suppress the note about my document getting rendered? How do I look at the temporary .md file? How do I prevent my document from being rendered? How do I output headers, raw HTML/LaTeX, paragraphs, etc.? How do I tweak the default format from write2word(), write2html(), or write2pdf()? How do I output to a file format other than word, HTML, and PDF? How do I avoid prefixes on my table captions in PDF? How do I output multiple tables with different titles? Introduction The write2*() functions were designed as an alternative to SAS’s ODS procedure for useRs who want to save R Markdown tables to separate Word, HTML, or PDF files without needing separate R Markdown programs. There are three shortcut functions for the most common output types: HTML, PDF, and Word. Each of these three functions calls write2(), an S3 function which accepts many file output types (see the help pages for rmarkdown::render()). Methods have been implemented for tableby(), modelsum(), and freqlist(), but also knitr::kable(), xtable::xtable(), and pander::pander_return(). The two most important things to recognize with write2() are the following: Which function is being used to output the object. Sometimes the write2 functions use summary(), while other times they will use print(). The details for each object specifically are described below. How the ... arguments are passed. To change the options for the summary-like or print-like function, you can pass named arguments which will in turn get passed to the appropriate function. Details for each object specifically are described below. A note on piping arsenal is piping-compatible! The write2*() functions are probably the most useful place to take advantage of the magrittr package’s piping framework, since commands are often nested several functions deep in the context of write2*(). Piping also allows the arsenal package to become a part of more standard analysis pipelines; instead of needing to write separate R Markdown programs, intermediate analysis tables and output can be easily incorporated into piped statements. This vignette will sprinkle the foward pipe (%&gt;%) throughout as a hint at the power and flexibility of arsenal and piping. Examples Using arsenal Objects library(arsenal) library(magrittr) data(mockstudy) tmpdir &lt;- tempdir() tableby For tableby objects, the output function in write2() is summary(). For summary.tableby objects, the output function is print(). For available arguments, see the help pages for summary.tableby(). Don’t use the option text = TRUE with the write2 functions. mylabels &lt;- list(sex = &quot;SEX&quot;, age =&quot;Age, yrs&quot;) tab1 &lt;- tableby(arm ~ sex + age, data=mockstudy) write2html( tab1, paste0(tmpdir, &quot;/test.tableby.html&quot;), quiet = TRUE, title = &quot;My test table&quot;, # passed to summary.tableby labelTranslations = mylabels, # passed to summary.tableby total = FALSE # passed to summary.tableby ) modelsum For modelsum objects, the output function in write2() is summary(). For summary.modelsum objects, the output function is print(). For available arguments, see the help pages for summary.modelsum(). Don’t use the option text = TRUE with the write2 functions. tab2 &lt;- modelsum(alk.phos ~ arm + ps + hgb, adjust= ~ age + sex, family = &quot;gaussian&quot;, data = mockstudy) write2pdf( tab2, paste0(tmpdir, &quot;/test.modelsum.pdf&quot;), quiet = TRUE, title = &quot;My test table&quot;, # passed to summary.modelsum show.intercept = FALSE, # passed to summary.modelsum digits = 5 # passed to summary.modelsum ) freqlist For freqlist objects, the output function in write2() is summary(). For summary.freqlist objects, the output function is print(). For available arguments, see the help pages for summary.freqlist(). mockstudy[, c(&quot;arm&quot;, &quot;sex&quot;, &quot;mdquality.s&quot;)] %&gt;% table(useNA = &quot;ifany&quot;) %&gt;% freqlist(groupBy = c(&quot;arm&quot;, &quot;sex&quot;)) %&gt;% write2word( paste0(tmpdir, &quot;/test.freqlist.doc&quot;), quiet = TRUE, single = FALSE, # passed to summary.freqlist title = &quot;My cool title&quot; # passed to summary.freqlist ) compare For compare.data.frame objects, the output function in write2() is summary(). For summary.compare.data.frame objects, the output function is print(). Examples Using Other Objects knitr::kable() For objects resulting from a call to kable(), the output function in write2() is print(). There aren’t any arguments to the print.knitr_kable() function. mockstudy %&gt;% head() %&gt;% knitr::kable() %&gt;% write2html(paste0(tmpdir, &quot;/test.kable.html&quot;), quiet = TRUE) xtable::xtable() For xtable objects, the output function in write2() is print(). For available arguments, see the help pages for print.xtable(). mockstudy %&gt;% head() %&gt;% xtable::xtable(caption = &quot;My xtable&quot;) %&gt;% write2pdf( paste0(tmpdir, &quot;/test.xtable.pdf&quot;), quiet = TRUE, comment = FALSE, # passed to print.xtable to turn off the default message about xtable version include.rownames = FALSE, # passed to print.xtable caption.placement = &quot;top&quot; # passed to print.xtable ) To make an HTML document, use the print.xtable() option type = &quot;html&quot;. mockstudy %&gt;% head() %&gt;% xtable::xtable(caption = &quot;My xtable&quot;) %&gt;% write2html( paste0(tmpdir, &quot;/test.xtable.html&quot;), quiet = TRUE, type = &quot;html&quot;, # passed to print.xtable comment = FALSE, # passed to print.xtable to turn off the default message about xtable version include.rownames = FALSE, # passed to print.xtable caption.placement = &quot;top&quot; # passed to print.xtable ) User beware! xtable() is not compatible with write2word(). pander::pander_return() Pander is a little bit more tricky. Since pander::pander() doesn’t return an object, the useR should instead use pander::pander_return(). For this (and for all character vectors), the the output function in write2() is cat(sep = &#39;\\n&#39;). write2word(pander::pander_return(head(mockstudy)), file = paste0(tmpdir, &quot;/test.pander.doc&quot;), quiet = TRUE) Output Multiple Tables to One Document To output multiple tables into a document, simply make a list of them and call the same function as before. mylist &lt;- list( tableby(sex ~ age, data = mockstudy), freqlist(table(mockstudy[, c(&quot;sex&quot;, &quot;arm&quot;)])), knitr::kable(head(mockstudy)) ) write2pdf(mylist, paste0(tmpdir, &quot;/test.mylist.pdf&quot;), quiet = TRUE) One neat side-effect of this function is that you can output text and headers, etc. The possibilities are endless! mylist2 &lt;- list( &quot;# Header 1&quot;, &quot;This is a small paragraph introducing tableby.&quot;, tableby(sex ~ age, data = mockstudy), &quot;&lt;hr&gt;&quot;, &quot;# Header 2&quot;, &quot;&lt;font color=&#39;red&#39;&gt;I can change color of my text!&lt;/font&gt;&quot; ) write2html(mylist2, paste0(tmpdir, &quot;/test.mylist2.html&quot;), quiet = TRUE) In fact, you can even recurse on the lists! write2pdf(list(mylist2, mylist), paste0(tmpdir, &quot;/test.mylists.pdf&quot;), quiet = TRUE) Output Other Objects Monospaced (as if in a terminal) It may be useful at times to write output that would normally be copied from the terminal. The default method for write2() does this automatically. To output the results of summary.lm(), for example: lm(age ~ sex, data = mockstudy) %&gt;% summary() %&gt;% write2pdf(paste0(tmpdir, &quot;/test.lm.pdf&quot;), quiet = TRUE) The verbatim() function is another option to explicitly alert write2() to do this. This becomes particularly helpful to overrule existing S3 methods. For example, suppose you wanted to just print a tableby object (as if it were to print in the terminal): tab4 &lt;- tableby(arm ~ sex + age, data=mockstudy) write2html(verbatim(tab4), paste0(tmpdir, &quot;/test.print.tableby.html&quot;), quiet = TRUE) Or suppose you wanted to print a character vector (as if it were to print in the terminal): chr &lt;- paste0(&quot;MyVector&quot;, 1:10) write2pdf(verbatim(chr), paste0(tmpdir, &quot;/test.character.pdf&quot;), quiet = TRUE) Add a YAML Header to the Output You can add a YAML header to write2() output using the yaml() function. mylist3 &lt;- list( yaml(title = &quot;Test YAML Title&quot;, author = &quot;My cool author name&quot;), &quot;# Header 1&quot;, &quot;This is a small paragraph introducing tableby.&quot;, tableby(sex ~ age, data = mockstudy) ) write2html(mylist3, paste0(tmpdir, &quot;/test.yaml.html&quot;), quiet = TRUE) In fact, all detected YAML pieces will be moved as the first output, so that the above code chunk gives the same output as this one: mylist4 &lt;- list( &quot;# Header 1&quot;, &quot;This is a small paragraph introducing tableby.&quot;, yaml(title = &quot;Test YAML Title&quot;), tableby(sex ~ age, data = mockstudy), yaml(author = &quot;My cool author name&quot;) ) write2html(mylist3, paste0(tmpdir, &quot;/test.yaml2.html&quot;), quiet = TRUE) FAQs How do I suppress the note about my document getting rendered? This is easily accomplished by using the argument quiet = TRUE (passed to the rmarkdown::render() function). write2html( knitr::kable(head(mockstudy)), paste0(tmpdir, &quot;/test.kable.quiet.html&quot;), quiet = TRUE # passed to rmarkdown::render ) How do I look at the temporary .md file? This is easily accomplished by using the option keep.md = TRUE. write2html( knitr::kable(head(mockstudy)), paste0(tmpdir, &quot;/test.kable.keep.md.html&quot;), quiet = TRUE, # passed to rmarkdown::render keep.md = TRUE ) How do I prevent my document from being rendered? This is easily accomplished by using the option render. = FALSE. Note that this will then default to keep.md = TRUE. write2html( knitr::kable(head(mockstudy)), paste0(tmpdir, &quot;/test.kable.dont.render.html&quot;), render. = FALSE ) How do I output headers, raw HTML/LaTeX, paragraphs, etc.? One can simply abuse the list S3 method for write2()! mylist2 &lt;- list( &quot;# Header 1&quot;, &quot;This is a small paragraph introducing tableby.&quot;, tableby(sex ~ age, data = mockstudy), &quot;&lt;hr&gt;&quot;, &quot;# Header 2&quot;, &quot;&lt;font color=&#39;red&#39;&gt;I can change color of my text!&lt;/font&gt;&quot; ) write2html(mylist2, paste0(tmpdir, &quot;/test.mylist2.html&quot;), quiet = TRUE) How do I tweak the default format from write2word(), write2html(), or write2pdf()? You can pass arguments to the format functions used behind the scenes. write2html( knitr::kable(head(mockstudy)), paste0(tmpdir, &quot;/test.kable.theme.html&quot;), quiet = TRUE, # passed to rmarkdown::render theme = &quot;yeti&quot; # passed to rmarkdown::html_document ) See the help pages for rmarkdown::word_document(), rmarkdown::html_document(), and rmarkdown::pdf_document(). How do I output to a file format other than word, HTML, and PDF? This can be done using the generic write2() function. The last argument in the function can be another format specification. For details on the acceptable inputs, see the help page for write2(). write2( knitr::kable(head(mockstudy[, 1:4])), paste0(tmpdir, &quot;/test.kable.rtf&quot;), quiet = TRUE, # passed to rmarkdown::render output_format = rmarkdown::rtf_document ) How do I avoid prefixes on my table captions in PDF? You can do this pretty easily with the yaml() function: mylist5 &lt;- list( yaml(&quot;header-includes&quot; = list(&quot;\\\\usepackage[labelformat=empty]{caption}&quot;)), &quot;# Header 1&quot;, &quot;This is a small paragraph introducing tableby.&quot;, tableby(sex ~ age, data = mockstudy) ) write2pdf(mylist5, paste0(tmpdir, &quot;/test.noprefixes.pdf&quot;), title = &quot;My tableby&quot;) How do I output multiple tables with different titles? There are now write2() methods for the summary objects of arsenal functions. This allows you to specify a title for each table: mylist6 &lt;- list( summary(tableby(sex ~ age, data = mockstudy), title = &quot;A Title for tableby&quot;), summary(modelsum(age ~ sex, data = mockstudy), title = &quot;A Title for modelsum&quot;), summary(freqlist(~ sex, data = mockstudy), title = &quot;A Title for freqlist&quot;) ) write2pdf(mylist6, paste0(tmpdir, &quot;/test.multiple.titles.pdf&quot;)) author: &quot;Kristian Larsen&quot; output: flexdashboard::flex_dashboard: orientation: rows vertical_layout: scroll from: https://datascienceplus.com/automated-dashboard-visualizations-with-deviation-in-r/?fbclid=IwAR2JcAMQ4eNRMrEBPGL79HDbS818vGZX0evs-ateBX0d9SRFIilY7U44Szw 20.2 Row 20.2.1 Chart A: Diverging Barcharts 20.2.2 Chart B: Diverging Lollipop Chart 20.3 Row 20.3.1 Cart C: Diverging Dot Plot print(paste0(&quot;Git Update Started at: &quot;, Sys.time())) CommitMessage &lt;- paste(&quot;updated on: &quot;, Sys.time(), sep = &quot;&quot;) wd &lt;- &quot;~/serdarbalci&quot; setorigin &lt;- &quot;git remote set-url origin git@github.com:sbalci/MyJournalWatch.git \\n&quot; gitCommand &lt;- paste(&quot;cd &quot;, wd, &quot; \\n git add . \\n git commit --message &#39;&quot;, CommitMessage, &quot;&#39; \\n&quot;, setorigin, &quot;git push origin master \\n&quot;, sep = &quot;&quot;) system(command = paste(gitCommand, &quot;\\n&quot;) , intern = TRUE, wait = TRUE) Sys.sleep(5) print(paste0(&quot;Git Update Ended at: &quot;, Sys.time())) 20.4 Describe results of analysis Copy/paste t-tests Directly to Manuscripts: https://neuropsychology.github.io/psycho.R//2018/06/19/analyze_ttest.html https://github.com/neuropsychology/psycho.R "],["citation.html", "Chapter 21 citation", " Chapter 21 citation My next citation is here1. “r dimensionBadge” “r altmetricBadge” “r cit_25783680”↩︎ "],["bbc-visual-and-data-journalism-cookbook-for-r-graphics.html", "Chapter 22 BBC Visual and Data Journalism cookbook for R graphics", " Chapter 22 BBC Visual and Data Journalism cookbook for R graphics https://bbc.github.io/rcookbook/ A brief introduction to bibliometrix https://cran.r-project.org/web/packages/bibliometrix/vignettes/bibliometrix-vignette.html Bibliographic Network Visualization for Academic Literature Reviews http://www.mburnamfink.com/blog/bibliographic-network-visualization-for-academic-literature-reviews https://embed.kumu.io/0b991b02bb20975fde904f4bf7433333#jpsp-top-50?s=%23doi-101037-0022-35147451252 More Than Words? Computer-Aided Text Analysis in Organizational Behavior and Psychology Research https://www.annualreviews.org/doi/10.1146/annurev-orgpsych-032117-104622 https://www.kumu.io/nicholasjkelley/jpsp-top-50 "],["knitcitations.html", "Chapter 23 knitcitations", " Chapter 23 knitcitations https://github.com/cboettig/knitcitations citation &quot;r citep(&quot;10.1890/11-0011.1&quot;)&quot; in text citation &quot;r citet(&quot;10.1098/rspb.2013.1372&quot;)&quot; in text write.bibtex(file=&quot;references.bib&quot;) "],["rcrossref.html", "Chapter 24 rcrossref", " Chapter 24 rcrossref https://github.com/ropensci/rcrossref "],["rorcid-tutorial.html", "Chapter 25 rorcid tutorial", " Chapter 25 rorcid tutorial https://ropensci.org/tutorials/rorcid_tutorial/ "],["rentrez-tutorial.html", "Chapter 26 rentrez tutorial", " Chapter 26 rentrez tutorial https://ropensci.org/tutorials/rentrez_tutorial/ "],["webscicorpus.html", "Chapter 27 WebSciCorpus", " Chapter 27 WebSciCorpus https://www.clarehooper.net/WebSciCorpus/ "],["web-of-science-wos-corpus-parsing-script.html", "Chapter 28 WEB OF SCIENCE (WOS) CORPUS | PARSING SCRIPT", " Chapter 28 WEB OF SCIENCE (WOS) CORPUS | PARSING SCRIPT https://docs.cortext.net/question/web-of-science-wos-corpus-parsing-script-2/ "],["t-lab-plus-2019.html", "Chapter 29 T-LAB PLUS 2019", " Chapter 29 T-LAB PLUS 2019 https://tlab.it/en/allegati/help_en_online/mmappe2.htm "],["tools-for-bibliometric-analyses.html", "Chapter 30 Tools for bibliometric analyses", " Chapter 30 Tools for bibliometric analyses https://ju.se/library/research--teaching-support/bibliometrics/tools-for-bibliometric-analyses.html "],["evidencepartners.html", "Chapter 31 evidencepartners", " Chapter 31 evidencepartners https://www.evidencepartners.com/ "],["r-script-for-creating-a-cross-citation-network.html", "Chapter 32 R script for creating a cross-citation network", " Chapter 32 R script for creating a cross-citation network https://www.researchgate.net/publication/327790285_R_script_for_creating_a_cross-citation_network Repository: https://github.com/arsiders/citation-network # RCitation - Quick Citation Network # Fall 2018 # A.R. Siders (siders@alumni.stanford.edu) # Creates a network of the citations among a set of academic papers. # Rationale: If full title of Article 2 is present in text of Article 1, Article 1 cites Article 2. # NOTE: Will only work in fields where full, unabbreviated titles are used in reference/bibliography citation format. # NOTE: Will have high error rate if titles are very short or comprised of common words (e.g., paper &quot;Vulnerability&quot; produced many false positives). Some errors result from authors using a shortened version of a title (e.g., only text before a colon) or incorrect citations or typos. Citation networks produced are therefore approximate and to be used primarily for exploration of the data. # NOTE: Error rate may be reduced by using only reference sections of the articles of interest, rather than full texts, but this will increase work required to prepare articles. # ==&gt; FIVE STEPS TO CITATION NETWORK # STEP 1. FORMAT INPUT # a. Papers: Folder of papers in txt format (UTF-8) organized *in SAME ORDER* as Titles # b. Titles: Column of paper titles in csv spreadsheet (Column #1) *in SAME ORDER* as documents in Papers folder. Need a header cell or top title will be removed. # Recommend naming all texts in Papers folder using author last name listed alphabetically. Organize Titles using same order. # STEP 2. PREP # set working directory setwd(&quot;C:\\[name of working space]&quot;) # make sure \\ not / in name setwd(&quot;C:/Users/User/OneDrive/Adaptive Capacity Text Mining/Citation Network Test/CitationNetwork Test Data&quot;) # load packages install.packages(c(&quot;tm&quot;,&quot;plyr&quot;)) library(tm) library(plyr) # STEP 3. LOAD INPUTS # a. Papers papers&lt;-Corpus(DirSource(&quot;[name of folder where papers located]&quot;)) papers&lt;-Corpus(DirSource(&quot;Papers&quot;)) # b. Titles titletable&lt;-read.csv(&quot;[name of titles file].csv&quot;) #make sure column has a header titletable&lt;-read.csv(&quot;TestTitles.csv&quot;) titles&lt;-as.vector(titletable[,1]) # load functions at bottom of this script (below Step 5) length(papers) length(titles) # STEP 4. RUN FUNCTION CitationNetwork&lt;-CreateCitationNetwork(papers,titles) # add date currentDate &lt;- Sys.Date() csvFileName &lt;- paste(&quot;CitationEdges&quot;,currentDate,&quot;.csv&quot;,sep=&quot;&quot;) # save results write.csv(CitationNetwork, file=csvFileName) # STEP 5. VISUALIZE NETWORK # Install Gephi or other network visualization software and load CitationEdges.csv # Load list of titles or other spreadsheet as nodes to visualize network # Gephi available at https://gephi.org/ # ===&gt; FUNCTIONS TO LOAD CreateCitationNetwork&lt;-function(papers,titles){ # prep papers corpus papers&lt;-tm_map(papers, content_transformer(tolower)) papers&lt;-tm_map(papers, removePunctuation) papers&lt;-tm_map(papers, removeNumbers) papers&lt;-tm_map(papers, stripWhitespace) # prep titles titles&lt;-removePunctuation(titles) titles&lt;-stripWhitespace(titles) titles&lt;-tolower(titles) # create citation true/false matrix Cites.TF&lt;-CiteMatrix(titles, papers) # format matrix into edges file CitationEdges&lt;-EdgesFormat(Cites.TF, titles) return(CitationEdges) } # format true/false matrix into edges file EdgesFormat&lt;-function(Cites.TF, titles){ #create an empty object to put information in edges&lt;-data.frame(matrix(NA), nrow=NA, ncol=NA) colnames(edges)&lt;- c(&quot;Source&quot;,&quot;Target&quot;,&quot;Weight&quot;) for (i in 1:length(Cites.TF)){ #for each document, run through all titles accross columns for (j in 1:ncol(Cites.TF)){ # for each title, see if document [row] cited that title [column] if (Cites.TF[i,j]==TRUE){ #if document is cited temp&lt;-data.frame(matrix(NA), nrow=NA, ncol=NA) colnames(temp)&lt;- c(&quot;Source&quot;,&quot;Target&quot;,&quot;Weight&quot;) # first column &lt;- document doing the citing temp[1,1]&lt;-titles[i] # second column &lt;- document being cited temp[1,2]&lt;-titles[j] # third column the yes/no [weight] temp[1,3]&lt;-1 temp[1,4]&lt;-&quot;Directed&quot; edges&lt;-rbind(edges,temp) } } } return(edges[-1,]) #-1 removes initial row of null values } # Citation true/false matrix CiteMatrix&lt;-function(search.vector, Ref.corpus){ # Creates a csv matrix with True/False for citation patterns citations&lt;-data.frame(matrix(NA, nrow = length(Ref.corpus), ncol=length(search.vector))) #Columns are the document being cited colnames(citations)&lt;-search.vector #Rows are the document doing the citing rownames(citations)&lt;-search.vector for (i in 1:length(search.vector)){ searchi&lt;-search.vector[i] papercite&lt;-grepl(searchi, Ref.corpus$content, fixed=TRUE) citations[,i]&lt;-papercite } return(citations) } The application of methods of social network analysis in bibliometrics and webometrics. Measures and tools https://www.researchgate.net/publication/327817518_The_application_of_methods_of_social_network_analysis_in_bibliometrics_and_webometrics_Measures_and_tools "],["scientominer-icr.html", "Chapter 33 ScientoMiner ICR", " Chapter 33 ScientoMiner ICR https://zenodo.org/record/1432557#.XItjfxO2k1J "],["onodo.html", "Chapter 34 onodo", " Chapter 34 onodo https://onodo.org/dashboard https://onodo.org/tutorials "],["bibexcel.html", "Chapter 35 BibExcel", " Chapter 35 BibExcel https://homepage.univie.ac.at/juan.gorraiz/bibexcel/ "],["scientometric-portal.html", "Chapter 36 Scientometric Portal", " Chapter 36 Scientometric Portal https://sites.google.com/site/hjamali/scientometric-portal "],["leydesdorff.html", "Chapter 37 leydesdorff", " Chapter 37 leydesdorff https://www.leydesdorff.net/software.htm "],["publish-or-perish.html", "Chapter 38 Publish or Perish", " Chapter 38 Publish or Perish https://harzing.com/resources/publish-or-perish "],["pajek-analysis-and-visualization-of-large-networks.html", "Chapter 39 Pajek: analysis and visualization of large networks", " Chapter 39 Pajek: analysis and visualization of large networks http://mrvar.fdv.uni-lj.si/pajek/ https://www.bioconductor.org/ ## try http:// if https:// URLs are not supported source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite() The Bioconductor 2018 Workshop Compilation https://bioconductor.github.io/BiocWorkshops/index.html https://github.com/Bioconductor/BiocWorkshops https://raw.githubusercontent.com/Bioconductor/BiocWorkshops/master/100_Morgan_RBiocForAll/ALL-phenoData.csv https://support.bioconductor.org/ https://bioconductor.org/help/course-materials/ https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=578954849_wF1QP81SIHdfr8b0kmZUOcsZcHYr&amp;clade=mammal&amp;org=Human&amp;db=hg38&amp;hgta_group=regulation&amp;hgta_track=knownGene&amp;hgta_table=0&amp;hgta_regionType=genome&amp;position=chr9%3A133252000-133280861&amp;hgta_outputType=primaryTable&amp;hgta_outFileName= https://bioconductor.github.io/BiocWorkshops/r-and-bioconductor-for-everyone-an-introduction.html Introduction to Bioconductor https://www.datacamp.com/community/tutorials/intro-bioconductor Important packages: - DNAStringSet - Biostrings - GenomicRanges https://bioconductor.org/packages https://support.bioconductor.org/ http://bioconductor.org/help/course-materials/ DESeq results to pathways in 60 Seconds with the fgsea package https://stephenturner.github.io/deseq-to-fgsea/ "],["bioconductor.html", "Chapter 40 Bioconductor 40.1 Courses &amp; Conferences", " Chapter 40 Bioconductor https://www.youtube.com/user/bioconductor 40.1 Courses &amp; Conferences https://www.bioconductor.org/help/course-materials/ "],["neuroconductor-tutorials.html", "Chapter 41 Neuroconductor Tutorials", " Chapter 41 Neuroconductor Tutorials https://neuroconductor.org/tutorials "],["neuroconductor-courses.html", "Chapter 42 Neuroconductor Courses", " Chapter 42 Neuroconductor Courses https://neuroconductor.org/courses An R interface for computational modeling of tumor progression https://bioconductor.org/packages/release/bioc/html/CancerInSilico.html https://bioconductor.org/packages/release/bioc/vignettes/CancerInSilico/inst/doc/CancerInSilico.html "],["running-a-cell-simulation.html", "Chapter 43 Running a Cell Simulation 43.1 Run Simple Simulation 43.2 Plot CellModel Object 43.3 Query Cell Information", " Chapter 43 Running a Cell Simulation 43.1 Run Simple Simulation 43.2 Plot CellModel Object 43.3 Query Cell Information "],["drugs.html", "Chapter 44 Drugs", " Chapter 44 Drugs "],["cell-types.html", "Chapter 45 Cell Types 45.1 Adding a Single Cell Type 45.2 Adding Multiple Cell Types 45.3 Getting Cell Type", " Chapter 45 Cell Types 45.1 Adding a Single Cell Type 45.2 Adding Multiple Cell Types 45.3 Getting Cell Type "],["pathways.html", "Chapter 46 Pathways 46.1 Calibrate Gene Expression Range 46.2 Generate Pathway Activity 46.3 Visualize Pathway Activity 46.4 Accounting for Model Effects 46.5 Normalize Pathway Activity", " Chapter 46 Pathways 46.1 Calibrate Gene Expression Range 46.2 Generate Pathway Activity 46.3 Visualize Pathway Activity 46.4 Accounting for Model Effects 46.5 Normalize Pathway Activity "],["simulating-bulk-gene-expression-data.html", "Chapter 47 Simulating Bulk Gene Expression Data 47.1 Simulating Microarray Data 47.2 Visualize Bulk Gene Expression Data", " Chapter 47 Simulating Bulk Gene Expression Data 47.1 Simulating Microarray Data 47.2 Visualize Bulk Gene Expression Data "],["simulating-single-cell-gene-expression-data.html", "Chapter 48 Simulating Single Cell Gene Expression Data 48.1 Cell Type Pathways 48.2 Simulating Single Cell RNA-seq 48.3 Visualize Single Cell Data", " Chapter 48 Simulating Single Cell Gene Expression Data 48.1 Cell Type Pathways 48.2 Simulating Single Cell RNA-seq 48.3 Visualize Single Cell Data "],["bcra.html", "Chapter 49 BCRA", " Chapter 49 BCRA https://cran.r-project.org/web/packages/BCRA/index.html "],["cgdsr.html", "Chapter 50 cgdsr", " Chapter 50 cgdsr cgdsr: R-Based API for Accessing the MSKCC Cancer Genomics Data Server (CGDS) https://cran.r-project.org/web/packages/cgdsr/index.html "],["tcgabiolinksgui.html", "Chapter 51 TCGAbiolinksGUI", " Chapter 51 TCGAbiolinksGUI https://bioconductor.org/packages/release/bioc/html/TCGAbiolinksGUI.html "],["rtcga.html", "Chapter 52 RTCGA", " Chapter 52 RTCGA "],["cancersubtypes.html", "Chapter 53 CancerSubtypes", " Chapter 53 CancerSubtypes "],["cancermutationanalysis.html", "Chapter 54 CancerMutationAnalysis", " Chapter 54 CancerMutationAnalysis "],["cancerclass.html", "Chapter 55 cancerclass", " Chapter 55 cancerclass "],["cancer.html", "Chapter 56 canceR", " Chapter 56 canceR "],["biocancer.html", "Chapter 57 bioCancer", " Chapter 57 bioCancer "],["tcgaretriever.html", "Chapter 58 TCGAretriever", " Chapter 58 TCGAretriever TCGAretriever: Retrieve Genomic and Clinical Data from TCGA https://cran.r-project.org/web/packages/TCGAretriever/index.html "],["tcga2stat.html", "Chapter 59 TCGA2STAT", " Chapter 59 TCGA2STAT https://cran.r-project.org/web/packages/TCGA2STAT/vignettes/TCGA2STAT.html "],["tciapathfinder.html", "Chapter 60 TCIApathfinder", " Chapter 60 TCIApathfinder TCIApathfinder: Client for the Cancer Imaging Archive REST API https://cran.r-project.org/web/packages/TCIApathfinder/index.html "],["milc.html", "Chapter 61 MILC", " Chapter 61 MILC MILC: MIcrosimulation Lung Cancer (MILC) model https://cran.r-project.org/web/packages/MILC/index.html "],["infiniumpurify.html", "Chapter 62 InfiniumPurify", " Chapter 62 InfiniumPurify InfiniumPurify: Estimate and Account for Tumor Purity in Cancer Methylation Data Analysis https://cran.r-project.org/web/packages/InfiniumPurify/index.html "],["rclone.html", "Chapter 63 rclone", " Chapter 63 rclone https://rclone.org/drive/ "],["rmdrive.html", "Chapter 64 rmdrive", " Chapter 64 rmdrive https://github.com/ekothe/rmdrive rstudioapi::selectDirectory() xaringan:::inf_mr() Load required packages Load required packages Load required packages Gerekli paketleri yükle library(tidyverse) "],["tips.html", "Chapter 65 tips", " Chapter 65 tips "],["environment-memory.html", "Chapter 66 environment memory", " Chapter 66 environment memory http://r-statistics.co/R-Tutorial.html As you create new variables, by default they get store in what is called a global environment. a &lt;- 10 b &lt;- 20 ls() # list objects in global env rm(a) # delete the object ‘a’ rm(list = ls()) # caution: delete all objects in .GlobalEnv gc() # free system memory However if you choose, you can create a new environment and store them there. rm(list=ls()) # remove all objects in work space env1 &lt;- new.env() # create a new environment assign(“a”, 3, envir = env1) # store a=3 inside env1 ls() # returns objects in .GlobalEnv ls(env1) # returns objects in env1 get(‘a’, envir=env1) # retrieve value from env1 sort(vec1) # ascending sort sort(vec1, decreasing = TRUE) # Descending sort Sorting can also be achieved using the order() function which returns the indices of elements in ascending order. vec1[order(vec1)] # ascending sort vec1[rev(order(vec1))] # descending sort seq(1, 10, by = 2) # diff between adj elements is 2 seq(1, 10, length=25) # length of the vector is 25 rep(1, 5) # repeat 1, five times. rep(1:3, 5) # repeat 1:3, 5 times rep(1:3, each=5) # repeat 1 to 3, each 5 times. subset(airquality, Day == 1, select = -Temp) # select Day=1 and exclude ‘Temp’ airquality[which(airquality$Day==1), -c(4)] # same as above set.seed(100) trainIndex &lt;- sample(c(1:nrow(airquality)), size=nrow(airquality)*0.7, replace=F) # get test sample indices airquality[trainIndex, ] # training data airquality[-trainIndex, ] # test data if(checkConditionIfTrue) { ….statements.. ….statements.. } else { # place the ‘else’ in same line as ‘}’ ….statements.. ….statements.. } for(counterVar in c(1:n)){ …. statements.. } 66.0.1 Compare Means "],["infer.html", "Chapter 67 infer", " Chapter 67 infer Randomization Examples using nycflights13 flights data https://cran.r-project.org/web/packages/infer/vignettes/flights_examples.html Hypothesis tests One numerical variable (mean) One numerical variable (median) One categorical (one proportion) null_distn &lt;- fli_small %&gt;% specify(response = day_hour, success = &quot;morning&quot;) %&gt;% hypothesize(null = &quot;point&quot;, p = .5) %&gt;% generate(reps = 1000, type = &quot;simulate&quot;) %&gt;% calculate(stat = &quot;prop&quot;) ggplot(null_distn, aes(x = stat)) + geom_bar() + geom_vline(xintercept = p_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &lt;= p_hat) * 2) p_value 0.132 Logical variables will be coerced to factors: null_distn &lt;- fli_small %&gt;% mutate(day_hour_logical = (day_hour == &quot;morning&quot;)) %&gt;% specify(response = day_hour_logical, success = &quot;TRUE&quot;) %&gt;% hypothesize(null = &quot;point&quot;, p = .5) %&gt;% generate(reps = 1000, type = &quot;simulate&quot;) %&gt;% calculate(stat = &quot;prop&quot;) Two categorical (2 level) variables d_hat &lt;- fli_small %&gt;% group_by(season) %&gt;% summarize(prop = mean(day_hour == &quot;morning&quot;)) %&gt;% summarize(diff(prop)) %&gt;% pull() null_distn &lt;- fli_small %&gt;% specify(day_hour ~ season, success = &quot;morning&quot;) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in props&quot;, order = c(&quot;winter&quot;, &quot;summer&quot;)) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = d_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &lt;= d_hat) * 2) %&gt;% pull() ## [1] 0.758 One categorical (&gt;2 level) - GoF Chisq_hat &lt;- fli_small %&gt;% specify(response = origin) %&gt;% hypothesize(null = &quot;point&quot;, p = c(&quot;EWR&quot; = .33, &quot;JFK&quot; = .33, &quot;LGA&quot; = .34)) %&gt;% calculate(stat = &quot;Chisq&quot;) null_distn &lt;- fli_small %&gt;% specify(response = origin) %&gt;% hypothesize(null = &quot;point&quot;, p = c(&quot;EWR&quot; = .33, &quot;JFK&quot; = .33, &quot;LGA&quot; = .34)) %&gt;% generate(reps = 1000, type = &quot;simulate&quot;) %&gt;% calculate(stat = &quot;Chisq&quot;) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = pull(Chisq_hat), color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &gt;= pull(Chisq_hat))) %&gt;% pull() ## [1] 0.002 Two categorical (&gt;2 level) variables Chisq_hat &lt;- fli_small %&gt;% chisq_stat(formula = day_hour ~ origin) null_distn &lt;- fli_small %&gt;% specify(day_hour ~ origin, success = &quot;morning&quot;) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;Chisq&quot;) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = pull(Chisq_hat), color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &gt;= pull(Chisq_hat))) %&gt;% pull() ## [1] 0.017 One numerical variable, one categorical (2 levels) (diff in means) d_hat &lt;- fli_small %&gt;% group_by(season) %&gt;% summarize(mean_stat = mean(dep_delay)) %&gt;% # Since summer - winter summarize(-diff(mean_stat)) %&gt;% pull() null_distn &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% # alt: response = dep_delay, # explanatory = season hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;summer&quot;, &quot;winter&quot;)) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = d_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &lt;= d_hat) * 2) %&gt;% pull() ## [1] 1.574 One numerical variable, one categorical (2 levels) (diff in medians) d_hat &lt;- fli_small %&gt;% group_by(season) %&gt;% summarize(median_stat = median(dep_delay)) %&gt;% # Since summer - winter summarize(-diff(median_stat)) %&gt;% pull() null_distn &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% # alt: response = dep_delay, # explanatory = season hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in medians&quot;, order = c(&quot;summer&quot;, &quot;winter&quot;)) ggplot(null_distn, aes(x = stat)) + geom_bar() + geom_vline(xintercept = d_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &gt;= d_hat) * 2) %&gt;% pull() ## [1] 0.068 One numerical, one categorical (&gt;2 levels) - ANOVA F_hat &lt;- anova( aov(formula = arr_delay ~ origin, data = fli_small) )$`F value`[1] null_distn &lt;- fli_small %&gt;% specify(arr_delay ~ origin) %&gt;% # alt: response = arr_delay, # explanatory = origin hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;F&quot;) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = F_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &gt;= F_hat)) %&gt;% pull() ## [1] 0.351 Two numerical vars - SLR slope_hat &lt;- lm(arr_delay ~ dep_delay, data = fli_small) %&gt;% broom::tidy() %&gt;% filter(term == &quot;dep_delay&quot;) %&gt;% pull(estimate) null_distn &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;slope&quot;) ggplot(null_distn, aes(x = stat)) + geom_density() + geom_vline(xintercept = slope_hat, color = &quot;red&quot;) null_distn %&gt;% summarize(p_value = mean(stat &gt;= slope_hat) * 2) %&gt;% pull() ## [1] 0 Confidence intervals One numerical (one mean) x_bar &lt;- fli_small %&gt;% summarize(mean(arr_delay)) %&gt;% pull() boot &lt;- fli_small %&gt;% specify(response = arr_delay) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;mean&quot;) %&gt;% pull() c(lower = x_bar - 2 * sd(boot), upper = x_bar + 2 * sd(boot)) ## lower upper ## 1.122209 8.021791 One categorical (one proportion) p_hat &lt;- fli_small %&gt;% summarize(mean(day_hour == &quot;morning&quot;)) %&gt;% pull() boot &lt;- fli_small %&gt;% specify(response = day_hour, success = &quot;morning&quot;) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;prop&quot;) %&gt;% pull() c(lower = p_hat - 2 * sd(boot), upper = p_hat + 2 * sd(boot)) ## lower upper ## 0.4194756 0.5125244 One numerical variable, one categorical (2 levels) (diff in means) d_hat &lt;- fli_small %&gt;% group_by(season) %&gt;% summarize(mean_stat = mean(arr_delay)) %&gt;% # Since summer - winter summarize(-diff(mean_stat)) %&gt;% pull() boot &lt;- fli_small %&gt;% specify(arr_delay ~ season) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;summer&quot;, &quot;winter&quot;)) %&gt;% pull() c(lower = d_hat - 2 * sd(boot), upper = d_hat + 2 * sd(boot)) ## lower upper ## -7.704370 6.213971 Two categorical variables (diff in proportions) d_hat &lt;- fli_small %&gt;% group_by(season) %&gt;% summarize(prop = mean(day_hour == &quot;morning&quot;)) %&gt;% # Since summer - winter summarize(-diff(prop)) %&gt;% pull() boot &lt;- fli_small %&gt;% specify(day_hour ~ season, success = &quot;morning&quot;) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;diff in props&quot;, order = c(&quot;summer&quot;, &quot;winter&quot;)) %&gt;% pull() c(lower = d_hat - 2 * sd(boot), upper = d_hat + 2 * sd(boot)) ## lower upper ## -0.07149487 0.11258550 Two numerical vars - SLR slope_hat &lt;- lm(arr_delay ~ dep_delay, data = fli_small) %&gt;% broom::tidy() %&gt;% filter(term == &quot;dep_delay&quot;) %&gt;% pull(estimate) boot &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;slope&quot;) %&gt;% pull() c(lower = slope_hat - 2 * sd(boot), upper = slope_hat + 2 * sd(boot)) ## lower upper ## 0.9657595 1.0681384 --- Examples using mtcars data https://cran.r-project.org/web/packages/infer/vignettes/mtcars_examples.html Examples using mtcars data Chester Ismay and Andrew Bray 2018-01-05 Note: The type argument in generate() is automatically filled based on the entries for specify() and hypothesize(). It can be removed throughout the examples that follow. It is left in to reiterate the type of generation process being performed. Data preparation library(infer) library(dplyr) mtcars &lt;- mtcars %&gt;% mutate(cyl = factor(cyl), vs = factor(vs), am = factor(am), gear = factor(gear), carb = factor(carb)) # For reproducibility set.seed(2018) One numerical variable (mean) mtcars %&gt;% specify(response = mpg) %&gt;% # formula alt: mpg ~ NULL hypothesize(null = &quot;point&quot;, mu = 25) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;mean&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 26.6 ## 2 2 25.1 ## 3 3 25.2 ## 4 4 24.7 ## 5 5 24.6 ## 6 6 25.8 ## 7 7 24.7 ## 8 8 25.6 ## 9 9 25.0 ## 10 10 25.1 ## # ... with 90 more rows One numerical variable (median) mtcars %&gt;% specify(response = mpg) %&gt;% # formula alt: mpg ~ NULL hypothesize(null = &quot;point&quot;, med = 26) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;median&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 28.2 ## 2 2 27.2 ## 3 3 26.2 ## 4 4 26 ## 5 5 26.5 ## 6 6 24.5 ## 7 7 26 ## 8 8 28.2 ## 9 9 28.2 ## 10 10 23.2 ## # ... with 90 more rows One categorical (2 level) variable mtcars %&gt;% specify(response = am, success = &quot;1&quot;) %&gt;% # formula alt: am ~ NULL hypothesize(null = &quot;point&quot;, p = .25) %&gt;% generate(reps = 100, type = &quot;simulate&quot;) %&gt;% calculate(stat = &quot;prop&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;fct&gt; &lt;dbl&gt; ## 1 1 0.375 ## 2 2 0.0625 ## 3 3 0.125 ## 4 4 0.25 ## 5 5 0.188 ## 6 6 0.406 ## 7 7 0.219 ## 8 8 0.375 ## 9 9 0.344 ## 10 10 0.188 ## # ... with 90 more rows Two categorical (2 level) variables mtcars %&gt;% specify(am ~ vs, success = &quot;1&quot;) %&gt;% # alt: response = am, explanatory = vs hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in props&quot;, order = c(&quot;0&quot;, &quot;1&quot;)) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.421 ## 2 2 -0.167 ## 3 3 -0.421 ## 4 4 -0.0397 ## 5 5 0.0873 ## 6 6 -0.0397 ## 7 7 -0.0397 ## 8 8 -0.0397 ## 9 9 0.0873 ## 10 10 -0.167 ## # ... with 90 more rows One categorical (&gt;2 level) - GoF mtcars %&gt;% specify(cyl ~ NULL) %&gt;% # alt: response = cyl hypothesize(null = &quot;point&quot;, p = c(&quot;4&quot; = .5, &quot;6&quot; = .25, &quot;8&quot; = .25)) %&gt;% generate(reps = 100, type = &quot;simulate&quot;) %&gt;% calculate(stat = &quot;Chisq&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;fct&gt; &lt;dbl&gt; ## 1 1 6.75 ## 2 2 1.69 ## 3 3 3.19 ## 4 4 1.69 ## 5 5 6 ## 6 6 2.69 ## 7 7 4.75 ## 8 8 0.75 ## 9 9 0.688 ## 10 10 3.69 ## # ... with 90 more rows Two categorical (&gt;2 level) variables mtcars %&gt;% specify(cyl ~ am) %&gt;% # alt: response = cyl, explanatory = am hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;Chisq&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1.34 ## 2 2 1.63 ## 3 3 1.63 ## 4 4 2.63 ## 5 5 3.90 ## 6 6 1.74 ## 7 7 0.126 ## 8 8 1.74 ## 9 9 1.34 ## 10 10 1.34 ## # ... with 90 more rows One numerical variable one categorical (2 levels) (diff in means) mtcars %&gt;% specify(mpg ~ am) %&gt;% # alt: response = mpg, explanatory = am hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;0&quot;, &quot;1&quot;)) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -1.10 ## 2 2 0.217 ## 3 3 -1.08 ## 4 4 -3.80 ## 5 5 3.08 ## 6 6 0.489 ## 7 7 2.34 ## 8 8 4.10 ## 9 9 -1.86 ## 10 10 -0.210 ## # ... with 90 more rows One numerical variable one categorical (2 levels) (diff in medians) mtcars %&gt;% specify(mpg ~ am) %&gt;% # alt: response = mpg, explanatory = am hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;diff in medians&quot;, order = c(&quot;0&quot;, &quot;1&quot;)) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.5 ## 2 2 -1.10 ## 3 3 5.20 ## 4 4 1.8 ## 5 5 0.5 ## 6 6 3.3 ## 7 7 -1.60 ## 8 8 -2.3 ## 9 9 2.90 ## 10 10 -0.5 ## # ... with 90 more rows One numerical one categorical (&gt;2 levels) - ANOVA mtcars %&gt;% specify(mpg ~ cyl) %&gt;% # alt: response = mpg, explanatory = cyl hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;F&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1.43 ## 2 2 1.65 ## 3 3 0.318 ## 4 4 0.393 ## 5 5 1.05 ## 6 6 0.826 ## 7 7 1.32 ## 8 8 0.833 ## 9 9 0.144 ## 10 10 0.365 ## # ... with 90 more rows Two numerical vars - SLR mtcars %&gt;% specify(mpg ~ hp) %&gt;% # alt: response = mpg, explanatory = cyl hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 100, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;slope&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.0151 ## 2 2 0.00224 ## 3 3 -0.0120 ## 4 4 0.00292 ## 5 5 0.0203 ## 6 6 -0.00730 ## 7 7 -0.0246 ## 8 8 0.00555 ## 9 9 0.0109 ## 10 10 0.0176 ## # ... with 90 more rows One numerical variable (standard deviation) Not currently implemented mtcars %&gt;% specify(response = mpg) %&gt;% # formula alt: mpg ~ NULL hypothesize(null = &quot;point&quot;, sigma = 5) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;sd&quot;) Confidence intervals One numerical (one mean) mtcars %&gt;% specify(response = mpg) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;mean&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 19.6 ## 2 2 21.8 ## 3 3 18.7 ## 4 4 19.2 ## 5 5 21.6 ## 6 6 19.9 ## 7 7 20.7 ## 8 8 19.3 ## 9 9 21.2 ## 10 10 21.3 ## # ... with 90 more rows One numerical (one median) mtcars %&gt;% specify(response = mpg) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;median&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 19.2 ## 2 2 20.1 ## 3 3 21 ## 4 4 17.8 ## 5 5 20.1 ## 6 6 19.2 ## 7 7 18.4 ## 8 8 19.2 ## 9 9 19.2 ## 10 10 18.0 ## # ... with 90 more rows One numerical (standard deviation) mtcars %&gt;% specify(response = mpg) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;sd&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 5.28 ## 2 2 6.74 ## 3 3 5.29 ## 4 4 5.41 ## 5 5 5.56 ## 6 6 5.65 ## 7 7 6.17 ## 8 8 6.40 ## 9 9 6.31 ## 10 10 6.11 ## # ... with 90 more rows One categorical (one proportion) mtcars %&gt;% specify(response = am, success = &quot;1&quot;) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;prop&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.375 ## 2 2 0.406 ## 3 3 0.406 ## 4 4 0.312 ## 5 5 0.312 ## 6 6 0.469 ## 7 7 0.438 ## 8 8 0.281 ## 9 9 0.438 ## 10 10 0.5 ## # ... with 90 more rows One numerical variable one categorical (2 levels) (diff in means) mtcars %&gt;% specify(mpg ~ am) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;0&quot;, &quot;1&quot;)) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -9.38 ## 2 2 -5.11 ## 3 3 -4.88 ## 4 4 -5.39 ## 5 5 -9.19 ## 6 6 -7.20 ## 7 7 -5.34 ## 8 8 -3.20 ## 9 9 -5.95 ## 10 10 -11.0 ## # ... with 90 more rows Two categorical variables (diff in proportions) mtcars %&gt;% specify(am ~ vs, success = &quot;1&quot;) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;diff in props&quot;, order = c(&quot;0&quot;, &quot;1&quot;)) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.352 ## 2 2 -0.15 ## 3 3 -0.294 ## 4 4 -0.254 ## 5 5 -0.438 ## 6 6 -0.126 ## 7 7 -0.188 ## 8 8 0.167 ## 9 9 -0.143 ## 10 10 -0.5 ## # ... with 90 more rows Two numerical vars - SLR mtcars %&gt;% specify(mpg ~ hp) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;slope&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.0850 ## 2 2 -0.0512 ## 3 3 -0.0736 ## 4 4 -0.0569 ## 5 5 -0.0930 ## 6 6 -0.0659 ## 7 7 -0.0710 ## 8 8 -0.0767 ## 9 9 -0.0556 ## 10 10 -0.0627 ## # ... with 90 more rows Two numerical vars - correlation mtcars %&gt;% specify(mpg ~ hp) %&gt;% generate(reps = 100, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;correlation&quot;) ## # A tibble: 100 x 2 ## replicate stat ## &lt;int&gt; &lt;dbl&gt; ## 1 1 -0.821 ## 2 2 -0.812 ## 3 3 -0.802 ## 4 4 -0.723 ## 5 5 -0.885 ## 6 6 -0.777 ## 7 7 -0.752 ## 8 8 -0.758 ## 9 9 -0.826 ## 10 10 -0.779 ## # ... with 90 more rows --- Two sample t test example using nycflights13 flights data https://cran.r-project.org/web/packages/infer/vignettes/two_sample_t.html Two sample t test example using nycflights13 flights data Chester Ismay 2018-11-15 Note: The type argument in generate() is automatically filled based on the entries for specify() and hypothesize(). It can be removed throughout the examples that follow. It is left in to reiterate the type of generation process being performed. Data preparation library(nycflights13) library(dplyr) library(stringr) library(infer) set.seed(2017) fli_small &lt;- flights %&gt;% sample_n(size = 500) %&gt;% mutate(half_year = case_when( between(month, 1, 6) ~ &quot;h1&quot;, between(month, 7, 12) ~ &quot;h2&quot; )) %&gt;% mutate(day_hour = case_when( between(hour, 1, 12) ~ &quot;morning&quot;, between(hour, 13, 24) ~ &quot;not morning&quot; )) %&gt;% select(arr_delay, dep_delay, half_year, day_hour, origin, carrier) Two numeric - arr_delay, dep_delay Two categories half_year (&quot;h1&quot;, &quot;h2&quot;), day_hour (&quot;morning&quot;, &quot;not morning&quot;) Three categories - origin (&quot;EWR&quot;, &quot;JFK&quot;, &quot;LGA&quot;) Sixteen categories - carrier One numerical variable, one categorical (2 levels) Calculate observed statistic The recommended approach is to use specify() %&gt;% calculate(): obs_t &lt;- fli_small %&gt;% specify(arr_delay ~ half_year) %&gt;% calculate(stat = &quot;t&quot;, order = c(&quot;h1&quot;, &quot;h2&quot;)) ## Warning: Removed 15 rows containing missing values. The observed t statistic is stat 0.8685 . Or using t_test in infer obs_t &lt;- fli_small %&gt;% t_test(formula = arr_delay ~ half_year, alternative = &quot;two_sided&quot;, order = c(&quot;h1&quot;, &quot;h2&quot;)) %&gt;% dplyr::pull(statistic) The observed t statistic is 0.8685. Or using another shortcut function in infer: obs_t &lt;- fli_small %&gt;% t_stat(formula = arr_delay ~ half_year, order = c(&quot;h1&quot;, &quot;h2&quot;)) The observed t statistic is statistic 0.8685 . Randomization approach to t-statistic t_null_perm &lt;- fli_small %&gt;% # alt: response = arr_delay, explanatory = half_year specify(arr_delay ~ half_year) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% generate(reps = 1000, type = &quot;permute&quot;) %&gt;% calculate(stat = &quot;t&quot;, order = c(&quot;h1&quot;, &quot;h2&quot;)) ## Warning: Removed 15 rows containing missing values. visualize(t_null_perm) + shade_p_value(obs_stat = obs_t, direction = &quot;two_sided&quot;) Calculate the randomization-based p-value t_null_perm %&gt;% get_p_value(obs_stat = obs_t, direction = &quot;two_sided&quot;) p_value 0.408 Theoretical distribution t_null_theor &lt;- fli_small %&gt;% # alt: response = arr_delay, explanatory = half_year specify(arr_delay ~ half_year) %&gt;% hypothesize(null = &quot;independence&quot;) %&gt;% # generate() ## Not used for theoretical calculate(stat = &quot;t&quot;, order = c(&quot;h1&quot;, &quot;h2&quot;)) ## Warning: Removed 15 rows containing missing values. visualize(t_null_theor, method = &quot;theoretical&quot;) + shade_p_value(obs_stat = obs_t, direction = &quot;two_sided&quot;) ## Warning: Check to make sure the conditions have been met for the ## theoretical method. {infer} currently does not check these for you. Overlay appropriate t distribution on top of permuted t-statistics visualize(t_null_perm, method = &quot;both&quot;) + shade_p_value(obs_stat = obs_t, direction = &quot;two_sided&quot;) ## Warning: Check to make sure the conditions have been met for the ## theoretical method. {infer} currently does not check these for you. Compute theoretical p-value fli_small %&gt;% t_test(formula = arr_delay ~ half_year, alternative = &quot;two_sided&quot;, order = c(&quot;h1&quot;, &quot;h2&quot;)) %&gt;% dplyr::pull(p_value) ## [1] 0.3855 67.0.1 Compare Proportions chisq.test {stats} R Documentation Pearson&#39;s Chi-squared Test for Count Data Description chisq.test performs chi-squared contingency table tests and goodness-of-fit tests. Usage chisq.test(x, y = NULL, correct = TRUE, p = rep(1/length(x), length(x)), rescale.p = FALSE, simulate.p.value = FALSE, B = 2000) Arguments x a numeric vector or matrix. x and y can also both be factors. y a numeric vector; ignored if x is a matrix. If x is a factor, y should be a factor of the same length. correct a logical indicating whether to apply continuity correction when computing the test statistic for 2 by 2 tables: one half is subtracted from all |O - E| differences; however, the correction will not be bigger than the differences themselves. No correction is done if simulate.p.value = TRUE. p a vector of probabilities of the same length of x. An error is given if any entry of p is negative. rescale.p a logical scalar; if TRUE then p is rescaled (if necessary) to sum to 1. If rescale.p is FALSE, and p does not sum to 1, an error is given. simulate.p.value a logical indicating whether to compute p-values by Monte Carlo simulation. B an integer specifying the number of replicates used in the Monte Carlo test. Details If x is a matrix with one row or column, or if x is a vector and y is not given, then a goodness-of-fit test is performed (x is treated as a one-dimensional contingency table). The entries of x must be non-negative integers. In this case, the hypothesis tested is whether the population probabilities equal those in p, or are all equal if p is not given. If x is a matrix with at least two rows and columns, it is taken as a two-dimensional contingency table: the entries of x must be non-negative integers. Otherwise, x and y must be vectors or factors of the same length; cases with missing values are removed, the objects are coerced to factors, and the contingency table is computed from these. Then Pearson&#39;s chi-squared test is performed of the null hypothesis that the joint distribution of the cell counts in a 2-dimensional contingency table is the product of the row and column marginals. If simulate.p.value is FALSE, the p-value is computed from the asymptotic chi-squared distribution of the test statistic; continuity correction is only used in the 2-by-2 case (if correct is TRUE, the default). Otherwise the p-value is computed for a Monte Carlo test (Hope, 1968) with B replicates. In the contingency table case simulation is done by random sampling from the set of all contingency tables with given marginals, and works only if the marginals are strictly positive. Continuity correction is never used, and the statistic is quoted without it. Note that this is not the usual sampling situation assumed for the chi-squared test but rather that for Fisher&#39;s exact test. In the goodness-of-fit case simulation is done by random sampling from the discrete distribution specified by p, each sample being of size n = sum(x). This simulation is done in R and may be slow. Value A list with class &quot;htest&quot; containing the following components: statistic the value the chi-squared test statistic. parameter the degrees of freedom of the approximate chi-squared distribution of the test statistic, NA if the p-value is computed by Monte Carlo simulation. p.value the p-value for the test. method a character string indicating the type of test performed, and whether Monte Carlo simulation or continuity correction was used. data.name a character string giving the name(s) of the data. observed the observed counts. expected the expected counts under the null hypothesis. residuals the Pearson residuals, (observed - expected) / sqrt(expected). stdres standardized residuals, (observed - expected) / sqrt(V), where V is the residual cell variance (Agresti, 2007, section 2.4.5 for the case where x is a matrix, n * p * (1 - p) otherwise). Source The code for Monte Carlo simulation is a C translation of the Fortran algorithm of Patefield (1981). References Hope, A. C. A. (1968). A simplified Monte Carlo significance test procedure. Journal of the Royal Statistical Society Series B, 30, 582–598. http://www.jstor.org/stable/2984263. Patefield, W. M. (1981). Algorithm AS 159: An efficient method of generating r x c tables with given row and column totals. Applied Statistics, 30, 91–97. doi: 10.2307/2346669. Agresti, A. (2007). An Introduction to Categorical Data Analysis, 2nd ed. New York: John Wiley &amp; Sons. Page 38. See Also For goodness-of-fit testing, notably of continuous distributions, ks.test. Examples ## From Agresti(2007) p.39 M &lt;- as.table(rbind(c(762, 327, 468), c(484, 239, 477))) dimnames(M) &lt;- list(gender = c(&quot;F&quot;, &quot;M&quot;), party = c(&quot;Democrat&quot;,&quot;Independent&quot;, &quot;Republican&quot;)) (Xsq &lt;- chisq.test(M)) # Prints test summary Xsq$observed # observed counts (same as M) Xsq$expected # expected counts under the null Xsq$residuals # Pearson residuals Xsq$stdres # standardized residuals ## Effect of simulating p-values x &lt;- matrix(c(12, 5, 7, 7), ncol = 2) chisq.test(x)$p.value # 0.4233 chisq.test(x, simulate.p.value = TRUE, B = 10000)$p.value # around 0.29! ## Testing for population probabilities ## Case A. Tabulated data x &lt;- c(A = 20, B = 15, C = 25) chisq.test(x) chisq.test(as.table(x)) # the same x &lt;- c(89,37,30,28,2) p &lt;- c(40,20,20,15,5) try( chisq.test(x, p = p) # gives an error ) chisq.test(x, p = p, rescale.p = TRUE) # works p &lt;- c(0.40,0.20,0.20,0.19,0.01) # Expected count in category 5 # is 1.86 &lt; 5 ==&gt; chi square approx. chisq.test(x, p = p) # maybe doubtful, but is ok! chisq.test(x, p = p, simulate.p.value = TRUE) ## Case B. Raw data x &lt;- trunc(5 * runif(100)) chisq.test(table(x)) # NOT &#39;chisq.test(x)&#39;! [Package stats version 3.5.1 Index] "],["infer-1.html", "Chapter 68 infer", " Chapter 68 infer Chi-squared test example using nycflights13 flights data https://cran.r-project.org/web/packages/infer/vignettes/chisq_test.html "],["comparisons-between-correlations.html", "Chapter 69 comparisons between correlations", " Chapter 69 comparisons between correlations http://comparingcorrelations.org/ "],["exploring-correlations-in-r-with-corrr.html", "Chapter 70 Exploring correlations in R with corrr", " Chapter 70 Exploring correlations in R with corrr https://drsimonj.svbtle.com/exploring-correlations-in-r-with-corrr output: html_notebook: fig_caption: yes highlight: tango number_sections: yes theme: paper toc: yes toc_depth: 5 toc_float: yes html_document: code_folding: hide df_print: kable keep_md: yes number_sections: yes theme: cerulean toc: yes toc_float: yes highlight: kate "],["data-list.html", "Chapter 71 Data List", " Chapter 71 Data List Learning Clinical Epidemiology with R http://datacompass.lshtm.ac.uk/599/ ISLR acs Download, Manipulate, and Present American Community Survey and Decennial Data from the US Census https://cran.r-project.org/web/packages/acs/index.html eurostat Tools for Eurostat Open Data https://cran.r-project.org/web/packages/eurostat/index.html Rilostat https://github.com/ilostat/Rilostat OECD https://cran.r-project.org/web/packages/OECD/vignettes/oecd_vignette_main.pdf gapminder Factfulness: Building Gapminder Income Mountains http://staff.math.su.se/hoehle/blog/2018/07/02/factfulness.html nycflights13 fivethirtyeight projects https://www.analyticsvidhya.com/blog/2014/11/data-science-projects-learn/ Miscellaneous Datasets http://users.stat.ufl.edu/~winner/datasets.html datasets https://www.rdocumentation.org/packages/datasets/versions/3.5.1 https://livebook.datascienceheroes.com/ "],["rdatatable.html", "Chapter 72 Rdatatable 72.1 Introduction to data.table", " Chapter 72 Rdatatable https://github.com/Rdatatable 72.1 Introduction to data.table https://cloud.r-project.org/web/packages/data.table/vignettes/datatable-intro.html DT = data.table( ID = c(&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;a&quot;,&quot;a&quot;,&quot;c&quot;), a = 1:6, b = 7:12, c = 13:18 ) DT class(DT$ID) getOption(&quot;datatable.print.nrows&quot;) ans &lt;- flights[origin == &quot;JFK&quot; &amp; month == 6L] head(ans) ans &lt;- flights[1:2] ans ans &lt;- flights[origin == &quot;JFK&quot; &amp; month == 6L][1:2] head(ans) ans &lt;- flights[order(origin, -dest)] head(ans) ans &lt;- flights[, arr_delay] head(ans) ans &lt;- flights[, arr_delay, dest] head(ans) ans &lt;- flights[, list(arr_delay)] head(ans) ans &lt;- flights[, .(arr_delay)] head(ans) ans &lt;- flights[, .(arr_delay, dep_delay)] head(ans) ans &lt;- flights[, .(delay_arr = arr_delay, delay_dep = dep_delay)] head(ans) ans &lt;- flights[, sum( (arr_delay + dep_delay) &lt; 0 )] ans ans &lt;- flights[origin == &quot;JFK&quot; &amp; month == 6L, .(m_arr = mean(arr_delay), m_dep = mean(dep_delay))] ans ans &lt;- flights[origin == &quot;JFK&quot; &amp; month == 6L, length(dest)] ans ans &lt;- flights[origin == &quot;JFK&quot; &amp; month == 6L, .N] ans ans &lt;- flights[, c(&quot;arr_delay&quot;, &quot;dep_delay&quot;)] head(ans) select_cols = c(&quot;arr_delay&quot;, &quot;dep_delay&quot;) flights[ , ..select_cols] flights[ , select_cols, with = FALSE] ans &lt;- flights[, !c(&quot;arr_delay&quot;, &quot;dep_delay&quot;)] ans &lt;- flights[, -c(&quot;arr_delay&quot;, &quot;dep_delay&quot;)] ans &lt;- flights[, year:day] ans &lt;- flights[, day:year] ans &lt;- flights[, -(year:day)] ans &lt;- flights[, !(year:day)] ans &lt;- flights[, .(.N), by = .(origin)] ans ans &lt;- flights[, .(.N), by = &quot;origin&quot;] ans ans &lt;- flights[, .N, by = origin] ans ans &lt;- flights[carrier == &quot;AA&quot;, .N, by = origin] ans ans &lt;- flights[carrier == &quot;AA&quot;, .N, by = .(origin, dest)] head(ans) ans &lt;- flights[carrier == &quot;AA&quot;, .N, by = c(&quot;origin&quot;, &quot;dest&quot;)] ans ans &lt;- flights[carrier == &quot;AA&quot;, .(mean(arr_delay), mean(dep_delay)), by = .(origin, dest, month)] ans ans &lt;- flights[carrier == &quot;AA&quot;, .(mean(arr_delay), mean(dep_delay)), keyby = .(origin, dest, month)] ans ans &lt;- flights[carrier == &quot;AA&quot;, .N, by = .(origin, dest)] ans ans &lt;- flights[carrier == &quot;AA&quot;, .N, by = .(origin, dest)][order(origin, -dest)] head(ans, 10) ans &lt;- flights[, .N, .(dep_delay&gt;0, arr_delay&gt;0)] ans flights[, .N, .(dep_delayed = dep_delay&gt;0, arr_delayed = arr_delay&gt;0)] "],["cheat-sheet.html", "Chapter 73 cheat sheet 73.1 Subsetting Rows Using i 73.2 Manipulating on Columns in j 73.3 Doing j by Group 73.4 Adding/Updating Columns By Reference in j Using := 73.5 Indexing And Keys", " Chapter 73 cheat sheet https://www.datacamp.com/community/tutorials/data-table-cheat-sheet https://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf http://r-datatable.com https://github.com/Rdatatable/data.table/wiki 73.1 Subsetting Rows Using i 73.2 Manipulating on Columns in j sonuç vektör olarak alınacaksa sadece sütun ismi yazılıyor sonuç data.frame olarak alınacaksa sütun ismi önünde . yazılıyor tek sütun üzerinden özet alma birden fazla sütun üzerinden özet alma 73.3 Doing j by Group 73.4 Adding/Updating Columns By Reference in j Using := 73.5 Indexing And Keys Installations for Data Science. Anaconda, RStudio, Spark, TensorFlow, AWS (Amazon Web Services). https://medium.com/@GalarnykMichael https://github.com/mGalarnyk/Installations_Mac_Ubuntu_Windows Google Cloud for Data Science: Beginner’s Guide https://www.datacamp.com/community/tutorials/google-cloud-data-science Deep Learning With Jupyter Notebooks In The Cloud https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws https://www.datacamp.com/community/tutorials/homebrew-install-use system() function works when I use R from terminal but not from RStudio #2193 https://github.com/rstudio/rstudio/issues/2193 myTerm &lt;- rstudioapi::terminalCreate(show = FALSE) rstudioapi::terminalSend(myTerm, &quot;esearch -db pubmed -query &#39;(diabetes AND pregnancy) AND (\\&quot;2017/01/01\\&quot;[PDAT] : \\&quot;2017/12/31\\&quot;[PDAT])&#39; | efetch -format xml | xtract -pattern Grant -element Agency | sort-uniq-count-rank | head -n 10 &gt; myquery.txt \\n&quot;) Sys.sleep(1) repeat{ Sys.sleep(0.1) if(rstudioapi::terminalBusy(myTerm) == FALSE){ print(&quot;Code Executed&quot;) break } } "],["decision-trees.html", "Chapter 74 Decision Trees", " Chapter 74 Decision Trees prune.carseats = prune.misclass(tree.carseats, best = 12) plot(prune.carseats) text(prune.carseats, pretty=0) It&#39;s a bit shallower than previous trees, and you can actually read the labels. Let&#39;s evaluate it on the test dataset again. tree.pred = predict(prune.carseats, carseats[-train,], type=&quot;class&quot;) with(carseats[-train,], table(tree.pred, High)) (74 + 39) / 150 Seems like the correct classifications dropped a little bit. It has done about the same as your original tree, so pruning did not hurt much with respect to misclassification errors, and gave a simpler tree. Often case, trees don&#39;t give very good prediction errors, so let&#39;s go ahead take a look at random forests and boosting, which tend to outperform trees as far as prediction and misclassification are concerned. Random Forests For this part, you will use the Boston housing data to explore random forests and boosting. The dataset is located in the MASS package. It gives housing values and other statistics in each of 506 suburbs of Boston based on a 1970 census. library(MASS) data(package=&quot;MASS&quot;) boston&lt;-Boston dim(boston) names(boston) Let&#39;s also load the randomForest package. require(randomForest) To prepare data for random forest, let&#39;s set the seed and create a sample training set of 300 observations. set.seed(101) train = sample(1:nrow(boston), 300) In this dataset, there are 506 surburbs of Boston. For each surburb, you have variables such as crime per capita, types of industry, average # of rooms per dwelling, average proportion of age of the houses etc. Let&#39;s use medv - the median value of owner-occupied homes for each of these surburbs, as the response variable. Let&#39;s fit a random forest and see how well it performs. As being said, you use the response medv, the median housing value (in $1K dollars), and the training sample set. rf.boston = randomForest(medv~., data = boston, subset = train) rf.boston Printing out the random forest gives its summary: the # of trees (500 were grown), the mean squared residuals (MSR), and the percentage of variance explained. The MSR and % variance explained are based on the out-of-bag estimates, a very clever device in random forests to get honest error estimates. The only tuning parameter in a random Forests is the argument called mtry, which is the number of variables that are selected at each split of each tree when you make a split. As seen here, mtry is 4 of the 13 exploratory variables (excluding medv) in the Boston Housing data - meaning that each time the tree comes to split a node, 4 variables would be selected at random, then the split would be confined to 1 of those 4 variables. That&#39;s how randomForests de-correlates the trees. You&#39;re going to fit a series of random forests. There are 13 variables, so let&#39;s have mtry range from 1 to 13: In order to record the errors, you set up 2 variables oob.err and test.err. In a loop of mtry from 1 to 13, you first fit the randomForest with that value of mtry on the train dataset, restricting the number of trees to be 350. Then you extract the mean-squared-error on the object (the out-of-bag error). Then you predict on the test dataset (boston[-train]) using fit (the fit of randomForest). Lastly, you compute the test error: mean-squared error, which is equals to mean( (medv - pred) ^ 2 ). oob.err = double(13) test.err = double(13) for(mtry in 1:13){ fit = randomForest(medv~., data = boston, subset=train, mtry=mtry, ntree = 350) oob.err[mtry] = fit$mse[350] pred = predict(fit, boston[-train,]) test.err[mtry] = with(boston[-train,], mean( (medv-pred)^2 )) } Basically you just grew 4550 trees (13 times 350). Now let&#39;s make a plot using the matplot command. The test error and the out-of-bag error are binded together to make a 2-column matrix. There are a few other arguments in the matrix, including the plotting character values (pch = 23 means filled diamond), colors (red and blue), type equals both (plotting both points and connecting them with the lines), and name of y-axis (Mean Squared Error). You can also put a legend at the top right corner of the plot. matplot(1:mtry, cbind(test.err, oob.err), pch = 23, col = c(&quot;red&quot;, &quot;blue&quot;), type = &quot;b&quot;, ylab=&quot;Mean Squared Error&quot;) legend(&quot;topright&quot;, legend = c(&quot;OOB&quot;, &quot;Test&quot;), pch = 23, col = c(&quot;red&quot;, &quot;blue&quot;)) Ideally, these 2 curves should line up, but it seems like the test error is a bit lower. However, there&#39;s a lot of variability in these test error estimates. Since the out-of-bag error estimate was computed on one dataset and the test error estimate was computed on another dataset, these differences are pretty much well within the standard errors. Notice that the red curve is smoothly above the blue curve? These error estimates are very correlated, because the randomForest with mtry = 4 is very similar to the one with mtry = 5. That&#39;s why each of the curves is quite smooth. What you see is that mtry around 4 seems to be the most optimal choice, at least for the test error. This value of mtry for the out-of-bag error equals 9. So with very few tiers, you have fitted a very powerful prediction model using random forests. How so? The left-hand side shows the performance of a single tree. The mean squared error on out-of-bag is 26, and you&#39;ve dropped down to about 15 (just a bit above half). This means you reduced the error by half. Likewise for the test error, you reduced the error from 20 to 12. Boosting Compared to random forests, boosting grows smaller and stubbier trees and goes at the bias. You will use the package GBM (Gradient Boosted Modeling), in R. require(gbm) GBM asks for the distribution, which is Gaussian, because you&#39;ll be doing squared error loss. You&#39;re going to ask GBM for 10,000 trees, which sounds like a lot, but these are going to be shallow trees. Interaction depth is the number of splits, so you want 4 splits in each tree. Shrinkage is 0.01, which is how much you&#39;re going to shrink the tree step back. boost.boston = gbm(medv~., data = boston[train,], distribution = &quot;gaussian&quot;, n.trees = 10000, shrinkage = 0.01, interaction.depth = 4) summary(boost.boston) The summary function gives a variable importance plot. It seems like there are 2 variables that have high relative importance: rm (number of rooms) and lstat (percentage of lower economic status people in the community). Let&#39;s plot these 2 variables: plot(boost.boston,i=&quot;lstat&quot;) plot(boost.boston,i=&quot;rm&quot;) The 1st plot shows that the higher the proportion of lower status people in the suburb, the lower the value of the housing prices. The 2nd plot shows the reversed relationship with the number of rooms: the average number of rooms in the house increases as the price increases. It&#39;s time to predict a boosted model on the test dataset. Let&#39;s look at the test performance as a function of the number of trees: First, you make a grid of number of trees in steps of 100 from 100 to 10,000. Then, you run the predict function on the boosted model. It takes n.trees as an argument, and produces a matrix of predictions on the test data. The dimensions of the matrix are 206 test observations and 100 different predict vectors at the 100 different values of tree. n.trees = seq(from = 100, to = 10000, by = 100) predmat = predict(boost.boston, newdata = boston[-train,], n.trees = n.trees) dim(predmat) It&#39;s time to compute the test error for each of the predict vectors: predmat is a matrix, medv is a vector, thus (predmat - medv) is a matrix of differences. You can use the apply function to the columns of these square differences (the mean). That would compute the column-wise mean squared error for the predict vectors. Then you make a plot using similar parameters to that one used for Random Forest. It would show a boosting error plot. boost.err = with(boston[-train,], apply( (predmat - medv)^2, 2, mean) ) plot(n.trees, boost.err, pch = 23, ylab = &quot;Mean Squared Error&quot;, xlab = &quot;# Trees&quot;, main = &quot;Boosting Test Error&quot;) abline(h = min(test.err), col = &quot;red&quot;) The boosting error pretty much drops down as the number of trees increases. This is an evidence showing that boosting is reluctant to overfit. Let&#39;s also include the best test error from the randomForest into the plot. Boosting actually gets a reasonable amount below the test error for randomForest. Conclusion So that&#39;s the end of this R tutorial on building decision tree models: classification trees, random forests, and boosted trees. The latter 2 are powerful methods that you can use anytime as needed. In my experience, boosting usually outperforms RandomForest, but RandomForest is easier to implement. In RandomForest, the only tuning parameter is the number of trees; while in boosting, more tuning parameters are required besides the number of trees, including the shrinkage and the interaction depth. If you would like to learn more, be sure to take a look at our Machine Learning Toolbox course for R. "],["decision-tree.html", "Chapter 75 decision tree", " Chapter 75 decision tree https://analytics4all.org/2016/11/23/r-decision-trees-regression/ "],["decision-tree-classifier-implementation-in-r.html", "Chapter 76 DECISION TREE CLASSIFIER IMPLEMENTATION IN R", " Chapter 76 DECISION TREE CLASSIFIER IMPLEMENTATION IN R https://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/ https://dataaspirant.com/2017/02/03/decision-tree-classifier-implementation-in-r/ "],["caret.html", "Chapter 77 caret 77.1 Descriptive Statistics 77.2 skimr", " Chapter 77 caret Classification And REgression Training 77.1 Descriptive Statistics 77.2 skimr https://cran.r-project.org/web/packages/skimr/vignettes/Using_skimr.html Exploratory Data Analysis in R (introduction) https://blog.datascienceheroes.com/exploratory-data-analysis-in-r-intro/ What’s so hard about histograms? http://tinlizzie.org/~aran/histograms/ "],["dataexplorer.html", "Chapter 78 DataExplorer", " Chapter 78 DataExplorer "],["webinar-tidyverse-exploratory-analysis-emily-robinson.html", "Chapter 79 Webinar: Tidyverse Exploratory Analysis (Emily Robinson)", " Chapter 79 Webinar: Tidyverse Exploratory Analysis (Emily Robinson) https://hookedondata.org/the-lesser-known-stars-of-the-tidyverse/ https://www.rstudio.com/resources/videos/the-lesser-known-stars-of-the-tidyverse/ https://github.com/robinsones/robinsones_blog/blob/master/content/post/multipleChoiceResponses.csv https://github.com/robinsones/robinsones_blog/blob/master/content/post/2018-11-16-the-lesser-known-stars-of-the-tidyverse.Rmd "],["i-only-use-r-for-descriptive-stats-and-thats-ok.html", "Chapter 80 I “only” use R for descriptive stats — and that’s OK", " Chapter 80 I “only” use R for descriptive stats — and that’s OK https://rforeval.com/descriptive-stats-r/ "],["histograms.html", "Chapter 81 histograms", " Chapter 81 histograms http://tinlizzie.org/histograms/ SEER China vs others https://www.rdocumentation.org/packages/bayesTFR/versions/6.1-2/topics/country.names https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/state.html "],["who-works-on-seer.html", "Chapter 82 Who works on SEER 82.1 Aim 82.2 Data retriveal from PubMed using EDirect", " Chapter 82 Who works on SEER If you want to see the code used in the analysis please click the code button on the right upper corner or throughout the page. Select from the tabs below. 82.1 Aim Aim: 82.2 Data retriveal from PubMed using EDirect Articles are downloaded as xml. At the time of the research the number of articles with ‘SEER Program’[Mesh] formula is “r dim(SEER_countries)[1]”. While helping the preparation of #PBPath Journal Watch (https://t.co/WiBsJixzlc) I thought that many SEER (???) studies are from China. So using edirect (???) and #RStats I draw the attached graph. What do you think? Do Chinese do research on SEER that much? pic.twitter.com/3Op5r9ofbK — Serdar Balcı ((???)) October 6, 2018 eurostat http://ec.europa.eu/eurostat http://ec.europa.eu/eurostat/data/database eurostat R package http://ropengov.github.io/eurostat/ Retrieval and Analysis of Eurostat Open Data with the eurostat Package https://journal.r-project.org/archive/2017/RJ-2017-019/index.html CheatSheet https://github.com/rOpenGov/eurostat/blob/master/vignettes/cheatsheet/eurostat_cheatsheet.pdf https://github.com/rstudio/cheatsheets/raw/master/eurostat.pdf Searching, downloading and manipulating Eurostat data with R http://ropengov.github.io/r/2015/05/01/eurostat-package-examples/ Mapping Eurostat information https://www.mytinyshinys.com/2017/07/11/eurostat/ eurostat-package published https://rpubs.com/muuankarski/27120 Tutorial (vignette) for the eurostat R package http://ropengov.github.io/eurostat/articles/eurostat_tutorial.html "],["revtools.html", "Chapter 83 revtools", " Chapter 83 revtools revtools: Tools to Support Evidence Synthesis https://cran.r-project.org/package=revtools https://revtools.net/ https://revtools.net/user_manual/1_introduction.html data1 &lt;- read_bibliography(&quot;my_data.ris&quot;) data2 &lt;- read_bibliography(&quot;my_data.bib&quot;) # If the files are in the working directory: file_names &lt;- list.files() # Or if they are in a subdirectory: file_names &lt;- paste0( &quot;./raw_data/&quot;, list.files(path = &quot;./raw_data/&quot;) ) # Then import to a list data_list &lt;- lapply( file_names, function(x){read_bibliography(x)} ) data &lt;- read_bibliography(&quot;my_data.ris&quot;) matches &lt;- find_duplicates( data = data, match_variable = &quot;title&quot;, group_variable = NULL, match_function = &quot;fuzzdist&quot;, method = &quot;fuzz_partial_ratio&quot;, threshold = 0 ) data_unique &lt;- extract_unique_references(data, matches) "],["screen-duplicates.html", "Chapter 84 screen_duplicates", " Chapter 84 screen_duplicates https://revtools.net/user_manual/4_removing_duplicates.html # 1. standalone; load in data in the app screen_titles() # 2. the same, but save back to workspace on exit result &lt;- screen_titles() # ditto, data &lt;- read_bibliography(&quot;my_data.ris&quot;) # load in data # 3. launch the app using data from the workspace screen_titles(data) # 4. specify an object to return data to result &lt;- screen_titles(data) "],["refmanager.html", "Chapter 85 RefManageR", " Chapter 85 RefManageR RefManageR: Straightforward ‘BibTeX’ and ‘BibLaTeX’ Bibliography Management https://cran.r-project.org/web/packages/RefManageR/index.html "],["bibtex.html", "Chapter 86 bibtex", " Chapter 86 bibtex bibtex: Bibtex Parser https://cran.r-project.org/web/packages/bibtex/index.html "],["dataexplorer-1.html", "Chapter 87 DataExplorer 87.1 File organization best practices 87.2 1 Cross tables 87.3 2 Model tables with finalfit() 87.4 3 Model tables manually using ff_merge() 87.5 4 Support for complex survey structures via library(survey) 87.6 Table 1 - Demographics 87.7 Table 2 - Association between tumour factors and 5 year mortality 87.8 Figure 1 - Association between tumour factors and 5 year mortality 87.9 Table 1 - Demographics 87.10 Table 2 - Association between tumour factors and 5 year mortality 87.11 Figure 1 - Association between tumour factors and 5 year mortality 87.12 Table 1 - Demographics 87.13 Table 2 - Association between tumour factors and 5 year mortality 87.14 Figure 1 - Association between tumour factors and 5 year mortality 87.15 Table 1 - Demographics 87.16 Table 2 - Association between tumour factors and 5 year mortality 87.17 Figure 1 - Association between tumour factors and 5 year mortality 87.18 Flipping Coin", " Chapter 87 DataExplorer https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html https://boxuancui.github.io/DataExplorer/ 87.1 File organization best practices This page summarises how to organize files and analysis before everything gets jumbled up: Setting up a reproducible data analysis workflow in R Basically they suggest: - using a project and project folder in RStudio for each analysis - using packrat as much as possible setwd() and getwd() is not necesary when you use projects. Why should I use the here package when I’m already using projects? https://malco.io/2018/11/05/why-should-i-use-the-here-package/ output: rmarkdown::html_vignette vignette: &gt; %\\VignetteIndexEntry{All tables examples} %\\VignetteEngine{knitr::rmarkdown} %\\VignetteEncoding{UTF-8} 87.2 1 Cross tables Two-way tables are used extensively in healthcare research, e.g. a 2x2 table comparing two factors with two levels each, or table 1 from a typical clinical study or trial The main functions all take a dependent variable - the outcome (maximum of 5 levels) - and explanatory variables - predictors or exposures (any number categorical or continuous variables). 87.2.1 1.01 Default Note, chi-squared warnings will be generated when the expected count in any cell is less than 5. Fisher’s exact test can be used as below, or go straight to a univariable logistic regression, e.g. colon_s %&gt;% finalfit(dependent, explanatory) 87.2.2 1.02 Add or edit variable labels 87.2.3 1.03 P-value for hypothesis test Chi-squared for categorical, Kruskal-Wallis/Mann-Whitney for continuous 87.2.4 1.04 With Fisher’s exact test 87.2.5 1.05 Median (interquartile range) instead of mean (standard deviation) … for continuous variables. 87.2.6 1.06 Missing values for the explanatory variables Always do this when describing your data. 87.2.7 1.07 Column proportions (rather than row) 87.2.8 1.08 Total column 87.2.9 1.09 Order a variable by total This is intended for when there is only one explanatory variable. 87.2.10 1.10 Label with dependent name The dependent name cannot be passed directly to the table intentionally. This is to avoid errors when code is copied and the name is not updated. Change the dependent label using the following. The prefix (“Dependent:”) and any suffix can be altered. 87.2.11 1.11 Dependent variable with any number of factor levels supported 87.2.12 1.12 Explanatory variable defaults to factor when ≤5 distinct values 87.2.13 1.13 Keep as continous variable when ≤5 distinct values 87.2.14 1.14 Stratified crosstables I’ve been meaning to include support for table stratification for a while. I have delayed for a good reason. Perhaps the most straightforward way to implement stratificiation is with dplyr::group_by(). However, the non-standard evaluation required for multiple strata may confuse as it is not implemented else where in the package (doesn’t work with group_by_). This translates to whether variable names are passed in quotes or not. Finally,. dplyr::do() is planned for deprecation, but there is no good alternative at the moment. Anyway, here is a solution, which while not that pretty, is very effective. 87.3 2 Model tables with finalfit() 87.3.1 2.01 Default Logistic regression first. 87.3.2 2.02 Hide reference levels Most appropriate when all explanatory variables are continuous or well-known binary variables, such as sex. 87.3.3 2.03 Model metrics 87.3.4 2.04 Model metrics can be applied to all supported base models 87.3.5 2.05 Reduced model 87.3.6 2.06 Include all models 87.3.7 2.06 Interactions Interactions can be specified in the normal way. Formatting the output is trickier. At the moment, we have left the default model output. This can be adjusted as necessary. 87.3.8 2.07 Interactions: create interaction variable with two factors 87.3.9 2.08 Dependent name The dependent name cannot be specified directly intentionally. This is to prevent errors when copying code. Re-label using ff_label(). The dependent prefix and suffix can also be altered. 87.3.10 2.09 Estimate name 87.3.11 2.10 Digits / decimal places Number of digits to round to regression results. (1) estimate, (2) confidence interval limits, (3) p-value. Default is c(2,2,3). Trailing zeros are preserved. Number of decimal places for counts and mean (sd) / median (IQR) not currently supported. Defaults are senisble :) 87.3.12 2.11 Confidence interval type One of c(\"profile\", \"default\") for GLM models (confint.glm()). Note, a little awkwardly, the ‘default’ setting is profile, rather than default. Profile levels are probably a little more accurate. Only go to default if taking a significant length of time for profile, i.e. data is greater than hundreds of thousands of lines. For glmer/lmer models (confint.merMod()), c(\"profile\", \"Wald\", \"boot\"). Not implemented for lm(), coxph() or coxphlist, which use default. 87.3.13 2.12 Confidence interval level Probably never change this :) Note, the p-value is intentionally not included for confidence levels other than 95% to avoid confusion. 87.3.14 2.13 Confidence interval separation Some like to avoid the hyphen so as not to confuse with minus sign. Obviously not an issue in logistic regression. 87.3.15 2.14 Mixed effects random-intercept model At its simplest, a random-intercept model can be specified using a single quoted variable. In this example, it is the equivalent of quoting {r # andom_effect = \"(1 | hospital)\". 87.3.16 2.15 Mixed effects random-slope model In the example below, allow the effect of age on outcome to vary by hospital. Note, this specification must have parentheses included. 87.3.17 2.16 Mixed effects random-slope model directly from lme4 Clearly, as models get more complex, parameters such as random effect group variances may require to be extracted directly from model outputs. 87.3.18 2.17 Exclude all missing data in final model from univariable analyses This can be useful if you want the numbers in the final table to match the final multivariable model. However, be careful to include a full explanation of this in the methods and the reason for exluding the missing data. 87.3.19 2.18 Linear regression 87.3.20 2.19 Mixed effects random-intercept linear regression 87.3.21 2.20 Mixed effects random-slope linear regression 87.3.22 2.21 Cox proportional hazards model (survival / time to event) 87.3.23 2.22 Cox proportional hazards model: change dependent label As above, the dependent label cannot be specfied directly in the model to avoid errors. However, in survival modelling the surivial object specification can be long or awkward. Therefore, here is the work around. 87.4 3 Model tables manually using ff_merge() 87.4.1 3.1 Basic table Note summary_factorlist() needs argument, fit_id = TRUE. 87.4.2 3.2 Complex table (all in single pipe) 87.4.3 3.3 Other GLM models 87.4.3.1 Poisson 87.4.3.2 Gamma 87.4.4 3.4 Weighted regression 87.4.5 3.5 Using base R functions Note ff_formula() convenience function to make multivariable formula (y ~ x1 + x2 + x3 etc.) from a dependent and explanatory vector of names. 87.4.6 3.6 Edit table rows This can be done as any dataframe would be edited. 87.4.7 3.7 Base model + individual explanatory variables This was an email enquiry about how to build on a base model. The example request was in a survival context. 87.5 4 Support for complex survey structures via library(survey) 87.5.1 4.1 Linear regression Examples taken from survey::svyglm() help page. 87.5.2 4.2 Binomial example Note model family needs specified and exponentiation set to TRUE if desired. devtools::install_github(&quot;ewenharrison/finalfit&quot;) 87.6 Table 1 - Demographics kable(table1, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 87.7 Table 2 - Association between tumour factors and 5 year mortality kable(table2, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 87.8 Figure 1 - Association between tumour factors and 5 year mortality devtools::install_github(&quot;ewenharrison/finalfit&quot;) 87.9 Table 1 - Demographics kable(table1, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 87.10 Table 2 - Association between tumour factors and 5 year mortality kable(table2, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 87.11 Figure 1 - Association between tumour factors and 5 year mortality 87.12 Table 1 - Demographics kable(table1, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;), booktabs=TRUE) country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 87.13 Table 2 - Association between tumour factors and 5 year mortality 87.14 Figure 1 - Association between tumour factors and 5 year mortality devtools::install_github(&quot;ewenharrison/finalfit&quot;) 87.15 Table 1 - Demographics kable(table1, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year cases population Afghanistan 1999 745 19987071 Afghanistan 2000 2666 20595360 Brazil 1999 37737 172006362 Brazil 2000 80488 174504898 China 1999 212258 1272915272 China 2000 213766 1280428583 87.16 Table 2 - Association between tumour factors and 5 year mortality kable(table2, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) country year type count Afghanistan 1999 cases 745 Afghanistan 1999 population 19987071 Afghanistan 2000 cases 2666 Afghanistan 2000 population 20595360 Brazil 1999 cases 37737 Brazil 1999 population 172006362 Brazil 2000 cases 80488 Brazil 2000 population 174504898 China 1999 cases 212258 China 1999 population 1272915272 China 2000 cases 213766 China 2000 population 1280428583 87.17 Figure 1 - Association between tumour factors and 5 year mortality 87.18 Flipping Coin https://www.littlemissdata.com/blog/prettytables "],["alternatives-to-the-default-r-outputs-for-glms-and-linear-models.html", "Chapter 88 5 Alternatives to the Default R Outputs for GLMs and Linear Models 88.1 Classic Output 88.2 stargazer 88.3 formattable 88.4 flipRegression", " Chapter 88 5 Alternatives to the Default R Outputs for GLMs and Linear Models https://www.displayr.com/5-alternatives-to-the-default-r-outputs-for-glms-and-linear-models/?utm_medium=Feed&amp;utm_source=Syndication 88.1 Classic Output 88.2 stargazer 88.3 formattable 88.4 flipRegression 88.4.1 Building Online Interactive Simulators for Predictive Models in R https://www.displayr.com/building-online-interactive-simulators-for-predictive-models-in-r/ "],["data-science-live-book.html", "Chapter 89 Data Science Live Book 89.1 master course links", " Chapter 89 Data Science Live Book https://livebook.datascienceheroes.com/ https://toolbox.google.com/datasetsearch http://archive.ics.uci.edu/ml/index.php http://asdfree.com/ https://rstudio-education.github.io/hopr/ What I Wish I Knew When I Started R https://www.williamrchase.com/slides/intro_r_anthropology_2018 https://sbalci.gitbooks.io/pathology-notes/content/pathology-residents/computational-pathology.html http://web.stanford.edu/class/bios221/book/ https://kbroman.org/minimal_make/ https://www.gnu.org/software/make/ https://kbroman.org/minimal_make/ https://www.datacamp.com/community/tutorials/shell-commands-data-scientist https://moderndive.com/3-viz.html https://www.causeweb.org/cause/ecots/ecots18/breakouts/7 https://plotly-book.cpsievert.me/ http://r-bio.github.io/01-intro-R/ https://www.rdatagen.net/post/by-vs-within/?platform=hootsuite http://www.biomart.org/download.html https://ropensci.org/blog/2018/07/24/educollab-challenges/ https://www.datacamp.com/community/tutorials/data-science-pitfalls https://serialmentor.com/dataviz/preface.html https://news.codecademy.com/errors-in-code-think-differently/?utm_source=customer.io&amp;utm_medium=email&amp;utm_campaign=fortnightly_8-1-18&amp;utm_content=ErrorFortnightly Data Science Live Book https://livebook.datascienceheroes.com/ School of Psychology at the University of New South Wales http://www.compcogscisydney.org/teaching/ Of Minds and Machines http://www.compcogscisydney.org/mm/ psyr: Using R in Psychological Science http://www.compcogscisydney.org/psyr/ Perception and Cognition http://www.compcogscisydney.org/psyc2071/ Learning Statistics with R http://www.compcogscisydney.org/learning-statistics-with-r/ Computational Cognitive Science http://www.compcogscisydney.org/ccs/ Advanced R https://adv-r.hadley.nz/ One Page R https://togaware.com/onepager/ htmlwidgets for R http://www.htmlwidgets.org/ http://gallery.htmlwidgets.org/ Learning R for Clinical Epidemiologists http://rpubs.com/michaelmarks/R-Clin-Epi r-tutor http://www.r-tutor.com/ Statistics Meets Big Data http://www.statsoft.org/ ModernDive https://moderndive.com/ Laerd Statistics https://statistics.laerd.com/ statpages http://statpages.info/index.html The R class R programming for biologists http://r-bio.github.io/ Sosyal Bilimler Araştırmaları İçin R https://bookdown.org/connect/#/apps/1531/access R for Psychological Science An introductory resource http://compcogscisydney.org/psyr/ Jamovi tutorial https://datalab.cc/tools/jamovi https://www.youtube.com/playlist?list=PLkk92zzyru5OAtc_ItUubaSSq6S_TGfRn 89.1 master course links "],["do-more-with-r.html", "Chapter 90 Do More with R", " Chapter 90 Do More with R https://www.infoworld.com/video/series/8563/do-more-with-r "],["getting-data-into-r-veriyi-ra-yükleme.html", "Chapter 91 Getting Data into R / Veriyi R’a yükleme 91.1 Import Data", " Chapter 91 Getting Data into R / Veriyi R’a yükleme 91.1 Import Data 91.1.1 Import using RStudio 91.1.2 Import CSV File 91.1.2.1 How to import multiple .csv files at once? https://stackoverflow.com/questions/11433432/how-to-import-multiple-csv-files-at-once temp = list.files(pattern=&quot;*.csv&quot;) myfiles = lapply(temp, read.delim) temp = list.files(pattern=&quot;*.csv&quot;) for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) temp = list.files(pattern=&quot;*.csv&quot;) list2env( lapply(setNames(temp, make.names(gsub(&quot;*.csv$&quot;, &quot;&quot;, temp))), read.csv), envir = .GlobalEnv) # Get the files names files = list.files(pattern=&quot;*.csv&quot;) # First apply read.csv, then rbind myfiles = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE))) library(data.table) DT = do.call(rbind, lapply(files, fread)) # The same using `{r # bindlist` DT = rbindlist(lapply(files, fread)) library(readr) library(dplyr) tbl = lapply(files, read_csv) %&gt;% bind_rows() data &lt;- read.csv( switch(animal, &quot;dog&quot; = &quot;dogdata.csv&quot;, &quot;cat&quot; = &quot;catdata.csv&quot;, &quot;rabbit&quot; = &quot;rabbitdata.csv&quot;) ) 91.1.3 Import TXT File 91.1.4 Import Excel File my_data &lt;- read_excel(file.choose()) files &lt;- list.files(pattern = &quot;.xlsx&quot;) data_xlsx_df &lt;- map_df(set_names(files), function(file) { file %&gt;% excel_sheets() %&gt;% set_names() %&gt;% map_df( ~ read_xlsx(path = file, sheet = .x, range = &quot;H3&quot;), .id = &quot;sheet&quot;) }, .id = &quot;file&quot;) 91.1.4.1 Import Sheets 91.1.5 Import SPSS File 91.1.6 Keep SPSS labels read.spss komutu ile değer etiketlerini almasını ve bunu liste olarak değil de data.frame olarak kaydetmesini istiyoruz aktardığımız data.frame’in özellikleri (attr) içinde değişkenlerin etiketleri var, bunları dışarı çıkartıyoruz elde ettiğimiz data.frame’deki satır isimleri değişkenlerin isimleri oluyor, karşılarında da değişken etiketleri var satır isimlerini de dışarı çıkartıyoruz Değişken etiketi olanları etiketleri ile diğerlerini olduğu gibi saklıyoruz son olarak da data.frame’deki sütun isimlerini değiştiriyoruz "],["export-data.html", "Chapter 92 Export Data", " Chapter 92 Export Data 92.0.1 Export to SPSS, while keeping labels R’da factor olan label verdiğiniz değişkenleri SPSS ya da diğer istatistik programlarına aktardığınızda bu tanımlamaları korumak işimize yarar. Bunun için foreign paketi ile bir txt dosyası ve bir sps dosyası oluşturuyoruz. SPSS’te sps dosyasını açıp kodu çalıştırarak tekrar atanan değerler geri yükleniyor. https://twitter.com/WeAreRLadies/status/1034817323922804737 f &lt;- list.files( &quot;my_folder&quot;, pattern = &quot;*.csv&quot;, full.names = TRUE) d &lt;- purrr::map_df(f, readr::read_csv, .id = &quot;id&quot;) m &lt;- lm(mpg ~ qsec + wt, data = mtcars) broom::tidy(m) Import a Directory of CSV Files at Once Using {purrr} and {readr} https://www.gerkelab.com/blog/2018/09/import-directory-csv-purrr-readr/ data_dir %&gt;% dir_ls(regexp = &quot;\\\\.csv$&quot;) %&gt;% map_dfr(read_csv, .id = &quot;source&quot;) %&gt;% mutate(Month_Year = myd(Month_Year, truncated = 1)) https://suatatan.wordpress.com/2017/10/07/bulk-replacing-turkish-characters-in-r/ Turkish character sometimes became the menace for the data scientist. To avoid the risks you may want to change it with safe characters. To do that you can use this code: #turkce karakter donusumu to.plain &lt;- function(s) { # 1 character substitutions old1 &lt;- “çğşıüöÇĞŞİÖÜ” new1 &lt;- “cgsiuocgsiou” s1 &lt;- chartr(old1, new1, s) # 2 character substitutions old2 &lt;- c(“œ”, “ß”, “æ”, “ø”) new2 &lt;- c(“oe”, “ss”, “ae”, “oe”) s2 &lt;- s1 for(i in seq_along(old2)) s2 &lt;- gsub(old2[i], new2[i], s2, fixed = TRUE) s2 } df$source=as.vector(sapply(df$source,to.plain)) to.plain(make.names(tolower(names(df)))) Remove all special characters from a string in R? https://stackoverflow.com/questions/10294284/remove-all-special-characters-from-a-string-in-r x &lt;- &quot;a1~!@#$%^&amp;*(){}_+:\\&quot;&lt;&gt;?,./;&#39;[]-=&quot; stringr::str_replace_all(x, &quot;[[:punct:]]&quot;, &quot; &quot;) stringr::str_replace_all(x, &quot;[^[:alnum:]]&quot;, &quot; &quot;) astr &lt;- &quot;Ábcdêãçoàúü&quot; iconv(astr, from = &#39;UTF-8&#39;, to = &#39;ASCII//TRANSLIT&#39;) Data &lt;- gsub(&quot;[^0-9A-Za-z///&#39; ]&quot;,&quot;&#39;&quot; , Data ,ignore.case = TRUE) Data &lt;- gsub(&quot;&#39;&#39;&quot;,&quot;&quot; , Data ,ignore.case = TRUE) "],["pdftables.html", "Chapter 93 pdftables", " Chapter 93 pdftables https://cran.r-project.org/web/packages/pdftables/vignettes/convert_pdf_tables.html "],["tabulizer.html", "Chapter 94 tabulizer", " Chapter 94 tabulizer Extract Tables from PDFs https://github.com/ropensci/tabulizer "],["rio.html", "Chapter 95 rio", " Chapter 95 rio Import, Export, and Convert Data Files https://thomasleeper.com/rio/index.html https://cran.r-project.org/web/packages/rio/vignettes/rio.html "],["read-with-purrr.html", "Chapter 96 read with purrr", " Chapter 96 read with purrr R tip: Iterate with purrr’s map_df function https://www.infoworld.com/video/89075/r-tip-iterate-with-purrrs-map-df-function "],["the-janitor-package.html", "Chapter 97 The janitor package 97.1 convert excel number into date", " Chapter 97 The janitor package https://garthtarr.github.io/meatR/janitor.html 97.1 convert excel number into date output: pdf_document: default html_document: default header-includes: - \\usepackage{pdflscape} - \\usepackage{xcolor} - \\newcommand{\\blandscape}{\\begin{landscape}} - \\newcommand{\\elandscape}{\\end{landscape}} "],["ggplot2-.html", "Chapter 98 ggplot2 —-", " Chapter 98 ggplot2 —- mpg library(&quot;tidyverse&quot;) ggplot(mpg) + geom_point(aes(x = displ, y = hwy)) ggplot(mpg, aes(model, manufacturer)) + geom_point() ggplot(mpg, aes(displ, cty, colour = year)) + geom_point() ggplot(mpg, aes(displ, hwy)) + geom_point(aes(shape = year)) ggplot(mpg, aes(displ, hwy)) + geom_point() + geom_smooth(span = 0.2) ggplot(mpg, aes(hwy)) + geom_histogram() + geom_freqpoly() ggplot(mpg, aes(cty, hwy)) + geom_point() + geom_smooth() ggplot(mpg, aes(class, hwy)) + geom_boxplot() ggplot(mpg, aes(reorder(class, hwy), hwy)) + geom_boxplot() "],["gganimate-.html", "Chapter 99 gganimate —-", " Chapter 99 gganimate —- library(gganimate) p &lt;- ggplot(iris, aes(x = Petal.Width, y = Petal.Length)) + geom_point() plot(p) anim &lt;- p + transition_states(Species, transition_length = 2, state_length = 1) anim p + enter_appear() {r # mytext To display the text, type {r # text_formatted outside of the chunk "],["ggpubr.html", "Chapter 100 ggpubr", " Chapter 100 ggpubr https://rpkgs.datanovia.com/ggpubr if(!require(devtools)) install.packages(&quot;devtools&quot;) devtools::install_github(&quot;kassambara/ggpubr&quot;) Distribution library(ggpubr) set.seed(1234) wdata = data.frame( sex = factor(rep(c(&quot;F&quot;, &quot;M&quot;), each=200)), weight = c(rnorm(200, 55), rnorm(200, 58))) head(wdata, 4) ggdensity(wdata, x = &quot;weight&quot;, add = &quot;mean&quot;, rug = TRUE, color = &quot;sex&quot;, fill = &quot;sex&quot;, palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;)) gghistogram(wdata, x = &quot;weight&quot;, add = &quot;mean&quot;, rug = TRUE, color = &quot;sex&quot;, fill = &quot;sex&quot;, palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;)) data(&quot;ToothGrowth&quot;) df &lt;- ToothGrowth head(df, 4) p &lt;- ggboxplot(df, x = &quot;dose&quot;, y = &quot;len&quot;, color = &quot;dose&quot;, palette =c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), add = &quot;jitter&quot;, shape = &quot;dose&quot;) p # Add p-values comparing groups # Specify the comparisons you want my_comparisons &lt;- list( c(&quot;0.5&quot;, &quot;1&quot;), c(&quot;1&quot;, &quot;2&quot;), c(&quot;0.5&quot;, &quot;2&quot;) ) p + stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value stat_compare_means(label.y = 50) # Add global p-value ggviolin(df, x = &quot;dose&quot;, y = &quot;len&quot;, fill = &quot;dose&quot;, palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), add = &quot;boxplot&quot;, add.params = list(fill = &quot;white&quot;))+ stat_compare_means(comparisons = my_comparisons, label = &quot;p.signif&quot;)+ # Add significance levels stat_compare_means(label.y = 50) # Add global the p-value data(&quot;mtcars&quot;) dfm &lt;- mtcars dfm$cyl &lt;- as.factor(dfm$cyl) dfm$name &lt;- rownames(dfm) head(dfm[, c(&quot;name&quot;, &quot;wt&quot;, &quot;mpg&quot;, &quot;cyl&quot;)]) ggbarplot(dfm, x = &quot;name&quot;, y = &quot;mpg&quot;, fill = &quot;cyl&quot;, # change fill color by cyl color = &quot;white&quot;, # Set bar border colors to white palette = &quot;jco&quot;, # jco journal color palett. see ?ggpar sort.val = &quot;desc&quot;, # Sort the value in dscending order sort.by.groups = FALSE, # Don&#39;t sort inside each group x.text.angle = 90 # Rotate vertically x axis texts ) ggbarplot(dfm, x = &quot;name&quot;, y = &quot;mpg&quot;, fill = &quot;cyl&quot;, # change fill color by cyl color = &quot;white&quot;, # Set bar border colors to white palette = &quot;jco&quot;, # jco journal color palett. see ?ggpar sort.val = &quot;asc&quot;, # Sort the value in dscending order sort.by.groups = TRUE, # Sort inside each group x.text.angle = 90 # Rotate vertically x axis texts ) dfm$mpg_z &lt;- (dfm$mpg -mean(dfm$mpg))/sd(dfm$mpg) dfm$mpg_grp &lt;- factor(ifelse(dfm$mpg_z &lt; 0, &quot;low&quot;, &quot;high&quot;), levels = c(&quot;low&quot;, &quot;high&quot;)) head(dfm[, c(&quot;name&quot;, &quot;wt&quot;, &quot;mpg&quot;, &quot;mpg_z&quot;, &quot;mpg_grp&quot;, &quot;cyl&quot;)]) ggbarplot(dfm, x = &quot;name&quot;, y = &quot;mpg_z&quot;, fill = &quot;mpg_grp&quot;, # change fill color by mpg_level color = &quot;white&quot;, # Set bar border colors to white palette = &quot;jco&quot;, # jco journal color palett. see ?ggpar sort.val = &quot;asc&quot;, # Sort the value in ascending order sort.by.groups = FALSE, # Don&#39;t sort inside each group x.text.angle = 90, # Rotate vertically x axis texts ylab = &quot;MPG z-score&quot;, xlab = FALSE, legend.title = &quot;MPG Group&quot; ) ggbarplot(dfm, x = &quot;name&quot;, y = &quot;mpg_z&quot;, fill = &quot;mpg_grp&quot;, # change fill color by mpg_level color = &quot;white&quot;, # Set bar border colors to white palette = &quot;jco&quot;, # jco journal color palett. see ?ggpar sort.val = &quot;desc&quot;, # Sort the value in descending order sort.by.groups = FALSE, # Don&#39;t sort inside each group x.text.angle = 90, # Rotate vertically x axis texts ylab = &quot;MPG z-score&quot;, legend.title = &quot;MPG Group&quot;, rotate = TRUE, ggtheme = theme_minimal() ) ggdotchart(dfm, x = &quot;name&quot;, y = &quot;mpg&quot;, color = &quot;cyl&quot;, # Color by groups palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), # Custom color palette sorting = &quot;ascending&quot;, # Sort value in descending order add = &quot;segments&quot;, # Add segments from y = 0 to dots ggtheme = theme_pubr() # ggplot2 theme ) ggdotchart(dfm, x = &quot;name&quot;, y = &quot;mpg&quot;, color = &quot;cyl&quot;, # Color by groups palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), # Custom color palette sorting = &quot;descending&quot;, # Sort value in descending order add = &quot;segments&quot;, # Add segments from y = 0 to dots rotate = TRUE, # Rotate vertically group = &quot;cyl&quot;, # Order by groups dot.size = 6, # Large dot size label = round(dfm$mpg), # Add mpg values as dot labels font.label = list(color = &quot;white&quot;, size = 9, vjust = 0.5), # Adjust label parameters ggtheme = theme_pubr() # ggplot2 theme ) ggdotchart(dfm, x = &quot;name&quot;, y = &quot;mpg_z&quot;, color = &quot;cyl&quot;, # Color by groups palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), # Custom color palette sorting = &quot;descending&quot;, # Sort value in descending order add = &quot;segments&quot;, # Add segments from y = 0 to dots add.params = list(color = &quot;lightgray&quot;, size = 2), # Change segment color and size group = &quot;cyl&quot;, # Order by groups dot.size = 6, # Large dot size label = round(dfm$mpg_z,1), # Add mpg values as dot labels font.label = list(color = &quot;white&quot;, size = 9, vjust = 0.5), # Adjust label parameters ggtheme = theme_pubr() # ggplot2 theme )+ geom_hline(yintercept = 0, linetype = 2, color = &quot;lightgray&quot;) ggdotchart(dfm, x = &quot;name&quot;, y = &quot;mpg&quot;, color = &quot;cyl&quot;, # Color by groups palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), # Custom color palette sorting = &quot;descending&quot;, # Sort value in descending order rotate = TRUE, # Rotate vertically dot.size = 2, # Large dot size y.text.col = TRUE, # Color y text by groups ggtheme = theme_pubr() # ggplot2 theme )+ theme_cleveland() # Add dashed grids print(paste0(&quot;Git Update Started at: &quot;, Sys.time())) CommitMessage &lt;- paste(&quot;updated on: &quot;, Sys.time(), sep = &quot;&quot;) wd &lt;- &quot;~/serdarbalci&quot; setorigin &lt;- &quot;git remote set-url origin git@github.com:sbalci/MyJournalWatch.git \\n&quot; gitCommand &lt;- paste(&quot;cd &quot;, wd, &quot; \\n git add . \\n git commit --message &#39;&quot;, CommitMessage, &quot;&#39; \\n&quot;, setorigin, &quot;git push origin master \\n&quot;, sep = &quot;&quot;) system(command = paste(gitCommand, &quot;\\n&quot;) , intern = TRUE, wait = TRUE) Sys.sleep(5) print(paste0(&quot;Git Update Ended at: &quot;, Sys.time())) "],["happy-git-and-github-for-the-user.html", "Chapter 101 Happy Git and GitHub for the useR 101.1 scholar.shiny", " Chapter 101 Happy Git and GitHub for the useR https://happygitwithr.com An introduction to Git and how to use it with RStudio http://r-bio.github.io/intro-git-rstudio/ https://andrewbtran.github.io/NICAR/2018/workflow/docs/03-integrating_github.html https://aberdeenstudygroup.github.io/studyGroup/lessons/SG-T1-GitHubVersionControl/VersionControl/ http://r-bio.github.io/intro-git-rstudio/ https://stackoverflow.com/questions/41688164/using-rstudio-to-make-pull-requests-in-git https://bookdown.org/rdpeng/RProgDA/version-control-and-github.html https://www.r-bloggers.com/rstudio-and-github/ http://happygitwithr.com/fork.html https://kbroman.org/github_tutorial/ https://kbroman.org/simple_site/ Helping you make your first pull request! https://github.com/thisisnic/first-contributions 101.0.1 scholar Analyse citation data from Google Scholar: https://github.com/jkeirstead/scholar/ 101.0.2 coauthornetwork Exploring Google Scholar coauthorship: https://cimentadaj.github.io/blog/2018-06-19-exploring-google-scholar-coauthorship/exploring-google-scholar-coauthorship/ 101.1 scholar.shiny A shiny application that interacts with Google Scholar https://github.com/agbarnett/scholar.shiny "],["flatly.html", "Chapter 102 flatly", " Chapter 102 flatly Texas Housing Prices: flatly theme https://elastic-lovelace-155848.netlify.com/gallery/themes/flatly.html "],["easyalluvial.html", "Chapter 103 easyalluvial", " Chapter 103 easyalluvial https://github.com/erblast/easyalluvial https://www.datisticsblog.com/2018/10/intro_easyalluvial/#features https://cran.r-project.org/web/packages/easyalluvial/index.html "],["rcolorbrewer.html", "Chapter 104 RColorBrewer", " Chapter 104 RColorBrewer How to expand color palette with ggplot and RColorBrewer https://www.r-bloggers.com/how-to-expand-color-palette-with-ggplot-and-rcolorbrewer/ "],["highcharter.html", "Chapter 105 highcharter", " Chapter 105 highcharter http://jkunst.com/highcharter/ https://github.com/jbkunst/highcharter http://www.htmlwidgets.org/index.html https://cran.r-project.org/web/packages/highcharter/index.html https://www.datacamp.com/community/tutorials/data-visualization-highcharter-r hchart works like ggplot2&#39;s qplot. hc_add_series works like ggplot2&#39;s geom_S. hcaes works like ggplot2&#39;s aes. Highmaps - Map Collection https://code.highcharts.com/mapdata/ download_map_data: Download the geojson data from the highcharts collection. get_data_from_map: Get the properties for each region in the map, as the keys from the map data. "],["taucharts.html", "Chapter 106 taucharts", " Chapter 106 taucharts https://www.infoworld.com/video/87337/r-tip-how-to-create-easy-interactive-scatter-plots-with-taucharts "],["gganimate.html", "Chapter 107 gganimate", " Chapter 107 gganimate https://www.infoworld.com/video/89987/r-tip-animations-in-r "],["ggplot2.html", "Chapter 108 ggplot2", " Chapter 108 ggplot2 http://r-statistics.co/ggplot2-Tutorial-With-R.html https://ggplot2.tidyverse.org/reference/ continue from here http://r-statistics.co/ggplot2-Tutorial-With-R.html "],["gganimate-1.html", "Chapter 109 gganimate", " Chapter 109 gganimate https://cran.r-project.org/web/packages/gganimate/vignettes/gganimate.html "],["ggforce.html", "Chapter 110 ggforce", " Chapter 110 ggforce "],["g2r.html", "Chapter 111 g2r", " Chapter 111 g2r remotes::install_github(&quot;JohnCoene/g2r&quot;) http://h2o-release.s3.amazonaws.com/h2o/rel-wright/10/docs-website/h2o-r/docs/articles/getting_started.html https://datascienceplus.com/hierarchical-clustering-in-r/ author: &#39;[Serdar Balcı, MD, Pathologist](https://sbalci.github.io/)&#39; date: &quot;`{r # format(Sys.Date())`&quot; output: revealjs::revealjs_presentation: incremental: yes theme: sky highlight: pygments center: no smart: yes transition: fade self_contained: yes ig_width: 7 fig_height: 6 fig_caption: yes reveal_options: slideNumber: yes previewLinks: yes prettydoc::html_pretty: theme: leonids highlight: github rmdshower::shower_presentation: null beamer_presentation: incremental: yes highlight: tango html_notebook: fig_caption: yes highlight: kate number_sections: yes theme: flatly toc: yes toc_depth: 5 toc_float: yes slidy_presentation: null pdf_document: toc: yes toc_depth: &#39;5&#39; html_document: fig_caption: yes keep_md: yes toc: yes toc_depth: 5 toc_float: yes xaringan::moon_reader: lib_dir: libs nature: beforeInit: - macros.js - https://platform.twitter.com/widgets.js highlightStyle: github highlightLines: yes countIncrementalSlides: no self_contained: yes ioslides_presentation: incremental: yes highlight: github institute: &#39;[serdarbalci.com](https://www.serdarbalci.com)&#39; editor_options: chunk_output_type: inline "],["how-to-prepare-data-for-histopathology-research.html", "Chapter 112 How to Prepare Data for Histopathology Research?", " Chapter 112 How to Prepare Data for Histopathology Research? Outline Why is Data Preparation Important? Do I need a specific Software? What are the Golden Rules? What do I do with Data after analysis? I got all the tables from the biostatistician, is it enough? What is a Good (Clean/Ideal/Tidy) Data? What is a Bad (Dirty/Common/Untidy) Data? Do I need to know statistics before collecting Data? Do I need to have a hypothesis before collecting Data? Do I need a research question before collecting Data? "],["how-to-prepare-data-for-histopathology-research-1.html", "Chapter 113 How to Prepare Data for Histopathology Research?", " Chapter 113 How to Prepare Data for Histopathology Research? We Should Collect the Data Related to What We will Report Recommendations for reporting histopathology studies: a proposal {r # PMID_25846513$title {r # citation_25846513 {r # PubMed_25846513 {r # addthis_inline_25846513 {r # PMID_25846513$abstract {r # doi_25846513 {r # dimensionBadge_25846513 {r # altmetricBadge_25846513 "],["tables-and-graphs-to-be-formed.html", "Chapter 114 Tables and Graphs to be Formed", " Chapter 114 Tables and Graphs to be Formed Table One: Clinical Features Related to this disease and Histopathological Features (like a CAP synoptic) Cross Tables IHC Tables Survival Tables and Graphs "],["age.html", "Chapter 115 Age", " Chapter 115 Age "],["gender.html", "Chapter 116 Gender", " Chapter 116 Gender Male Female Non-binary (based on research) For missing values: {gender} 📦 https://lincolnmullen.com/software/gender/ https://github.com/ropensci/gender "],["surgery-type.html", "Chapter 117 Surgery Type", " Chapter 117 Surgery Type "],["histopatoloji-çalışmalarında-istatistik-analizi-için-nasıl-veri-hazırlanır.html", "Chapter 118 Histopatoloji çalışmalarında istatistik analizi için nasıl veri hazırlanır?", " Chapter 118 Histopatoloji çalışmalarında istatistik analizi için nasıl veri hazırlanır? İstatistik analizlerinde en çok vakit alan kısım verilerin düzenlenmesi ve analize hazır hale getirilmesidir. Bu durum o kadar belirgindir ki veri analizi ile ilgili eğitimlerin de özel bir kısmını “veri temizleme” dersleri oluşturmaktadır \\(Coursera\\). Analize hazır haldeki veri “temiz veri” olarak adlandırılır \\(Tidy Data, H.Wickham\\). İstatistikçilerin kısıtlı vakti olduğunu düşünüldüğünde verinin temiz olarak teslim edilmesi onların veriyi rahat anlamalarına ve veri temizleme için ayıracakları vakit yerine sizin araştırmanızdaki ilginç noktalara odaklanmalarına yardımcı olacaktır. Ayrıca temiz veri ile çalışmanın istatistikçileri daha mutlu ettiğini ve özen gösterilmiş bir veride onların da daha özenli çalıştığını gözlemlediğimi belirtmek isterim. Bu yazıda hipotetik bir histopatoloji çalışması için basamak basamak veri hazırlanma süreci anlatılacaktır. Histopatolojik makalelerde bulunması gereken minimum bilgiler Bu yazıda kendi karşılaştığım problemleri ve literatürdeki önerileri \\(Virchows Arch \\(2015\\) 466:611–615) derlemeye çalıştım. Statistical Problems to Document and to Avoid Manuscript Checklist for Authors http://biostat.mc.vanderbilt.edu/wiki/Main/ManuscriptChecklist Aslında bir “eski tümöre yeni boya” olarak adlandırılan ve sık yapılan bir çalışma türünü inceleyeceğiz. Bunun için yapılacak ilk iş çalışılacak tümörle ilgili CAP protokolünü dikkatlice okumaktır. CAP protokollerinin özellikle not ve açıklama kısımlarındaki detaylar çok faydalı olacaktır. Bundan sonra bir boş kağıt alıp CAP protokolünde raporda belirtilmesi gereken konular maddeler halinde sıralanmalıdır. Bu maddeler çalışmanın tasarlamasından, analizine, yorumuna ve tartışmasına çok yardımcı olacaktır. 118 Temiz veri için dikkat edilmesi gereken kurallar: Her satır tek hasta Her sütun tek bilgi Her bilgi tek bir şekilde ifade edilecek 118 Verinin girileceği bilgisayar programı Aynı değerin farklı şekilde yazılması Veri hazırlamak için excel ya da filemaker kullanılmasını öneririm. 118 Vaka numarası Çalışmaya kaç vaka alınacak? Her değişken için 10 vaka? Vakaların seçilme şekli: Gelişigüzel? Randomize? Birbirini takip eden \\(consequative\\) 118 Yıl Hangi yıl aralığı tercih edilmeli? Yıl aralığınının belirtilmesi nadir vakalarda vaka sayısı ile ilgili bilgi verebilir. Bu nedenle klinikteki toplam vaka sayısı ile karşılaştırma yapılması Bir klinikten çıkan vaka sayısı da o klinikte bu işin ne kadar ciddi yapıldığının ve tecrübenin göstergesi. Kabul şansını arttıran faktör. İmmünohistokimya için eski vakalar mı tercih edilecek yeni vakalar mı? 118 Biyopsi No 118 TC Kimlik, Hasta No, Ad Soyad hasta bazlı çalışma vs örnek bazlı çalışma HIPAA kuralları 118 Yaş Yıl, ay Eğer tümör belli bir yaş aralığında görülüyor, ya da bimodal dağılım gösteriyorsa \\(osteosarkom gibi\\) bu durumu 118 Doğum Tarihi 118 Cinsiyet 118 Tümör çapı 118 T evresi 118 N evresi Lenf nodu Direk invazyon 118 M evresi 118 TNM/AJCC evresi 118 Histopatolojik tip 118 Lenfovasküler İnvazyon \\(LVI\\) Lenfovasküler invazyon çoğu tümör raporlarında belirtilmesi gereken bir özelliktir. Önerilen kodlama şekli var ise 1, yok ise 0 şeklindedir. Lenfatik ve vasküler invazyon ayrı ayrı da kodlanabilir. Mesela kolon tümörlerinde ekstramural venöz invazyonun belirtilmesi gibi. CAP protokollerinde “equivocal” olarak belirtilen şüpheli durumlardan mümkün oldukça kaçınmak analizlerin daha rahat yapılabilmesi için gereklidir. “Extensive retraction artefact” gibi özellikli durumlar çalışmıyorsa immünohistokimyasal çalışmalara gerek olmadan rutin H&amp;E değerlendirme yeterlidir. Raporlardan elde edilen bulgular da analiz için kullanılabilir. Özellikle rutin rapora göre tedavi planlanan durumlarda, doğal seyri seyretmek istediğiniz çalışmalarda bunu yapabilirsiniz. Patologların ise yaptıkları çalışmalarda mutlaka tüm vakalara yeniden bakmaları önerilir. Bazen araştırmacılar sadece “negatif” olarak raporlanan vakalara bakıp, bunlarda “atlanan” lenfovasküler invazyonu yakalamaya çalışırlar. Bu durumda lenfovasküler invazyon yüzdeniz literatürden yüksek çıkacaktır \\(Yanlış negatifler azalacaktır\\). Pozitif olan olgulara da bakılmalı, “pozitif” olarak raporlanan ve aslında lenfovasküler invazyonu olmayan vakalar \\(yanlış pozitif\\) ise negatif olarak analize alınmalıdır. Lenf nodunda metastaz olan olgularda lenfovasküler invazyonu pozitif olarak kabul etmek uygun değildir. Lenf noduna metastaz yapmanın ayrı peritümöral lenfovasküler invazyon tespit edilmesinin ayrı tümör gelişim basamakları olduğu düşünülmelidir. 118 Perinöral \\(perinöryal\\) invazyon 118 Cerrahi sınır 118 Ek hastalık 118 İkinci primer Birden fazla tümörü olan olgularda klinik gidişi ve sağkalımı diğer tümör etkiliyor olabilir. Sistoprostatektomilerde ürotelyal karsinom sağkalıma, prostat tümörlerinden daha fazla etki edecektir. Bu vakaların çıkartılması da insidansı etkileyebilir. Bu nedenle çalışmanın tasarımına göre bu vakaları eklemek ya da çıakrtmak gerekecektir. 118 İmmünohistokimya Pozitif, negatif Kayıp, korunmuş Şiddet Yaygınlık H-skor, Allred score, Quick score Hangi hücre pozitif Hangi komponent pozitif \\(nükleer, sitoplazmik, membranöz\\) Yüzde Sonuçları gruplama Uygun antikor klonunu seçmek ayrı bir yazı konusu olmalı. 118 Ameliyat şekli 118 Sağkalım Sağkalım verisi de hassas bilgilerdendir. Ölüm bildirim sistemi Tarihler Tanı tarihi Son tarih Tarih girerken neye dikkat edelim \\(İngilizce ve Türkçe farklı tarih formatları\\) 118 Overall survival 118 Disease Free Survival 118 Vertikal tarama 118 Bilinmeyen veriler, Eksik veriler, Missing values Her eksik hücre, çok değişkenli analizden o vakanın düşmesine neden olacaktır. Eksik camlar Eksik verileri excelde kontrol etme 118 Tek merkez, çok merkezli çalışma 118 İstatistikçiye sorulması gereken sorular Çalışmaya başlamadan önce, hangi soruları soracağınızı zaten planlamış olmanız ve buna göre verilerinizi düzenlemiş olmanız gerekir. Yine de çalışma sürerken ve çalışmanın sonunda yeni sorular ve düşünceler ortaya çıkabilir. Sorulacak sorular ve yapılacak analizler için bir ön hazırlık yapmak ve bunları düzgün cümleler halinde kaydetmek önemlidir. Mesela “tümör tipleri ile X protein ekspresyonunu karşılaştırmak istiyorum” bir soru olabilir. Ama daha iyisi “X proteininin ekspresyonunun A tümöründe B tümörüne göre daha fazla olduğunu düşünüyorum, bunun öyle olup olmadığını analiz etmenizi istiyorum” daha da anlaşılır bir soru olacaktır. 118 Bana p değeri ver 118 Hangi istatistik yöntemlerini bilmem lazım Tıp fakültesinin ilk yıllarında öğrenilen istatistikle ilgili kavramlar yıllar içinde unutuluyor. Elbette herkesin detaylı olarak istatistik metodlarını bilmesine gerek yok. Ancak yine de bir istatistik okuryazarlığının \\(statistical literacy\\) olmasında fayda var. ANOVA testi 30 vaka sayılı, tercihen verilerin normal dağıldığı durumlarda ve veriler ölçülebilir ve sürekli nitelikte ise kullanılır. Mesela yaş, özefagus lümeninin, özefagus duvarına oranı gibi durumlarda kullanılabilir. Ancak histopatolojik dercelendirme ya da evreleme gibi kesikli değişkenlerin olduğu durumlarda parametrik test olan ANOVA önerilmez. Grade 1 ila grade 2 arasındaki fark ile grade 2 ila grade 3 arasındaki fark matematiksel olarak eşit değildir. Grade 2, grade 1 den 2 kat kötü, grade 3 ise grade 1’den 3 kat kötüdür gibi bir yorum yapılmaz. Hastaların kanser evresinin ortalama 2,5 , ya da tümör grade’inin ortalama 1,2 olarak verilmesi önerilmez. Bunun yerine ortanca ve çeyrekler arası fark \\(median, interquartile range\\) kullanılması daha uygun olur. Bu nedenle yapılacak test de ANOVA’nın nonparametrik karşılığı olan Kruskal Wallis testidir. Ölçüm şeklinde olan, sürekli değişkenlerde bile vaka sayısının 30’dan az ise ya da veriler normal dağılmıyorsa birden fazla grubun karşılaştırmasında da Kruskal Wallis testi kullanılır. İstatistik dışı bakış açısı ile; Kanser evreleme çalışmalarında \\(lenf nodu sayısında\\) logaritmik dönüşüm çok kullanılıyor. Ve hemen tüm çalışmalarda işe yarıyor. Örnek https://www.ncbi.nlm.nih.gov/pubmed/28094085 Ama klinikte bilgisayar destekli bir karar sistemi kullanılmadığı zaman bu logaritmik değerler çok afaki kalabiliyor. Model anlamlı olsa da pratikte anlaması zor oluyor. Normallik yoksa nonparametrik testleri bir kademe daha rahat anlayabiliyorum. "],["top-ten-errors-of-statistical-analysis-in-observational-studies-for-cancer-research.html", "Chapter 119 Top ten errors of statistical analysis in observational studies for cancer research", " Chapter 119 Top ten errors of statistical analysis in observational studies for cancer research https://rd.springer.com/article/10.1007%2Fs12094-017-1817-9 "],["tweets.html", "Chapter 120 Tweets", " Chapter 120 Tweets author: &quot;Derleyen [Serdar Balcı, MD, Pathologist](https://sbalci.github.io/)&quot; date: &quot;`{r # format(Sys.Date())`&quot; output: rmdformats::html_clean: highlight: kate html_notebook: fig_caption: yes highlight: kate number_sections: yes theme: flatly toc: yes toc_depth: 5 toc_float: yes pdf_document: toc: yes toc_depth: &#39;5&#39; html_document: fig_caption: yes keep_md: yes toc: yes toc_depth: 5 toc_float: yes library(knitr) library(rmdformats) ## Global options options(max.print=&quot;75&quot;) opts_chunk$set(echo=TRUE, cache=TRUE, prompt=FALSE, tidy=TRUE, comment=NA, message=FALSE, warning=FALSE) opts_knit$set(width=75) R generation https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x "],["r-yükleme.html", "Chapter 121 R yükleme 121.1 R-project 121.2 RStudio 121.3 X11 121.4 Java OS", " Chapter 121 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY 121.1 R-project https://cran.r-project.org/ 121.2 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 121.2.1 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ 121.3 X11 https://www.xquartz.org/ 121.4 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor.html", "Chapter 122 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 122 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf "],["r-paketleri.html", "Chapter 123 R paketleri 123.1 Neden paketler var 123.2 Paketleri nereden bulabiliriz 123.3 Kendi paket evrenini oluştur 123.4 R için yardım bulma 123.5 R paket yükleme", " Chapter 123 R paketleri 123.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/ 123.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch Awesome R https://awesome-r.com/ 123.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 123.4 R için yardım bulma # ?mean # ??efetch # help(merge) # example(merge) Vignette RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Reproducible Examples Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 123.5 R paket yükleme install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) # install.packages(&#39;tidyverse&#39;, dependencies = TRUE) install.packages(&#39;jmv&#39;, # dependencies = TRUE) install.packages(&#39;questionr&#39;, dependencies = TRUE) # install.packages(&#39;Rcmdr&#39;, dependencies = TRUE) install.packages(&#39;summarytools&#39;) # require(tidyverse) require(jmv) require(questionr) library(summarytools) # library(gganimate) "],["r-studio-ile-proje-oluşturma.html", "Chapter 124 R studio ile proje oluşturma", " Chapter 124 R studio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme.html", "Chapter 125 RStudio ile veri yükleme 125.1 Excel 125.2 SPSS 125.3 csv", " Chapter 125 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 125.1 Excel 125.2 SPSS 125.3 csv "],["veriyi-görüntüleme.html", "Chapter 126 Veriyi görüntüleme", " Chapter 126 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 # library(nycflights13) summary(flights) View(data) data head tail glimpse str skimr::skim() "],["veriyi-değiştirme.html", "Chapter 127 Veriyi değiştirme 127.1 Veriyi kod ile değiştirelim 127.2 Veriyi eklentilerle değiştirme 127.3 RStudio aracılığıyla recode", " Chapter 127 Veriyi değiştirme 127.1 Veriyi kod ile değiştirelim 127.2 Veriyi eklentilerle değiştirme 127.3 RStudio aracılığıyla recode questionr paketi kullanılacak https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler.html", "Chapter 128 Basit tanımlayıcı istatistikler 128.1 summarytools 128.2 skimr 128.3 DataExplorer 128.4 Grafikler", " Chapter 128 Basit tanımlayıcı istatistikler summary() mean median min max sd table() library(readr) irisdata &lt;- read_csv(&quot;data/iris.csv&quot;) jmv::descriptives(data = irisdata, vars = &quot;Sepal.Length&quot;, splitBy = &quot;Species&quot;, freq = TRUE, hist = TRUE, dens = TRUE, bar = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sum = TRUE, sd = TRUE, variance = TRUE, range = TRUE, se = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE, pcEqGr = TRUE) DESCRIPTIVES Descriptives ───────────────────────────────────────────────────── Species Sepal.Length ───────────────────────────────────────────────────── N setosa 50 versicolor 50 virginica 50 Missing setosa 0 versicolor 0 virginica 0 Mean setosa 5.006000 versicolor 5.936000 virginica 6.588000 Std. error mean setosa 0.04984957 versicolor 0.07299762 virginica 0.08992695 Median setosa 5.000000 versicolor 5.900000 virginica 6.500000 Mode setosa 5.000000 versicolor 5.500000 virginica 6.300000 Sum setosa 250.3000 versicolor 296.8000 virginica 329.4000 Standard deviation setosa 0.3524897 versicolor 0.5161711 virginica 0.6358796 Variance setosa 0.1242490 versicolor 0.2664327 virginica 0.4043429 Range setosa 1.500000 versicolor 2.100000 virginica 3.000000 Minimum setosa 4.300000 versicolor 4.900000 virginica 4.900000 Maximum setosa 5.800000 versicolor 7.000000 virginica 7.900000 Skewness setosa 0.1200870 versicolor 0.1053776 virginica 0.1180151 Std. error skewness setosa 0.3366007 versicolor 0.3366007 virginica 0.3366007 Kurtosis setosa -0.2526888 versicolor -0.5330095 virginica 0.03290442 Std. error kurtosis setosa 0.6619084 versicolor 0.6619084 virginica 0.6619084 25th percentile setosa 4.800000 versicolor 5.600000 virginica 6.225000 50th percentile setosa 5.000000 versicolor 5.900000 virginica 6.500000 75th percentile setosa 5.200000 versicolor 6.300000 virginica 6.900000 ───────────────────────────────────────────────────── 128.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 128.2 skimr library(skimr) skim(df) 128.3 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 128.4 Grafikler descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["rcmdr.html", "Chapter 129 Rcmdr", " Chapter 129 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ "],["jamovi.html", "Chapter 130 jamovi", " Chapter 130 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["sonraki-konular.html", "Chapter 131 Sonraki Konular", " Chapter 131 Sonraki Konular RStudio ile GitHub Hipotez testleri R Markdown ve R Notebook ile tekrarlanabilir rapor "],["diğer-kodlar.html", "Chapter 132 Diğer kodlar", " Chapter 132 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim.html", "Chapter 133 Geri Bildirim", " Chapter 133 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. author: &quot;Derleyen [Serdar Balcı, MD, Pathologist](https://sbalci.github.io/)&quot; date: &quot;`{r # format(Sys.Date())`&quot; output: rmdformats::html_clean: highlight: kate html_notebook: fig_caption: yes highlight: kate number_sections: yes theme: flatly toc: yes toc_depth: 5 toc_float: yes pdf_document: toc: yes toc_depth: &#39;5&#39; html_document: fig_caption: yes keep_md: yes toc: yes toc_depth: 5 toc_float: yes R generation https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x "],["r-yükleme-1.html", "Chapter 134 R yükleme 134.1 R-project 134.2 RStudio 134.3 X11 134.4 Java OS", " Chapter 134 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY 134.1 R-project https://cran.r-project.org/ 134.2 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 134.2.1 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ 134.3 X11 https://www.xquartz.org/ 134.4 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor-1.html", "Chapter 135 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 135 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf "],["r-paketleri-1.html", "Chapter 136 R paketleri 136.1 Neden paketler var 136.2 Paketleri nereden bulabiliriz 136.3 Kendi paket evrenini oluştur 136.4 R için yardım bulma 136.5 R paket yükleme", " Chapter 136 R paketleri 136.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/ 136.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch Awesome R https://awesome-r.com/ 136.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 136.4 R için yardım bulma # ?mean # ??efetch # help(merge) # example(merge) Vignette RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Reproducible Examples Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 136.5 R paket yükleme install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) # install.packages(&#39;tidyverse&#39;, dependencies = TRUE) install.packages(&#39;jmv&#39;, # dependencies = TRUE) install.packages(&#39;questionr&#39;, dependencies = TRUE) # install.packages(&#39;Rcmdr&#39;, dependencies = TRUE) install.packages(&#39;summarytools&#39;) # require(tidyverse) require(jmv) require(questionr) library(summarytools) # library(gganimate) "],["r-studio-ile-proje-oluşturma-1.html", "Chapter 137 R studio ile proje oluşturma", " Chapter 137 R studio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme-1.html", "Chapter 138 RStudio ile veri yükleme 138.1 Excel 138.2 SPSS 138.3 csv", " Chapter 138 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 138.1 Excel 138.2 SPSS 138.3 csv "],["veriyi-görüntüleme-1.html", "Chapter 139 Veriyi görüntüleme", " Chapter 139 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 # library(nycflights13) summary(flights) View(data) data head tail glimpse str skimr::skim() "],["veriyi-değiştirme-1.html", "Chapter 140 Veriyi değiştirme 140.1 Veriyi kod ile değiştirelim 140.2 Veriyi eklentilerle değiştirme 140.3 RStudio aracılığıyla recode", " Chapter 140 Veriyi değiştirme 140.1 Veriyi kod ile değiştirelim 140.2 Veriyi eklentilerle değiştirme 140.3 RStudio aracılığıyla recode questionr paketi kullanılacak https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler-1.html", "Chapter 141 Basit tanımlayıcı istatistikler 141.1 summarytools 141.2 skimr 141.3 DataExplorer 141.4 Grafikler", " Chapter 141 Basit tanımlayıcı istatistikler summary() mean median min max sd table() 141.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 141.2 skimr library(skimr) skim(df) 141.3 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 141.4 Grafikler descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["rcmdr-1.html", "Chapter 142 Rcmdr", " Chapter 142 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ "],["jamovi-1.html", "Chapter 143 jamovi", " Chapter 143 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["sonraki-konular-1.html", "Chapter 144 Sonraki Konular", " Chapter 144 Sonraki Konular RStudio ile GitHub Hipotez testleri R Markdown ve R Notebook ile tekrarlanabilir rapor "],["diğer-kodlar-1.html", "Chapter 145 Diğer kodlar", " Chapter 145 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim-1.html", "Chapter 146 Geri Bildirim", " Chapter 146 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. library(knitr) library(rmdformats) ## Global options options(max.print = &quot;75&quot;) opts_chunk$set(echo = TRUE, cache = TRUE, prompt = FALSE, tidy = TRUE, comment = NA, message = FALSE, warning = FALSE) opts_knit$set(width = 75) R generation https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x "],["r-yükleme-2.html", "Chapter 147 R yükleme 147.1 R-project 147.2 RStudio 147.3 X11 147.4 Java OS", " Chapter 147 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY 147.1 R-project https://cran.r-project.org/ 147.2 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 147.2.1 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ 147.3 X11 https://www.xquartz.org/ 147.4 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor-2.html", "Chapter 148 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 148 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf "],["r-paketleri-2.html", "Chapter 149 R paketleri 149.1 Neden paketler var 149.2 Paketleri nereden bulabiliriz 149.3 Kendi paket evrenini oluştur 149.4 R için yardım bulma 149.5 R paket yükleme", " Chapter 149 R paketleri 149.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/ 149.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch Awesome R https://awesome-r.com/ 149.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 149.4 R için yardım bulma # ?mean # ??efetch # help(merge) # example(merge) Vignette RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Reproducible Examples Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 149.5 R paket yükleme install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) # install.packages(&#39;tidyverse&#39;, dependencies = TRUE) install.packages(&#39;jmv&#39;, # dependencies = TRUE) install.packages(&#39;questionr&#39;, dependencies = TRUE) # install.packages(&#39;Rcmdr&#39;, dependencies = TRUE) install.packages(&#39;summarytools&#39;) # require(tidyverse) require(jmv) require(questionr) library(summarytools) # library(gganimate) "],["r-studio-ile-proje-oluşturma-2.html", "Chapter 150 R studio ile proje oluşturma", " Chapter 150 R studio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme-2.html", "Chapter 151 RStudio ile veri yükleme 151.1 Excel 151.2 SPSS 151.3 csv", " Chapter 151 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 151.1 Excel 151.2 SPSS 151.3 csv "],["veriyi-görüntüleme-2.html", "Chapter 152 Veriyi görüntüleme", " Chapter 152 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 # library(nycflights13) summary(flights) View(data) data head tail glimpse str skimr::skim() "],["veriyi-değiştirme-2.html", "Chapter 153 Veriyi değiştirme 153.1 Veriyi kod ile değiştirelim 153.2 Veriyi eklentilerle değiştirme 153.3 RStudio aracılığıyla recode", " Chapter 153 Veriyi değiştirme 153.1 Veriyi kod ile değiştirelim 153.2 Veriyi eklentilerle değiştirme 153.3 RStudio aracılığıyla recode questionr paketi kullanılacak https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler-2.html", "Chapter 154 Basit tanımlayıcı istatistikler 154.1 summarytools 154.2 skimr 154.3 DataExplorer 154.4 Grafikler", " Chapter 154 Basit tanımlayıcı istatistikler summary() mean median min max sd table() library(readr) irisdata &lt;- read_csv(&quot;data/iris.csv&quot;) jmv::descriptives(data = irisdata, vars = &quot;Sepal.Length&quot;, splitBy = &quot;Species&quot;, freq = TRUE, hist = TRUE, dens = TRUE, bar = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sum = TRUE, sd = TRUE, variance = TRUE, range = TRUE, se = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE, pcEqGr = TRUE) DESCRIPTIVES Descriptives ───────────────────────────────────────────────────── Species Sepal.Length ───────────────────────────────────────────────────── N setosa 50 versicolor 50 virginica 50 Missing setosa 0 versicolor 0 virginica 0 Mean setosa 5.006000 versicolor 5.936000 virginica 6.588000 Std. error mean setosa 0.04984957 versicolor 0.07299762 virginica 0.08992695 Median setosa 5.000000 versicolor 5.900000 virginica 6.500000 Mode setosa 5.000000 versicolor 5.500000 virginica 6.300000 Sum setosa 250.3000 versicolor 296.8000 virginica 329.4000 Standard deviation setosa 0.3524897 versicolor 0.5161711 virginica 0.6358796 Variance setosa 0.1242490 versicolor 0.2664327 virginica 0.4043429 Range setosa 1.500000 versicolor 2.100000 virginica 3.000000 Minimum setosa 4.300000 versicolor 4.900000 virginica 4.900000 Maximum setosa 5.800000 versicolor 7.000000 virginica 7.900000 Skewness setosa 0.1200870 versicolor 0.1053776 virginica 0.1180151 Std. error skewness setosa 0.3366007 versicolor 0.3366007 virginica 0.3366007 Kurtosis setosa -0.2526888 versicolor -0.5330095 virginica 0.03290442 Std. error kurtosis setosa 0.6619084 versicolor 0.6619084 virginica 0.6619084 25th percentile setosa 4.800000 versicolor 5.600000 virginica 6.225000 50th percentile setosa 5.000000 versicolor 5.900000 virginica 6.500000 75th percentile setosa 5.200000 versicolor 6.300000 virginica 6.900000 ───────────────────────────────────────────────────── 154.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 154.2 skimr library(skimr) skim(df) 154.3 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 154.4 Grafikler descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["rcmdr-2.html", "Chapter 155 Rcmdr", " Chapter 155 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ "],["jamovi-2.html", "Chapter 156 jamovi", " Chapter 156 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["sonraki-konular-2.html", "Chapter 157 Sonraki Konular", " Chapter 157 Sonraki Konular RStudio ile GitHub Hipotez testleri R Markdown ve R Notebook ile tekrarlanabilir rapor "],["diğer-kodlar-2.html", "Chapter 158 Diğer kodlar", " Chapter 158 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim-2.html", "Chapter 159 Geri Bildirim", " Chapter 159 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. library(knitr) library(dplyr) library(huxtable) options(huxtable.knit_print_df = FALSE) is_latex &lt;- guess_knitr_output_format() == &quot;latex&quot; # is_latex &lt;- TRUE knitr::knit_hooks$set(barrier = function(before, options, envir) { if (!before &amp;&amp; is_latex) knitr::asis_output(&quot;\\\\FloatBarrier&quot;) }) if (is_latex) knitr::opts_chunk$set(barrier = TRUE) huxtable::hux_logo(latex = is_latex) Table 159.1: h ux t a ble # PLAN Make single document work in notebook format (maybe with minimal changes) # Installation Dplyr examples Examples with where and friends Different kinds of # output Cookbook? Limitations "],["introduction.html", "Chapter 160 Introduction 160.1 About this document 160.2 Huxtable 160.3 Installation 160.4 Getting started", " Chapter 160 Introduction 160.1 About this document This is the introductory vignette for the R package ‘huxtable’, version {r # packageVersion('huxtable'). A current version is available on the web in HTML or PDF format. 160.2 Huxtable Huxtable is a package for creating text tables. It is powerful, but easy to use. It is meant to be a replacement for packages like xtable, which is useful but not always very user-friendly. Huxtable’s features include: Export to LaTeX, HTML, Word and Markdown Easy integration with knitr and rmarkdown documents Multirow and multicolumn cells Fine-grained control over cell background, spacing, alignment, size and borders Control over text font, style, size, colour, alignment, number format and rotation Table manipulation using standard R subsetting, or dplyr functions like filter and select Easy conditional formatting based on table contents Quick table themes Automatic creation of regression output tables with the huxreg function We will cover all of these features below. 160.3 Installation If you haven’t already installed huxtable, you can do so from the R command line: install.packages(&quot;huxtable&quot;) 160.4 Getting started A huxtable is a way of representing a table of text data in R. You already know that R can represent a table of data in a data frame. For example, if mydata is a data frame, then mydata[1, 2] represents the the data in row 1, column 2, and mydata$start_time is all the data in the column called start_time. A huxtable is just a data frame with some extra properties. So, if myhux is a huxtable, then myhux[1, 2] represents the data in row 1 column 2, as before. But this cell will also have some other properties - for example, the font size of the text, or the colour of the cell border. To create a table with huxtable, use the function huxtable, or hux for short. This works very much like data.frame. If you already have your data in a data frame, you can convert it to a huxtable with as_hux. If you look at a huxtable in R, it will print out a simple representation of the data. Notice that we’ve added the column names to the data frame itself, using the add_colnames argument to hux. We’re going to print them out, so they need to be part of the actual table. NB: This means that row 1 of your data will be row 2 of the huxtable, and the column names of your data will be the new row 1. To print a huxtable out using LaTeX or HTML, just call print_latex or print_html. In knitr documents, like this one, you can simply evaluate the hux. It will know what format to print itself in. "],["changing-the-look-and-feel.html", "Chapter 161 Changing the look and feel 161.1 Huxtable properties 161.2 Tidyverse syntax 161.3 Getting properties", " Chapter 161 Changing the look and feel 161.1 Huxtable properties The default output is a very plain table. Let’s make it a bit smarter. We’ll make the table headings bold, draw a line under the header row, and add some horizontal space to the cells. We also need to change that default number formatting to look less scientific. To do this, we need to set cell level properties. You set properties by assigning to the property name, just as you assign names(x) &lt;- new_names in base R. The following commands assign the value 10 to the {r # ight_padding and left_padding properties, for all cells in ht: Similarly, we can set the number_format property to change how numbers are displayed in cells: To assign properties to just some cells, you use subsetting, just as in base R. So, to make the first row of the table bold and give it a bottom border, we do: After these changes, our table looks smarter: So far, all these properties have been set at cell level. Different cells can have different alignment, text formatting and so on. By contrast, caption is a table-level property. It only takes one value, which sets a table caption. As well as cell properties and table properties, there is also one row property, row heights, and one column property, column widths. The table below shows a complete list of properties. Most properties work the same for LaTeX and HTML, though there are some exceptions. sides &lt;- c(&quot;left_&quot;, &quot;right_&quot;, &quot;top_&quot;, &quot;bottom_&quot;) props &lt;- list() props[[&quot;Cell_Text&quot;]] &lt;- sort(c(&quot;font&quot;, &quot;text_color&quot;, &quot;wrap&quot;, &quot;bold&quot;, &quot;italic&quot;, &quot;font&quot;, &quot;font_size&quot;, &quot;na_string&quot;, &quot;escape_contents&quot;, &quot;number_format&quot;, &quot;rotation&quot;)) props[[&quot;Cell&quot;]] &lt;- sort(c(&quot;align&quot;, &quot;valign&quot;, &quot;rowspan&quot;, &quot;colspan&quot;, &quot;background_color&quot;, paste0(sides, &quot;border&quot;), paste0(sides, &quot;border_color&quot;), paste0(sides, &quot;padding&quot;))) props[[&quot;Row&quot;]] &lt;- &quot;row_height&quot; props[[&quot;Column&quot;]] &lt;- &quot;col_width&quot; props[[&quot;Table&quot;]] &lt;- sort(c(&quot;width&quot;, &quot;height&quot;, &quot;position&quot;, &quot;caption&quot;, &quot;caption_pos&quot;, &quot;tabular_environment&quot;, &quot;label&quot;, &quot;latex_float&quot;)) maxl &lt;- max(sapply(props, length)) props &lt;- lapply(props, function(x) c(x, rep(&quot;&quot;, maxl - length(x)))) ss_font &lt;- if (guess_knitr_output_format() == &quot;latex&quot;) &quot;cmtt&quot; else &quot;courier&quot; prop_hux &lt;- hux(as.data.frame(props)) %&gt;% add_colnames %&gt;% { foo &lt;- . foo[1, ] &lt;- gsub(&quot;_&quot;, &quot; &quot;, foo[1, ]) foo } %&gt;% set_font(-1, everywhere, ss_font) %&gt;% set_bold(1, everywhere, TRUE) %&gt;% set_width(0.9) %&gt;% set_background_color(everywhere, evens, grey(0.9)) %&gt;% set_left_border(everywhere, 1, 1) %&gt;% set_right_border(everywhere, final(), 1) %&gt;% set_top_border(1, everywhere, 1) %&gt;% set_bottom_border(1, everywhere, 1) %&gt;% set_bottom_border(final(), everywhere, 1) %&gt;% set_top_padding(2) %&gt;% set_bottom_padding(4) %&gt;% set_caption(&quot;Huxtable properties&quot;) %&gt;% set_position(&quot;left&quot;) %&gt;% set_col_width(c(0.2, 0.25, 0.15, 0.15, 0.25)) prop_hux Table 161.1: Huxtable properties Cell TextCellRowColumnTable Cell_TextCellRowColumnTable boldalignrow_heightcol_widthcaption escape_contentsbackground_colorcaption_pos fontbottom_borderheight fontbottom_border_colorlabel font_sizebottom_paddinglatex_float italiccolspanposition na_stringleft_bordertabular_environment number_formatleft_border_colorwidth rotationleft_padding text_colorright_border wrapright_border_color right_padding rowspan top_border top_border_color top_padding valign 161.2 Tidyverse syntax If you prefer a tidyverse style of code, using the pipe operator %&gt;%, then you can use set_* functions. These have the same name as the property, with set_ prepended. For example, to set the bold property, you use the set_bold function. set_* functions return the modified huxtable, so you can chain them together like this: set_* functions for cell properties are called like this: set_xxx(ht, row, col, value) or like this: set_xxx(ht, value). If you use the second form, then the value is set for all cells. set_* functions for table properties are always called like set_xxx(ht, value). We’ll learn more about this interface in a moment. There are also four useful convenience functions: set_all_borders sets left, right, top and bottom borders for selected cells; set_all_border_colors sets left, right, top and bottom border colors; set_all_padding sets left, right, top and bottom padding (the amount of space between the content and the border); set_outer_borders sets an outer border around a rectangle of cells. 161.3 Getting properties To get the current properties of a huxtable, just use the properties function without the left arrow: italic(ht) position(ht) As before, you can use subsetting to get particular rows or columns: bottom_border(ht)[1:2, ] bold(ht)[, &quot;Salary&quot;] "],["editing-content.html", "Chapter 162 Editing content 162.1 Standard subsetting 162.2 Using dplyr with huxtable 162.3 Functions to insert rows, columns and footnotes", " Chapter 162 Editing content 162.1 Standard subsetting You can subset, sort and generally data-wrangle a huxtable just like a normal data frame. Cell and table properties will be carried over into subsets. 162.2 Using dplyr with huxtable You can also use dplyr functions to edit a huxtable: In general it is a good idea to prepare your data first, before styling it. For example, it was easier to sort the cars_mpg data by cylinder, before adding column names to the data frame itself. 162.3 Functions to insert rows, columns and footnotes Huxtable has three convenience functions for adding a row or column to your table: insert_row, insert_column and add_footnote. insert_row and insert_column let you add a single row or column. The after parameter specifies where in the table to do the insertion, i.e. after what row or column number. add_footnote adds a single cell in a new row at the bottom. The cell spans the whole table row, and has a border above. "],["more-formatting.html", "Chapter 163 More formatting 163.1 Number format 163.2 Automatic formatting 163.3 Escaping HTML or LaTeX 163.4 Width and cell wrapping 163.5 Adding row and column names 163.6 Column and row spans 163.7 Quick themes", " Chapter 163 More formatting 163.1 Number format You can change how huxtable formats numbers using number_format. Set number_format to a number of decimal places (for more advanced options, see the help files). This affects all numbers, or number-like substrings within your cells. You can also align columns by decimal places. If you want to do this for a cell, just set the align property to ‘.’ (or whatever you use for a decimal point). There is currently no true way to align cells by the decimal point in HTML, and only limited possibilities in TeX, so this works by right-padding cells with spaces. The output may look better if you use a fixed width font. 163.2 Automatic formatting By default, when you create a huxtable using huxtable or as_huxtable, the package will guess defaults for number formatting and alignment, based on the type of data in your columns. Numeric data will be right-aligned or aligned on the decimal point; character data will be left aligned; and the package will try to set sensible defaults for number formatting. If you want to, you can turn this off with autoformat = FALSE: 163.3 Escaping HTML or LaTeX By default, HTML or LaTeX code will be escaped: To avoid this, set the escape_contents property to FALSE. 163.4 Width and cell wrapping You can set table widths using the width property, and column widths using the col_width property. If you use numbers for these, they will be interpreted as proportions of the table width (or for width, a proportion of the width of the surrounding text). If you use character vectors, they must be valid CSS or LaTeX widths. The only unit both systems have in common is pt for points. It is best to set table width explicitly, then set column widths as proportions. By default, if a cell contains long contents, it will be stretched. Use the wrap property to allow cell contents to wrap over multiple lines: 163.5 Adding row and column names Just like data frames, huxtables can have row and column names. Often, we want to add these to the final table. You can do this using either the add_colnames/add_rownames arguments to as_huxtable, or the add_colnames()/add_rownames() functions. (Note that earlier versions of dplyr used to have functions with the same name.) 163.6 Column and row spans Huxtable cells can span multiple rows or columns, using the colspan and {r # owspan properties. 163.7 Quick themes Huxtable comes with some predefined themes for formatting. "],["selecting-rows-columns-and-cells.html", "Chapter 164 Selecting rows, columns and cells 164.1 Row and column functions 164.2 Conditional formatting", " Chapter 164 Selecting rows, columns and cells 164.1 Row and column functions If you use the set_* style functions, huxtable has some convenience functions for selecting rows and columns. To select all rows, or all columns, use everywhere in the row or column specification. To select just even or odd-numbered rows or columns, use evens or odds. To select the last n rows or columns, use final(n). To select every nth row, use every(n) and to do this starting from row m use every(n, from = m). With these functions it is easy to add striped backgrounds to tables: Of course you could also just do 1:nrow(car_ht), but, in the middle of a dplyr pipe, you may not know exactly how many rows or columns you have. Also, these functions make your code easy to read. You can also use dplyr functions like starts_with(), contains(), and matches() to specify columns by column name. For a full list of these functions, see ?select_helpers. Note that unlike in dplyr’s select function, you have to specify rows as well as columns. Lastly, remember that you can set a property for every cell by simply omitting the {r # ow and col arguments, like this: set_background_color(ht, 'orange'). 164.2 Conditional formatting You may want to apply conditional formatting to cells, based on their contents. Suppose we want to display a table of correlations, and to highlight ones which are significant. We can use the where() function to select those cells. We have now seen three ways to call set_* functions in huxtable: With four arguments, like set_property(hux_object, rows, cols, value); With two arguments, like set_property(hux_object, value) to set a property everywhere; With three arguments, like set_property(hux_object, where(condition), value) to set a property for specific cells. The second argument of the three-argument version must return a 2-column matrix. Each row of the matrix gives one cell. where() does this for you: it takes a logical matrix argument and returns the rows and columns where a condition is TRUE. It’s easiest to show this with an example: set_* functions have one more optional argument, the byrow argument, which is FALSE by default. If you set a single pattern for many cells, you may want the pattern to fill the matrix by column or by row. The default fills the pattern in going down columns. If you set byrow = TRUE, the pattern goes across rows instead. (This is a bit confusing: typically, byrow = TRUE means that the columns will all look the same. But it works the same way as the byrow argument to matrix().) "],["creating-a-regression-table.html", "Chapter 165 Creating a regression table", " Chapter 165 Creating a regression table A common task for scientists is to create a table of regressions. The function huxreg does this for you. Here’s a quick example: For more information see the huxreg vignette, available online in HTML or PDF or in R via vignette('huxreg'). "],["output-to-different-formats.html", "Chapter 166 Output to different formats 166.1 Automatic pretty-printing of data frames 166.2 Using huxtables in knitr and rmarkdown 166.3 Quick output commands", " Chapter 166 Output to different formats 166.1 Automatic pretty-printing of data frames If you load huxtable within a knitr document, it will automatically format data frames for you by installing a knit_print.data_frame command. options(huxtable.knit_print_df = TRUE) If you don’t want this (e.g. if you want to use knitr::kable or the printr package, then you can turn it off like this: 166.2 Using huxtables in knitr and rmarkdown If you use knitr and rmarkdown in RStudio, huxtable objects should automatically display in the appropriate format (HTML or LaTeX). You need to have some LaTeX packages installed for huxtable to work. To find out what these are, you can call {r # eport_latex_dependencies(). This will print out and/or return a set of usepackage{...} statements. If you use Sweave or knitr without rmarkdown, you can use this function in your LaTeX preamble to load the packages you need. Rmarkdown exports to Word via Markdown. You can use huxtable to do this, but since Markdown tables are rather basic, a lot of formatting will be lost. If you want to create Word or Powerpoint documents directly, install the flextable package from CRAN. You can then convert your huxtable objects to flextable objects and include them in Word or Powerpoint documents. Almost all formatting should work. See the flextable and officer documentation and ?as_flextable for more details. Similarly, to create formatted reports in Excel, install the openxlsx package. You can then use as_Workbook to convert your huxtables to Workbook objects, and save them using openxlsx::saveWorkbook. Sometimes you may want to select how huxtable objects are printed by default. For example, in an RStudio notebook (a .Rmd document with output_format = html_notebook), huxtable can’t automatically work out what format to use, as of the time of writing. You can set it manually using options(huxtable.print = print_notebook) which prints out HTML in an appropriate format. You can print a huxtable on screen using print_screen (or just by typing its name at the command line.) Borders, column and row spans and cell alignment are shown. If the crayon package is installed, and your terminal or R IDE supports it, border, text and background colours are also displayed. print_screen(ht) If you need to output to another format, file an issue request on Github. 166.3 Quick output commands Sometimes you quickly want to get your data into a Word, HTML or PDF document. To do this you can use the quick_docx, quick_html, quick_pdf and quick_xlsx functions. These are called with one or more huxtable objects, or objects which can be turned into a huxtable such as data frames. A new document of the appropriate type will be created. By default the file will be in the current directory under the name e.g. huxtable-output.pdf. If the file already exists, you’ll be asked to confirm the overwrite. For non-interactive use, you must specify a filename yourself explicitly – this keeps you from accidentally trashing your files. quick_pdf(mtcars) quick_pdf(mtcars, file = &quot;motorcars data.pdf&quot;) "],["end-matter.html", "Chapter 167 End matter", " Chapter 167 End matter For more information, see the website or github. "],["glue.html", "Chapter 168 Glue", " Chapter 168 Glue Glue strings to data in R. Small, fast, dependency free interpreted string literals. https://glue.tidyverse.org/ "],["infer-package.html", "Chapter 169 infer package", " Chapter 169 infer package Statistical Inference: A Tidy Approach https://ismayc.github.io/talks/ness-infer/slide_deck.html https://infer.netlify.com/ https://moderndive.netlify.com/ https://cran.r-project.org/web/packages/infer/index.html "],["hypothesis-testing.html", "Chapter 170 Hypothesis Testing 170.1 Test Selection", " Chapter 170 Hypothesis Testing 170.1 Test Selection 170.1.1 Statkat https://statkat.com/ https://statkat.com/stattest_overview.php 170.1.1.1 Jamovi Statkat module https://blog.jamovi.org/2018/06/25/statkat.html "],["infer-2.html", "Chapter 171 infer", " Chapter 171 infer Full infer pipeline examples using nycflights13 flights data https://cran.r-project.org/web/packages/infer/vignettes/observed_stat_examples.html Full infer pipeline examples using nycflights13 flights data Chester Ismay Updated on 2018-06-14 Data preparation library(nycflights13) library(dplyr) library(ggplot2) library(stringr) library(infer) set.seed(2017) fli_small &lt;- flights %&gt;% na.omit() %&gt;% sample_n(size = 500) %&gt;% mutate(season = case_when( month %in% c(10:12, 1:3) ~ “winter”, month %in% c(4:9) ~ “summer” )) %&gt;% mutate(day_hour = case_when( between(hour, 1, 12) ~ “morning”, between(hour, 13, 24) ~ “not morning” )) %&gt;% select(arr_delay, dep_delay, season, day_hour, origin, carrier) Two numeric - arr_delay, dep_delay Two categories season (“winter”, “summer”), day_hour (“morning”, “not morning”) Three categories - origin (“EWR”, “JFK”, “LGA”) Sixteen categories - carrier Hypothesis tests One numerical variable (mean) Observed stat ( x_bar &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% calculate(stat = “mean”) ) stat 10.4 null_distn &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% hypothesize(null = “point”, mu = 10) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “mean”) ## Setting type = \"bootstrap\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = x_bar, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = x_bar, direction = “two_sided”) p_value 0.794 One numerical variable (standardized mean t) Observed stat ( t_bar &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% calculate(stat = “t”) ) stat 6.93 null_distn &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% hypothesize(null = “point”, mu = 8) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “t”) ## Setting type = \"bootstrap\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = t_bar, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = t_bar, direction = “two_sided”) p_value 0 One numerical variable (median) Observed stat ( x_tilde &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% calculate(stat = “median”) ) stat -2 null_distn &lt;- fli_small %&gt;% specify(response = dep_delay) %&gt;% hypothesize(null = “point”, med = -1) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “median”) ## Setting type = \"bootstrap\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = x_tilde, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = x_tilde, direction = “two_sided”) p_value 0.15 One categorical (one proportion) Observed stat ( p_hat &lt;- fli_small %&gt;% specify(response = day_hour, success = “morning”) %&gt;% calculate(stat = “prop”) ) stat 0.466 null_distn &lt;- fli_small %&gt;% specify(response = day_hour, success = “morning”) %&gt;% hypothesize(null = “point”, p = .5) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “prop”) ## Setting type = \"simulate\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = p_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = p_hat, direction = “two_sided”) p_value 0.11 Logical variables will be coerced to factors: null_distn &lt;- fli_small %&gt;% mutate(day_hour_logical = (day_hour == “morning”)) %&gt;% specify(response = day_hour_logical, success = “TRUE”) %&gt;% hypothesize(null = “point”, p = .5) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “prop”) ## Setting type = \"simulate\" in generate(). One categorical variable (standardized proportion z) Not yet implemented. Two categorical (2 level) variables Observed stat ( d_hat &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% calculate(stat = “diff in props”, order = c(“winter”, “summer”)) ) stat -0.0205 null_distn &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “diff in props”, order = c(“winter”, “summer”)) ## Setting type = \"permute\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = d_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = d_hat, direction = “two_sided”) p_value 0.708 Two categorical (2 level) variables (z) Standardized observed stat ( z_hat &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% calculate(stat = “z”, order = c(“winter”, “summer”)) ) stat -0.4605 null_distn &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000) %&gt;% calculate(stat = “z”, order = c(“winter”, “summer”)) ## Setting type = \"permute\" in generate(). visualize(null_distn) + shade_p_value(obs_stat = z_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = z_hat, direction = “two_sided”) p_value 0.684 Note the similarities in this plot and the previous one. One categorical (&gt;2 level) - GoF Observed stat Note the need to add in the hypothesized values here to compute the observed statistic. ( Chisq_hat &lt;- fli_small %&gt;% specify(response = origin) %&gt;% hypothesize(null = “point”, p = c(“EWR” = .33, “JFK” = .33, “LGA” = .34)) %&gt;% calculate(stat = “Chisq”) ) stat 10.4 null_distn &lt;- fli_small %&gt;% specify(response = origin) %&gt;% hypothesize(null = “point”, p = c(“EWR” = .33, “JFK” = .33, “LGA” = .34)) %&gt;% generate(reps = 1000, type = “simulate”) %&gt;% calculate(stat = “Chisq”) visualize(null_distn) + shade_p_value(obs_stat = Chisq_hat, direction = “greater”) null_distn %&gt;% get_p_value(obs_stat = Chisq_hat, direction = “greater”) p_value 0.005 Two categorical (&gt;2 level) variables Observed stat ( Chisq_hat &lt;- fli_small %&gt;% specify(formula = day_hour ~ origin) %&gt;% calculate(stat = “Chisq”) ) stat 9.027 null_distn &lt;- fli_small %&gt;% specify(day_hour ~ origin) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “Chisq”) visualize(null_distn) + shade_p_value(obs_stat = Chisq_hat, direction = “greater”) null_distn %&gt;% get_p_value(obs_stat = Chisq_hat, direction = “greater”) p_value 0.007 One numerical variable, one categorical (2 levels) (diff in means) Observed stat ( d_hat &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% calculate(stat = “diff in means”, order = c(“summer”, “winter”)) ) stat 2.266 null_distn &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “diff in means”, order = c(“summer”, “winter”)) visualize(null_distn) + shade_p_value(obs_stat = d_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = d_hat, direction = “two_sided”) p_value 0.488 One numerical variable, one categorical (2 levels) (t) Standardized observed stat ( t_hat &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% calculate(stat = “t”, order = c(“summer”, “winter”)) ) stat 0.7542 null_distn &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “t”, order = c(“summer”, “winter”)) visualize(null_distn) + shade_p_value(obs_stat = t_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = t_hat, direction = “two_sided”) p_value 0.49 Note the similarities in this plot and the previous one. One numerical variable, one categorical (2 levels) (diff in medians) Observed stat ( d_hat &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% calculate(stat = “diff in medians”, order = c(“summer”, “winter”)) ) stat 2 null_distn &lt;- fli_small %&gt;% specify(dep_delay ~ season) %&gt;% # alt: response = dep_delay, # explanatory = season hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “diff in medians”, order = c(“summer”, “winter”)) visualize(null_distn) + shade_p_value(obs_stat = d_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = d_hat, direction = “two_sided”) p_value 0.084 One numerical, one categorical (&gt;2 levels) - ANOVA Observed stat ( F_hat &lt;- fli_small %&gt;% specify(arr_delay ~ origin) %&gt;% calculate(stat = “F”) ) stat 1.084 null_distn &lt;- fli_small %&gt;% specify(arr_delay ~ origin) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “F”) visualize(null_distn) + shade_p_value(obs_stat = F_hat, direction = “greater”) null_distn %&gt;% get_p_value(obs_stat = F_hat, direction = “greater”) p_value 0.353 Two numerical vars - SLR Observed stat ( slope_hat &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% calculate(stat = “slope”) ) stat 1.017 null_distn &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “slope”) visualize(null_distn) + shade_p_value(obs_stat = slope_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = slope_hat, direction = “two_sided”) p_value 0 Two numerical vars - correlation Observed stat ( correlation_hat &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% calculate(stat = “correlation”) ) stat 0.8943 null_distn &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% hypothesize(null = “independence”) %&gt;% generate(reps = 1000, type = “permute”) %&gt;% calculate(stat = “correlation”) visualize(null_distn) + shade_p_value(obs_stat = correlation_hat, direction = “two_sided”) null_distn %&gt;% get_p_value(obs_stat = correlation_hat, direction = “two_sided”) p_value 0 Two numerical vars - SLR (t) Not currently implemented since t could refer to standardized slope or standardized correlation. Confidence intervals One numerical (one mean) Point estimate ( x_bar &lt;- fli_small %&gt;% specify(response = arr_delay) %&gt;% calculate(stat = “mean”) ) stat 4.572 boot &lt;- fli_small %&gt;% specify(response = arr_delay) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “mean”) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% 1.436 7.819 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = x_bar) ) lower upper 1.267 7.877 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) One numerical (one mean - standardized) Point estimate ( t_hat &lt;- fli_small %&gt;% specify(response = arr_delay) %&gt;% calculate(stat = “t”) ) stat 2.679 boot &lt;- fli_small %&gt;% specify(response = arr_delay) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “t”) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% 0.9338 4.362 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = t_hat) ) lower upper 0.9141 4.444 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) One categorical (one proportion) Point estimate ( p_hat &lt;- fli_small %&gt;% specify(response = day_hour, success = “morning”) %&gt;% calculate(stat = “prop”) ) stat 0.466 boot &lt;- fli_small %&gt;% specify(response = day_hour, success = “morning”) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “prop”) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% 0.42 0.508 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = p_hat) ) lower upper 0.4218 0.5102 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) One categorical variable (standardized proportion z) Not yet implemented. One numerical variable, one categorical (2 levels) (diff in means) Point estimate ( d_hat &lt;- fli_small %&gt;% specify(arr_delay ~ season) %&gt;% calculate(stat = “diff in means”, order = c(“summer”, “winter”)) ) stat -0.7452 boot &lt;- fli_small %&gt;% specify(arr_delay ~ season) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “diff in means”, order = c(“summer”, “winter”)) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% -7.167 6.079 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = d_hat) ) lower upper -7.296 5.806 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) One numerical variable, one categorical (2 levels) (t) Standardized point estimate ( t_hat &lt;- fli_small %&gt;% specify(arr_delay ~ season) %&gt;% calculate(stat = “t”, order = c(“summer”, “winter”)) ) stat -0.2182 boot &lt;- fli_small %&gt;% specify(arr_delay ~ season) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “t”, order = c(“summer”, “winter”)) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% -2.236 1.718 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = t_hat) ) lower upper -2.183 1.746 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) Two categorical variables (diff in proportions) Point estimate ( d_hat &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% calculate(stat = “diff in props”, order = c(“summer”, “winter”)) ) stat 0.0205 boot &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “diff in props”, order = c(“summer”, “winter”)) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% -0.0648 0.1083 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = d_hat) ) lower upper -0.0676 0.1087 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) Two categorical variables (z) Standardized point estimate ( z_hat &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% calculate(stat = “z”, order = c(“summer”, “winter”)) ) stat 0.4605 boot &lt;- fli_small %&gt;% specify(day_hour ~ season, success = “morning”) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “z”, order = c(“summer”, “winter”)) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% -1.479 2.501 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = z_hat) ) lower upper -1.522 2.443 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) Two numerical vars - SLR Point estimate ( slope_hat &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% calculate(stat = “slope”) ) stat 1.017 boot &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “slope”) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% 0.9728 1.074 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = slope_hat) ) lower upper 0.9653 1.069 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) Two numerical vars - correlation Point estimate ( correlation_hat &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% calculate(stat = “correlation”) ) stat 0.8943 boot &lt;- fli_small %&gt;% specify(arr_delay ~ dep_delay) %&gt;% generate(reps = 1000, type = “bootstrap”) %&gt;% calculate(stat = “correlation”) ( percentile_ci &lt;- get_ci(boot) ) 2.5% 97.5% 0.8502 0.9218 visualize(boot) + shade_confidence_interval(endpoints = percentile_ci) ( standard_error_ci &lt;- get_ci(boot, type = “se”, point_estimate = correlation_hat) ) lower upper 0.858 0.9306 visualize(boot) + shade_confidence_interval(endpoints = standard_error_ci) Two numerical vars - t Not currently implemented since t could refer to standardized slope or standardized correlation. https://keras.io/ https://datascienceplus.com/k-means-clustering-in-r/ lessRstats.com/lessR.r tour of lessR functions for data analysis Purpose: Provide basic statistical computations for the analyses presented in intro stat texts and more Get R http://r-project.org one time only, to get the lessR functions onto your computer if asked to install into a personal library, say Yes Begin each R session by loading the lessR functions help read data from one of many different formats into a data table called mydata with the same Read statement: csv, tab-delimited text, Excel, SPSS, and SAS Categorical: Gender coded M, F; Dept coded ACCT, ADMN, FINC, MKTG, SALE Numeric: Salary and Years mydata &lt;- Read() or {r # d(), browse for text, Excel, SPSS, SAS, or R data file data included as part of lessR https://www.datacamp.com/community/tutorials/linear-regression-R "],["code-for-workshop-introduction-to-machine-learning-with-r.html", "Chapter 172 Code for Workshop: Introduction to Machine Learning with R", " Chapter 172 Code for Workshop: Introduction to Machine Learning with R https://shirinsplayground.netlify.com/2018/06/intro_to_ml_workshop_heidelberg/ {r , echo=TRUE, cache=FALSE} library(knitr) library(rmdformats) ## Global options options(max.print=&quot;75&quot;) opts_chunk$set(echo=TRUE, cache=TRUE, prompt=FALSE, tidy=TRUE, comment=NA, message=FALSE, warning=FALSE) opts_knit$set(width=75) "],["r-hakkında.html", "Chapter 173 R hakkında", " Chapter 173 R hakkında R generation https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x "],["r-yükleme-3.html", "Chapter 174 R yükleme 174.1 R-project 174.2 RStudio 174.3 X11 174.4 Java OS", " Chapter 174 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY 174.1 R-project https://cran.r-project.org/ 174.2 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 174.2.1 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ 174.3 X11 https://www.xquartz.org/ 174.4 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor-3.html", "Chapter 175 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 175 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf "],["r-paketleri-3.html", "Chapter 176 R paketleri 176.1 Neden paketler var 176.2 Paketleri nereden bulabiliriz 176.3 Kendi paket evrenini oluştur 176.4 R için yardım bulma 176.5 R paket yükleme", " Chapter 176 R paketleri 176.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/ 176.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch Awesome R https://awesome-r.com/ 176.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 176.4 R için yardım bulma # ?mean # ??efetch # help(merge) # example(merge) Vignette RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Reproducible Examples Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 176.5 R paket yükleme install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) # install.packages(&#39;tidyverse&#39;, dependencies = TRUE) install.packages(&#39;jmv&#39;, # dependencies = TRUE) install.packages(&#39;questionr&#39;, dependencies = TRUE) # install.packages(&#39;Rcmdr&#39;, dependencies = TRUE) install.packages(&#39;summarytools&#39;) # require(tidyverse) require(jmv) require(questionr) library(summarytools) # library(gganimate) "],["r-studio-ile-proje-oluşturma-3.html", "Chapter 177 R studio ile proje oluşturma", " Chapter 177 R studio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme-3.html", "Chapter 178 RStudio ile veri yükleme 178.1 Excel 178.2 SPSS 178.3 csv", " Chapter 178 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 178.1 Excel 178.2 SPSS 178.3 csv "],["veriyi-görüntüleme-3.html", "Chapter 179 Veriyi görüntüleme", " Chapter 179 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 # library(nycflights13) summary(flights) View(data) data head tail glimpse str skimr::skim() "],["veriyi-değiştirme-3.html", "Chapter 180 Veriyi değiştirme 180.1 Veriyi kod ile değiştirelim 180.2 Veriyi eklentilerle değiştirme 180.3 RStudio aracılığıyla recode", " Chapter 180 Veriyi değiştirme 180.1 Veriyi kod ile değiştirelim 180.2 Veriyi eklentilerle değiştirme 180.3 RStudio aracılığıyla recode questionr paketi kullanılacak https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler-3.html", "Chapter 181 Basit tanımlayıcı istatistikler 181.1 summarytools 181.2 skimr 181.3 DataExplorer 181.4 Grafikler", " Chapter 181 Basit tanımlayıcı istatistikler summary() mean median min max sd table() library(readr) irisdata &lt;- read_csv(&quot;data/iris.csv&quot;) jmv::descriptives(data = irisdata, vars = &quot;Sepal.Length&quot;, splitBy = &quot;Species&quot;, freq = TRUE, hist = TRUE, dens = TRUE, bar = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sum = TRUE, sd = TRUE, variance = TRUE, range = TRUE, se = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE, pcEqGr = TRUE) DESCRIPTIVES Descriptives ───────────────────────────────────────────────────── Species Sepal.Length ───────────────────────────────────────────────────── N setosa 50 versicolor 50 virginica 50 Missing setosa 0 versicolor 0 virginica 0 Mean setosa 5.006000 versicolor 5.936000 virginica 6.588000 Std. error mean setosa 0.04984957 versicolor 0.07299762 virginica 0.08992695 Median setosa 5.000000 versicolor 5.900000 virginica 6.500000 Mode setosa 5.000000 versicolor 5.500000 virginica 6.300000 Sum setosa 250.3000 versicolor 296.8000 virginica 329.4000 Standard deviation setosa 0.3524897 versicolor 0.5161711 virginica 0.6358796 Variance setosa 0.1242490 versicolor 0.2664327 virginica 0.4043429 Range setosa 1.500000 versicolor 2.100000 virginica 3.000000 Minimum setosa 4.300000 versicolor 4.900000 virginica 4.900000 Maximum setosa 5.800000 versicolor 7.000000 virginica 7.900000 Skewness setosa 0.1200870 versicolor 0.1053776 virginica 0.1180151 Std. error skewness setosa 0.3366007 versicolor 0.3366007 virginica 0.3366007 Kurtosis setosa -0.2526888 versicolor -0.5330095 virginica 0.03290442 Std. error kurtosis setosa 0.6619084 versicolor 0.6619084 virginica 0.6619084 25th percentile setosa 4.800000 versicolor 5.600000 virginica 6.225000 50th percentile setosa 5.000000 versicolor 5.900000 virginica 6.500000 75th percentile setosa 5.200000 versicolor 6.300000 virginica 6.900000 ───────────────────────────────────────────────────── 181.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 181.2 skimr library(skimr) skim(df) 181.3 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 181.4 Grafikler descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["rcmdr-3.html", "Chapter 182 Rcmdr", " Chapter 182 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ "],["jamovi-3.html", "Chapter 183 jamovi", " Chapter 183 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["sonraki-konular-3.html", "Chapter 184 Sonraki Konular", " Chapter 184 Sonraki Konular RStudio ile GitHub Hipotez testleri R Markdown ve R Notebook ile tekrarlanabilir rapor "],["diğer-kodlar-3.html", "Chapter 185 Diğer kodlar", " Chapter 185 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim-3.html", "Chapter 186 Geri Bildirim", " Chapter 186 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. "],["recipes-for-mining-twitter-data-with-rtweet.html", "Chapter 187 21 Recipes for Mining Twitter Data with rtweet", " Chapter 187 21 Recipes for Mining Twitter Data with rtweet https://rud.is/books/21-recipes/ http://rtweet.info/index.html scifi &lt;- search_tweets(“#NationalScienceFictionDay”, n=1500) data_frame(txt=str_replace_all(scifi$text, “#NationalScienceFictionDay”, \"“)) %&gt;% unnest_tokens(word, txt) %&gt;% anti_join(stop_words,”word“) %&gt;% anti_join(rtweet::stopwordslangs,”word“) %&gt;% anti_join(data_frame(word=c(”https“,”t.co“)),”word“) %&gt;% # need to make a more technical stopwords list or clean up the text better filter(nchar(word)&gt;3) %&gt;% pull(word) %&gt;% paste0(collapse=” \") -&gt; txt cloud_img &lt;- word_cloud(txt, width=800, height=500, min_font_size=10, max_font_size=60, scale=“log”) image_write(cloud_img, “data/wordcloud.png”) library(rtweet) library(LSAfun) library(jerichojars) # hrbrmstr/jerichojars library(jericho) # hrbrmstr/jericho library(tidyverse) stiles &lt;- get_timeline(“stiles”) filter(stiles, str_detect(urls_expanded_url, “nyti|reut|wapo|lat\\.ms|53ei”)) %&gt;% # only get tweets with news links pull(urls_expanded_url) %&gt;% # extract the links flatten_chr() %&gt;% # mush them into a nice character vector head(3) %&gt;% # get the first 3 map_chr(~{ httr::GET(.x) %&gt;% # get the URL (I’m lazily calling “fair use” here vs check robots.txt since I’m suggesting you do this for your benefit vs profit) httr::content(as=“text”) %&gt;% # extract the HTML jericho::html_to_text() %&gt;% # strip away extraneous HTML tags LSAfun::genericSummary(k=3) %&gt;% # summarise! paste0(collapse=“”) # easier to see }) %&gt;% walk(cat) library(rtweet) library(tidyverse) (brooke_followers &lt;- rtweet::get_followers(“gbwanderson”)) (brooke_friends &lt;- rtweet::get_friends(“gbwanderson”)) output: flexdashboard::flex_dashboard "],["page-1.html", "Chapter 188 Page 1 188.1 Column 188.2 Column", " Chapter 188 Page 1 188.1 Column 188.1.1 Chart 1 188.2 Column 188.2.1 Chart 2 188.2.2 Chart 3 "],["page-2.html", "Chapter 189 Page 2 189.1 Row 189.2 Row", " Chapter 189 Page 2 189.1 Row 189.1.1 Chart 1 189.2 Row 189.2.1 Chart 2 189.2.2 Chart 3 https://mxnet.apache.org/versions/master/install/index.html?platform=MacOS&amp;language=R&amp;processor=CPU https://mxnet.apache.org/versions/master/api/r/index.html https://mxnet.apache.org/versions/master/tutorials/index.html R Tutorials Getting Started Basic Classification Using a pre-trained model for Image Classification Models MNIST Handwritten Digit Classification with Convolutional Network Shakespeare generation with Character-level RNN API Guides NDArray API Symbol API Callbacks Custom Data Iterators Custom Loss Functions https://gist.github.com/sbalci https://docs.ropensci.org/gistr/ https://docs.ropensci.org/gistr/articles/gistr.html `{r # gistembedcodes` {r # gistembedcodes Text Analysis of Newspaper News on Electoral Integrity and Electoral Violence in Turkey http://rpubs.com/emretoros/dievt subtitle: &quot;&lt;br/&gt;with xaringan&quot; author: &quot;Yihui Xie&quot; date: &quot;2016/12/12 (updated: `{r # Sys.Date()`)&quot; output: xaringan::moon_reader: lib_dir: libs nature: highlightStyle: github highlightLines: true countIncrementalSlides: false ??? Image credit: Wikimedia Commons class: inverse, center, middle "],["get-started.html", "Chapter 190 Get Started", " Chapter 190 Get Started "],["hello-world.html", "Chapter 191 Hello World", " Chapter 191 Hello World Install the xaringan package from Github: devtools::install_github(&quot;yihui/xaringan&quot;) – You are recommended to use the RStudio IDE, but you do not have to. Create a new R Markdown document from the menu File -&gt; New File -&gt; R Markdown -&gt; From Template -&gt; Ninja Presentation;1 – Click the Knit button to compile it; – or use the RStudio Addin2 “Infinite Moon Reader” to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer. .footnote[ [1] 中文用户请看这份教程 [2] See #2 if you do not see the template or addin in RStudio. ] "],["hello-ninja.html", "Chapter 192 Hello Ninja", " Chapter 192 Hello Ninja As a presentation ninja, you certainly should not be satisfied by the “Hello World” example. You need to understand more about two things: The remark.js library; The xaringan package; Basically xaringan injected the chakra of R Markdown (minus Pandoc) into remark.js. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (knitr). "],["remark-js.html", "Chapter 193 remark.js", " Chapter 193 remark.js You can see an introduction of remark.js from its homepage. You should read the remark.js Wiki at least once to know how to create a new slide (Markdown syntax* and slide properties); format a slide (e.g. text alignment); configure the slideshow; and use the presentation (keyboard shortcuts). It is important to be familiar with remark.js before you can understand the options in xaringan. .footnote[[*] It is different with Pandoc’s Markdown! It is limited but should be enough for presentation purposes. Come on… You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js may be improved in the future.] class: inverse, middle, center "],["using-xaringan.html", "Chapter 194 Using xaringan", " Chapter 194 Using xaringan "],["xaringan.html", "Chapter 195 xaringan", " Chapter 195 xaringan Provides an R Markdown output format xaringan::moon_reader as a wrapper for remark.js, and you can use it in the YAML metadata, e.g. --- title: &quot;A Cool Presentation&quot; output: xaringan::moon_reader: yolo: true nature: autoplay: 30000 --- See the help page ?xaringan::moon_reader for all possible options that you can use. "],["remark-js-vs-xaringan.html", "Chapter 196 remark.js vs xaringan", " Chapter 196 remark.js vs xaringan Some differences between using remark.js (left) and using xaringan (right): .pull-left[ 1. Start with a boilerplate HTML file; Plain Markdown; Write JavaScript to autoplay slides; Manually configure MathJax; Highlight code with *; Edit Markdown source and refresh browser to see updated slides; ] .pull-right[ 1. Start with an R Markdown document; R Markdown (can embed R/other code chunks); Provide an option autoplay; MathJax just works;* Highlight code with {{}}; The RStudio addin “Infinite Moon Reader” automatically refreshes slides on changes; ] .footnote[[*] Not really. See next page.] "],["math-expressions.html", "Chapter 197 Math Expressions", " Chapter 197 Math Expressions You can write LaTeX math expressions inside a pair of dollar signs, e.g. $+$ renders \\(\\alpha+\\beta\\). You can use the display style with double dollar signs: $$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$ \\[\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\\] Limitations: The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character; There should not be spaces after the opening $ or before the closing $. Math does not work on the title slide (see #61 for a workaround). "],["r-code.html", "Chapter 198 R Code", " Chapter 198 R Code # a boring regression fit = lm(dist ~ 1 + speed, data = cars) coef(summary(fit)) # Estimate Std. Error t value Pr(&gt;|t|) # (Intercept) -17.579095 6.7584402 -2.601058 1.231882e-02 # speed 3.932409 0.4155128 9.463990 1.489836e-12 dojutsu = c(&quot;地爆天星&quot;, &quot;天照&quot;, &quot;加具土命&quot;, &quot;神威&quot;, &quot;須佐能乎&quot;, &quot;無限月読&quot;) grep(&quot;天&quot;, dojutsu, value = TRUE) # [1] &quot;地爆天星&quot; &quot;天照&quot; "],["r-plots.html", "Chapter 199 R Plots", " Chapter 199 R Plots par(mar = c(4, 4, 1, 0.1)) plot(cars, pch = 19, col = &quot;darkgray&quot;, las = 1) abline(fit, lwd = 2) "],["tables.html", "Chapter 200 Tables", " Chapter 200 Tables If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g., "],["html-widgets.html", "Chapter 201 HTML Widgets", " Chapter 201 HTML Widgets I have not thoroughly tested HTML widgets against xaringan. Some may work well, and some may not. It is a little tricky. Similarly, the Shiny mode ({r # untime: shiny) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications. See the next page for two HTML widgets. library(leaflet) leaflet() %&gt;% addTiles() %&gt;% setView(-93.65, 42.0285, zoom = 17) DT::datatable( head(iris, 10), fillContainer = FALSE, options = list(pageLength = 8) ) "],["some-tips.html", "Chapter 202 Some Tips", " Chapter 202 Some Tips When you use the “Infinite Moon Reader” addin in RStudio, your R session will be blocked by default. You can click the red button on the right of the console to stop serving the slides, or use the daemonized mode so that it does not block your R session. To do the latter, you can set the option {r # options(servr.daemon = TRUE) in your current R session, or in ~/.Rprofile so that it is applied to all future R sessions. I do the latter by myself. To know more about the web server, see the servr package. – Do not forget to try the yolo option of xaringan::moon_reader. output: xaringan::moon_reader: yolo: true "],["some-tips-1.html", "Chapter 203 Some Tips", " Chapter 203 Some Tips Slides can be automatically played if you set the autoplay option under nature, e.g. go to the next slide every 30 seconds in a lightning talk: output: xaringan::moon_reader: nature: autoplay: 30000 – A countdown timer can be added to every page of the slides using the countdown option under nature, e.g. if you want to spend one minute on every page when you give the talk, you can set: output: xaringan::moon_reader: nature: countdown: 60000 Then you will see a timer counting down from 01:00, to 00:59, 00:58, … When the time is out, the timer will continue but the time turns red. "],["some-tips-2.html", "Chapter 204 Some Tips", " Chapter 204 Some Tips The title slide is created automatically by xaringan, but it is just another remark.js slide added before your other slides. The title slide is set to class: center, middle, inverse, title-slide by default. You can change the classes applied to the title slide with the titleSlideClass option of nature (title-slide is always applied). output: xaringan::moon_reader: nature: titleSlideClass: [top, left, inverse] – If you’d like to create your own title slide, disable xaringan’s title slide with the seal = FALSE option of moon_reader. output: xaringan::moon_reader: seal: false "],["some-tips-3.html", "Chapter 205 Some Tips", " Chapter 205 Some Tips There are several ways to build incremental slides. See this presentation for examples. The option highlightLines: true of nature will highlight code lines that start with *, or are wrapped in {{ }}, or have trailing comments #&lt;&lt;; output: xaringan::moon_reader: nature: highlightLines: true See examples on the next page. "],["some-tips-4.html", "Chapter 206 Some Tips", " Chapter 206 Some Tips .pull-left[ An example using a leading *: ```{r # if (TRUE) { ** message(&quot;Very important!&quot;) } ``` Output: {r # if (TRUE) { * message(\"Very important!\") } This is invalid R code, so it is a plain fenced code block that is not executed. ] .pull-right[ An example using {{}}: `{r # &#39;&#39;````{r tidy=FALSE} if (TRUE) { *{{ message(&quot;Very important!&quot;) }} } ``` Output: if (TRUE) { {{ message(&quot;Very important!&quot;) }} } It is valid R code so you can run it. Note that {{}} can wrap an R expression of multiple lines. ] "],["some-tips-5.html", "Chapter 207 Some Tips", " Chapter 207 Some Tips An example of using the trailing comment #&lt;&lt; to highlight lines: `{r # &#39;&#39;````{r tidy=FALSE} library(ggplot2) ggplot(mtcars) + aes(mpg, disp) + geom_point() + #&lt;&lt; geom_smooth() #&lt;&lt; ``` Output: library(ggplot2) ggplot(mtcars) + aes(mpg, disp) + geom_point() + #&lt;&lt; geom_smooth() #&lt;&lt; "],["some-tips-6.html", "Chapter 208 Some Tips", " Chapter 208 Some Tips When you enable line-highlighting, you can also use the chunk option highlight.output to highlight specific lines of the text output from a code chunk. For example, highlight.output = TRUE means highlighting all lines, and highlight.output = c(1, 3) means highlighting the first and third line. `{r # &#39;&#39;````{r, highlight.output=c(1, 3)} head(iris) ``` head(iris) Table 208.1: Sepal.LengthSepal.WidthPetal.LengthPetal.WidthSpecies 5.13.51.40.2setosa 4.93&nbsp;&nbsp;1.40.2setosa 4.73.21.30.2setosa 4.63.11.50.2setosa 5&nbsp;&nbsp;3.61.40.2setosa 5.43.91.70.4setosa Question: what does highlight.output = c(TRUE, FALSE) mean? (Hint: think about R’s recycling of vectors) "],["some-tips-7.html", "Chapter 209 Some Tips", " Chapter 209 Some Tips To make slides work offline, you need to download a copy of remark.js in advance, because xaringan uses the online version by default (see the help page ?xaringan::moon_reader). You can use xaringan::summon_remark() to download the latest or a specified version of remark.js. By default, it is downloaded to libs/remark-latest.min.js. Then change the chakra option in YAML to point to this file, e.g. output: xaringan::moon_reader: chakra: libs/remark-latest.min.js If you used Google fonts in slides (the default theme uses Yanone Kaffeesatz, Droid Serif, and Source Code Pro), they won’t work offline unless you download or install them locally. The Heroku app google-webfonts-helper can help you download fonts and generate the necessary CSS. "],["macros.html", "Chapter 210 Macros", " Chapter 210 Macros remark.js allows users to define custom macros (JS functions) that can be applied to Markdown text using the syntax ![:macroName arg1, arg2, ...] or ![:macroName arg1, arg2, ...](this). For example, before remark.js initializes the slides, you can define a macro named scale: remark.macros.scale = function (percentage) { var url = this; return &#39;&lt;img src=&quot;&#39; + url + &#39;&quot; style=&quot;width: &#39; + percentage + &#39;&quot; /&gt;&#39;; }; Then the Markdown text ![:scale 50%](image.jpg) will be translated to &lt;img src=&quot;image.jpg&quot; style=&quot;width: 50%&quot; /&gt; "],["macros-continued.html", "Chapter 211 Macros (continued)", " Chapter 211 Macros (continued) To insert macros in xaringan slides, you can use the option beforeInit under the option nature, e.g., output: xaringan::moon_reader: nature: beforeInit: &quot;macros.js&quot; You save your remark.js macros in the file macros.js. The beforeInit option can be used to insert arbitrary JS code before {r # emark.create(). Inserting macros is just one of its possible applications. "],["css.html", "Chapter 212 CSS", " Chapter 212 CSS Among all options in xaringan::moon_reader, the most challenging but perhaps also the most rewarding one is css, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know. You can see the default CSS file here. You can completely replace it with your own CSS files, or define new rules to override the default. See the help page ?xaringan::moon_reader for more information. "],["css-1.html", "Chapter 213 CSS", " Chapter 213 CSS For example, suppose you want to change the font for code from the default “Source Code Pro” to “Ubuntu Mono”. You can create a CSS file named, say, ubuntu-mono.css: @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic); .remark-code, .remark-inline-code { font-family: &#39;Ubuntu Mono&#39;; } Then set the css option in the YAML metadata: output: xaringan::moon_reader: css: [&quot;default&quot;, &quot;ubuntu-mono.css&quot;] Here I assume ubuntu-mono.css is under the same directory as your Rmd. See yihui/xaringan#83 for an example of using the Fira Code font, which supports ligatures in program code. "],["themes.html", "Chapter 214 Themes", " Chapter 214 Themes Don’t want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files foo.css and foo-fonts.css, where foo is the theme name. Below are some existing themes: "],["themes-1.html", "Chapter 215 Themes", " Chapter 215 Themes To use a theme, you can specify the css option as an array of CSS filenames (without the .css extensions), e.g., output: xaringan::moon_reader: css: [default, metropolis, metropolis-fonts] If you want to contribute a theme to xaringan, please read this blog post. background-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg) background-size: 100px background-position: 90% 8% "],["sharingan.html", "Chapter 216 Sharingan", " Chapter 216 Sharingan The R package name xaringan was derived1 from Sharingan, a dōjutsu in the Japanese anime Naruto with two abilities: the “Eye of Insight” the “Eye of Hypnotism” I think a presentation is basically a way to communicate insights to the audience, and a great presentation may even “hypnotize” the audience.2,3 .footnote[ [1] In Chinese, the pronounciation of X is Sh /ʃ/ (as in shrimp). Now you should have a better idea of how to pronounce my last name Xie. [2] By comparison, bad presentations only put the audience to sleep. [3] Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations. ] "],["naruto-terminology.html", "Chapter 217 Naruto terminology", " Chapter 217 Naruto terminology The xaringan package borrowed a few terms from Naruto, such as Sharingan (写輪眼; the package name) The moon reader (月読; an attractive R Markdown output format) Chakra (查克拉; the path to the remark.js library, which is the power to drive the presentation) Nature transformation (性質変化; transform the chakra by setting different options) The infinite moon reader (無限月読; start a local web server to continuously serve your slides) The summoning technique (download remark.js from the web) You can click the links to know more about them if you want. The jutsu “Moon Reader” may seem a little evil, but that does not mean your slides are evil. class: center "],["hand-seals-.html", "Chapter 218 Hand seals (印)", " Chapter 218 Hand seals (印) Press h or ? to see the possible ninjutsu you can use in remark.js. class: center, middle "],["thanks.html", "Chapter 219 Thanks!", " Chapter 219 Thanks! Slides created via the R package xaringan. The chakra comes from remark.js, knitr, and R Markdown. copied from: https://cran.r-project.org/web/packages/papeR/vignettes/papeR_introduction.html The package is intended to ease reporting of standard data analysis tasks such as descriptive statistics, simple test results, plots and to prettify the output of various statistical models. https://github.com/hofnerb/papeR 219.0.0.1 Conversion to labeled data frames Instead of manually setting labels, we can simply convert a data frame to a labeled data frame, either with the function as.ldf() or with convert.labels(). Actually, both calls reference the same function (for an object of class data.frame). While as.ldf() can be seen as the classical counterpart of is.ldf(), the function name convert.labels() is inspired by the fact that these functions either convert the variable names to labels or convert other variable labels to papeR-type variable labels. Hence, these functions can, for example, be used to convert labels from data sets which are imported via the function {r # ead.spss() to papeR-type variable labels. If no variable labels are specified, the original variable names are used. 219.0.1 Plotting labeled data frames For data frames of class 'ldf', there exist special plotting functions: As one can see, the plot type is automatically determined based on the data type and the axis label is defined by the labels(). To obtain group comparisons, we can use grouped plots. To plot all variable in the groups of Sex one can use We can as well plot everything against the metrical variable distance To plot only a subset of the data, say all but Subject, against distance and suppress the regression line we can use Note that again we can use either variable names or indices to specify the variables which are to be plotted. 219.0.2 Summary tables One can use the command summarize() to automatically produce summary tables for either numerical variables (i.e., variables where is.numeric() is TRUE) or categorical variables (where is.factor() is TRUE). We now extract a summary table for numerical variables of the Orthodont data set: Similarly, we can extract summaries for all factor variables. As one of the factors is the Subject which has {r # nlevels(Orthodont$Subject) levels, each with {r # unique(table(Orthodont$Subject)) observations, we exclude this from the summary table and only have a look at Sex Again, as for the plots, one can specify groups to obtain grouped statistics: Per default, one also gets tests for group differences: 219.0.3 Converting summaries to PDF So far, we only got standard R output. Yet, any of these summary tables can be easily converted to LaTeX code using the package xtable. In papeR two special functions xtable.summary() and print.xtable.summary() are defined for easy and pretty conversion. In Sweave we can use {r # &lt;&lt;echo = TRUE, results = tex&gt;&gt;= xtable(summarize(Orthodont, type = &quot;numeric&quot;)) xtable(summarize(Orthodont, type = &quot;factor&quot;, variables = &quot;Sex&quot;)) xtable(summarize(Orthodont, type = &quot;numeric&quot;, group = &quot;Sex&quot;)) @ and in knitr we can use {r # &lt;&lt;echo = TRUE, results = &#39;asis&#39;&gt;&gt;= xtable(summarize(Orthodont, type = &quot;numeric&quot;)) xtable(summarize(Orthodont, type = &quot;factor&quot;, variables = &quot;Sex&quot;)) xtable(summarize(Orthodont, type = &quot;numeric&quot;, group = &quot;Sex&quot;)) @ to get the following PDF output LaTeX Output Note that per default, booktabs is set to TRUE in print.xtable.summary, and thus \\usepackage{booktabs} is needed in the header of the LaTeX report. For details on LaTeX summary tables see the dedicated vignette, which can be obtained, e.g., via vignette(\"papeR\\_with\\_latex\", package = \"papeR\"). See also there for more details on summary tables in general. 219.0.4 Converting summaries to Markdown To obtain markdown output we can use, for example, the function kable() from package knitr on the summary objects: library(&quot;knitr&quot;) kable(summarize(Orthodont, type = &quot;numeric&quot;)) kable(summarize(Orthodont, type = &quot;factor&quot;, variables = &quot;Sex&quot;, cumulative = TRUE)) kable(summarize(Orthodont, type = &quot;numeric&quot;, group = &quot;Sex&quot;, test = FALSE)) which gives the following results library(&quot;knitr&quot;) kable(summarize(Orthodont, type = &quot;numeric&quot;)) kable(summarize(Orthodont, type = &quot;factor&quot;, variables = &quot;Sex&quot;, cumulative = TRUE)) kable(summarize(Orthodont, type = &quot;numeric&quot;, group = &quot;Sex&quot;)) 219.0.5 Prettify model output To prettify the output of a linear model, one can use the function prettify(). This function adds confidence intervals, properly prints p-values, adds significance stars to the output (if desired) and additionally adds pretty formatting for factors. {r eval=FALSE, include=FALSE, echo=TRUE} linmod &lt;- lm(distance ~ age + Sex, data = Orthodont) ## Extract pretty summary (pretty_lm &lt;- prettify(summary(linmod))) The resulting table can now be formatted for printing using packages like xtable for LaTeX which can be used in .Rnw files with the option {r # esults='asis' (in knitr) or {r # esults = tex (in Sweave) {r, results=&#39;hide&#39;} xtable(pretty_lm) In markdown files (.Rmd) one can instead use the function kable() with the chunk option {r # esults='asis'. The result looks as follows: {r, results=&#39;asis&#39;} kable(pretty_lm) 219.0.5.1 Supported objects The function prettify is currently implemented for objects of the following classes: lm (linear models) glm (generalized linear models) coxph (Cox proportional hazards models) lme (linear mixed models; implemented in package nlme) mer (linear mixed models; implemented in package lme4, version &lt; 1.0) merMod (linear mixed models; implemented in package lme4, version &gt;= 1.0) anova (anova objects) How to calculate statistical power for your meta-analysis https://towardsdatascience.com/how-to-calculate-statistical-power-for-your-meta-analysis-e108ee586ae8 "],["introduction-1.html", "Chapter 220 Introduction", " Chapter 220 Introduction In this page one can found all the R functions discussed in Perugini, Gallucci, Constantini (2018), A practical primer to power analysis for simple experimental designs. International Review of Social Psychology. rewf here. Examples are taken from the papers. In all the examples that require multiple lines of code the user needs to update only the variables listed before ### end of input ### comment. The results are computed automatically for the required N. Small changes in the code are required to compute other power parameters. "],["t-test.html", "Chapter 221 t-test 221.1 Independent Samples 221.2 Sensitivity analysis 221.3 Paired Samples", " Chapter 221 t-test 221.1 Independent Samples A very simple function for independent samples t-test. To use with Cohen’s d, set sd=1 and put delta=d, where d is your effect size. Required n for each group should be rounded up to the first whole number. Exactly one of n, delta, sd, power, and sig.level must be NULL. The NULL parameter is estimated by the function. Thus, post-hoc analysis is done omitting power and including n. ?power.t.test for all the other options. 221.2 Sensitivity analysis In the paper we suggested to look at the relationship between total sample size and effect size for a given power level (.80 in the example) and alpha (.05 in the example). In R this can be done as follows: 221.3 Paired Samples Same function with the option type = \"paired\" "],["one-way-analysis-of-variance.html", "Chapter 222 One way Analysis of Variance", " Chapter 222 One way Analysis of Variance For all F-test related power analysis, it is generally better to use pwr.f2.test() function from pwr package. The function uses \\(f^2\\) as effect size, which is the square of the \\(f\\) used by GPower “ANOVA: Fixed effects, omnibus and one-way”. Here we assume one has the \\(\\eta_p^2\\), which in one-way ANOVA is the \\(R^2\\). For required N (total sample size) one needs to input also \\(k\\), the number of groups defined by the independent variable. "],["factorial-designs.html", "Chapter 223 Factorial Designs 223.1 method 1 223.2 Method 2 223.3 Power analysis for contrasts 223.4 Guessing the interaction effect size from one-way designs 223.5 Means based method", " Chapter 223 Factorial Designs “Assume that in a 3 X 2 factorial design the researcher expects the interaction to explain around 10% of the variance. If the researcher expects no main effect, the proportion of residual variance is 1-.10=.90, so the pη2=.10.” 223.1 method 1 Here we keep using pwr.f2.test because it can be used for any F-test in the linear model. However, for prospective power (required total N) the function returns the required error degrees of freedom, so the required N must be approximate adding the effects degrees of freedom to the error degrees of freedom. The following code does it automatically. 223.2 Method 2 The package easypower provides short cuts for factorial ANOVA power analysis. It provides a dedicated function n.multiway() which simplifies computation of required N for main effects and interaction. It does not provide estimates for post-hoc power and other applications of power analysis. Results are the same than method 1 a part from rounding. 223.3 Power analysis for contrasts 223.3.1 Generic Contrasts Main effects and interaction for example in Table 2. They are all equivalent, so we go for the interaction. We compute the \\(f\\) as in the paper, but use \\(f^2\\) as required by `pwr.f2. 223.4 Guessing the interaction effect size from one-way designs Consider the case in which the pattern of means in Table 3, case 1, in the paper is taken from a one-way design in which A1 and A2 show means equal to 5 and 2, respectively, and the same within groups variability (say equal to 1). Basically, the researcher observes in the literature a one-way design with only A as a factor and wishes to test the moderating effect of B in a 2 x 2 design. The B factor has two levels, that for simplicity we name “replicated” and “moderated”. The problem is to determine the power parameters of the expected interaction effect. 223.5 Means based method 223.5.1 Percentage of moderation Researcher should estimate the percentage of moderation, where 100% means full suppression of the effec, 200% full reversing of the effect. 223.5.2 Paper example “An example of a more complex design” Consider a researcher who wishes to design a moderation study based on an one-way design with four conditions implementing an increasing intensity of a stimulus, such that the observed pattern of mean shows a linear trend. In particular, the observed linear trend contrast has an p=.184, corresponding to a f=0.475. The same results can be obtained if one anticipates all expected means and pooled standard deviation (tedious method) "],["regression-analysis.html", "Chapter 224 Regression Analysis", " Chapter 224 Regression Analysis Any effect in simple and the multiple regression for which the \\(\\eta_p^2\\) is available can be evaluated witht he following code. here is an example for a regression with three predictors and a small effect size, according to Cohen’s (Cohen, 1988) classification. "],["moderated-regression.html", "Chapter 225 Moderated regression 225.1 Interaction between continuous and dichotomous predictors. 225.2 Interaction between continuous predictors", " Chapter 225 Moderated regression 225.1 Interaction between continuous and dichotomous predictors. The researcher needs to estimate the expected correlation between the continuous independent variable and the dependent variable for the two groups defined by the moderator. 225.2 Interaction between continuous predictors The researcher needs to estimate the expected correlation between the continuous independent variables and the dependent variable, and the change of correlation from the average value of the moderator to one standard deviation above average of the moderator. We assume here that there "],["mediation.html", "Chapter 226 Mediation", " Chapter 226 Mediation 226.0.1 method based on Sobel test 226.0.2 method based on bootstrap analysis The code below allows computing the power achieved with a certain sample size, that must be indicated as nobs below. The achieved power for the Indirect/Mediation effect (ab) using a sample of size nobs can be read under column “Power”. The following code is based on boostrap and it takes a lot of time (several hours) to run. Be extremely patient (or leave it running at night). If you have a multi-core processor, function power.boot implements parallel processing to speed-up computations. See ?power.boot for details. library(&quot;bmem&quot;) ### input ### a, b, are the coefficients as in standard mediational path diagram, n ### is the sample size- a &lt;- 0.8186 b &lt;- 0.4039 c &lt;- 0.4334 nobs &lt;- 100 ### end of input ### model &lt;- paste(c(&quot;M ~ a*X + start(&quot;, a, &quot;)*X&quot;, &quot;Y ~ b*M + c*X + start(&quot;, b, &quot;) * M + start(.4334)*X&quot;, &quot;X ~~ start(1)*X&quot;, &quot;M ~~ start(1)*M&quot;, &quot;Y ~~ start(1)*Y&quot;), collapse = &quot;\\n&quot;) set.seed(1234) power.result &lt;- power.boot(model, indirect = &quot;ab := a*b&quot;, nobs = nobs) summary(power.result) A Practical Primer To Power Analysis for Simple Experimental Designs. International Review of Social Psychology, 31(1), 20. DOI: http://doi.org/10.5334/irsp.181 https://www.rips-irsp.com/article/10.5334/irsp.181/ https://github.com/mcfanda/primerPowerIRSP "],["prepare-data-for-analysis-veriyi-analiz-için-hazırlamak.html", "Chapter 227 Prepare Data for Analysis / Veriyi Analiz için hazırlamak 227.1 The Quartz guide to bad data 227.2 Kötü veri kılavuzu 227.3 data organization organizing data in spreadsheets 227.4 Tidy Data 227.5 The Ten Commandments for a well-formatted database 227.6 Software specific problems 227.7 Data reorganization", " Chapter 227 Prepare Data for Analysis / Veriyi Analiz için hazırlamak 227.1 The Quartz guide to bad data An exhaustive reference to problems seen in real-world data along with suggestions on how to resolve them. https://github.com/Quartz/bad-data-guide 227.2 Kötü veri kılavuzu Kötü veri kılavuzu https://sbalci.github.io/Kotu-Veri-Kilavuzu/index.html 227.3 data organization organizing data in spreadsheets https://kbroman.org/dataorg/ Daniel Kaplan. (2018) Teaching Stats for Data Science. The American Statistician 72:1, pages 89-96. https://doi.org/10.1080/00031305.2017.1375989 227.4 Tidy Data Hadley Wickham. Tidy data. The Journal of Statistical Software, vol. 59, 2014. http://vita.had.co.nz/papers/tidy-data.html https://www.jstatsoft.org/article/view/v059i10 http://dx.doi.org/10.18637/jss.v059.i10 227.5 The Ten Commandments for a well-formatted database The Ten Commandments for a well-formatted database https://rtask.thinkr.fr/blog/the-ten-commandments-for-a-well-formatted-database/ 227.6 Software specific problems 227.6.1 Keep SPSS labels read.spss komutu ile değer etiketlerini almasını ve bunu liste olarak değil de data.frame olarak kaydetmesini istiyoruz aktardığımız data.frame’in özellikleri (attr) içinde değişkenlerin etiketleri var, bunları dışarı çıkartıyoruz elde ettiğimiz data.frame’deki satır isimleri değişkenlerin isimleri oluyor, karşılarında da değişken etiketleri var satır isimlerini de dışarı çıkartıyoruz Değişken etiketi olanları etiketleri ile diğerlerini olduğu gibi saklıyoruz son olarak da data.frame’deki sütun isimlerini değiştiriyoruz 227.6.2 Make both computer and human readible variable names turkce karakter donusumu 227.6.3 Anonimisation 227.6.4 Add subject ID to the data / veriye ID ekleme 227.7 Data reorganization https://stackoverflow.com/questions/22353633/filter-for-complete-cases-in-data-frame-using-dplyr-case-wise-deletion df %&gt;% na.omit or this: df %&gt;% filter(complete.cases(.)) or this: library(tidyr) df %&gt;% drop_na If you want to filter based on one variable’s missingness, use a conditional: df %&gt;% filter(!is.na(x1)) or df %&gt;% drop_na(x1) Other answers indicate that of the solutions above na.omit is much slower but that has to be balanced against the fact that it returns and row indices of the omitted rows as the na.action attribute whereas the other solutions above do not. str(df %&gt;% na.omit) ‘data.frame’: 2 obs. of 2 variables: $ x1: num 1 2 $ x2: num 1 2 - attr(, “na.action”)= ‘omit’ Named int 3 4 ..- attr(, “names”)= chr “3” “4” ozp &lt;- veri %&gt;% select(RaporNo, Hasta, cinsiyet, Yas, ozp_parca, ozp_kaset, ozp_cap, ozp_tani, ozp_kod) %&gt;% filter(!is.na(ozp_parca) | !is.na(ozp_kaset) | !is.na(ozp_cap) | !is.na(ozp_tani) | !is.na(ozp_kod) ) ozp2 &lt;- veri %&gt;% select(RaporNo, Hasta, cinsiyet, Yas, ozp_parca, ozp_kaset, ozp_cap, ozp_tani, ozp_kod) %&gt;% filter(complete.cases(ozp_parca, ozp_kaset, ozp_cap, ozp_tani, ozp_kod) ) ozp3 &lt;- veri %&gt;% select(RaporNo, Hasta, cinsiyet, Yas, ozp_parca, ozp_kaset, ozp_cap, ozp_tani, ozp_kod) %&gt;% na.omit(ozp_parca, ozp_kaset, ozp_cap, ozp_tani, ozp_kod) "],["xray.html", "Chapter 228 xray", " Chapter 228 xray The R Package to Have X Ray Vision on your Datasets https://blog.datascienceheroes.com/x-ray-vision-on-your-datasets/ "],["convert-all-data-frame-into-character.html", "Chapter 229 convert all data.frame into character", " Chapter 229 convert all data.frame into character df &lt;- purrr::map_df(df, as.character) "],["rcase4base-reshape-data-with-base-r.html", "Chapter 230 R:case4base - reshape data with base R", " Chapter 230 R:case4base - reshape data with base R https://jozefhajnala.gitlab.io/r/r002-data-manipulation/ "],["rcase4base-data-aggregation-with-base-r.html", "Chapter 231 R:case4base - data aggregation with base R", " Chapter 231 R:case4base - data aggregation with base R https://jozefhajnala.gitlab.io/r/r003-aggregation/ "],["tidyr.html", "Chapter 232 tidyr", " Chapter 232 tidyr This week I'm going to be looking at some #tidyr functions! 💡 First is uncount() which might come in handy if you want to transform a summary table to individual rows. #rstats pic.twitter.com/UZE0wUcEHC — Nic Crane ((???)) November 26, 2018 df &lt;- data.frame( V1 = c(0, 0, 0, 0, 1, 1, 1, 1, 0, 1), V2 = c(1, 1, 1, 0, 0, 0, 0, 0, 0, 1), V3 = c(0, 0, 0, 1, 1, 1, 1, 1, 0, 1) ) df$V1_rec &lt;- grepl(pattern = &quot;0&quot;, x = df$V1) df$V2_rec &lt;- grepl(pattern = &quot;0&quot;, x = df$V2) df$V3_rec &lt;- grepl(pattern = &quot;0&quot;, x = df$V3) df %&gt;% mutate(toplam = select(., V1_rec:V3_rec) %&gt;% rowSums(na.rm = TRUE) ) http://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb https://www.youtube.com/watch?v=5_QXMwezPJE&amp;list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y&amp;index=2 https://developers.google.com/edu/python/ "],["quanteda-quantitative-analysis-of-textual-data.html", "Chapter 233 quanteda: Quantitative Analysis of Textual Data", " Chapter 233 quanteda: Quantitative Analysis of Textual Data An R package for the Quantitative Analysis of Textual Data https://quanteda.io https://github.com/quanteda/quanteda "],["quick-start-guide.html", "Chapter 234 Quick Start Guide", " Chapter 234 Quick Start Guide https://quanteda.io/articles/pkgdown/quickstart.html # devtools package required to install quanteda from Github # devtools::install_github(&#39;quanteda/quanteda&#39;) install.packages(&#39;quanteda&#39;) # install.packages(&#39;readtext&#39;) "],["readtext-import-and-handling-for-plain-and-formatted-text-files.html", "Chapter 235 readtext: Import and handling for plain and formatted text files", " Chapter 235 readtext: Import and handling for plain and formatted text files https://readtext.quanteda.io https://github.com/quanteda/readtext "],["httpsgithub-comquantedareadtext.html", "Chapter 236 https://github.com/quanteda/readtext", " Chapter 236 https://github.com/quanteda/readtext "],["httpsgithub-comquantedastopwords.html", "Chapter 237 https://github.com/quanteda/stopwords", " Chapter 237 https://github.com/quanteda/stopwords "],["httpsgithub-comquantedaspacyr.html", "Chapter 238 https://github.com/quanteda/spacyr", " Chapter 238 https://github.com/quanteda/spacyr "],["httpsgithub-comquantedaquanteda-corpora.html", "Chapter 239 https://github.com/quanteda/quanteda.corpora", " Chapter 239 https://github.com/quanteda/quanteda.corpora "],["httpsgithub-comkbenoitquanteda-dictionaries.html", "Chapter 240 https://github.com/kbenoit/quanteda.dictionaries", " Chapter 240 https://github.com/kbenoit/quanteda.dictionaries "],["httpsquanteda-ioarticlesquickstart-html.html", "Chapter 241 https://quanteda.io/articles/quickstart.html", " Chapter 241 https://quanteda.io/articles/quickstart.html "],["httpsquanteda-ioarticlespkgdowncomparison-html.html", "Chapter 242 https://quanteda.io/articles/pkgdown/comparison.html", " Chapter 242 https://quanteda.io/articles/pkgdown/comparison.html "],["httpsquanteda-ioarticlespkgdowndesign-html.html", "Chapter 243 https://quanteda.io/articles/pkgdown/design.html", " Chapter 243 https://quanteda.io/articles/pkgdown/design.html "],["httpsquanteda-ioarticlespkgdownexamplesphrase-html.html", "Chapter 244 https://quanteda.io/articles/pkgdown/examples/phrase.html", " Chapter 244 https://quanteda.io/articles/pkgdown/examples/phrase.html "],["httpsquanteda-ioarticlespkgdownexamplesplotting-html.html", "Chapter 245 https://quanteda.io/articles/pkgdown/examples/plotting.html", " Chapter 245 https://quanteda.io/articles/pkgdown/examples/plotting.html "],["httpsquanteda-ioarticlespkgdownexampleslsa-html.html", "Chapter 246 https://quanteda.io/articles/pkgdown/examples/lsa.html", " Chapter 246 https://quanteda.io/articles/pkgdown/examples/lsa.html "],["httpsquanteda-ioarticlespkgdownexamplestwitter-html.html", "Chapter 247 https://quanteda.io/articles/pkgdown/examples/twitter.html", " Chapter 247 https://quanteda.io/articles/pkgdown/examples/twitter.html "],["httpsquanteda-ioarticlespkgdownreplicationdigital-humanities-html.html", "Chapter 248 https://quanteda.io/articles/pkgdown/replication/digital-humanities.html", " Chapter 248 https://quanteda.io/articles/pkgdown/replication/digital-humanities.html "],["httpsquanteda-ioarticlespkgdownreplicationtext2vec-html.html", "Chapter 249 https://quanteda.io/articles/pkgdown/replication/text2vec.html", " Chapter 249 https://quanteda.io/articles/pkgdown/replication/text2vec.html "],["httpsquanteda-ioarticlespkgdownreplicationqss-html.html", "Chapter 250 https://quanteda.io/articles/pkgdown/replication/qss.html", " Chapter 250 https://quanteda.io/articles/pkgdown/replication/qss.html "],["footer.html", "Chapter 251 footer", " Chapter 251 footer citation(package = &quot;quanteda&quot;) Benoit K, Watanabe K, Wang H, Nulty P, Obeng A, Müller S, Matsuo A (2018). &quot;quanteda: An R package for the quantitative analysis of textual data.&quot; _Journal of Open Source Software_, *3*(30), 774. doi: 10.21105/joss.00774 (URL: https://doi.org/10.21105/joss.00774), &lt;URL: https://quanteda.io&gt;. A BibTeX entry for LaTeX users is @Article{, title = {quanteda: An R package for the quantitative analysis of textual data}, journal = {Journal of Open Source Software}, author = {Kenneth Benoit and Kohei Watanabe and Haiyan Wang and Paul Nulty and Adam Obeng and Stefan Müller and Akitaka Matsuo}, doi = {10.21105/joss.00774}, url = {https://quanteda.io}, volume = {3}, number = {30}, pages = {774}, year = {2018}, } "],["r-için-arayüzler.html", "Chapter 252 R için arayüzler 252.1 Analiz için genel GUI 252.2 Raporlama için 252.3 Grafikler", " Chapter 252 R için arayüzler 252.1 Analiz için genel GUI 252.1.1 R Commander https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/ #### Obtain names of all packages on CRAN names.available.packages &lt;- rownames(available.packages()) #### Extract packages names that contain Rcmdr Rcmdr.related.packages &lt;- names.available.packages[grep(&quot;Rcmdr&quot;, names.available.packages)] Rcmdr.related.packages #### Install these packages install.packages(pkgs = Rcmdr.related.packages) # load library &amp; run Rcmdr library(Rcmdr) # run Rcmdr Rcmdr::Commander() 252.1.1.1 EZR An extension for R Commander http://www.jichi.ac.jp/saitama-sct/SaitamaHP.files/statmedEN.html Investigation of the freely available easy-to-use software ‘EZR’ for medical statistics 252.1.2 RKWard https://rkward.kde.org/Main_Page 252.1.3 Rattle https://rattle.togaware.com/ 252.1.4 Jamovi https://www.jamovi.org/ 252.1.5 JASP https://jasp-stats.org/ 252.1.6 Blue Sky Statistics https://www.blueskystatistics.com/ 252.1.7 R AnalyticFlow https://r.analyticflow.com/en/ 252.1.8 Deducer http://www.deducer.org/pmwiki/pmwiki.php?n=Main.DeducerManual https://r4stats.com/2018/06/13/deducer/ install.packages(c(&quot;JGR&quot;,&quot;Deducer&quot;,&quot;DeducerExtras&quot;)) library(&quot;JGR&quot;) JGR() 252.1.9 Radiant https://radiant-rstats.github.io/docs/tutorials.html 252.1.10 lessR https://cran.r-project.org/web/packages/lessR/index.html http://www.lessrstats.com/ http://www.lessrstats.com/videos.html 252.1.11 Renjin http://www.renjin.org/ 252.1.12 FastR https://github.com/oracle/fastr http://www.graalvm.org/docs/reference-manual/languages/r/ 252.2 Raporlama için 252.2.1 Stencila 252.2.2 Datazar 252.3 Grafikler 252.3.1 esquisse https://github.com/dreamRs/esquisse 252.3.2 ggExtra https://github.com/daattali/ggExtra 252.3.3 ggplotAssist https://github.com/cardiomoon/ggplotAssist 252.3.4 ggraptR https://github.com/cargomoose/ggraptR "],["eclipse-an-alternative-to-rstudio.html", "Chapter 253 Eclipse – an alternative to RStudio", " Chapter 253 Eclipse – an alternative to RStudio https://datascienceplus.com/eclipse-an-alternative-to-rstudio-part-1/ "],["diğer-kodlar-4.html", "Chapter 254 Diğer kodlar", " Chapter 254 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim-4.html", "Chapter 255 Geri Bildirim", " Chapter 255 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. Reproducible workflows at scale with drake https://ropensci.org/commcalls/2019-09-24/ "],["r-nerede-kullanılır.html", "Chapter 256 R nerede kullanılır", " Chapter 256 R nerede kullanılır Veri düzenleme İstatistik analiz Web sayfası hazırlama (Statik/Dinamik) https://sbalci.github.io/ https://kevinrue.shinyapps.io/isee-shiny-contest/ Sunum hazırlama (bu sunum) Programlama https://serdarbalci.netlify.com/pathtweets/ Otomatik, periodik ve tekrarlanabilir rapor hazırlama https://sbalci.github.io/AutoJournalWatch/GallbladderRecent.html pdf, html, ppt oluşturma tez yazma kitap yazma CV oluşturma https://rpubs.com/sbalci/CV poster hazırlama rapor şablonu oluşturma Robot uygulamaları (Arudino kodu) … "],["r-generation.html", "Chapter 257 R generation", " Chapter 257 R generation R yıllar içinde çok fazla değişim gösterdi https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x :scale 30% "],["r-yükleme-4.html", "Chapter 258 R yükleme 258.1 R-project 258.2 RStudio 258.3 MacOS için", " Chapter 258 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY What is R? 258.1 R-project https://cran.r-project.org/ 258.2 RStudio 258.2.1 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 258.2.2 RStudio 258.2.3 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ devtools::install_github(&quot;rstudio/addinexamples&quot;, type = &quot;source&quot;) 258.3 MacOS için 258.3.1 X11 https://www.xquartz.org/ 258.3.2 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor-4.html", "Chapter 259 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 259 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf #RStats — There are always several ways to do the same thing… nice example on with the identity matrix by (???) https://t.co/O3GXdPiM32 — Colin Fay 🤘 ((???)) April 1, 2019 "],["r-paketleri-4.html", "Chapter 260 R paketleri 260.1 Neden paketler var 260.2 Paketleri nereden bulabiliriz 260.3 Kendi paket evrenini oluştur 260.4 R paket yükleme 260.5 Paket çağırma", " Chapter 260 R paketleri 260.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 260.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html CRAN Task Views https://cran.r-project.org/web/views/ Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch CRANsearcher https://github.com/RhoInc/CRANsearcher Awesome R https://awesome-r.com/ 260.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 260.4 R paket yükleme {r # install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) 260.5 Paket çağırma {r # require(tidyverse) require(jmv) require(questionr) library(summarytools) library(gganimate) "],["r-için-yardım-bulma-4.html", "Chapter 261 R için yardım bulma", " Chapter 261 R için yardım bulma {r # ?mean ??efetch help(merge) example(merge) RSiteSearch(&quot;shiny&quot;) Vignette :scale 80% RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Google’da ararken [R] yazmak da işe yarayabiliyor. searcher package 📦 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Use Reproducible Examples When Asking Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 Keeping up to date with R news https://masalmon.eu/2019/01/25/uptodate/ "],["rstudio-ile-proje-oluşturma.html", "Chapter 262 Rstudio ile proje oluşturma", " Chapter 262 Rstudio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme-4.html", "Chapter 263 RStudio ile veri yükleme 263.1 Excel 263.2 SPSS 263.3 CSV", " Chapter 263 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 263.1 Excel 263.2 SPSS 263.3 CSV "],["veriyi-görüntüleme-4.html", "Chapter 264 Veriyi görüntüleme", " Chapter 264 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 "],["veriyi-görüntüleme-5.html", "Chapter 265 Veriyi görüntüleme", " Chapter 265 Veriyi görüntüleme {r # library(nycflights13) summary(flights) {r # View(data) {r # data() {r # head(data, n = 10) {r # tail(data) {r # glimpse(data) {r # str(data) {r # skimr::skim() "],["veriyi-değiştirme-4.html", "Chapter 266 Veriyi değiştirme 266.1 Veriyi kod ile değiştirelim 266.2 Veriyi eklentilerle değiştirme 266.3 RStudio aracılığıyla recode", " Chapter 266 Veriyi değiştirme 266.1 Veriyi kod ile değiştirelim 266.2 Veriyi eklentilerle değiştirme :scale 30% 266.3 RStudio aracılığıyla recode questionr paketi kullanılacak :scale 30% https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler-4.html", "Chapter 267 Basit tanımlayıcı istatistikler 267.1 summarytools 267.2 DataExplorer 267.3 inspectdf 267.4 Grafikler", " Chapter 267 Basit tanımlayıcı istatistikler summary() mean median min max sd table() library(readr) irisdata &lt;- read_csv(&quot;data/iris.csv&quot;) jmv::descriptives(data = irisdata, vars = &quot;Sepal.Length&quot;, splitBy = &quot;Species&quot;, freq = TRUE, hist = TRUE, dens = TRUE, bar = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sum = TRUE, sd = TRUE, variance = TRUE, range = TRUE, se = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE, pcEqGr = TRUE) DESCRIPTIVES Descriptives ───────────────────────────────────────────────────── Species Sepal.Length ───────────────────────────────────────────────────── N setosa 50 versicolor 50 virginica 50 Missing setosa 0 versicolor 0 virginica 0 Mean setosa 5.006000 versicolor 5.936000 virginica 6.588000 Std. error mean setosa 0.04984957 versicolor 0.07299762 virginica 0.08992695 Median setosa 5.000000 versicolor 5.900000 virginica 6.500000 Mode setosa 5.000000 versicolor 5.500000 virginica 6.300000 Sum setosa 250.3000 versicolor 296.8000 virginica 329.4000 Standard deviation setosa 0.3524897 versicolor 0.5161711 virginica 0.6358796 Variance setosa 0.1242490 versicolor 0.2664327 virginica 0.4043429 Range setosa 1.500000 versicolor 2.100000 virginica 3.000000 Minimum setosa 4.300000 versicolor 4.900000 virginica 4.900000 Maximum setosa 5.800000 versicolor 7.000000 virginica 7.900000 Skewness setosa 0.1200870 versicolor 0.1053776 virginica 0.1180151 Std. error skewness setosa 0.3366007 versicolor 0.3366007 virginica 0.3366007 Kurtosis setosa -0.2526888 versicolor -0.5330095 virginica 0.03290442 Std. error kurtosis setosa 0.6619084 versicolor 0.6619084 virginica 0.6619084 25th percentile setosa 4.800000 versicolor 5.600000 virginica 6.225000 50th percentile setosa 5.000000 versicolor 5.900000 virginica 6.500000 75th percentile setosa 5.200000 versicolor 6.300000 virginica 6.900000 ───────────────────────────────────────────────────── 267.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 267.2 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 267.3 inspectdf https://github.com/alastairrushworth/inspectdf 267.4 Grafikler # library(ggplot2) library(mosaic) mPlot(irisdata) descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) A beginner kit for #rstats The Landscape of R Packages for Automated Exploratory Data Analysis https://journal.r-project.org/archive/2019/RJ-2019-033/ (???){RJ-2019-033, author = {Mateusz Staniak and Przemysław Biecek}, title = {{The Landscape of R Packages for Automated Exploratory Data Analysis}}, year = {2019}, journal = {{The R Journal}}, doi = {10.32614/RJ-2019-033}, url = {https://journal.r-project.org/archive/2019/RJ-2019-033/index.html} } Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["bazı-arayüzler.html", "Chapter 268 Bazı arayüzler 268.1 Rcmdr 268.2 jamovi", " Chapter 268 Bazı arayüzler https://sbalci.github.io/MyRCodesForDataAnalysis/R-Arayuzler.nb.html 268.1 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ 268.2 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["r-nereden-öğrenilir.html", "Chapter 269 R nereden öğrenilir", " Chapter 269 R nereden öğrenilir https://sbalci.github.io/MyRCodesForDataAnalysis/WhereToLearnR.nb.html "],["sonraki-konular-4.html", "Chapter 270 Sonraki Konular", " Chapter 270 Sonraki Konular RStudio ile GitHub kullanımı R Markdown ve R Notebook ile tekrarlanabilir rapor Hipotez testleri "],["geri-bildirim-5.html", "Chapter 271 Geri Bildirim", " Chapter 271 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. "],["libraries-used.html", "Chapter 272 Libraries Used", " Chapter 272 Libraries Used citation(&quot;tidyverse&quot;) citation(&quot;foreign&quot;) citation(&quot;tidylog&quot;) citation(&quot;janitor&quot;) citation(&quot;jmv&quot;) citation(&quot;tangram&quot;) citation(&quot;finalfit&quot;) citation(&quot;summarytools&quot;) citation(&quot;ggstatplot&quot;) citation(&quot;readxl&quot;) "],["iletişim.html", "Chapter 273 İletişim", " Chapter 273 İletişim Completed on {r # Sys.time(). Serdar Balci, MD, Pathologist drserdarbalci@gmail.com https://rpubs.com/sbalci/CV https://sbalci.github.io/ https://github.com/sbalci https://twitter.com/serdarbalci author: &quot;[Serdar Balcı, MD, Pathologist](https://sbalci.github.io/)&quot; institute: &quot;[serdarbalci.com](https://www.serdarbalci.com)&quot; date: &quot;`{r # format(Sys.Date())`&quot; output: revealjs::revealjs_presentation: incremental: true theme: sky highlight: pygments center: false smart: true transition: fade self_contained: true ig_width: 7 fig_height: 6 fig_caption: true reveal_options: slideNumber: true previewLinks: true rmdshower::shower_presentation: xaringan::moon_reader: lib_dir: libs nature: beforeInit: [&quot;macros.js&quot;, &quot;https://platform.twitter.com/widgets.js&quot;] highlightStyle: github highlightLines: true countIncrementalSlides: false self_contained: true html_notebook: fig_caption: yes highlight: kate number_sections: yes theme: flatly toc: yes toc_depth: 5 toc_float: yes prettydoc::html_pretty: theme: leonids highlight: github pdf_document: toc: yes toc_depth: &#39;5&#39; html_document: fig_caption: yes keep_md: yes toc: yes toc_depth: 5 toc_float: yes editor_options: chunk_output_type: inline "],["tekrarlanabilir-analiz-ve-rapor.html", "Chapter 274 Tekrarlanabilir Analiz ve Rapor 274.1 Replication Crisis 274.2 Replication Crisis Excel Version", " Chapter 274 Tekrarlanabilir Analiz ve Rapor 274.1 Replication Crisis https://en.wikipedia.org/wiki/Replication_crisis 274.2 Replication Crisis Excel Version "],["rstudio-ile-proje-oluştur.html", "Chapter 275 RStudio ile proje oluştur", " Chapter 275 RStudio ile proje oluştur "],["r-notebook.html", "Chapter 276 R Notebook 276.1 R Notebook dökümanı oluşturma 276.2 R Notebook’tan html, pdf ve word oluşturma 276.3 RNotebook vs RMarkdown", " Chapter 276 R Notebook 276.1 R Notebook dökümanı oluşturma 276.2 R Notebook’tan html, pdf ve word oluşturma 276.3 RNotebook vs RMarkdown https://youtu.be/zNzZ1PfUDNk "],["r-markdown.html", "Chapter 277 R Markdown 277.1 Hem kendi kodları hem de html kodları yazılabilir 277.2 R Markdown: The Definitive Guide 277.3 R Markdown syntax 277.4 Remedy Package 277.5 R Markdown paket ve şablonları 277.6 Render Markdown via code 277.7 pandoc Rstudio integration", " Chapter 277 R Markdown 277.1 Hem kendi kodları hem de html kodları yazılabilir https://rmarkdown.rstudio.com What is R Markdown? from RStudio, Inc. on Vimeo. 277.2 R Markdown: The Definitive Guide https://bookdown.org/yihui/rmarkdown/ 277.3 R Markdown syntax https://gist.github.com/MinhasKamal/7fdebb7c424d23149140 277.4 Remedy Package 277.4.1 Remedy 277.5 R Markdown paket ve şablonları https://bookdown.org/yihui/rmarkdown/document-templates.html 277.6 Render Markdown via code inside R markdown::markdownToHTML(&#39;markdown_example.md&#39;, &#39;markdown_example.html&#39;) command line R -e &quot;markdown::markdownToHTML(&#39;markdown_example.md&#39;, &#39;markdown_example.html&#39;)&quot; 277.7 pandoc Rstudio integration command line export PATH=$PATH:/Applications/RStudio.app/Contents/MacOS/pandoc R -e &quot;rmarkdown::render(&#39;markdown_example.md&#39;)&quot; "],["rmarkdown-chunk-içinde-r-kodlarını-çalıştırma.html", "Chapter 278 RMarkdown chunk içinde R kodlarını çalıştırma", " Chapter 278 RMarkdown chunk içinde R kodlarını çalıştırma {r, results=&#39;asis&#39;} iris %&gt;% tibble::as_tibble() %&gt;% details::details(summary = &#39;tibble&#39;) "],["metin-arasında-r-kodlarını-çalıştırma.html", "Chapter 279 Metin arasında R kodlarını çalıştırma", " Chapter 279 Metin arasında R kodlarını çalıştırma "],["chunk-options.html", "Chapter 280 Chunk Options 280.1 Global Options 280.2 Other Code Languages", " Chapter 280 Chunk Options 280.1 Global Options {r , include=FALSE} knitr::opts_chunk$set(fig.width = 12, fig.height = 8, fig.path = &#39;Figs/&#39;, echo = TRUE, warning = FALSE, message = FALSE, error = FALSE, eval = TRUE, tidy = TRUE, comment = NA) 280.2 Other Code Languages "],["r-markdown-kod-örneği.html", "Chapter 281 R Markdown kod örneği", " Chapter 281 R Markdown kod örneği {r} data(&quot;cancer&quot;) cancer foreign::write.foreign(df = cancer, datafile = &quot;data/cancer.sav&quot;, codefile = &quot;data/cancer.spo&quot;, package = &quot;SPSS&quot; ) "],["r-markdown-paket-çağırma.html", "Chapter 282 R Markdown Paket Çağırma 📦 282.1 Sık kullandığım paketler 📦", " Chapter 282 R Markdown Paket Çağırma 📦 {r} suppressPackageStartupMessages(library(&quot;tidyverse&quot;)) suppressPackageStartupMessages(library(&quot;survival&quot;)) 282.1 Sık kullandığım paketler 📦 {tidyverse} {tidylog} {lubridate} {janitor} {readxl} {foreign} {summarytools} {ggstatsplot} {tangram} {finalfit} {psycho} {jmv} {survival} {survminer} {report} {kableExtra} "],["r-markdown-veri-yükleme-spss.html", "Chapter 283 R Markdown Veri Yükleme SPSS", " Chapter 283 R Markdown Veri Yükleme SPSS "],["r-markdown-veri-yükleme-excel.html", "Chapter 284 R Markdown Veri Yükleme Excel", " Chapter 284 R Markdown Veri Yükleme Excel "],["veri-görüntüleme.html", "Chapter 285 Veri Görüntüleme", " Chapter 285 Veri Görüntüleme {r} View(mydata) glimpse(mydata) "],["veri-düzenleme.html", "Chapter 286 Veri Düzenleme", " Chapter 286 Veri Düzenleme {r} mydata &lt;- janitor::clean_names(mydata) {r} mydata$sontarih &lt;- janitor::excel_numeric_to_date( as.numeric(mydata$olum_tarihi) ) "],["recode.html", "Chapter 287 Recode", " Chapter 287 Recode {r} mydata$Outcome &lt;- &quot;Dead&quot; mydata$Outcome[mydata$olum_tarihi == &quot;yok&quot;] &lt;- &quot;Alive&quot; {r} ## Recoding mydata$cinsiyet into mydata$Cinsiyet mydata$Cinsiyet &lt;- recode(mydata$cinsiyet, &quot;K&quot; = &quot;Kadin&quot;, &quot;E&quot; = &quot;Erkek&quot;) mydata$Cinsiyet &lt;- factor(mydata$Cinsiyet) "],["recode-regular-expression.html", "Chapter 288 Recode regular expression", " Chapter 288 Recode regular expression {r recode TNM stage} #pT2N0Mx -&gt; 2 mydata$Tstage &lt;- stringr::str_match( mydata$patolojik_evre, paste(&#39;(.+)&#39;, &quot;N&quot;, sep=&#39;&#39;))[,2] ) "],["recode-regular-expression-case-when.html", "Chapter 289 Recode regular expression case_when", " Chapter 289 Recode regular expression case_when {r recode TNM2} mydata &lt;- mydata %&gt;% mutate( T_stage = case_when( grepl(pattern = &quot;T1&quot;, x = .$Tstage) == TRUE ~ &quot;T1&quot;, grepl(pattern = &quot;T2&quot;, x = .$Tstage) == TRUE ~ &quot;T2&quot;, grepl(pattern = &quot;T3&quot;, x = .$Tstage) == TRUE ~ &quot;T3&quot;, grepl(pattern = &quot;T4&quot;, x = .$Tstage) == TRUE ~ &quot;T4&quot;, TRUE ~ &quot;Tx&quot; ) ) "],["recode-regular-expression-case-when-1.html", "Chapter 290 Recode regular expression case_when", " Chapter 290 Recode regular expression case_when {r} mydata &lt;- mydata %&gt;% mutate( TumorPDL1gr1 = case_when( t_pdl1 &lt; 1 ~ &quot;kucuk1&quot;, t_pdl1 &gt;= 1 ~ &quot;buyukesit1&quot; ) ) "],["r-markdown-tanımlayıcı-istatistikler.html", "Chapter 291 R Markdown Tanımlayıcı İstatistikler 291.1 Table One 291.2 The Grammar of Tables 291.3 Kategorik Veriler 291.4 Kategorik Veriler için Grafikler 291.5 Continious Variables", " Chapter 291 R Markdown Tanımlayıcı İstatistikler {r} library(summarytools) view(dfSummary(colon_s)) A beginner kit for #rstats The Landscape of R Packages for Automated Exploratory Data Analysis https://journal.r-project.org/archive/2019/RJ-2019-033/ (???){RJ-2019-033, author = {Mateusz Staniak and Przemysław Biecek}, title = {{The Landscape of R Packages for Automated Exploratory Data Analysis}}, year = {2019}, journal = {{The R Journal}}, doi = {10.32614/RJ-2019-033}, url = {https://journal.r-project.org/archive/2019/RJ-2019-033/index.html} } 291.1 Table One {r, results=&#39;asis&#39;} # cat(names(mydata), sep = &quot; + \\n&quot;) library(arsenal) tab1 &lt;- tableby(~ Cinsiyet + Yas + TumorYerlesimi , data = mydata) summary(tab1) 291.2 The Grammar of Tables tangram: The Grammar of Tables A grammar of tables Grammar of Tables? Easily generate information-rich, publication-quality tables from R 291.3 Kategorik Veriler {r} mydata %&gt;% janitor::tabyl(Categorical) %&gt;% adorn_pct_formatting(rounding = &#39;half up&#39;, digits = 1) %&gt;% knitr::kable() {r crosstable} mydata %&gt;% summary_factorlist(dependent = dependent, explanatory = explanatory, total_col = TRUE, p = TRUE, add_dependent_label = TRUE) -&gt; table knitr::kable(table, row.names = FALSE, align = c(&#39;l&#39;, &#39;l&#39;, &#39;r&#39;, &#39;r&#39;, &#39;r&#39;)) 291.4 Kategorik Veriler için Grafikler {r ggstatplot, layout=&#39;l-page&#39;} mydata %&gt;% ggstatsplot::ggbarstats(data = ., main = Categorical_variable, condition = dependent_variable ) 291.5 Continious Variables {r} mydata %&gt;% jmv::descriptives( data = ., vars = c(yas), hist = TRUE, dens = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sd = TRUE, variance = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE) "],["r-markdown-örneği-çapraz-tablolar.html", "Chapter 292 R Markdown örneği Çapraz Tablolar", " Chapter 292 R Markdown örneği Çapraz Tablolar {r crosstable} library(finalfit) mydata %&gt;% summary_factorlist(dependent = dependent, explanatory = explanatory, column = TRUE, total_col = TRUE, p = TRUE, add_dependent_label = TRUE, na_include=FALSE # catTest = catTestfisher ) -&gt; table knitr::kable(table, row.names = FALSE, align = c(&#39;l&#39;, &#39;l&#39;, &#39;r&#39;, &#39;r&#39;, &#39;r&#39;)) "],["r-markdown-örneği-sağkalım.html", "Chapter 293 R Markdown örneği Sağkalım 293.1 Sağkalım için veriyi düzenleme 293.2 Kaplan-Meier 293.3 Sağkalım Tabloları 293.4 Pairwise comparison 293.5 Multivariate Analysis Survival", " Chapter 293 R Markdown örneği Sağkalım Drawing Survival Curves Using ggplot2 https://rpkgs.datanovia.com/survminer/reference/ggsurvplot.html 293.1 Sağkalım için veriyi düzenleme {r define survival time} mydata$int &lt;- lubridate::interval( lubridate::ymd(mydata$CerrahiTarih), lubridate::ymd(mydata$SonTarih) ) mydata$OverallTime &lt;- lubridate::time_length(mydata$int, &quot;month&quot;) mydata$OverallTime &lt;- round(mydata$OverallTime, digits = 1) {r} ## Recoding mydata$Outcome into mydata$Outcome2 mydata$Outcome2 &lt;- recode(mydata$Outcome, &quot;Alive&quot; = &quot;0&quot;, &quot;Dead&quot; = &quot;1&quot;) mydata$Outcome2 &lt;- as.numeric(mydata$Outcome2) 293.2 Kaplan-Meier {r Kaplan-Meier} mydata %&gt;% finalfit::surv_plot(dependent, explanatory, xlab=&#39;Time (months)&#39;, pval=TRUE, legend = &#39;none&#39;, break.time.by = 12, xlim = c(0,60), legend.labs = c(&#39;a&#39;,&#39;b&#39;) ) 293.3 Sağkalım Tabloları {r} km_fit &lt;- survfit(dependent ~ explanatory, data = mydata) km_fit {r, eval=FALSE, include=FALSE, echo=TRUE} library(survival) km &lt;- with(mydata, Surv(OverallTime, Outcome2)) # head(km,80) # plot(km) {r 1-3-5-yr} summary(km_fit, times = c(12,36,60)) 293.4 Pairwise comparison {r} survminer::pairwise_survdiff(formula = Surv(time, Outcome) ~ Group, data = mydata, p.adjust.method = &quot;BH&quot;) 293.5 Multivariate Analysis Survival {r Multivariate Analysis, eval=FALSE, include=FALSE, echo=TRUE} library(finalfit) library(survival) explanatoryMultivariate &lt;- explanatoryKM dependentMultivariate &lt;- dependentKM mydata %&gt;% finalfit(dependentMultivariate, explanatoryMultivariate) -&gt; tMultivariate knitr::kable(tMultivariate, row.names=FALSE, align=c(&quot;l&quot;, &quot;l&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;, &quot;r&quot;)) "],["jamovi-6.html", "Chapter 294 jamovi 294.1 jamovi ve R entegrasyonu 294.2 {jmv} paket kodları", " Chapter 294 jamovi 294.1 jamovi ve R entegrasyonu Rj Editor – Analyse your data with R in jamovi 294.2 {jmv} paket kodları jamovi syntax mode "],["güncellemeler-olunca-kodlar-çalışacak-mı.html", "Chapter 295 Güncellemeler olunca kodlar çalışacak mı? 295.1 Paket Kütüphaneleri 295.2 Docker 295.3 Yeni R sürümleri", " Chapter 295 Güncellemeler olunca kodlar çalışacak mı? 295.1 Paket Kütüphaneleri packrat / renv https://environments.rstudio.com 295.2 Docker docker 295.2.1 The Rocker Project Docker Containers for the R Environment docker run --rm -ti rocker/r-base Or get started with an RStudio® instance: docker run -e PASSWORD=yourpassword --rm -p 8787:8787 rocker/rstudio and point your browser to localhost:8787 Log in with user/password rstudio/yourpassword Managing containers 295.3 Yeni R sürümleri RSwitch https://rud.is/rswitch/ Using RSwitch https://rud.is/rswitch/guide/ : scale 30% "],["yedeklemeyi-nasıl-yapacağız.html", "Chapter 296 Yedeklemeyi nasıl yapacağız 296.1 Projeyi düzgün organize edin 296.2 Save Final Data 296.3 GitHub 296.4 GitHub Yedekleme", " Chapter 296 Yedeklemeyi nasıl yapacağız 296.1 Projeyi düzgün organize edin pdf R images bib {r load library} source(file = here::here(&quot;R&quot;, &quot;loadLibrary.R&quot;)) 296.2 Save Final Data {r} saved data after analysis to `mydata.xlsx`. save.image(file = here::here(&quot;data&quot;, &quot;mydata_work_space.RData&quot;)) readr::write_rds(x = mydata, path = here::here(&quot;data&quot;, &quot;mydata_afteranalysis.rds&quot;)) saveRDS(object = mydata, file = here::here(&quot;data&quot;, &quot;mydata.rds&quot;)) writexl::write_xlsx(mydata, here::here(&quot;data&quot;, &quot;mydata.xlsx&quot;)) paste0(rownames(file.info(here::here(&quot;data&quot;, &quot;mydata.xlsx&quot;))), &quot; : &quot;, file.info(here::here(&quot;data&quot;, &quot;mydata.xlsx&quot;))$ctime) 296.3 GitHub {r github push} CommitMessage &lt;- paste(&quot;updated on &quot;, Sys.time(), sep = &quot;&quot;) wd &lt;- getwd() gitCommand &lt;- paste(&quot;cd &quot;, wd, &quot; \\n git add . \\n git commit --message &#39;&quot;, CommitMessage, &quot;&#39; \\n git push origin master \\n&quot;, sep = &quot;&quot; ) system(command = gitCommand, intern = TRUE ) 296.4 GitHub Yedekleme CommitMessage &lt;- paste(&quot;updated on &quot;, Sys.time(), sep = &quot;&quot;) wd &lt;- getwd() gitCommand &lt;- paste(&quot;cd &quot;, wd, &quot; \\n git add . \\n git commit --message &#39;&quot;, CommitMessage, &quot;&#39; \\n git push origin master \\n&quot;, sep = &quot;&quot;) system(command = gitCommand, intern = TRUE) [1] &quot;[master afbb980] updated on 2020-12-12 21:26:11&quot; [2] &quot; 1128 files changed, 1846999 insertions(+), 88465 deletions(-)&quot; [3] &quot; create mode 100644 .gitignore&quot; [4] &quot; create mode 100644 01-intro.Rmd&quot; [5] &quot; rename Rmds-mds-markdown/02-literature.Rmd =&gt; 02-literature-1.Rmd (100%)&quot; [6] &quot; create mode 100644 02-literature.Rmd&quot; [7] &quot; rename Rmds-mds-markdown/03-method.Rmd =&gt; 03-method.Rmd (100%)&quot; [8] &quot; rename Rmds-mds-markdown/04-application.Rmd =&gt; 04-application.Rmd (100%)&quot; [9] &quot; rename Rmds-mds-markdown/05-summary.Rmd =&gt; 05-summary.Rmd (100%)&quot; [10] &quot; create mode 100644 06-references.Rmd&quot; [11] &quot; create mode 100644 12-ArticlesPerJournalsPerCountry.Rmd&quot; [12] &quot; create mode 100644 13-CountryBasedComparison.Rmd&quot; [13] &quot; create mode 100644 14-JournalWatchPBPath.Rmd&quot; [14] &quot; create mode 100644 15-MeSH_Terms_Pathology_Articles_From_Turkey.Rmd&quot; [15] &quot; create mode 100644 16-6-tables.Rmd&quot; [16] &quot; create mode 100644 AnalysingtheHIVpandemic.Rmd&quot; [17] &quot; create mode 100644 AutomatedDashboardDeviation.Rmd&quot; [18] &quot; create mode 100644 Autoreport.Rmd&quot; [19] &quot; create mode 100644 Bibliography.Rmd&quot; [20] &quot; create mode 100644 Biyoinformatik.Rmd&quot; [21] &quot; create mode 100644 CancerInSilico.Rmd&quot; [22] &quot; create mode 100644 CancerPackages.Rmd&quot; [23] &quot; create mode 100644 CloudForResearch.Rmd&quot; [24] &quot; create mode 100644 CompareMeans.Rmd&quot; [25] &quot; create mode 100644 CompareProportions.Rmd&quot; [26] &quot; create mode 100644 ContingencyTables.Rmd&quot; [27] &quot; create mode 100644 Correlations.Rmd&quot; [28] &quot; create mode 100644 DataList.Rmd&quot; [29] &quot; create mode 100644 DataScienceLiveBook.Rmd&quot; [30] &quot; create mode 100644 DataTools.Rmd&quot; [31] &quot; create mode 100644 DecisionTreeKararAgaci.Rmd&quot; [32] &quot; create mode 100644 DescriptiveStatistics.Rmd&quot; [33] &quot; create mode 100644 EvidenceSynthesisProjects.Rmd&quot; [34] &quot; create mode 100644 ExplatoryDataAnalysisSummaryStatistics.Rmd&quot; [35] &quot; create mode 100644 FileOrganization.Rmd&quot; [36] &quot; create mode 100644 FlippingCoin.Rmd&quot; [37] &quot; create mode 100644 GeneralLinearModels.Rmd&quot; [38] &quot; create mode 100644 GeneralResources.Rmd&quot; [39] &quot; create mode 100644 GettingDataVeriYukleme.Rmd&quot; [40] &quot; create mode 100644 GitHub.Rmd&quot; [41] &quot; create mode 100644 GoogleScholar.Rmd&quot; [42] &quot; create mode 100644 Graphs.Rmd&quot; [43] &quot; create mode 100644 HierarchicalClustering.Rmd&quot; [44] &quot; create mode 100644 How-To-Use-R-With-Excel.Rmd&quot; [45] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research.html&quot; [46] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research.nb.html&quot; [47] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/fonts/open-sans-400.woff&quot; [48] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/fonts/open-sans-700.woff&quot; [49] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/images/body-bg.jpg&quot; [50] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/images/body-bg.png&quot; [51] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/images/header-bg.jpg&quot; [52] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/images/highlight-bg.jpg&quot; [53] &quot; delete mode 100644 How-to-Prepare-Data-for-Histopathology-Research_files/style.css&quot; [54] &quot; create mode 100644 HypothesisTesting.Rmd&quot; [55] &quot; create mode 100644 KMeansClustering.Rmd&quot; [56] &quot; create mode 100644 LinearRegression.Rmd&quot; [57] &quot; create mode 100644 MachineLearning.Rmd&quot; [58] &quot; delete mode 100644 Mining-Twitter-Data-rtweet.nb.html&quot; [59] &quot; create mode 100644 MultiplePages.Rmd&quot; [60] &quot; delete mode 100644 MyGIST.nb.html&quot; [61] &quot; create mode 100644 MyRCodesForDataAnalysis.Rmd&quot; [62] &quot; create mode 100644 MyRCodesForDataAnalysis.log&quot; [63] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/__packages&quot; [64] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/citation 2_3ec1d498db2f3c3def85059b929481be.RData&quot; [65] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/citation 2_3ec1d498db2f3c3def85059b929481be.rdb&quot; [66] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/citation 2_3ec1d498db2f3c3def85059b929481be.rdx&quot; [67] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/descriptive_8373dcdda2eb5532607372ea71a3792d.RData&quot; [68] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/descriptive_8373dcdda2eb5532607372ea71a3792d.rdb&quot; [69] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/descriptive_8373dcdda2eb5532607372ea71a3792d.rdx&quot; [70] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/download package_2be2311dcb9d2b35629cadb4936fad71.RData&quot; [71] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/download package_2be2311dcb9d2b35629cadb4936fad71.rdb&quot; [72] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/download package_2be2311dcb9d2b35629cadb4936fad71.rdx&quot; [73] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/grouped_plot_3c20d65a56efef6bbc74fcd467a9bc41.RData&quot; [74] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/grouped_plot_3c20d65a56efef6bbc74fcd467a9bc41.rdb&quot; [75] &quot; create mode 100644 MyRCodesForDataAnalysis_cache/html/grouped_plot_3c20d65a56efef6bbc74fcd467a9bc41.rdx&quot; [ reached getOption(&quot;max.print&quot;) -- omitted 1028 entries ] "],["her-dökümanın-sonuna-kullandığınız-kütüphaneler-için-atıf-yazdırabilirsiniz.html", "Chapter 297 Her dökümanın sonuna kullandığınız kütüphaneler için atıf yazdırabilirsiniz 297.1 Libraries Used 297.2 Bu oturuma spesifik kullanılan paketler 297.3 Tek tek paket atıfları 297.4 Jamovi ve R için atıf örneği", " Chapter 297 Her dökümanın sonuna kullandığınız kütüphaneler için atıf yazdırabilirsiniz {r} citation() 297.1 Libraries Used citation() To cite R in publications use: R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/. A BibTeX entry for LaTeX users is @Manual{, title = {R: A Language and Environment for Statistical Computing}, author = {{R Core Team}}, organization = {R Foundation for Statistical Computing}, address = {Vienna, Austria}, year = {2020}, url = {https://www.R-project.org/}, } We have invested a lot of time and effort in creating R, please cite it when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for citing R packages. 297.2 Bu oturuma spesifik kullanılan paketler # report::cite_packages(session = sessionInfo()) 297.3 Tek tek paket atıfları {r citations} citation(&quot;tidyverse&quot;) citation(&quot;readxl&quot;) citation(&quot;janitor&quot;) citation(&quot;report&quot;) citation(&quot;finalfit&quot;) citation(&quot;ggstatplot&quot;) 297.4 Jamovi ve R için atıf örneği The jamovi project (2019). jamovi. (Version 0.9) [Computer Software]. Retrieved from https://www.jamovi.org. R Core Team (2018). R: A Language and envionment for statistical computing. [Computer software]. Retrieved from https://cran.r-project.org/. Fox, J., &amp; Weisberg, S. (2018). car: Companion to Applied Regression. [R package]. Retrieved from https://cran.r-project.org/package=car. "],["her-dökümanın-sonuna-oturum-detaylarınızı-yazdırabilirsiniz.html", "Chapter 298 Her dökümanın sonuna oturum detaylarınızı yazdırabilirsiniz 298.1 Session Info", " Chapter 298 Her dökümanın sonuna oturum detaylarınızı yazdırabilirsiniz {r session info, echo=TRUE} sessionInfo() 298.1 Session Info sessionInfo() R version 4.0.3 (2020-10-10) Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.7 Matrix products: default BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] easypower_1.0.1 pwr_1.3-0 readxl_1.3.1 huxtable_5.1.1 [5] DT_0.15 leaflet_2.0.3 summarytools_0.9.8 rmdformats_1.0.0 [9] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 [13] readr_1.4.0 tidyr_1.1.2 tibble_3.0.4 ggplot2_3.3.2 [17] tidyverse_1.3.0 knitr_1.30 loaded via a namespace (and not attached): [1] httr_1.4.2 jsonlite_1.7.1 modelr_0.1.8 assertthat_0.2.1 [5] highr_0.8 pander_0.6.3 cellranger_1.1.0 yaml_2.2.1 [9] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 [13] pryr_0.1.4 checkmate_2.0.0 rvest_0.3.6 RefManageR_1.3.0 [17] colorspace_2.0-0 htmltools_0.5.0 plyr_1.8.6 pkgconfig_2.0.3 [21] broom_0.7.2 haven_2.3.1 magick_2.5.2 bookdown_0.21 [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 [33] evaluate_0.14 fs_1.5.0 fansi_0.4.1 xml2_1.3.2 [37] rapportools_1.0 tools_4.0.3 hms_0.5.3 formatR_1.7 [41] lifecycle_0.2.0 matrixStats_0.56.0 munsell_0.5.0 reprex_0.3.0 [45] compiler_4.0.3 rlang_0.4.9 grid_4.0.3 rstudioapi_0.13 [49] htmlwidgets_1.5.1 crosstalk_1.1.0.1 tcltk_4.0.3 base64enc_0.1-3 [53] labeling_0.4.2 rmarkdown_2.5 gtable_0.3.0 codetools_0.2-16 [57] DBI_1.1.0 curl_4.3 R6_2.5.0 lubridate_1.7.9.2 [61] stringi_1.5.3 Rcpp_1.0.5 vctrs_0.3.5 dbplyr_2.0.0 [65] tidyselect_1.1.0 xfun_0.19 "],["sonraki-konular-5.html", "Chapter 299 Sonraki Konular", " Chapter 299 Sonraki Konular RStudio ile GitHub kullanımı … "],["önerilen-kaynaklar.html", "Chapter 300 Önerilen Kaynaklar", " Chapter 300 Önerilen Kaynaklar Reproducible Templates for Analysis and Dissemination Happy Git and GitHub for the useR "],["sunum-linkleri.html", "Chapter 301 Sunum Linkleri", " Chapter 301 Sunum Linkleri https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.html https://forms.gle/UqGJBiAjB8uLPRon8 "],["geri-bildirim-6.html", "Chapter 302 Geri Bildirim", " Chapter 302 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. "],["iletişim-1.html", "Chapter 303 İletişim", " Chapter 303 İletişim Completed on {r # Sys.Date(). Serdar Balci, MD, Pathologist drserdarbalci@gmail.com https://rpubs.com/sbalci/CV https://sbalci.github.io/ https://github.com/sbalci https://twitter.com/serdarbalci "],["other-links.html", "Chapter 304 Other Links", " Chapter 304 Other Links https://andrewbtran.github.io/NICAR/2018/workflow/docs/02-rmarkdown.html Troubleshooting in R Markdown https://smithcollege-sds.github.io/sds-public/rmarkdown_problems.html http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html https://kbroman.org/knitr_knutshell/pages/overview.html https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html https://kbroman.org/knitr_knutshell/pages/markdown.html https://onp4.com/ csv {headers: true, title: &quot;**Drawing Tables In Markdown**&quot;} Name, Surname, Known As, Age Marcelo, David, coldzera, 22 Oleksandr, Kostyliev, s1mple, 19 Nikola, Kovač, NiKo, 20 Richard, Papillon, shox, 25 Nicolai, Reedtz, dev1ce, 21 {pgn} [Event &quot;Bled-Zagreb-Belgrade Candidates&quot;] [Site &quot;Bled, Zagreb &amp; Belgrade YUG&quot;] [Date &quot;1959.10.11&quot;] [Round &quot;20&quot;] [Result &quot;1-0&quot;] [White &quot;Mikhail Tal&quot;] [Black &quot;Robert James Fischer&quot;] 1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5. Be2 O-O 6. Nf3 e5 7. d5 Nbd7 8. Bg5 h6 9. Bh4 a6 10. O-O Qe8 11. Nd2 Nh7 12. b4 Bf6 13. Bxf6 Nhxf6 14. Nb3 Qe7 15. Qd2 Kh7 16. Qe3 Ng8 17. c5 f5 18. exf5 gxf5 19. f4 exf4 20. Qxf4 dxc5 21. Bd3 cxb4 22. Rae1 Qf6 23. Re6 Qxc3 24. Bxf5+ Rxf5 25. Qxf5+ Kh8 26. Rf3 Qb2 27. Re8 Nf6 28. Qxf6+ Qxf6 29. Rxf6 Kg7 30. Rff8 Ne7 31. Na5 h5 32. h4 Rb8 33. Nc4 b5 34. Ne5 1-0 Keeping Credentials Secret with Keyrings in R https://ras44.github.io/blog/2019/01/19/keeping-credentials-secret-with-keyrings-in-r.html How to build a website with Blogdown in R http://www.storybench.org/how-to-build-a-website-with-blogdown-in-r/ "],["readclipboard.html", "Chapter 305 readClipboard", " Chapter 305 readClipboard setwd(readClipboard()) #Rstats: When using setwd(), R expects forward-slashes in the directory name. But on Windows, copying the directory from folder gives back-slashes. To ‘de-windowsify’ the path name, copy the windows directory &amp; use:setwd(readClipboard())#phdchat #phd pic.twitter.com/cMbdmhNVuf — Guy Prochilo 🏳️ 🌈 ((???)) January 9, 2019 "],["separate.html", "Chapter 306 separate", " Chapter 306 separate One form of messy data is a table in which multiple variables are stored in a single column. The #tidyverse separate() function will transform this type of data into one column per variable by simply specifying the separator! #rstats #tidytuesday #animation #dataviz pic.twitter.com/jjVvqWToIg — Omni Analytics Group ((???)) January 22, 2019 "],["glue-1.html", "Chapter 307 glue", " Chapter 307 glue  glue:: finally clicked for me this AM! 🤓I work with monthly data files and need to update filenames often. My go-to is paste0(). Gave glue() another try. Way less fiddling with commas &amp; quote marks, and it's easier to see the filename. #Rstats #tidyverse pic.twitter.com/EdpozMxrtM — Adam Stone ((???)) January 23, 2019 #RStats — {dplyr} debugging tip: put a browser() somewhere inside your mutate() call to have access to the intermediate elements and to the columns: pic.twitter.com/KN53YJIMOe — Colin Fay 🤘 ((???)) January 23, 2019 Accidentally discovered if you copy &amp; paste a file into your #R script you get the filepath including filename with / (not ) and you just delete \"file:///\"; off the start and don't have to change to / (???) demanded I tweet this #rstats — Faye Jackson ((???)) January 18, 2019 https://radiant-rstats.github.io/docs/ http://jkunst.com/rchess/ https://github.com/jbkunst/rchess https://rc2e.com/index.html "],["my-r-codes-for-data-analysis.html", "Chapter 308 My R Codes For Data Analysis", " Chapter 308 My R Codes For Data Analysis UNDER CONSTRUCTION 🛠️️🔩 This repository is a draft version of many different codes. Organizing them will take some time. That is why I have started a template repository on GitHub. https://github.com/sbalci/histopathology-template/ https://sbalci.github.io/histopathology-template/ These templates will allow me to make histopathology research data analysis easier and more standard. Bir sonraki R-project sunumuna şu linkten belirtilen gün ve saatte erişebilirsiniz. Bir sonraki sunum: R, RStudio ve RMarkdown ile Tekrarlanabilir Rapor Join Zoom Meeting https://us04web.zoom.us/j/808337924 Meeting ID: 808 337 924 Sunum linkleri: https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/R-Markdown.html 25 Eylül 2019 https://youtu.be/GZ85WE9f2R0 https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.html https://sbalci.github.io/MyRCodesForDataAnalysis/R-Giris.nb.html Anonim Geri Bildirim: https://goo.gl/forms/YjGZ5DHgtPlR1RnB3 "],["lecture-notes.html", "Chapter 309 Lecture Notes 309.1 Introduction 309.2 Use R Markdown", " Chapter 309 Lecture Notes 309.1 Introduction R-Giris R-Giris Sunum R-Arayuzler Where To Learn R 309.2 Use R Markdown R-Markdown R-Markdown Sunum "],["my-r-codes-for-data-analysis-1.html", "Chapter 310 My R Codes For Data Analysis", " Chapter 310 My R Codes For Data Analysis In this repository I am going to collect R codes for data analysis. The title says “My R Codes” but I am only the collector. I will try to refer the original sources as far as I can. Serdar Balci, MD, Pathologist My aim is to collect all the codes one needs, where one starts with an excel or spss file and then end with the most common analysis used in histopathology papers : example table There are plenty of ways to do an analysis in R, which is great but also confusing for the newbies. I will collect the codes here so that I can refer later and then update them as I learn more. See the links for the Codes below: WorldBankCountryAnalysis.R 1 cards.R 2 DataCamp.R 3 GABAHip.R 4 googleCite.R 5 makenames.R 6 R-Program-Env-1-2.R 8 SurvivalAnalysis.R 9 SurvivalAnalysisR.R 10 tangram.R 11 TurkPathScholar.R deneme.R geom_bartext.R gilbert-dahl.R GitHubUpdateV2.R join-animations-with-gganimate.R plumber.R plumberRun.R power_multiplot.R quRan-data-raw-clean_data.R Retrieve_pubmed_citation_data.R sf_transitions.R silge.R 12 ArticlesPerJournalsPerCountry.Rmd 13 CountryBasedComparison.Rmd 14 JournalWatchPBPath.Rmd 15 MeSH_Terms_Pathology_Articles_From_Turkey.Rmd 16 6-tables.Rmd arsenal.Rmd AutomatedDashboardDeviation.Rmd Autoreport.Rmd bbplot.Rmd Bibliography.Rmd bioconductor.Rmd Biyoinformatik.Rmd CancerInSilico.Rmd CancerPackages.Rmd CloudForResearch.Rmd codes.Rmd CompareMeans.Rmd CompareProportions.Rmd ContingencyTables.Rmd Correlations.Rmd DataList.Rmd DataScienceLiveBook.Rmd datatable.Rmd DataTools.Rmd DecisionTreeKararAgaci.Rmd DescriptiveStatistics.Rmd drive.Rmd edirect-addin.Rmd eurostat.Rmd EvidenceSynthesisProjects.Rmd ExplatoryDataAnalysisSummaryStatistics.Rmd FileOrganization.Rmd finalfit.Rmd finalfit2.Rmd FlippingCoin.Rmd formattable.Rmd Formulas.Rmd GeneralLinearModels.Rmd GeneralResources.Rmd GettingDataVeriYukleme.Rmd GitHub.Rmd githubdocument.Rmd googledrive-trial.Rmd GoogleScholar.Rmd Graphs.Rmd h2o.Rmd HierarchicalClustering.Rmd HistopathologyResearchTemplate.Rmd How-To-Use-R-With-Excel.Rmd htmlclean.Rmd htmldocco.Rmd huxtable.Rmd HypothesisTesting.Rmd keras.Rmd KMeansClustering.Rmd lessR.Rmd LinearRegression.Rmd MachineLearning.Rmd material.Rmd MultiplePages.Rmd mxnet.Rmd news.Rmd Ninja.Rmd OpenCPU.Rmd papeR.Rmd papeR2.Rmd Power_Analysis.Rmd power.Rmd PowerAnalysis.Rmd PrepareData.Rmd PythonPandas.Rmd R-Arayuzler.Rmd R-Giris.Rmd R-Tipps.Rmd radix.Rmd rchess.Rmd readthedown.Rmd Regression.Rmd reprex.Rmd ReproducibleResearch.Rmd RISmed.Rmd RinPathologyResearch.Rmd rmarkdown_websites_tutorial.Rmd rmarkdown_websites_tutorial2.Rmd ROC.Rmd rorcid.Rmd RPackagesUsed.Rmd SankeyDiagrams.Rmd SensitivitySpecificity.Rmd shiny.Rmd ShinyCodes.Rmd snahelper.Rmd summarytools_introduction.Rmd summarytools_markdown.Rmd survival_analysis_in_r_tutorial.Rmd survival_analysis_in_r_tutorial2.Rmd SurvivalAnalysis.Rmd SyncingGitHubFork.Rmd Table.Rmd tensorflow.Rmd TextMining.Rmd the-lesser-known-stars-of-the-tidyverse.Rmd tuftedoc.Rmd Tutorials.Rmd tweetbook1.Rmd Twitter.Rmd TwitterDashboard.Rmd Untitled1.Rmd Untitled22.Rmd VisualisationGraphsPlots.Rmd WebScrapping.Rmd WhereToLearnR.Rmd "],["getting-data-into-r-veriyi-ra-yükleme-1.html", "Chapter 311 Getting Data into R / Veriyi R’a yükleme", " Chapter 311 Getting Data into R / Veriyi R’a yükleme https://sbalci.github.io/MyRCodesForDataAnalysis/GettingDataVeriYukleme.nb.html Import Data Import using RStudio Import CSV File Import TXT File Import Excel File Import Sheets Import SPSS File Export Data Export to SPSS, while keeping labels "],["prepare-data-for-analysis-veriyi-analiz-için-hazırlamak-1.html", "Chapter 312 Prepare Data for Analysis / Veriyi Analiz için hazırlamak 312.1 data.table", " Chapter 312 Prepare Data for Analysis / Veriyi Analiz için hazırlamak https://sbalci.github.io/MyRCodesForDataAnalysis/PrepareData.nb.html 312.1 data.table https://sbalci.github.io/MyRCodesForDataAnalysis/datatable.nb.html "],["file-organization-best-practices-1.html", "Chapter 313 File organization best practices", " Chapter 313 File organization best practices https://sbalci.github.io/MyRCodesForDataAnalysis/FileOrganization.nb.html "],["analysis-3.html", "Chapter 314 Analysis 314.1 Descriptive Statistics, Exploratory Data Analysis, Summary Statistics 314.2 Hypothesis Testing 314.3 Survival Analysis in R 314.4 Contingency Tables 314.5 Other Analysis", " Chapter 314 Analysis 314.1 Descriptive Statistics, Exploratory Data Analysis, Summary Statistics https://sbalci.github.io/MyRCodesForDataAnalysis/DescriptiveStatistics.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/ExplatoryDataAnalysisSummaryStatistics.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/freq-tables.html the-lesser-known-stars-of-the-tidyverse.nb.html 314.2 Hypothesis Testing https://sbalci.github.io/MyRCodesForDataAnalysis/HypothesisTesting.nb.html 314.2.1 Compare Means https://sbalci.github.io/MyRCodesForDataAnalysis/CompareMeans.nb.html 314.2.2 Compare Proportions https://sbalci.github.io/MyRCodesForDataAnalysis/CompareProportions.nb.html 314.3 Survival Analysis in R https://sbalci.github.io/MyRCodesForDataAnalysis/SurvivalAnalysis.nb.html https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html 314.4 Contingency Tables https://sbalci.github.io/MyRCodesForDataAnalysis/ContingencyTables.nb.html 314.5 Other Analysis 314.5.1 Regression https://sbalci.github.io/MyRCodesForDataAnalysis/Regression.nb.html 314.5.2 LinearRegression.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/LinearRegression.nb.html 314.5.3 General Linear Models https://sbalci.github.io/MyRCodesForDataAnalysis/GeneralLinearModels.nb.html 314.5.4 Decision Trees https://sbalci.github.io/MyRCodesForDataAnalysis/DecisionTreeKararAgaci.nb.html 314.5.5 Clustering 314.5.6 K Means Clustering https://sbalci.github.io/MyRCodesForDataAnalysis/KMeansClustering.nb.html 314.5.7 Hierarchical Clustering https://sbalci.github.io/MyRCodesForDataAnalysis/HierarchicalClustering.nb.html "],["graphs-plots.html", "Chapter 315 Graphs Plots 315.1 Sankey Diagrams", " Chapter 315 Graphs Plots https://sbalci.github.io/MyRCodesForDataAnalysis/VisualisationGraphsPlots.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/Graphs.nb.html 315.1 Sankey Diagrams https://sbalci.github.io/MyRCodesForDataAnalysis/SankeyDiagrams.nb.html "],["reporting.html", "Chapter 316 Reporting 316.1 Reproducible Research 316.2 Tables 316.3 Autoreport 316.4 shiny 316.5 Creating websites in R", " Chapter 316 Reporting 316.1 Reproducible Research https://sbalci.github.io/MyRCodesForDataAnalysis/ReproducibleResearch.nb.html 316.2 Tables https://sbalci.github.io/MyRCodesForDataAnalysis/Table.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/finalfit.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/formattable.nb.html 316.3 Autoreport https://sbalci.github.io/MyRCodesForDataAnalysis/Autoreport.nb.html 316.4 shiny https://sbalci.github.io/MyRCodesForDataAnalysis/shiny.nb.html 316.5 Creating websites in R https://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html "],["bioinformatics.html", "Chapter 317 Bioinformatics 317.1 bioconductor", " Chapter 317 Bioinformatics 317.1 bioconductor https://sbalci.github.io/MyRCodesForDataAnalysis/bioconductor.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/CancerInSilico.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/CancerPackages.nb.html "],["backup-analysis-and-data.html", "Chapter 318 Backup Analysis and Data 318.1 GitHub", " Chapter 318 Backup Analysis and Data 318.1 GitHub https://sbalci.github.io/MyRCodesForDataAnalysis/GitHub.nb.html SyncingGitHubFork.nb.html "],["text-analysis-sentiment-analysis.html", "Chapter 319 Text Analysis Sentiment Analysis 319.1 Twitter Analysis With R 319.2 News 319.3 web scrapping", " Chapter 319 Text Analysis Sentiment Analysis https://sbalci.github.io/MyRCodesForDataAnalysis/TextMining.nb.html 319.1 Twitter Analysis With R https://sbalci.github.io/MyRCodesForDataAnalysis/Twitter.nb.html 319.2 News https://sbalci.github.io/MyRCodesForDataAnalysis/news.nb.html 319.3 web scrapping https://sbalci.github.io/MyRCodesForDataAnalysis/WebScrapping.nb.html "],["bibliography.html", "Chapter 320 Bibliography 320.1 PubMed 320.2 ORCID 320.3 Google Scholar 320.4 Power Analysis 320.5 Formulas 320.6 Flipping Coin", " Chapter 320 Bibliography Other Bibliographic Studies: https://sbalci.github.io/ResearchOnBibliography/ https://sbalci.github.io/MyRCodesForDataAnalysis/Bibliography.nb.html 320.1 PubMed 320.1.1 RISmed https://sbalci.github.io/MyRCodesForDataAnalysis/RISmed.nb.html 320.2 ORCID 320.2.1 rorcid https://sbalci.github.io/MyRCodesForDataAnalysis/rorcid.nb.html 320.3 Google Scholar https://sbalci.github.io/MyRCodesForDataAnalysis/GoogleScholar.nb.html 320.3.1 Scholar 320.3.2 Coauthor 320.4 Power Analysis https://sbalci.github.io/MyRCodesForDataAnalysis/PowerAnalysis.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/Power_Analysis.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/PowerAnalysis.nb.html 320.5 Formulas https://sbalci.github.io/MyRCodesForDataAnalysis/Formulas.nb.html 320.6 Flipping Coin https://sbalci.github.io/MyRCodesForDataAnalysis/FlippingCoin.nb.html "],["general-resources.html", "Chapter 321 General Resources", " Chapter 321 General Resources https://sbalci.github.io/MyRCodesForDataAnalysis/GeneralResources.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/DataScienceLiveBook.nb.html "],["package-list.html", "Chapter 322 Package List", " Chapter 322 Package List https://sbalci.github.io/MyRCodesForDataAnalysis/RPackagesUsed.nb.html "],["data-list-1.html", "Chapter 323 Data List", " Chapter 323 Data List https://sbalci.github.io/MyRCodesForDataAnalysis/DataList.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/eurostat.nb.html "],["data-tools.html", "Chapter 324 Data Tools", " Chapter 324 Data Tools https://sbalci.github.io/MyRCodesForDataAnalysis/DataTools.nb.html "],["miscellaneous.html", "Chapter 325 Miscellaneous", " Chapter 325 Miscellaneous https://sbalci.github.io/MyRCodesForDataAnalysis/codes.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/OpenCPU.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/papeR.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/Tutorials.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/PythonPandas.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/lessR.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/arsenal.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/rchess.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/EvidenceSynthesisProjects.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/MachineLearning.nb.html https://sbalci.github.io/MyRCodesForDataAnalysis/Correlations.nb.html https://xgboost.readthedocs.io/en/latest/index.html https://sbalci.github.io/MyRCodesForDataAnalysis/R-Tipps.nb.html "],["feedback-4.html", "Chapter 326 Feedback", " Chapter 326 Feedback Yours truly would like to hear your feedback: feedback form See https://sbalci.github.io/ for other analysis. You may also contact with me with the comment field below. {% if page.comments %} Please enable JavaScript to view the comments powered by Disqus. {% endif %} library(knitr) library(rmdformats) ## Global options options(max.print = &quot;75&quot;) opts_chunk$set(echo = TRUE, cache = TRUE, prompt = FALSE, tidy = TRUE, comment = NA, message = FALSE, warning = FALSE) opts_knit$set(width = 75) R generation https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x "],["r-yükleme-5.html", "Chapter 327 R yükleme 327.1 R-project 327.2 RStudio 327.3 X11 327.4 Java OS", " Chapter 327 R yükleme http://www.youtube.com/watch?v=XcBLEVknqvY 327.1 R-project https://cran.r-project.org/ 327.2 RStudio https://www.rstudio.com/ https://www.rstudio.com/products/rstudio/download/ https://moderndive.com/2-getting-started.html 327.2.1 RStudio eklentileri Discover and install useful RStudio addins https://cran.r-project.org/web/packages/addinslist/README.html https://rstudio.github.io/rstudioaddins/ 327.3 X11 https://www.xquartz.org/ 327.4 Java OS https://support.apple.com/kb/dl1572 "],["r-zor-şeyler-için-kolay-kolay-şeyler-için-zor-5.html", "Chapter 328 R zor şeyler için kolay, kolay şeyler için zor", " Chapter 328 R zor şeyler için kolay, kolay şeyler için zor R makes easy things hard, and hard things easy Aynı şeyi çok fazla şekilde yapmak mümkün R Syntax Comparison::CHEAT SHEET https://www.amelia.mn/Syntax-cheatsheet.pdf "],["r-paketleri-5.html", "Chapter 329 R paketleri 329.1 Neden paketler var 329.2 Paketleri nereden bulabiliriz 329.3 Kendi paket evrenini oluştur 329.4 R için yardım bulma 329.5 R paket yükleme", " Chapter 329 R paketleri 329.1 Neden paketler var I love the #rstats community.Someone is like, “oh hey peeps, I saw a big need for this mundane but difficult task that I infrequently do, so I created a package that will literally scrape the last bits of peanut butter out of the jar for you. It's called pbplyr.”What a tribe. — Frank Elavsky  ʳ ((???)) July 3, 2018 https://blog.mitchelloharawild.com/blog/user-2018-feature-wall/ 329.2 Paketleri nereden bulabiliriz Available CRAN Packages By Name https://cran.r-project.org/web/packages/available_packages_by_name.html Bioconductor https://www.bioconductor.org RecommendR http://recommendr.info/ pkgsearch CRAN package search https://github.com/metacran/pkgsearch Awesome R https://awesome-r.com/ 329.3 Kendi paket evrenini oluştur pkgverse: Build a Meta-Package Universe https://cran.r-project.org/web/packages/pkgverse/index.html 329.4 R için yardım bulma # ?mean # ??efetch # help(merge) # example(merge) Vignette RDocumentation https://www.rdocumentation.org R Package Documentation https://rdrr.io/ GitHub Stackoverflow https://stackoverflow.com/ Google uygun anahtar kelime How I use #rstats h/t (???) pic.twitter.com/erRnTG0Ujr — Emily Bovee ((???)) August 10, 2018 Awesome Cheatsheet https://github.com/detailyang/awesome-cheatsheet http://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf https://www.rstudio.com/resources/cheatsheets/ Awesome R https://github.com/qinwf/awesome-R#readme https://awesome-r.com/ Twitter https://twitter.com/hashtag/rstats?src=hash Reproducible Examples Got a question to ask on (???) or post on (???)? No time to read the long post on how to use reprex? Here is a 20-second gif for you to format your R codes nicely and for others to reproduce your problem. (An example from a talk given by (???)) #rstat pic.twitter.com/gpuGXpFIsX — ZhiYang ((???)) October 18, 2018 329.5 R paket yükleme install.packages(&quot;tidyverse&quot;, dependencies = TRUE) install.packages(&quot;jmv&quot;, dependencies = TRUE) install.packages(&quot;questionr&quot;, dependencies = TRUE) install.packages(&quot;Rcmdr&quot;, dependencies = TRUE) install.packages(&quot;summarytools&quot;) # install.packages(&#39;tidyverse&#39;, dependencies = TRUE) install.packages(&#39;jmv&#39;, # dependencies = TRUE) install.packages(&#39;questionr&#39;, dependencies = TRUE) # install.packages(&#39;Rcmdr&#39;, dependencies = TRUE) install.packages(&#39;summarytools&#39;) # require(tidyverse) require(jmv) require(questionr) library(summarytools) # library(gganimate) "],["r-studio-ile-proje-oluşturma-4.html", "Chapter 330 R studio ile proje oluşturma", " Chapter 330 R studio ile proje oluşturma https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects "],["rstudio-ile-veri-yükleme-5.html", "Chapter 331 RStudio ile veri yükleme 331.1 Excel 331.2 SPSS 331.3 csv", " Chapter 331 RStudio ile veri yükleme https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-RStudio 331.1 Excel 331.2 SPSS 331.3 csv "],["veriyi-görüntüleme-6.html", "Chapter 332 Veriyi görüntüleme", " Chapter 332 Veriyi görüntüleme Spreadsheet users using #rstats: where's the data?#rstats users using spreadsheets: where's the code? — Leonard Kiefer ((???)) July 7, 2018 # library(nycflights13) summary(flights) View(data) data head tail glimpse str skimr::skim() "],["veriyi-değiştirme-5.html", "Chapter 333 Veriyi değiştirme 333.1 Veriyi kod ile değiştirelim 333.2 Veriyi eklentilerle değiştirme 333.3 RStudio aracılığıyla recode", " Chapter 333 Veriyi değiştirme 333.1 Veriyi kod ile değiştirelim 333.2 Veriyi eklentilerle değiştirme 333.3 RStudio aracılığıyla recode questionr paketi kullanılacak https://juba.github.io/questionr/articles/recoding_addins.html "],["basit-tanımlayıcı-istatistikler-5.html", "Chapter 334 Basit tanımlayıcı istatistikler 334.1 summarytools 334.2 skimr 334.3 DataExplorer 334.4 Grafikler", " Chapter 334 Basit tanımlayıcı istatistikler summary() mean median min max sd table() library(readr) irisdata &lt;- read_csv(&quot;data/iris.csv&quot;) jmv::descriptives(data = irisdata, vars = &quot;Sepal.Length&quot;, splitBy = &quot;Species&quot;, freq = TRUE, hist = TRUE, dens = TRUE, bar = TRUE, box = TRUE, violin = TRUE, dot = TRUE, mode = TRUE, sum = TRUE, sd = TRUE, variance = TRUE, range = TRUE, se = TRUE, skew = TRUE, kurt = TRUE, quart = TRUE, pcEqGr = TRUE) DESCRIPTIVES Descriptives ───────────────────────────────────────────────────── Species Sepal.Length ───────────────────────────────────────────────────── N setosa 50 versicolor 50 virginica 50 Missing setosa 0 versicolor 0 virginica 0 Mean setosa 5.006000 versicolor 5.936000 virginica 6.588000 Std. error mean setosa 0.04984957 versicolor 0.07299762 virginica 0.08992695 Median setosa 5.000000 versicolor 5.900000 virginica 6.500000 Mode setosa 5.000000 versicolor 5.500000 virginica 6.300000 Sum setosa 250.3000 versicolor 296.8000 virginica 329.4000 Standard deviation setosa 0.3524897 versicolor 0.5161711 virginica 0.6358796 Variance setosa 0.1242490 versicolor 0.2664327 virginica 0.4043429 Range setosa 1.500000 versicolor 2.100000 virginica 3.000000 Minimum setosa 4.300000 versicolor 4.900000 virginica 4.900000 Maximum setosa 5.800000 versicolor 7.000000 virginica 7.900000 Skewness setosa 0.1200870 versicolor 0.1053776 virginica 0.1180151 Std. error skewness setosa 0.3366007 versicolor 0.3366007 virginica 0.3366007 Kurtosis setosa -0.2526888 versicolor -0.5330095 virginica 0.03290442 Std. error kurtosis setosa 0.6619084 versicolor 0.6619084 virginica 0.6619084 25th percentile setosa 4.800000 versicolor 5.600000 virginica 6.225000 50th percentile setosa 5.000000 versicolor 5.900000 virginica 6.500000 75th percentile setosa 5.200000 versicolor 6.300000 virginica 6.900000 ───────────────────────────────────────────────────── 334.1 summarytools https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html 334.2 skimr library(skimr) skim(df) 334.3 DataExplorer library(DataExplorer) DataExplorer::create_report(df) 334.4 Grafikler descr(tobacco, style = &#39;rmarkdown&#39;) print(descr(tobacco), method = &#39;render&#39;, table.classes = &#39;st-small&#39;) dfSummary(tobacco, style = &#39;grid&#39;, plain.ascii = FALSE) print(dfSummary(tobacco, graph.magnif = 0.75), method = &#39;render&#39;) Here, building up a #ggplot2 as slowly as possible, #rstats. Incremental adjustments. #rstatsteachingideas pic.twitter.com/nUulQl8bPh — Gina Reynolds ((???)) August 13, 2018 Dreaming of a fancy #Rstats #ggplot #dataviz but still scared of typing #code? (???) esquisse package has you covered https://t.co/1vIDXcVAAF pic.twitter.com/RlTkptnrNv — Radoslaw Panczak ((???)) October 2, 2018 "],["rcmdr-5.html", "Chapter 335 Rcmdr", " Chapter 335 Rcmdr library(Rcmdr) Rcmdr::Commander() A Comparative Review of the R Commander GUI for R http://r4stats.com/articles/software-reviews/r-commander/ "],["jamovi-7.html", "Chapter 336 jamovi", " Chapter 336 jamovi https://www.jamovi.org/ https://blog.jamovi.org/2018/07/30/rj.html "],["sonraki-konular-6.html", "Chapter 337 Sonraki Konular", " Chapter 337 Sonraki Konular RStudio ile GitHub Hipotez testleri R Markdown ve R Notebook ile tekrarlanabilir rapor "],["diğer-kodlar-5.html", "Chapter 338 Diğer kodlar", " Chapter 338 Diğer kodlar Diğer kodlar için bakınız: https://sbalci.github.io/ "],["geri-bildirim-7.html", "Chapter 339 Geri Bildirim 339.1 HTML Rendering 339.2 Rmarkdown Style 339.3 HTML Rendering", " Chapter 339 Geri Bildirim Geri bildirim için tıklayınız: Geri bildirim formu Please enable JavaScript to view the comments powered by Disqus. library(summarytools) st_css() &lt;style type=&quot;text/css&quot;&gt; img { background-color: transparent; border: 0; } .st-table td, .st-table th { padding: 8px; } .st-table &gt; thead &gt; tr { background-color: #eeeeee; } .st-cross-table td { text-align: center; } .st-descr-table td { text-align: right; } table.st-table th { text-align: center; } table.st-table &gt; thead &gt; tr { background-color: #eeeeee; } table.st-table td span { display: block; } table.st-table &gt; tfoot &gt; tr &gt; td { border:none; } .st-container { width: 100%; padding-right: 15px; padding-left: 15px; margin-right: auto; margin-left: auto; margin-top: 15px; } .st-multiline { white-space: pre; } .st-table { width: auto; table-layout: auto; margin-top: 20px; margin-bottom: 20px; max-width: 100%; background-color: transparent; border-collapse: collapse; } .st-table &gt; thead &gt; tr &gt; th, .st-table &gt; tbody &gt; tr &gt; th, .st-table &gt; tfoot &gt; tr &gt; th, .st-table &gt; thead &gt; tr &gt; td, .st-table &gt; tbody &gt; tr &gt; td, .st-table &gt; tfoot &gt; tr &gt; td { vertical-align: middle; } .st-table-bordered { border: 1px solid #bbbbbb; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; tbody &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table-bordered &gt; tbody &gt; tr &gt; td { border: 1px solid #cccccc; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table thead &gt; tr &gt; th { border-bottom: none; } .st-freq-table &gt; thead &gt; tr &gt; th, .st-freq-table &gt; tbody &gt; tr &gt; th, .st-freq-table &gt; tfoot &gt; tr &gt; th, .st-freq-table &gt; thead &gt; tr &gt; td, .st-freq-table &gt; tbody &gt; tr &gt; td, .st-freq-table &gt; tfoot &gt; tr &gt; td, .st-freq-table-nomiss &gt; thead &gt; tr &gt; th, .st-freq-table-nomiss &gt; tbody &gt; tr &gt; th, .st-freq-table-nomiss &gt; tfoot &gt; tr &gt; th, .st-freq-table-nomiss &gt; thead &gt; tr &gt; td, .st-freq-table-nomiss &gt; tbody &gt; tr &gt; td, .st-freq-table-nomiss &gt; tfoot &gt; tr &gt; td, .st-cross-table &gt; thead &gt; tr &gt; th, .st-cross-table &gt; tbody &gt; tr &gt; th, .st-cross-table &gt; tfoot &gt; tr &gt; th, .st-cross-table &gt; thead &gt; tr &gt; td, .st-cross-table &gt; tbody &gt; tr &gt; td, .st-cross-table &gt; tfoot &gt; tr &gt; td { padding-left: 20px; padding-right: 20px; } .st-table-bordered &gt; thead &gt; tr &gt; th, .st-table-bordered &gt; tbody &gt; tr &gt; th, .st-table-bordered &gt; thead &gt; tr &gt; td, .st-table-bordered &gt; tbody &gt; tr &gt; td { border: 1px solid #cccccc; } .st-table-striped &gt; tbody &gt; tr:nth-of-type(odd) { background-color: #ffffff; } .st-table-striped &gt; tbody &gt; tr:nth-of-type(even) { background-color: #f9f9f9; } .st-descr-table &gt; thead &gt; tr &gt; th, .st-descr-table &gt; tbody &gt; tr &gt; th, .st-descr-table &gt; thead &gt; tr &gt; td, .st-descr-table &gt; tbody &gt; tr &gt; td { padding-left: 24px; padding-right: 24px; word-wrap: break-word; } .st-freq-table, .st-freq-table-nomiss, .st-cross-table { border: medium none; } .st-freq-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(1), .st-cross-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(1), .st-cross-table &gt; thead &gt; tr:nth-child(1) &gt; th:nth-child(3) { border: none; background-color: #ffffff; text-align: center; } .st-protect-top-border { border-top: 1px solid #cccccc !important; } .st-ws-char { display: inline; color: #999999; letter-spacing: 0.2em; } /* Optionnal classes */ .st-small { font-size: 13px; } .st-small td, .st-small th { padding: 8px; } .st-small &gt; thead &gt; tr &gt; th, .st-small &gt; tbody &gt; tr &gt; th, .st-small &gt; thead &gt; tr &gt; td, .st-small &gt; tbody &gt; tr &gt; td { padding-left: 12px; padding-right: 12px; } &lt;/style&gt; st_options(bootstrap.css = FALSE, # Already part of the theme so no need for it plain.ascii = FALSE, # One of the essential settings style = &quot;rmarkdown&quot;, # Idem. dfSummary.silent = TRUE, # Suppresses messages about temporary files footnote = NA, # Keeping the results minimalistic subtitle.emphasis = FALSE) # For the vignette theme, this gives # much better results. Your mileage may vary. freq(tobacco$gender, style = &quot;rmarkdown&quot;) ### Frequencies **tobacco$gender** **Type:** Factor | &amp;nbsp; | Freq | % Valid | % Valid Cum. | % Total | % Total Cum. | |-----------:|-----:|--------:|-------------:|--------:|-------------:| | **F** | 489 | 50.00 | 50.00 | 48.90 | 48.90 | | **M** | 489 | 50.00 | 100.00 | 48.90 | 97.80 | | **\\&lt;NA\\&gt;** | 22 | | | 2.20 | 100.00 | | **Total** | 1000 | 100.00 | 100.00 | 100.00 | 100.00 | 339.1 HTML Rendering If you find the table too large, you can use table.classes = 'st-small' - an example is provided further below. Back to top 339.2 Rmarkdown Style Tables with heading spanning over 2 rows are not fully supported in markdown (yet), but the result is getting close to acceptable. This, however, is not true for all themes. That’s why the rendering method is preferred. 339.3 HTML Rendering For best results, use this method. Back to top "],["descr2.html", "Chapter 340 descr() 2 340.1 Rmarkdown Style 340.2 HTML Rendering", " Chapter 340 descr() 2 descr() is also best used with style = 'rmarkdown', and HTML rendering is also supported. 340.1 Rmarkdown Style 340.2 HTML Rendering We’ll use table.classes = ‘st-small’ to show how it affects the table’s size (compare to the freq() table rendered earlier). Back to top "],["dfsummary1.html", "Chapter 341 dfSummary() 1 341.1 Grid Style", " Chapter 341 dfSummary() 1 341.1 Grid Style This style gives good results, and since v0.9, the graphs are shown as true images. Don’t forget to specify plain.ascii = FALSE (or set it as a global option with st_options(plain.ascii = FALSE)), or you won’t get good results. dfSummary(tobacco, style = &quot;grid&quot;, graph.magnif = 0.75, tmp.img.dir = &quot;/tmp&quot;) Logistic Regression in R Tutorial https://www.datacamp.com/community/tutorials/logistic-regression-R https://www.youtube.com/watch?v=MmTPhGQWPUo https://reprex.tidyverse.org/index.html (y &lt;- 1:4) #&gt; [1] 1 2 3 4 mean(y) #&gt; [1] 2.5 Created on 2018-09-21 by the reprex package (v0.2.1) karthik/binder-test Example repo for testing holepunch https://github.com/karthik/binder-test Hole punch https://karthik.github.io/holepunch/ How to set up a My Binder for your R project rstudio2019/binder-notes.md https://github.com/karthik/rstudio2019/blob/master/binder-notes.md reproducibility guidelines https://kbroman.org/blog/2019/04/01/reproducibility-guidelines/ Disease risk modelling and visualization using R http://manio.org/2015/06/22/my-approach-to-reproducible-research.html initial steps toward reproducible research https://kbroman.org/steps2rr/ Comments on reproducibility https://kbroman.org/knitr_knutshell/pages/reproducible.html Reproducible science in R https://grunwaldlab.github.io/Reproducible-science-in-R/index.html The Practice of Reproducible Research Case Studies and Lessons from the Data-Intensive Sciences https://www.practicereproducibleresearch.org/ papaja papaja (Preparing APA Journal Articles) is an R package that provides document formats and helper functions to produce complete APA manscripts from RMarkdown-files (PDF and Word documents). https://crsh.github.io/papaja/ Stencila An open source office suite for reproducible research http://stenci.la/ redoc - reversible R Markdown/MS Word documents. https://noamross.github.io/redoc/ --- output: redoc::rdocx_reversible: keep_md: TRUE highlight_outputs: TRUE --- redoc::undoc(&quot;reversible2.docx&quot;) redoc::undoc(file.choose()) redoc::redoc_extract_rmd(&quot;reversible.docx&quot;) "],["docker-1.html", "Chapter 342 docker", " Chapter 342 docker An Introduction to Docker for R Users https://colinfay.me/docker-r-reproducibility/ "],["naming-files.html", "Chapter 343 Naming Files", " Chapter 343 Naming Files How to name files https://speakerdeck.com/jennybc/how-to-name-files "],["example-articles.html", "Chapter 344 Example Articles 344.1 Types of websites 344.2 R Markdown website basics 344.3 GitHub 344.4 Personal websites 344.5 Package websites 344.6 Project websites 344.7 Blogs 344.8 Additional resources 344.9 Demo 344.10 Types of websites 344.11 R Markdown website basics 344.12 GitHub 344.13 Personal websites 344.14 Package websites 344.15 Project websites 344.16 Blogs 344.17 Additional resources 344.18 Demo", " Chapter 344 Example Articles Increasing the Transparency of Research Papers withExplorable Multiverse Analyses https://hal.inria.fr/hal-01976951/document Replication Study: Transcriptional amplification in tumor cells with elevated c-Myc https://repro.elifesciences.org/example.html Introducing eLife’s first computationally reproducible article https://elifesciences.org/labs/ad58f08d/introducing-elife-s-first-computationally-reproducible-article Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis https://explorablemultiverse.github.io/examples/frequentist/ R Online Try R Run a piece of code against a specific version of R, from 3.6.0 to 3.1.0. https://srv.colinfay.me:1001/#about https://github.com/ColinFay/ronline Sys.setenv( DSN = &quot;database_name&quot;, UID = &quot;User ID&quot;, PASS = &quot;Password&quot; ) db &lt;- DBI::dbConnect( drv = odbc::odbc(), dsn = Sys.getenv(&quot;DSN&quot;), uid = Sys.getenv(&quot;UID&quot;), pwd = Sys.getenv(&quot;PASS&quot;) ) Progesterone Receptor Status Predicts Response to Progestin Therapy in Endometriosis https://www.ncbi.nlm.nih.gov/pubmed/30357380 irr: Various Coefficients of Interrater Reliability and Agreement https://cran.r-project.org/web/packages/irr/index.html library(RISmed) library(ggplot2) query &lt;- “(exome OR whole OR deep OR high-throughput OR (next AND generation) OR (massively AND parallel)) AND sequencing” ngs_search &lt;- EUtilsSummary(query, type=“esearch”,db = “pubmed”,mindate=1980, maxdate=2013, retmax=30000) QueryCount(ngs_search) ngs_records &lt;- EUtilsGet(ngs_search) years &lt;- Year(ngs_records) ngs_pubs_count &lt;- as.data.frame(table(years)) total &lt;- NULL for (i in 1980:2013){ peryear &lt;- EUtilsSummary(\"“, type=”esearch“, db=”pubmed“, mindate=i, maxdate=i) total[i] &lt;- QueryCount(peryear) } year &lt;- 1980:2013 total_pubs_count&lt;- as.data.frame(cbind(year,total[year])) names(total_pubs_count) &lt;- c(”year“,”Total_publications“) names(ngs_pubs_count) &lt;- c(”year“,”NGS_publications“) pubs_year &lt;- merge(ngs_pubs_count,total_pubs_count,by=”year\") pubs_year\\(NGS_publications_normalized &lt;- pubs_year\\)NGS_publications *100000 / pubs_year$Total_publications write.table(pubs_year,“NGS_publications_per_year.txt”,quote=F,sep=\",row.names=F) journal &lt;- MedlineTA(ngs_records) ngs_journal_count &lt;- as.data.frame(table(journal)) ngs_journal_count_top25 &lt;- ngs_journal_count[order(-ngs_journal_count[,2]),][1:25,] journal_names &lt;- paste(ngs_journal_count_top25$journal,“[jo]”,sep=\"\") total_journal &lt;- NULL for (i in journal_names){ perjournal &lt;- EUtilsSummary(i, type=‘esearch’, db=‘pubmed’,mindate=1980, maxdate=2013) total_journal[i] &lt;- QueryCount(perjournal) } journal_ngs_total &lt;- cbind(ngs_journal_count_top25,total_journal) names(journal_ngs_total) &lt;- c(“journal”,“NGS_publications”,“Total_publications”) journal_ngs_total\\(NGS_publications_normalized &lt;- journal_ngs_total\\)NGS_publications / journal_ngs_total$Total_publications write.table(journal_ngs_total,“NGS_publications_per_journal.txt”,quote=F,sep=\",row.names=F) pubs_per_year &lt;- read.table(“NGS_publications_per_year.txt”,header = T,sep=“) pubs_per_journal &lt;- read.table(”NGS_publications_per_journal.txt“,header = T,sep=”) ggplot(pubs_per_year,aes(year, NGS_publications_normalized)) + geom_line (colour=“blue”,size=2) + xlab(“Year”) + ylab(“NGS/100000 articles”)+ ggtitle(“NGS PubMed articles”) ggplot(pubs_per_journal,aes(journal, NGS_publications,fill=journal)) + geom_bar(stat=“identity”)+ coord_flip()+ theme(legend.position=“none”) ggplot(pubs_per_journal ,aes(journal, NGS_publications_normalized,fill=journal)) + geom_bar(stat=“identity”)+ coord_flip()+ theme(legend.position=“none”) http://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html This tutorial provides an introduction to creating websites using R, R Markdown and GitHub pages. This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center Department of Epidemiology and Biostatistics R User Group meeting on January 23, 2018. The current version was updated and presented at the R Ladies NYC Meetup on February 15, 2018. 344.1 Types of websites The main types of websites you may want to create include: Personal websites Package websites Project websites Blogs 344.2 R Markdown website basics The minimum requirements for an R Markdown website are: index.Rmd: contains the content for the website homepage _site.yml: contains metadata for the website A basic example of a _site.yml file for a website with two pages: name:&quot;my-website&quot; navbar:title:&quot;My Website&quot; left:-text:&quot;Home&quot; href:index.html -text:&quot;About&quot; href:about.html And a basic index.Rmd to create the Home page: --- title: &quot;My Website&quot; --- Hello, Website! Welcome to the world. You can find an overview of R Markdown website basics here. 344.3 GitHub This tutorial will focus on hosting websites through GitHub pages. Hosting websites on GitHub pages is free. If you don’t have a GitHub account already, sign up for one at https://github.com/join?source=header-home with username YOUR_GH_NAME. I’ll be referring to this username, YOUR_GH_NAME, as “your GitHub username” throughout this tutorial. There are other free sites for website hosting, and another popular choice is Netlify. 344.4 Personal websites An example from the homepage of my personal website: There are two main steps for creating a personal website that will be hosted on GitHub: GitHub setup Local setup 344.4.1 GitHub setup Create a GitHub repository (“repo”) named YOUR_GH_NAME.github.io, where YOUR_GH_NAME is your GitHub username. Initialize it with a README For the GitHub inexperienced: this can ease the process of cloning the repo by initializing the remote repo with a master branch 344.4.2 Local setup Clone this remote repository to a local directory with the same name, YOUR_GH_NAME.github.io Add an R Project to this directory Create a _site.yml and index.Rmd file in your new directory 344.4.3 Why do I need an R Project? The R Project is useful because RStudio will recognize your project as a website, and provide appropriate build tools. Note: After creating the R Project and initial files, you may need to close the project and reopen it before R will recognize it as a website and show the appropriate build tools. 344.4.4 Create content Edit the _site.yml file to change the metadata, layout, and theme of your website. Preview Jekyll themes here and play around with different options. Themes are easy to change even after you have added content. For example, the _site.yml for my personal website looks like this: name: &quot;Emily C. Zabor&quot; output_dir: &quot;.&quot; navbar: title: &quot;Emily C. Zabor&quot; left: - text: &quot;Writing&quot; href: research.html - text: &quot;Speaking&quot; href: talks.html - text: &quot;Programming&quot; href: software.html - text: &quot;Teaching&quot; href: teaching.html right: - icon: fa-envelope fa-lg href: contact.html - icon: fa-github fa-lg href: http://github.com/zabore - icon: fa-twitter fa-lg href: https://twitter.com/zabormetrics - icon: fa-linkedin fa-lg href: https://www.linkedin.com/in/emily-zabor-59b902b7/ output: html_document: theme: paper css: &#39;styles.css&#39; Edit and create .Rmd files that contain your website content, which will produce the html pages of your website when you knit them. For example, the index.Rmd file for my personal website homepage looks like this: --- --- &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot; type=&quot;text/css&quot;&gt; &lt;img src=&quot;images/emily_2.jpg&quot; style=&quot;width:25%; border:10px solid; margin-right: 20px&quot; align=&quot;left&quot;&gt; I like to analyze data to answer research questions and test hypotheses. Currently I investigate questions related to breast cancer through my work as a Research Biostatistician at [Memorial Sloan Kettering Cancer Center](https://www.mskcc.org/departments/epidemiology-biostatistics) in the department of Epidemiology &amp; Biostatistics. I graduated from the [University of Minnesota](http://www.sph.umn.edu/academics/divisions/biostatistics/) with a MS in biostatistics in 2010. In 2012 I began working toward my DrPH in biostatistics as a part-time student at [Columbia University](https://www.mailman.columbia.edu/become-student/departments/biostatistics), where I am investigating statistical methods for the study of etiologic heterogeneity in epidemiologic studies under the advisement of [Dr. Shuang Wang](https://www.mailman.columbia.edu/people/our-faculty/sw2206) at Columbia University and [Dr. Colin Begg](https://www.mskcc.org/profile/colin-begg) at Memorial Sloan Kettering Cancer Center. I expect to graduate by the end of 2018. I am a well-known R enthusiast, including serving on the board and being an active member of [R Ladies NYC](http://www.rladiesnyc.org/). My full CV is available [here](files/Zabor_CV_2017_Q4.pdf). Once you have your content written and the layout setup, on the Build tab in RStudio, select “Build Website”: Now your local directory contains all of the files needed for your website: 344.4.5 Deploy website Basic approach: Select “Upload files” from the main page of your GitHub repo: And simply drag or select the files from the local repository: Advanced approach (recommended): use Git from the shell, from a Git client, or from within RStudio (another great reason to use an R Project!) But this is not a Git/GitHub tutorial. If you want to learn more about Git/GitHub, which I encourage you to do, here’s a great resource to get you started: http://happygitwithr.com/ 344.4.6 Custom domains The default is for your site to be hosted at http://YOUR_GH_NAME.github.io, but you can add a custom domain name as well. There are two steps: In your GitHub repository YOUR_GH_NAME.github.io, go to Settings &gt; GitHub pages. Type your domain name in the box under Custom domain and hit Save. Add a CNAME file to your GitHub repsitory YOUR_GH_NAME.github.io. It will appear like this in your repository: And inside the file you will simply have your domain name: 344.5 Package websites An example from the website for my package ezfun: Use Hadley Wickham’s great package pkgdown to easily build a website from your package that is hosted on GitHub. Details of pkgdown can be found on the pkgdown website, which was also created using pkgdown. This assumes you already have an R package with a local directory and a GitHub repository. From within your package directory run: devtools::install_github(&quot;hadley/pkgdown&quot;) pkgdown::build_site() This will add a folder called docs to the local directory for your package Upload/push these changes to the GitHub repository for your package In the GitHub repository for your package go to Settings &gt; GitHub pages. Select “master branch/docs folder” as the source and hit Save The page will be added as to your personal website as YOUR_GH_NAME.github.io/repo_name The Home page of the site will be pulled from the README file on your package repository The Reference page of the site lists the included functions with their description Each function can be clicked through to see the help page, if any Would also build pages for any available vignettes And you’re done, it’s that easy. 344.6 Project websites You can create a website for a non-package repository as well. For example, I have a page on my website linking to the repository in which this tutorial is stored. 344.6.1 Local setup From within the local directory of the project of interest: Create a _site.yml and index.Rmd file in your new directory Edit these files to create content and manage layout, as before for personal websites 344.6.2 GitHub setup Upload/push these new files to the GitHub repository for your project Enable GitHub pages for the repository by going to Settings &gt; GitHub Pages, where you’ll select the “master branch” folder and hit Save 344.7 Blogs R Markdown websites are simple to create and deploy, but can become cumbersome if you make frequent updates or additions to the website, as in the case of a blog. Luckily, the R package blogdown exists just for this purpose. blogdown is an R package that allows you to create static websites, which means that the deployed version of the website only consists of JavaScript, HTML, CSS, and images. Luckily the blogdown package makes it so that you don’t have to know any of those things to create a beautiful website for your blog, powered by Hugo. For a complete resource on using the blogdown website, checkout this short blogdown book. I don’t have a personal blog, so let’s look at the website I built to feature the events and blog of the R-Ladies NYC organization as an example. 344.7.1 Setup The first three steps are similar to those from creating a basic R Markdown website: Create a GitHub repository named YOUR_GH_NAME.github.io, where YOUR_GH_NAME is your GitHub username, initialized with a README file Clone the GitHub repo to a local directory with the same name Add an R Project to the local directoroy Next we get started with blogdown. Install blogdown and Hugo install.packages(&quot;blogdown&quot;) blogdown::install_hugo() Choose a theme and find the link to the theme’s GitHub repository. In this case themes aren’t quite as easy to change as with basic R Markdown websites, so choose carefully. Within your project session, generate a new site. The option theme_example = TRUE will obtain the files for an example site that you can then customize for your needs. Below “user/repo” refers to the GitHub username and GitHub repository for your selected theme. blogdown::new_site(theme = &quot;user/repo&quot;, theme_example = TRUE) This will generate all of the file structure for your new blog. After this is complete, you should quit and then reopen the project. Upon reopening, RStudio will recognize the project as a website. 344.7.2 Customizing the appearance Make changes to the config.toml file (equivalent to the _site.yml from basic R Markdown websites) to change the layout and appearance of your website. The available features of the config.toml file will differ depending on your theme, and most theme examples come with a well annotated config.toml that you can use as a template. Once you have customized your website features, click on the RStudio addin “Serve Site” to preview the site locally. 344.7.3 Writing a new blog post There are several ways to create a new post for your site, but the easiest is using the RStudio addin “New Post”: This opens a pop-up where you can enter the meta-data for a new post: In addition to setting the Title, Author and Date of the post, you can additionally create categories, which will organize your posts in folders, and can add tags to posts, which can make them searchable within your site’s content. Be aware that the functioning of these features will vary by theme. Dates can be in the future to allow future release of a post. Notice at the bottom that you can select whether to use a regular markdown (.md) or R markdown (.Rmd) file. .Rmd files will have to be rendered before generating html pages so it is best practice to limit their use to cases where R code is included. A file name and slug will automatically be generated based on the other metadata. The slug is a URL friendly title of your post. 344.7.4 Hosting A blogdown site is a bit more cumbersome both to build and to host on GitHub as compared to a regular R Markdown website, and as compared to what I described above. Problem 1: Because it is a static site, upon building, the files needed to generate the site online are automatically created in a separate subdirectory called public within your local directory. However this will cause problems with GitHub hosting since the files to host need to be in the local YOUR_GH_NAME.github.io directory My solution: Maintain separate directories for the source files (I named this directory “source”) and for the static files (the directory YOUR_GH_NAME.github.io) that will be generated on build. The “source” folder is where your R project and config.toml files will live. In your config.toml use the option publishDir = to customize blogdown to publish to the YOUR_GH_NAME.github.io folder, rather than to the default local location Problem 2: GitHub defaults to using Jekyll with website content, and this needs to be disabled since blogdown sites are built with Hugo To get around this, you need to include an empty file named .nojekyll in your GitHub repo YOUR_GH_NAME.github.io, prior to publishing. 344.8 Additional resources A compiled list of the additional resources/links presented throughout this tutorial: http://rmarkdown.rstudio.com/rmarkdown_websites.html: an overview of R Markdown website basics http://jekyllthemes.org/: Jekyll themes for use with your R Markdown website http://happygitwithr.com/: an introduction to Git/GitHub http://pkgdown.r-lib.org/: Hadley Wickham’s pkgdown website https://bookdown.org/yihui/blogdown/: Yihui Xie’s blogdown book https://themes.gohugo.io/: Hugo themes for use with your blogdown website 344.9 Demo This tutorial provides an introduction to creating websites using R, R Markdown and GitHub pages. This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center Department of Epidemiology and Biostatistics R User Group meeting on January 23, 2018. The current version was updated and presented at the R Ladies NYC Meetup on February 15, 2018. 344.10 Types of websites The main types of websites you may want to create include: Personal websites Package websites Project websites Blogs 344.11 R Markdown website basics The minimum requirements for an R Markdown website are: index.Rmd: contains the content for the website homepage _site.yml: contains metadata for the website A basic example of a _site.yml file for a website with two pages: name:&quot;my-website&quot; navbar:title:&quot;My Website&quot; left:-text:&quot;Home&quot; href:index.html -text:&quot;About&quot; href:about.html And a basic index.Rmd to create the Home page: --- title: &quot;My Website&quot; --- Hello, Website! Welcome to the world. You can find an overview of R Markdown website basics here. 344.12 GitHub This tutorial will focus on hosting websites through GitHub pages. Hosting websites on GitHub pages is free. If you don’t have a GitHub account already, sign up for one at https://github.com/join?source=header-home with username YOUR_GH_NAME. I’ll be referring to this username, YOUR_GH_NAME, as “your GitHub username” throughout this tutorial. There are other free sites for website hosting, and another popular choice is Netlify. 344.13 Personal websites An example from the homepage of my personal website: There are two main steps for creating a personal website that will be hosted on GitHub: GitHub setup Local setup 344.13.1 GitHub setup Create a GitHub repository (“repo”) named YOUR_GH_NAME.github.io, where YOUR_GH_NAME is your GitHub username. Initialize it with a README For the GitHub inexperienced: this can ease the process of cloning the repo by initializing the remote repo with a master branch 344.13.2 Local setup Clone this remote repository to a local directory with the same name, YOUR_GH_NAME.github.io Add an R Project to this directory Create a _site.yml and index.Rmd file in your new directory 344.13.3 Why do I need an R Project? The R Project is useful because RStudio will recognize your project as a website, and provide appropriate build tools. Note: After creating the R Project and initial files, you may need to close the project and reopen it before R will recognize it as a website and show the appropriate build tools. 344.13.4 Create content Edit the _site.yml file to change the metadata, layout, and theme of your website. Preview Jekyll themes here and play around with different options. Themes are easy to change even after you have added content. For example, the _site.yml for my personal website looks like this: name: &quot;Emily C. Zabor&quot; output_dir: &quot;.&quot; navbar: title: &quot;Emily C. Zabor&quot; left: - text: &quot;Writing&quot; href: research.html - text: &quot;Speaking&quot; href: talks.html - text: &quot;Programming&quot; href: software.html - text: &quot;Teaching&quot; href: teaching.html right: - icon: fa-envelope fa-lg href: contact.html - icon: fa-github fa-lg href: http://github.com/zabore - icon: fa-twitter fa-lg href: https://twitter.com/zabormetrics - icon: fa-linkedin fa-lg href: https://www.linkedin.com/in/emily-zabor-59b902b7/ output: html_document: theme: paper css: &#39;styles.css&#39; Edit and create .Rmd files that contain your website content, which will produce the html pages of your website when you knit them. For example, the index.Rmd file for my personal website homepage looks like this: --- --- &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot; type=&quot;text/css&quot;&gt; &lt;img src=&quot;images/emily_2.jpg&quot; style=&quot;width:25%; border:10px solid; margin-right: 20px&quot; align=&quot;left&quot;&gt; I like to analyze data to answer research questions and test hypotheses. Currently I investigate questions related to breast cancer through my work as a Research Biostatistician at [Memorial Sloan Kettering Cancer Center](https://www.mskcc.org/departments/epidemiology-biostatistics) in the department of Epidemiology &amp; Biostatistics. I graduated from the [University of Minnesota](http://www.sph.umn.edu/academics/divisions/biostatistics/) with a MS in biostatistics in 2010. In 2012 I began working toward my DrPH in biostatistics as a part-time student at [Columbia University](https://www.mailman.columbia.edu/become-student/departments/biostatistics), where I am investigating statistical methods for the study of etiologic heterogeneity in epidemiologic studies under the advisement of [Dr. Shuang Wang](https://www.mailman.columbia.edu/people/our-faculty/sw2206) at Columbia University and [Dr. Colin Begg](https://www.mskcc.org/profile/colin-begg) at Memorial Sloan Kettering Cancer Center. I expect to graduate by the end of 2018. I am a well-known R enthusiast, including serving on the board and being an active member of [R Ladies NYC](http://www.rladiesnyc.org/). My full CV is available [here](files/Zabor_CV_2017_Q4.pdf). Once you have your content written and the layout setup, on the Build tab in RStudio, select “Build Website”: Now your local directory contains all of the files needed for your website: 344.13.5 Deploy website Basic approach: Select “Upload files” from the main page of your GitHub repo: And simply drag or select the files from the local repository: Advanced approach (recommended): use Git from the shell, from a Git client, or from within RStudio (another great reason to use an R Project!) But this is not a Git/GitHub tutorial. If you want to learn more about Git/GitHub, which I encourage you to do, here’s a great resource to get you started: http://happygitwithr.com/ 344.13.6 Custom domains The default is for your site to be hosted at http://YOUR_GH_NAME.github.io, but you can add a custom domain name as well. There are two steps: In your GitHub repository YOUR_GH_NAME.github.io, go to Settings &gt; GitHub pages. Type your domain name in the box under Custom domain and hit Save. Add a CNAME file to your GitHub repsitory YOUR_GH_NAME.github.io. It will appear like this in your repository: And inside the file you will simply have your domain name: 344.14 Package websites An example from the website for my package ezfun: Use Hadley Wickham’s great package pkgdown to easily build a website from your package that is hosted on GitHub. Details of pkgdown can be found on the pkgdown website, which was also created using pkgdown. This assumes you already have an R package with a local directory and a GitHub repository. From within your package directory run: devtools::install_github(&quot;hadley/pkgdown&quot;) pkgdown::build_site() This will add a folder called docs to the local directory for your package Upload/push these changes to the GitHub repository for your package In the GitHub repository for your package go to Settings &gt; GitHub pages. Select “master branch/docs folder” as the source and hit Save The page will be added as to your personal website as YOUR_GH_NAME.github.io/repo_name The Home page of the site will be pulled from the README file on your package repository The Reference page of the site lists the included functions with their description Each function can be clicked through to see the help page, if any Would also build pages for any available vignettes And you’re done, it’s that easy. 344.15 Project websites You can create a website for a non-package repository as well. For example, I have a page on my website linking to the repository in which this tutorial is stored. 344.15.1 Local setup From within the local directory of the project of interest: Create a _site.yml and index.Rmd file in your new directory Edit these files to create content and manage layout, as before for personal websites 344.15.2 GitHub setup Upload/push these new files to the GitHub repository for your project Enable GitHub pages for the repository by going to Settings &gt; GitHub Pages, where you’ll select the “master branch” folder and hit Save 344.16 Blogs R Markdown websites are simple to create and deploy, but can become cumbersome if you make frequent updates or additions to the website, as in the case of a blog. Luckily, the R package blogdown exists just for this purpose. blogdown is an R package that allows you to create static websites, which means that the deployed version of the website only consists of JavaScript, HTML, CSS, and images. Luckily the blogdown package makes it so that you don’t have to know any of those things to create a beautiful website for your blog, powered by Hugo. For a complete resource on using the blogdown website, checkout this short blogdown book. I don’t have a personal blog, so let’s look at the website I built to feature the events and blog of the R-Ladies NYC organization as an example. 344.16.1 Setup The first three steps are similar to those from creating a basic R Markdown website: Create a GitHub repository named YOUR_GH_NAME.github.io, where YOUR_GH_NAME is your GitHub username, initialized with a README file Clone the GitHub repo to a local directory with the same name Add an R Project to the local directoroy Next we get started with blogdown. Install blogdown and Hugo install.packages(&quot;blogdown&quot;) blogdown::install_hugo() Choose a theme and find the link to the theme’s GitHub repository. In this case themes aren’t quite as easy to change as with basic R Markdown websites, so choose carefully. Within your project session, generate a new site. The option theme_example = TRUE will obtain the files for an example site that you can then customize for your needs. Below “user/repo” refers to the GitHub username and GitHub repository for your selected theme. blogdown::new_site(theme = &quot;user/repo&quot;, theme_example = TRUE) This will generate all of the file structure for your new blog. After this is complete, you should quit and then reopen the project. Upon reopening, RStudio will recognize the project as a website. 344.16.2 Customizing the appearance Make changes to the config.toml file (equivalent to the _site.yml from basic R Markdown websites) to change the layout and appearance of your website. The available features of the config.toml file will differ depending on your theme, and most theme examples come with a well annotated config.toml that you can use as a template. Once you have customized your website features, click on the RStudio addin “Serve Site” to preview the site locally. 344.16.3 Writing a new blog post There are several ways to create a new post for your site, but the easiest is using the RStudio addin “New Post”: This opens a pop-up where you can enter the meta-data for a new post: In addition to setting the Title, Author and Date of the post, you can additionally create categories, which will organize your posts in folders, and can add tags to posts, which can make them searchable within your site’s content. Be aware that the functioning of these features will vary by theme. Dates can be in the future to allow future release of a post. Notice at the bottom that you can select whether to use a regular markdown (.md) or R markdown (.Rmd) file. .Rmd files will have to be rendered before generating html pages so it is best practice to limit their use to cases where R code is included. A file name and slug will automatically be generated based on the other metadata. The slug is a URL friendly title of your post. 344.16.4 Hosting A blogdown site is a bit more cumbersome both to build and to host on GitHub as compared to a regular R Markdown website, and as compared to what I described above. Problem 1: Because it is a static site, upon building, the files needed to generate the site online are automatically created in a separate subdirectory called public within your local directory. However this will cause problems with GitHub hosting since the files to host need to be in the local YOUR_GH_NAME.github.io directory My solution: Maintain separate directories for the source files (I named this directory “source”) and for the static files (the directory YOUR_GH_NAME.github.io) that will be generated on build. The “source” folder is where your R project and config.toml files will live. In your config.toml use the option publishDir = to customize blogdown to publish to the YOUR_GH_NAME.github.io folder, rather than to the default local location Problem 2: GitHub defaults to using Jekyll with website content, and this needs to be disabled since blogdown sites are built with Hugo To get around this, you need to include an empty file named .nojekyll in your GitHub repo YOUR_GH_NAME.github.io, prior to publishing. 344.17 Additional resources A compiled list of the additional resources/links presented throughout this tutorial: http://rmarkdown.rstudio.com/rmarkdown_websites.html: an overview of R Markdown website basics http://jekyllthemes.org/: Jekyll themes for use with your R Markdown website http://happygitwithr.com/: an introduction to Git/GitHub http://pkgdown.r-lib.org/: Hadley Wickham’s pkgdown website https://bookdown.org/yihui/blogdown/: Yihui Xie’s blogdown book https://themes.gohugo.io/: Hugo themes for use with your blogdown website 344.18 Demo "],["tidyroc.html", "Chapter 345 tidyroc", " Chapter 345 tidyroc https://github.com/dariyasydykova/tidyroc "],["section.html", "Chapter 346 ", " Chapter 346 Introduction to ORCID Researcher Identifiers in R with rorcid https://www.pauloldham.net/introduction-to-orcid-with-rorcid/ "],["r-package-development.html", "Chapter 347 R package development", " Chapter 347 R package development Analyses as Packages http://rmflight.github.io/posts/2014/07/analyses_as_packages.html Creating an analysis as a package and vignette http://rmflight.github.io/posts/2014/07/vignetteAnalysis.html pkgdown https://pkgdown.r-lib.org/index.html Writing an R package from scratch https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/ R packages http://r-pkgs.had.co.nz/intro.html https://r-pkgs.org devtools https://github.com/r-lib/devtools "],["purrr.html", "Chapter 348 purrr", " Chapter 348 purrr Learning Functional Programming &amp; purrr https://paulvanderlaken.com/2018/12/05/learning-functional-programming-purrr/ "],["diagrammer.html", "Chapter 349 DiagrammeR", " Chapter 349 DiagrammeR http://rich-iannone.github.io/DiagrammeR/ "],["gggenes.html", "Chapter 350 gggenes", " Chapter 350 gggenes https://cran.r-project.org/web/packages/gggenes/vignettes/introduction-to-gggenes.html "],["textminer.html", "Chapter 351 textmineR", " Chapter 351 textmineR https://cran.r-project.org/web/packages/textmineR/vignettes/a_start_here.html https://cran.r-project.org/web/packages/textmineR/vignettes/b_document_clustering.html https://cran.r-project.org/web/packages/textmineR/vignettes/c_topic_modeling.html https://cran.r-project.org/web/packages/textmineR/vignettes/d_text_embeddings.html https://cran.r-project.org/web/packages/textmineR/vignettes/e_doc_summarization.html "],["tidyshiny.html", "Chapter 352 tidyshiny", " Chapter 352 tidyshiny https://github.com/MangoTheCat/tidyshiny/ "],["rio-1.html", "Chapter 353 rio", " Chapter 353 rio https://cran.r-project.org/web/packages/rio/README.html install.packages(“rio”) install_formats() "],["addinplots.html", "Chapter 354 addinplots", " Chapter 354 addinplots RStudio Addins for plotting https://github.com/homerhanumat/addinplots/ "],["citr.html", "Chapter 355 citr", " Chapter 355 citr citr: RStudio Addin to Insert Markdown Citations https://github.com/crsh/citr "],["ggplotassist-1.html", "Chapter 356 ggplotAssist", " Chapter 356 ggplotAssist https://github.com/cardiomoon/ggplotAssist/blob/master/README.md "],["radiant-1.html", "Chapter 357 Radiant", " Chapter 357 Radiant Radiant – Business analytics using R and Shiny https://radiant-rstats.github.io/docs/tutorials.html "],["rspivot.html", "Chapter 358 rspivot", " Chapter 358 rspivot https://ryantimpe.github.io/rspivot/index.html "],["finalfit.html", "Chapter 359 finalfit", " Chapter 359 finalfit http://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/ "],["ggraptr-1.html", "Chapter 360 ggraptR", " Chapter 360 ggraptR https://github.com/cargomoose/ggraptR "],["bookdownthemeeditor.html", "Chapter 361 bookdownThemeEditor", " Chapter 361 bookdownThemeEditor https://github.com/hebrewseniorlife/bookdownThemeEditor "],["esquisse-1.html", "Chapter 362 esquisse", " Chapter 362 esquisse https://github.com/dreamRs/esquisse "],["ggtextures.html", "Chapter 363 ggtextures", " Chapter 363 ggtextures https://github.com/clauswilke/ggtextures "],["ggstatsplot.html", "Chapter 364 ggstatsplot 364.1 ggcoefstats", " Chapter 364 ggstatsplot ggplot2 Based Plots with Statistical Details https://indrajeetpatil.github.io/ggstatsplot/ 364.1 ggcoefstats https://indrajeetpatil.github.io/ggstatsplot/articles/ggcoefstats.html "],["choroplethr.html", "Chapter 365 Choroplethr", " Chapter 365 Choroplethr https://arilamstein.com/open-source/ "],["purrr-1.html", "Chapter 366 purrr", " Chapter 366 purrr https://colinfay.me/happy-dev-purrr/ "],["knitcitations-1.html", "Chapter 367 knitcitations", " Chapter 367 knitcitations http://www.carlboettiger.info/2012/05/30/knitcitations.html "],["infer-3.html", "Chapter 368 infer 368.1 Packages to be studied", " Chapter 368 infer Tidy Statistical Inference https://cran.r-project.org/web/packages/infer/index.html https://kbroman.org/pkg_primer/ 368.1 Packages to be studied https://cran.rstudio.com/web/packages/sys/ "],["scales.html", "Chapter 369 scales", " Chapter 369 scales Scale Functions for Visualization https://cran.r-project.org/web/packages/scales/index.html "],["animation.html", "Chapter 370 animation", " Chapter 370 animation A Gallery of Animations in Statistics and Utilities to Create Animations https://cran.r-project.org/web/packages/animation/ "],["gganimate-2.html", "Chapter 371 gganimate", " Chapter 371 gganimate A Grammar of Animated Graphics https://github.com/thomasp85/gganimate https://cran.r-project.org/web/packages/naniar/index.html https://hughjonesd.github.io/anim.plots/anim.plots.html You Can Design a Good Chart with R https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e Bubble-grid-maps https://jschoeley.github.io/2018/06/30/bubble-grid-map.html Taking control of animations in R and demystifying them in the process https://www.data-imaginist.com/2017/animating-the-logo/?utm_content=bufferd418f&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer https://cran.r-project.org/web/packages/rticles/rticles.pdf https://colinfay.me/build-api-wrapper-package-r/ https://www.datacamp.com/community/tutorials/setup-data-science-environment https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html####installation https://cran.r-project.org/web/packages/expss/vignettes/tables-with-labels.html https://cran.r-project.org/web/packages/tabulizer/vignettes/tabulizer.html https://github.com/benjaminrich/table1 https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html https://twitter.com/mitchoharawild/status/1007297976711110659?s=12 https://twitter.com/mf_viz/status/1004954297962917891?s=12 https://github.com/cmap/morpheus.R https://github.com/talgalili/heatmaply/ https://github.com/rstudio/d3heatmap http://worksmarter.pl/en/post/webscraping-case-study-1/ http://worksmarter.pl/en/post/job-automation-r-1/ http://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/ https://www.r-bloggers.com/how-to-plot-with-ggiraph/ https://www.r-bloggers.com/understanding-pca-using-stack-overflow-data/ https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r/ http://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0188299 https://github.com/trinker/reports Animated Directional Chord Diagrams https://guyabel.com/post/animated-directional-chord-diagrams/ modelDown: a website generator for your predictive models http://smarterpoland.pl/index.php/2018/06/modeldown-a-website-generator-for-your-predictive-models/ "],["drake.html", "Chapter 372 drake 372.1 chromoMap 372.2 tabplot 372.3 treemap 372.4 VIM 372.5 survey 372.6 tidytext 372.7 rapport an R templating system 372.8 ztable 372.9 texreg 372.10 SortableHTMLTables 372.11 hwriter 372.12 HTMLUtils 372.13 htmlTable 372.14 formattable 372.15 DT 372.16 stargazer 372.17 conflicted 372.18 psycho 372.19 styler 372.20 tidyverse 372.21 splitstackshape 372.22 epiR 372.23 lmtest 372.24 popEpi 372.25 Extra tools to go with ‘Epi’ and make nice rate tables 372.26 survival 372.27 survminer 372.28 Random-Effects Modeks 372.29 Multiple Imputation 372.30 Really nice summmary tables 372.31 Complex survey data analysis 372.32 For handling complex survey data 372.33 Alternative methods for ICC calculation from survey data 372.34 Meta-analysis 372.35 abind 372.36 acepack 372.37 AlgDesign 372.38 AnnotationDbi 372.39 aplpack 372.40 arm 372.41 assertthat 372.42 backports 372.43 base 372.44 base64enc 372.45 BCA 372.46 BH 372.47 BiasedUrn 372.48 bindr 372.49 bindrcpp 372.50 Biobase 372.51 BiocGenerics 372.52 BiocInstaller 372.53 bit 372.54 bit64 372.55 bitops 372.56 blob 372.57 boot 372.58 broom 372.59 BsMD 372.60 ca 372.61 car 372.62 caTools 372.63 cellranger 372.64 checkmate 372.65 class 372.66 cluster 372.67 clv 372.68 coda 372.69 codetools 372.70 coin 372.71 colorspace 372.72 combinat 372.73 compiler 372.74 conf.design 372.75 curl 372.76 data.table 372.77 datasets 372.78 date 372.79 DBI 372.80 deldir 372.81 depthTools 372.82 DiceDesign 372.83 dichromat 372.84 digest 372.85 DoE.base 372.86 DoE.wrapper 372.87 doParallel 372.88 dplyr 372.89 e1071 372.90 effects 372.91 ENmisc 372.92 epiR 372.93 estimability 372.94 evaluate 372.95 ez 372.96 flexclust 372.97 forcats 372.98 foreach 372.99 foreign 372.100 formatR 372.101 Formula 372.102 fracdiff 372.103 FrF2 372.104 gdata 372.105 ggplot2 372.106 ggthemes 372.107 ggvis 372.108 glue 372.109 goftest 372.110 graphics 372.111 grDevices 372.112 grid 372.113 gridBase 372.114 gridExtra 372.115 gtable 372.116 gtools 372.117 haven 372.118 highr 372.119 Hmisc 372.120 hms 372.121 htmlTable 372.122 htmltools 372.123 htmlwidgets 372.124 httpuv 372.125 httr 372.126 igraph 372.127 IRanges 372.128 irlba 372.129 iterators 372.130 jsonlite 372.131 KernSmooth 372.132 knitr 372.133 labeling 372.134 lattice 372.135 latticeExtra 372.136 lazyeval 372.137 leaps 372.138 lhs 372.139 lme4 372.140 lmtest 372.141 lsmeans 372.142 lubridate 372.143 magrittr 372.144 markdown 372.145 MASS 372.146 Matrix 372.147 matrixcalc 372.148 MatrixModels 372.149 memoise 372.150 methods 372.151 mgcv 372.152 mi 372.153 mime 372.154 minqa 372.155 mnormt 372.156 modelr 372.157 modeltools 372.158 multcomp 372.159 munsell 372.160 mvtnorm 372.161 nlme 372.162 nloptr 372.163 NLP 372.164 NMF 372.165 nnet 372.166 nortest 372.167 openssl 372.168 ordinal 372.169 orloca 372.170 orloca.es 372.171 parallel 372.172 pbkrtest 372.173 pkgconfig 372.174 pkgmaker 372.175 plogr 372.176 plyr 372.177 polyclip 372.178 psych 372.179 purrr 372.180 quadprog 372.181 quantmod 372.182 quantreg 372.183 R2HTML 372.184 R6 372.185 randtests 372.186 Rcmdr 372.187 RcmdrMisc 372.188 RcmdrPlugin.BCA 372.189 RcmdrPlugin.coin 372.190 RcmdrPlugin.depthTools 372.191 RcmdrPlugin.DoE 372.192 RcmdrPlugin.doex 372.193 RcmdrPlugin.EACSPIR 372.194 RcmdrPlugin.EBM 372.195 RcmdrPlugin.epack 372.196 RcmdrPlugin.EZR 372.197 RcmdrPlugin.KMggplot2 372.198 RcmdrPlugin.mosaic 372.199 RcmdrPlugin.MPAStats 372.200 RcmdrPlugin.orloca 372.201 RcmdrPlugin.plotByGroup 372.202 RcmdrPlugin.qual 372.203 RcmdrPlugin.SCDA 372.204 RcmdrPlugin.sampling 372.205 RcmdrPlugin.seeg 372.206 RcmdrPlugin.SLC 372.207 RcmdrPlugin.SM 372.208 RcmdrPlugin.steepness 372.209 RcmdrPlugin.survival 372.210 RcmdrPlugin.TeachingDemos 372.211 RcmdrPlugin.temis 372.212 RcmdrPlugin.UCA 372.213 RColorBrewer 372.214 Rcpp 372.215 RcppArmadillo 372.216 RcppEigen 372.217 readr 372.218 readxl 372.219 registry 372.220 relimp 372.221 rematch 372.222 reshape 372.223 reshape2 372.224 rgl 372.225 RISmed 372.226 rJava 372.227 rlang 372.228 rmarkdown 372.229 RMySQL 372.230 rngtools 372.231 rpart 372.232 rpart.plot 372.233 rprojroot 372.234 rsm 372.235 rticles tufte 372.236 RSQLite 372.237 rvest 372.238 S4Vectors 372.239 sandwich 372.240 scales 372.241 scatterplot3d 372.242 SCMA 372.243 SCRT 372.244 SCVA 372.245 seeg 372.246 selectr 372.247 sem 372.248 sfsmisc 372.249 sgeostat 372.250 shiny 372.251 shinythemes 372.252 slam 372.253 SLC 372.254 sourcetools 372.255 SparseM 372.256 spatial 372.257 spatstat 372.258 spatstat.utils 372.259 splines 372.260 stats 372.261 stats4 372.262 steepness 372.263 stringi 372.264 stringr 372.265 survival 372.266 tcltk 372.267 tcltk2 372.268 TeachingDemos 372.269 tensor 372.270 TH.data 372.271 tibble 372.272 tidyr 372.273 tidyverse 372.274 timeDate 372.275 tkrplot 372.276 tm 372.277 tools 372.278 tseries 372.279 TTR 372.280 ucminf 372.281 utils 372.282 vcd 372.283 viridis 372.284 viridisLite 372.285 XLConnect 372.286 XLConnectJars 372.287 xml2 372.288 xtable 372.289 xts 372.290 yaml 372.291 zoo 372.292 Rcmdr 372.293 Schedule R Script 372.294 flatxml 372.295 roomba 372.296 tufterhandout 372.297 papeR 372.298 tm", " Chapter 372 drake https://ropensci.github.io/drake/ 372.1 chromoMap An R package for Interactive visualization and mapping of human chromosomes https://cran.r-project.org/web/packages/chromoMap/vignettes/chromoMap.html 372.2 tabplot Tableplot, a Visualization of Large Datasets https://cran.r-project.org/web/packages/tabplot/index.html https://cran.r-project.org/web/packages/tabplot/vignettes/tabplot-vignette.html https://cran.r-project.org/web/packages/tabplot/vignettes/tabplot-timings.html 372.3 treemap Treemap Visualization https://cran.r-project.org/web/packages/treemap/index.html 372.4 VIM Visualization and Imputation of Missing Values https://cran.r-project.org/web/packages/VIM/index.html 372.5 survey https://cran.r-project.org/web/packages/survey/index.html 372.6 tidytext https://cran.r-project.org/web/packages/tidytext/index.html https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html https://cran.r-project.org/web/packages/tidytext/vignettes/tidying_casting.html https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html 372.7 rapport an R templating system http://rapport-package.info/ 372.8 ztable https://github.com/cardiomoon/ztable 372.9 texreg https://cran.r-project.org/web/packages/texreg/vignettes/texreg.pdf 372.10 SortableHTMLTables https://cran.r-project.org/web/packages/SortableHTMLTables/index.html 372.11 hwriter https://cran.r-project.org/web/packages/hwriter/vignettes/hwriter.pdf 372.12 HTMLUtils https://cran.r-project.org/web/packages/HTMLUtils/index.html 372.13 htmlTable https://cran.r-project.org/web/packages/htmlTable/index.html 372.14 formattable https://cran.r-project.org/web/packages/formattable/index.html 372.15 DT DT: An R interface to the DataTables library https://rstudio.github.io/DT/ 372.16 stargazer Well-Formatted Regression and Summary Statistics Tables https://cran.r-project.org/web/packages/stargazer/index.html 372.17 conflicted 372.18 psycho 372.19 styler 372.20 tidyverse 372.21 splitstackshape The “splitstackshape” package for R https://www.r-bloggers.com/the-splitstackshape-package-for-r/ 372.22 epiR Basic Epi install.packages(“epiR”) 372.23 lmtest Some useful epitools especially 2*2 tables and stratified MH Odds install.packages(“lmtest”) 372.24 popEpi install.packages(“popEpi”) 372.25 Extra tools to go with ‘Epi’ and make nice rate tables 372.26 survival install.packages(“survival”) for survial analysis, kaplan-meier plots and cox regression 372.27 survminer install.packages(“survminer”) Really nice KM plots! 372.28 Random-Effects Modeks install.packages(“lme4”) install.packages(“sjstats”) 372.29 Multiple Imputation install.packages(“mice”) install.packages(“arsenal”) 372.30 Really nice summmary tables 372.31 Complex survey data analysis install.packages(“survey”) 372.32 For handling complex survey data install.packages(“ICC”) 372.33 Alternative methods for ICC calculation from survey data 372.34 Meta-analysis install.packages(“meta”) install.packages(“metafor”) install.packages(“workflowr”) install.packages(“DiagrammeR”) install.packages(“tangram”) devtools::install_github(“lbusett/insert_table”) 372.35 abind 372.36 acepack 372.37 AlgDesign 372.38 AnnotationDbi 372.39 aplpack 372.40 arm 372.41 assertthat 372.42 backports 372.43 base 372.44 base64enc 372.45 BCA 372.46 BH 372.47 BiasedUrn 372.48 bindr 372.49 bindrcpp 372.50 Biobase 372.51 BiocGenerics 372.52 BiocInstaller 372.53 bit 372.54 bit64 372.55 bitops 372.56 blob 372.57 boot 372.58 broom 372.59 BsMD 372.60 ca 372.61 car 372.62 caTools 372.63 cellranger 372.64 checkmate 372.65 class 372.66 cluster 372.67 clv 372.68 coda 372.69 codetools 372.70 coin 372.71 colorspace 372.72 combinat 372.73 compiler 372.74 conf.design 372.75 curl 372.76 data.table 372.77 datasets 372.78 date 372.79 DBI 372.80 deldir 372.81 depthTools 372.82 DiceDesign 372.83 dichromat 372.84 digest 372.85 DoE.base 372.86 DoE.wrapper 372.87 doParallel 372.88 dplyr 372.89 e1071 372.90 effects 372.91 ENmisc 372.92 epiR 372.93 estimability 372.94 evaluate 372.95 ez 372.96 flexclust 372.97 forcats 372.98 foreach 372.99 foreign 372.100 formatR 372.101 Formula 372.102 fracdiff 372.103 FrF2 372.104 gdata 372.105 ggplot2 http://www.cookbook-r.com/Graphs/ 372.105.1 ggplot2 extensions http://www.ggplot2-exts.org/gallery/ http://corybrunson.github.io/ggalluvial/ http://www.sthda.com/english/rpkgs/survminer/ 372.106 ggthemes 372.107 ggvis 372.108 glue 372.109 goftest 372.110 graphics 372.111 grDevices 372.112 grid 372.113 gridBase 372.114 gridExtra 372.115 gtable 372.116 gtools 372.117 haven 372.118 highr 372.119 Hmisc 372.120 hms 372.121 htmlTable 372.122 htmltools 372.123 htmlwidgets 372.124 httpuv 372.125 httr 372.126 igraph 372.127 IRanges 372.128 irlba 372.129 iterators 372.130 jsonlite 372.131 KernSmooth 372.132 knitr 372.133 labeling 372.134 lattice 372.135 latticeExtra 372.136 lazyeval 372.137 leaps 372.138 lhs 372.139 lme4 372.140 lmtest 372.141 lsmeans 372.142 lubridate 372.143 magrittr 372.144 markdown 372.145 MASS 372.146 Matrix 372.147 matrixcalc 372.148 MatrixModels 372.149 memoise 372.150 methods 372.151 mgcv 372.152 mi 372.153 mime 372.154 minqa 372.155 mnormt 372.156 modelr 372.157 modeltools 372.158 multcomp 372.159 munsell 372.160 mvtnorm 372.161 nlme 372.162 nloptr 372.163 NLP 372.164 NMF 372.165 nnet 372.166 nortest 372.167 openssl 372.168 ordinal 372.169 orloca 372.170 orloca.es 372.171 parallel 372.172 pbkrtest 372.173 pkgconfig 372.174 pkgmaker 372.175 plogr 372.176 plyr 372.177 polyclip 372.178 psych 372.179 purrr https://colinfay.me/happy-dev-purrr/ 372.180 quadprog 372.181 quantmod 372.182 quantreg 372.183 R2HTML 372.184 R6 372.185 randtests 372.186 Rcmdr 372.187 RcmdrMisc 372.188 RcmdrPlugin.BCA 372.189 RcmdrPlugin.coin 372.190 RcmdrPlugin.depthTools 372.191 RcmdrPlugin.DoE 372.192 RcmdrPlugin.doex 372.193 RcmdrPlugin.EACSPIR 372.194 RcmdrPlugin.EBM 372.195 RcmdrPlugin.epack 372.196 RcmdrPlugin.EZR 372.197 RcmdrPlugin.KMggplot2 372.198 RcmdrPlugin.mosaic 372.199 RcmdrPlugin.MPAStats 372.200 RcmdrPlugin.orloca 372.201 RcmdrPlugin.plotByGroup 372.202 RcmdrPlugin.qual 372.203 RcmdrPlugin.SCDA 372.204 RcmdrPlugin.sampling Tools for sampling in Official Statistical Surveys https://cran.r-project.org/web/packages/RcmdrPlugin.sampling/index.html 372.205 RcmdrPlugin.seeg 372.206 RcmdrPlugin.SLC 372.207 RcmdrPlugin.SM 372.208 RcmdrPlugin.steepness 372.209 RcmdrPlugin.survival 372.210 RcmdrPlugin.TeachingDemos 372.211 RcmdrPlugin.temis 372.212 RcmdrPlugin.UCA 372.213 RColorBrewer 372.214 Rcpp 372.215 RcppArmadillo 372.216 RcppEigen 372.217 readr 372.218 readxl 372.219 registry 372.220 relimp 372.221 rematch 372.222 reshape 372.223 reshape2 372.224 rgl 372.225 RISmed 372.226 rJava 372.227 rlang 372.228 rmarkdown 372.229 RMySQL 372.230 rngtools 372.231 rpart 372.232 rpart.plot 372.233 rprojroot 372.234 rsm 372.235 rticles tufte https://github.com/rstudio/rticles https://www.coursera.org/learn/reproducible-templates-analysis/lecture/QaDy7/building-a-document-template-part-2 https://www.coursera.org/learn/reproducible-templates-analysis/supplement/GQz0G/lecture-prep-code-file https://github.com/rstudio/tufte 372.236 RSQLite 372.237 rvest 372.238 S4Vectors 372.239 sandwich 372.240 scales 372.241 scatterplot3d 372.242 SCMA 372.243 SCRT 372.244 SCVA 372.245 seeg 372.246 selectr 372.247 sem 372.248 sfsmisc 372.249 sgeostat 372.250 shiny 372.251 shinythemes 372.252 slam 372.253 SLC 372.254 sourcetools 372.255 SparseM 372.256 spatial 372.257 spatstat 372.258 spatstat.utils 372.259 splines 372.260 stats 372.261 stats4 372.262 steepness 372.263 stringi 372.264 stringr 372.265 survival 372.266 tcltk 372.267 tcltk2 372.268 TeachingDemos 372.269 tensor 372.270 TH.data 372.271 tibble 372.272 tidyr 372.273 tidyverse 372.274 timeDate 372.275 tkrplot 372.276 tm 372.277 tools 372.278 tseries 372.279 TTR 372.280 ucminf 372.281 utils 372.282 vcd 372.283 viridis 372.284 viridisLite 372.285 XLConnect 372.286 XLConnectJars 372.287 xml2 372.288 xtable 372.289 xts 372.290 yaml 372.291 zoo install.packages(“stargazer”) install.packages(“pander”) install.packages(“tables”) install.packages(“ascii”) install.packages(“xtable”) devtools::install_github(“hadley/dplyr”) install.packages(“gapminder”) install.packages(“alluvial”) vignette(“databases”, package = “dplyr”) install.packages(“robustbase”) install.packages(“insuranceData”) install.packages(“Lahman”) install.packages(“tidyverse”) install.packages(“qdap”) install.packages(“openxlsx”) devtools::install_github(“kassambara/r2excel”) install.packages(“WriteXLS”) install.packages(“XLConnect”) library(XLConnect) 372.292 Rcmdr install.packages(“tidyverse”) install.packages(“devtools”) devtools::install_github(“hadley/colformat”) devtools::install_github(“ropenscilabs/skimr”) install.packages(“hflights”) install.packages(“dbplyr”) install.packages(“xlsx”) require(devtools) install_github(“ProjectMOSAIC/mosaic”) install.packages(“jmv”) install.packages(“wordcloud”) install.packages(“https://cran.r-project.org/src/contrib/Archive/tm/tm_0.6.tar.gz”, repos = NULL) install.packages(“SnowballC”) install.packages(“RColorBrewer”) install.packages(“tidytext”) install.packages(“packrat”) install.packages(“testthat”) install.packages(“prettydoc”) install.packages(“rmdformats”) install.packages(c(“fivethirtyeight”, “tidyverse”, “knitr”, “kableExtra”, “ggthemes”)) library(devtools) install_github(“SPSStoR”, username = “lebebr01”) library(SPSStoR) survival survminer install.packages(“tutorial”) devtools::install_github(“romainfrancois/highlight”) install.packages(“highr”, repos = “http://rforge.net”, type = “source”) install.packages(“xplain”) 372.293 Schedule R Script library(knitr) library(markdown) knit(“SchedulePubMedAnalysis.Rmd”) markdownToHTML(“SchedulePubMedAnalysis.md”, “docs/SchedulePubMedAnalysis.html”) setwd(“~”) file.choose() library(rmarkdown) Preperation Packages Schedule R Script https://github.com/jkeirstead/scholar http://rogiersbart.blogspot.com.tr/2015/05/put-google-scholar-citations-on-your.html http://tuxette.nathalievilla.org/?p=1682 https://github.com/sunitj/scholar https://tgmstat.wordpress.com/2013/09/11/schedule-rscript-with-cron/ https://github.com/ropensci/git2r library(knitr) library(markdown) install.packages(‘data.table’) install.packages(‘knitr’) install.packages(‘miniUI’) install.packages(‘shiny’) install.packages(‘shinyFiles’) install.packages(“taskscheduleR”, repos = “http://www.datatailor.be/rcube”, type = “source”) devtools::install_github(“bnosac/cronR”) install.packages(‘scholar’) install.packages(“git2r”) 372.294 flatxml http://www.zuckarelli.de/flatxml/articles/example/example.html 372.295 roomba General purpose API response tidier https://github.com/ropenscilabs/roomba/ 372.296 tufterhandout Tufte-style html document format for rmarkdown https://cran.r-project.org/web/packages/tufterhandout/index.html 372.297 papeR https://sbalci.github.io/MyRCodesForDataAnalysis/papeR.nb.html 372.298 tm install.packages(“tm”) https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf https://atom.io/packages/hydrogen R Package Documentation https://rdrr.io/ R Packages Search and Statistics https://www.rpackages.io/ ReporteRs is an R package for creating Microsoft Word and Powerpoint documents. https://davidgohel.github.io/ReporteRs/ officer Manipulation of Microsoft Word and PowerPoint Documents https://cran.r-project.org/web/packages/officer/ pubh https://cran.rstudio.com/web/packages/pubh/vignettes/introduction.html What does visdat do? Initially inspired by csv-fingerprint, vis_dat helps you visualise a dataframe and “get a look at the data” by displaying the variable classes in a dataframe as a plot with vis_dat, and getting a brief look into missing data patterns using vis_miss. https://www.tidyverse.org/ https://cran.r-project.org/web/packages/shiny/index.html https://rmarkdown.rstudio.com/ http://ggplot2.org/ https://yihui.name/knitr/ http://vita.had.co.nz/papers/tidy-data.html https://blog.rstudio.com/2015/04/09/readr-0-1-0/ http://readxl.tidyverse.org/ https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html https://github.com/r-lib/devtools https://cran.r-project.org/web/packages/magrittr/index.html http://rstudio.github.io/packrat/ https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html https://github.com/tidyverse/dplyr https://cran.r-project.org/web/packages/broom/vignettes/broom.html https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html http://tibble.tidyverse.org/ https://blog.rstudio.com/2016/03/29/feather/ https://blog.rstudio.com/2016/08/31/forcats-0-1-0/ https://github.com/tidyverse/hms https://github.com/trestletech/plumber https://github.com/r-lib/testthat http://purrr.tidyverse.org/ "],["broom-1.html", "Chapter 373 broom 373.1 abind 373.2 acepack 373.3 addinexamples 373.4 additivityTests 373.5 ade4 373.6 AER 373.7 afex 373.8 AlgDesign 373.9 alluvial 373.10 alr4 373.11 animation 373.12 ANTsR 373.13 ANTsRCore 373.14 anytime 373.15 apaTables 373.16 aplpack 373.17 arm 373.18 arsenal 373.19 ash 373.20 assertthat 373.21 aws.s3 373.22 aws.signature 373.23 backports 373.24 base 373.25 base64enc 373.26 BayesFactor 373.27 bayesplot 373.28 BCA 373.29 BcDiag 373.30 BDgraph 373.31 bdsmatrix 373.32 BH 373.33 BiasedUrn 373.34 BiBitR 373.35 bibtex 373.36 biclust 373.37 bindr 373.38 bindrcpp 373.39 BiocGenerics 373.40 BiocInstaller 373.41 biostatmethods 373.42 bit 373.43 bit64 373.44 bitops 373.45 blob 373.46 blogdown 373.47 bookdown 373.48 boot 373.49 brew 373.50 bridgesampling 373.51 brms 373.52 Brobdingnag 373.53 broom 373.54 BsMD 373.55 ca 373.56 cairoDevice 373.57 callr 373.58 car 373.59 carData 373.60 carbonate 373.61 caTools 373.62 cellranger 373.63 checkmate 373.64 class 373.65 classInt 373.66 cli 373.67 clipr 373.68 clisymbols 373.69 clue 373.70 cluster 373.71 clv 373.72 cmaker 373.73 cmprsk 373.74 coauthornetwork 373.75 cobs 373.76 coda 373.77 CodeDepends 373.78 codetools 373.79 coin 373.80 colorspace 373.81 colourpicker 373.82 combinat 373.83 commonmark 373.84 compiler 373.85 conf.design 373.86 config 373.87 conflicted 373.88 contfrac 373.89 corpcor 373.90 covr 373.91 cowplot 373.92 coxme 373.93 cramer 373.94 crayon 373.95 cronR 373.96 crosstalk 373.97 csvy 373.98 curl 373.99 d3Network 373.100 data.table 373.101 data.tree 373.102 datapasta 373.103 datasets 373.104 date 373.105 DBI 373.106 dbplyr 373.107 debugme 373.108 Deducer 373.109 DeducerExtras 373.110 demography 373.111 dendextend 373.112 DEoptimR 373.113 depthTools 373.114 desc 373.115 descr1 373.116 DescTools 373.117 deSolve 373.118 devtools 373.119 DiagrammeR 373.120 DiceDesign 373.121 dichromat 373.122 digest 373.123 diptest 373.124 DoE.base 373.125 DoE.wrapper 373.126 doParallel 373.127 downloader 373.128 dplyr 373.129 DT 373.130 dtplyr 373.131 dunn.test 373.132 dygraphs 373.133 e1071 373.134 EcoVirtual 373.135 effects 373.136 effsize 373.137 ellipse 373.138 elliptic 373.139 emmeans 373.140 enc 373.141 ENmisc 373.142 Epi 373.143 epibasix 373.144 epiDisplay 373.145 epiR 373.146 epitools 373.147 errorist 373.148 estimability 373.149 etm 373.150 evaluate 373.151 exact2x2 373.152 exactci 373.153 exactRankTests 373.154 experiment 373.155 expm 373.156 extrantsr 373.157 ez 373.158 FactoMineR 373.159 Fahrmeir 373.160 fansi 373.161 fastmatch 373.162 fBasics 373.163 fda 373.164 fdrtool 373.165 feather 373.166 ff 373.167 ffbase 373.168 finalfit 373.169 fit.models 373.170 fivethirtyeight 373.171 flashClust 373.172 flatxml 373.173 flexclust 373.174 flexmix 373.175 flextable 373.176 FNN 373.177 forcats 373.178 foreach 373.179 forecast 373.180 forecastHybrid 373.181 foreign 373.182 formatR 373.183 formattable 373.184 Formula 373.185 fpc 373.186 fracdiff 373.187 FrF2 373.188 fslr 373.189 fst 373.190 ftsa 373.191 gdata 373.192 gdtools 373.193 gee 373.194 getPass 373.195 GGally 373.196 ggcorrplot 373.197 ggdendro 373.198 ggExtra 373.199 ggforce 373.200 ggformula 373.201 ggfortify 373.202 ggm 373.203 ggplot2 373.204 ggplot2movies 373.205 ggpubr 373.206 ggraph 373.207 ggrepel 373.208 ggridges 373.209 ggsci 373.210 ggsignif 373.211 ggstance 373.212 ggstatsplot 373.213 ggthemes 373.214 ggvis 373.215 gh 373.216 git2r 373.217 glasso 373.218 glmmTMB 373.219 glue 373.220 gmailr 373.221 gmodels 373.222 gmp 373.223 gnm 373.224 googledrive 373.225 markdrive 373.226 googleVis 373.227 GPArotation 373.228 gplots 373.229 graph 373.230 graphics 373.231 graphTweets 373.232 grDevices 373.233 grid 373.234 gridExtra 373.235 gsl 373.236 gss 373.237 gtable 373.238 gtools 373.239 gWidgets 373.240 gWidgetstcltk 373.241 GWRM 373.242 h2o 373.243 hash 373.244 haven 373.245 hdrcde 373.246 hexbin 373.247 HH 373.248 highlight 373.249 highr 373.250 Hmisc 373.251 hms 373.252 htmlTable 373.253 htmltools 373.254 htmlwidgets 373.255 httpuv 373.256 httr 373.257 huge 373.258 hunspell 373.259 hypergeo 373.260 ICC 373.261 IRdisplay 373.262 IRkernel 373.263 ISLR 373.264 ISwR 373.265 ITKR 373.266 igraph 373.267 influenceR 373.268 ini 373.269 inline 373.270 ipred 373.271 irlba 373.272 irr 373.273 iterators 373.274 JavaGD 373.275 JGR 373.276 jmv 373.277 jmvcore 373.278 jmvconnect 373.279 jomo 373.280 jose 373.281 jpeg 373.282 jsonlite 373.283 kableExtra 373.284 kernlab 373.285 KernSmooth 373.286 klaR 373.287 km.ci 373.288 KMsurv 373.289 knitr 373.290 kohonen 373.291 ks 373.292 labeling 373.293 labelled 373.294 Lahman 373.295 later 373.296 lattice 373.297 latticeExtra 373.298 lava 373.299 lavaan 373.300 lazyeval 373.301 leaps 373.302 lfstat 373.303 lhs 373.304 lintr 373.305 lisrelToR 373.306 lme4 373.307 lmerTest 373.308 lmom 373.309 lmomRFA 373.310 lmtest 373.311 locfit 373.312 loo 373.313 lpSolve 373.314 lubridate 373.315 MAd 373.316 magic 373.317 magicfor 373.318 magrittr 373.319 manipulate 373.320 manipulateWidget 373.321 mapproj 373.322 maps 373.323 maptools 373.324 markdown 373.325 MASS 373.326 Matrix 373.327 matrixcalc 373.328 MatrixModels 373.329 matrixStats 373.330 maxstat 373.331 MBESS 373.332 mc2d 373.333 mclust 373.334 memisc 373.335 memoise 373.336 meta 373.337 metafor 373.338 methods 373.339 mgcv 373.340 mi 373.341 mice 373.342 microbenchmark 373.343 mime 373.344 miniUI 373.345 minpack.lm 373.346 minqa 373.347 misc3d 373.348 mitml 373.349 mixlm 373.350 mixOmics 373.351 mlbench 373.352 mnormt 373.353 modelr 373.354 modeltools 373.355 mosaic 373.356 mosaicCore 373.357 mosaicData 373.358 multcomp 373.359 multcompView 373.360 multicool 373.361 MuMIn 373.362 munsell 373.363 mvnormtest 373.364 mvtnorm 373.365 network 373.366 networkD3 373.367 neurobase 373.368 neuroim 373.369 nFactors 373.370 nleqslv 373.371 nlme 373.372 nloptr 373.373 NLP 373.374 nnet 373.375 nortest 373.376 nparLD 373.377 numbers 373.378 numDeriv 373.379 nycflights13 373.380 OceanView 373.381 officer 373.382 OpenMx 373.383 openssl 373.384 openxlsx 373.385 OptimClassifier 373.386 ordinal 373.387 orloca 373.388 orloca.es 373.389 oro.dicom 373.390 oro.nifti 373.391 packagefinder 373.392 packrat 373.393 pacman 373.394 pan 373.395 pander 373.396 papeR 373.397 parallel 373.398 party 373.399 pbapply 373.400 pbdZMQ 373.401 pbivnorm 373.402 pbkrtest 373.403 pcaPP 373.404 permute 373.405 phia 373.406 pillar 373.407 pkgbuild 373.408 pkgconfig 373.409 pkgload 373.410 PKI 373.411 plogr 373.412 plot3D 373.413 plot3Drgl 373.414 plotly 373.415 pls 373.416 plyr 373.417 PMCMR 373.418 png 373.419 popEpi 373.420 ppcor 373.421 prabclus 373.422 pracma 373.423 praise 373.424 prediction 373.425 prettydoc 373.426 prettyR 373.427 prettyunits 373.428 pROC 373.429 processx 373.430 prodlim 373.431 progress 373.432 promises 373.433 pspearman 373.434 psych 373.435 psycho 373.436 pubh 373.437 purrr 373.438 purrrlyr 373.439 pwr 373.440 qgraph 373.441 quadprog 373.442 quantmod 373.443 quantreg 373.444 questionr 373.445 qvcalc 373.446 R.cache 373.447 R.matlab 373.448 R.methodsS3 373.449 R.oo 373.450 R.utils 373.451 R2HTML 373.452 R6 373.453 rainbow 373.454 rainfreq 373.455 randomcoloR 373.456 randtests 373.457 ranger 373.458 RApiDatetime 373.459 rappdirs 373.460 rARPACK 373.461 raster 373.462 rattle 373.463 rCharts 373.464 rcmdcheck 373.465 Rcmdr 373.466 RcmdrMisc 373.467 RcmdrPlugin.aRnova 373.468 RcmdrPlugin.BCA 373.469 RcmdrPlugin.BiclustGUI 373.470 RcmdrPlugin.coin 373.471 RcmdrPlugin.depthTools 373.472 RcmdrPlugin.DoE 373.473 RcmdrPlugin.doex 373.474 RcmdrPlugin.EACSPIR 373.475 RcmdrPlugin.EBM 373.476 RcmdrPlugin.EcoVirtual 373.477 RcmdrPlugin.epack 373.478 RcmdrPlugin.Export 373.479 RcmdrPlugin.EZR 373.480 RcmdrPlugin.FactoMineR 373.481 RcmdrPlugin.FuzzyClust 373.482 RcmdrPlugin.GWRM 373.483 RcmdrPlugin.HH 373.484 RcmdrPlugin.IPSUR 373.485 RcmdrPlugin.KMggplot2 373.486 RcmdrPlugin.lfstat 373.487 RcmdrPlugin.MA 373.488 RcmdrPlugin.mosaic 373.489 RcmdrPlugin.MPAStats 373.490 RcmdrPlugin.NMBU 373.491 RcmdrPlugin.OptimClassifier 373.492 RcmdrPlugin.orloca 373.493 RcmdrPlugin.PcaRobust 373.494 RcmdrPlugin.plotByGroup 373.495 RcmdrPlugin.pointG 373.496 RcmdrPlugin.qual 373.497 RcmdrPlugin.RiskDemo 373.498 RcmdrPlugin.RMTCJags 373.499 RcmdrPlugin.ROC 373.500 RcmdrPlugin.sampling 373.501 RcmdrPlugin.SCDA 373.502 RcmdrPlugin.SLC 373.503 RcmdrPlugin.SM 373.504 RcmdrPlugin.sos 373.505 RcmdrPlugin.steepness 373.506 RcmdrPlugin.survival 373.507 RcmdrPlugin.sutteForecastR 373.508 RcmdrPlugin.TeachingDemos 373.509 RcmdrPlugin.temis 373.510 RcmdrPlugin.UCA 373.511 RColorBrewer 373.512 Rcpp 373.513 RcppArmadillo 373.514 RcppEigen 373.515 RCurl 373.516 readODS 373.517 readr 373.518 readstata13 373.519 readxl 373.520 RefManageR 373.521 relimp 373.522 rematch 373.523 rematch2 373.524 remotes 373.525 repr 373.526 reprex 373.527 reshape 373.528 reshape2 373.529 ResourceSelection 373.530 rex 373.531 rgexf 373.532 rgl 373.533 RGtk2 373.534 rhandsontable 373.535 RISmed 373.536 rio 373.537 rjags 373.538 rJava 373.539 rjson 373.540 RJSONIO 373.541 rlang 373.542 rmarkdown 373.543 rmatio 373.544 rmdformats 373.545 rmeta 373.546 Rmpfr 373.547 RMySQL 373.548 RNifti 373.549 robets 373.550 robust 373.551 robustbase 373.552 rockchalk 373.553 ROCR 373.554 Rook 373.555 roomba 373.556 roxygen2 373.557 rpart 373.558 rpart.plot 373.559 rpf 373.560 RPostgreSQL 373.561 rprojroot 373.562 rrcov 373.563 rsconnect 373.564 rsm 373.565 RSpectra 373.566 RSQLite 373.567 rstan 373.568 rstanarm 373.569 rstantools 373.570 rstudioapi 373.571 RStudioConsoleRender 373.572 rsvd 373.573 Rtsne 373.574 rtweet 373.575 runjags 373.576 RVAideMemoire 373.577 rversions 373.578 rvest 373.579 rvg 373.580 s4vd 373.581 sampling 373.582 sandwich 373.583 scales 373.584 scatr 373.585 scatterplot3d 373.586 scholar 373.587 SCMA 373.588 SCRT 373.589 SCVA 373.590 sde 373.591 SDMTools 373.592 selectr 373.593 sem 373.594 SemiCompRisks 373.595 semPlot 373.596 semTools 373.597 sendmailR 373.598 servr 373.599 sessioninfo 373.600 sf 373.601 sfsmisc 373.602 shape 373.603 shiny 373.604 shinyFiles 373.605 shinyjs 373.606 shinystan 373.607 shinythemes 373.608 sjlabelled 373.609 sjmisc 373.610 sjstats 373.611 skimr 373.612 slam 373.613 SLC 373.614 Sleuth2 373.615 smcure 373.616 sna 373.617 snakecase 373.618 som 373.619 sos 373.620 sourcetools 373.621 sp 373.622 sparklyr 373.623 SparseM 373.624 spatial 373.625 spData 373.626 splines 373.627 splitstackshape 373.628 SQUAREM 373.629 ssanv 373.630 ssgraph 373.631 stabledist 373.632 StanHeaders 373.633 stapler 373.634 stargazer 373.635 statisticalModeling 373.636 statnet.common 373.637 stats 373.638 stats4 373.639 steepness 373.640 stencila 373.641 stringdist 373.642 stringi 373.643 stringr 373.644 strucchange 373.645 styler 373.646 superbiclust 373.647 SuppDists 373.648 survey 373.649 survival 373.650 survminer 373.651 survMisc 373.652 sutteForecastR 373.653 svglite 373.654 tableone 373.655 tables 373.656 tabplot 373.657 tangram 373.658 tcltk 373.659 tcltk2 373.660 TeachingDemos 373.661 testit 373.662 testthat 373.663 TH.data 373.664 threejs 373.665 tibble 373.666 tidybayes 373.667 tidygraph 373.668 tidyr 373.669 tidyselect 373.670 tidyverse 373.671 timeDate 373.672 timeSeries 373.673 tinytex 373.674 tkrplot 373.675 tm 373.676 TMB 373.677 tools 373.678 tree 373.679 triebeard 373.680 trimcluster 373.681 tseries 373.682 TTR 373.683 tufterhandout 373.684 tutorial 373.685 tweenr 373.686 ucminf 373.687 units 373.688 updateR 373.689 urca 373.690 urltools 373.691 uroot 373.692 userfriendlyscience 373.693 usethis 373.694 utf8 373.695 utils 373.696 uuid 373.697 V8 373.698 vcd 373.699 vcdExtra 373.700 vegan 373.701 VGAM 373.702 ViewPipeSteps 373.703 viridis 373.704 viridisLite 373.705 visdat 373.706 visNetwork 373.707 visreg 373.708 wbstats 373.709 webshot 373.710 whisker 373.711 WhiteStripe 373.712 withr 373.713 wordcloud 373.714 workflowr 373.715 writexl 373.716 WRS2 373.717 xfun 373.718 XLConnect 373.719 XLConnectJars 373.720 xlsx 373.721 xlsxjars 373.722 XML 373.723 xml2 373.724 xplain 373.725 xray 373.726 xtable 373.727 xts 373.728 yaImpute 373.729 yaml 373.730 zip 373.731 zoo 373.732 Effsize 373.733 keyring 373.734 testthat 373.735 cronR", " Chapter 373 broom summarizes key information about models https://broom.tidyverse.org/index.html 373.1 abind 373.2 acepack 373.3 addinexamples 373.4 additivityTests 373.5 ade4 373.6 AER 373.7 afex 373.8 AlgDesign 373.9 alluvial 373.10 alr4 373.11 animation 373.12 ANTsR 373.13 ANTsRCore 373.14 anytime 373.15 apaTables 373.16 aplpack 373.17 arm 373.18 arsenal 373.19 ash 373.20 assertthat 373.21 aws.s3 373.22 aws.signature 373.23 backports 373.24 base 373.25 base64enc 373.26 BayesFactor 373.27 bayesplot 373.28 BCA 373.29 BcDiag 373.30 BDgraph 373.31 bdsmatrix 373.32 BH 373.33 BiasedUrn 373.34 BiBitR 373.35 bibtex 373.36 biclust 373.37 bindr 373.38 bindrcpp 373.39 BiocGenerics 373.40 BiocInstaller 373.41 biostatmethods 373.42 bit 373.43 bit64 373.44 bitops 373.45 blob 373.46 blogdown 373.47 bookdown 373.48 boot 373.49 brew 373.50 bridgesampling 373.51 brms 373.52 Brobdingnag 373.53 broom 373.54 BsMD 373.55 ca 373.56 cairoDevice 373.57 callr 373.58 car 373.59 carData 373.60 carbonate https://yonicd.github.io/carbonate/ https://carbon.now.sh/ 373.61 caTools 373.62 cellranger 373.63 checkmate 373.64 class 373.65 classInt 373.66 cli 373.67 clipr 373.68 clisymbols 373.69 clue 373.70 cluster 373.71 clv 373.72 cmaker 373.73 cmprsk 373.74 coauthornetwork 373.75 cobs 373.76 coda 373.77 CodeDepends 373.78 codetools 373.79 coin 373.80 colorspace 373.81 colourpicker 373.82 combinat 373.83 commonmark 373.84 compiler 373.85 conf.design 373.86 config 373.87 conflicted 373.88 contfrac 373.89 corpcor 373.90 covr 373.91 cowplot 373.92 coxme 373.93 cramer 373.94 crayon 373.95 cronR 373.96 crosstalk 373.97 csvy 373.98 curl 373.99 d3Network 373.100 data.table 373.101 data.tree 373.102 datapasta https://github.com/MilesMcBain/datapasta 373.103 datasets 373.104 date 373.105 DBI 373.106 dbplyr 373.107 debugme 373.108 Deducer 373.109 DeducerExtras 373.110 demography 373.111 dendextend 373.112 DEoptimR 373.113 depthTools 373.114 desc 373.115 descr1 373.116 DescTools 373.117 deSolve 373.118 devtools 373.119 DiagrammeR 373.120 DiceDesign 373.121 dichromat 373.122 digest 373.123 diptest 373.124 DoE.base 373.125 DoE.wrapper 373.126 doParallel 373.127 downloader 373.128 dplyr 373.129 DT 373.130 dtplyr 373.131 dunn.test 373.132 dygraphs 373.133 e1071 373.134 EcoVirtual 373.135 effects 373.136 effsize 373.137 ellipse 373.138 elliptic 373.139 emmeans 373.140 enc 373.141 ENmisc 373.142 Epi 373.143 epibasix 373.144 epiDisplay 373.145 epiR 373.146 epitools 373.147 errorist Automatic Error and Warning Search https://github.com/coatless/errorist 373.148 estimability 373.149 etm 373.150 evaluate 373.151 exact2x2 373.152 exactci 373.153 exactRankTests 373.154 experiment 373.155 expm 373.156 extrantsr 373.157 ez 373.158 FactoMineR 373.159 Fahrmeir 373.160 fansi 373.161 fastmatch 373.162 fBasics 373.163 fda 373.164 fdrtool 373.165 feather 373.166 ff 373.167 ffbase 373.168 finalfit 373.169 fit.models 373.170 fivethirtyeight 373.171 flashClust 373.172 flatxml 373.173 flexclust 373.174 flexmix 373.175 flextable 373.176 FNN 373.177 forcats 373.178 foreach 373.179 forecast 373.180 forecastHybrid 373.181 foreign 373.182 formatR 373.183 formattable 373.184 Formula 373.185 fpc 373.186 fracdiff 373.187 FrF2 373.188 fslr 373.189 fst 373.190 ftsa 373.191 gdata 373.192 gdtools 373.193 gee 373.194 getPass 373.195 GGally 373.196 ggcorrplot 373.197 ggdendro 373.198 ggExtra 373.199 ggforce 373.200 ggformula 373.201 ggfortify 373.202 ggm 373.203 ggplot2 373.204 ggplot2movies 373.205 ggpubr 373.206 ggraph 373.207 ggrepel 373.208 ggridges 373.209 ggsci 373.210 ggsignif 373.211 ggstance 373.212 ggstatsplot 373.213 ggthemes 373.214 ggvis 373.215 gh 373.216 git2r 373.217 glasso 373.218 glmmTMB 373.219 glue 373.220 gmailr 373.221 gmodels 373.222 gmp 373.223 gnm 373.224 googledrive https://googledrive.tidyverse.org/ 373.225 markdrive https://github.com/MilesMcBain/markdrive 373.226 googleVis 373.227 GPArotation 373.228 gplots 373.229 graph 373.230 graphics 373.231 graphTweets 373.232 grDevices 373.233 grid 373.234 gridExtra 373.235 gsl 373.236 gss 373.237 gtable 373.238 gtools 373.239 gWidgets 373.240 gWidgetstcltk 373.241 GWRM 373.242 h2o 373.243 hash 373.244 haven 373.245 hdrcde 373.246 hexbin 373.247 HH 373.248 highlight 373.249 highr 373.250 Hmisc 373.251 hms 373.252 htmlTable 373.253 htmltools 373.254 htmlwidgets 373.255 httpuv 373.256 httr 373.257 huge 373.258 hunspell 373.259 hypergeo 373.260 ICC 373.261 IRdisplay 373.262 IRkernel 373.263 ISLR 373.264 ISwR 373.265 ITKR 373.266 igraph 373.267 influenceR 373.268 ini 373.269 inline 373.270 ipred 373.271 irlba 373.272 irr 373.273 iterators 373.274 JavaGD 373.275 JGR 373.276 jmv 373.277 jmvcore 373.278 jmvconnect https://cran.r-project.org/package=jmvconnect 373.279 jomo 373.280 jose 373.281 jpeg 373.282 jsonlite 373.283 kableExtra 373.284 kernlab 373.285 KernSmooth 373.286 klaR 373.287 km.ci 373.288 KMsurv 373.289 knitr 373.290 kohonen 373.291 ks 373.292 labeling 373.293 labelled 373.294 Lahman 373.295 later 373.296 lattice 373.297 latticeExtra 373.298 lava 373.299 lavaan 373.300 lazyeval 373.301 leaps 373.302 lfstat 373.303 lhs 373.304 lintr 373.305 lisrelToR 373.306 lme4 373.307 lmerTest 373.308 lmom 373.309 lmomRFA 373.310 lmtest 373.311 locfit 373.312 loo 373.313 lpSolve 373.314 lubridate 373.315 MAd 373.316 magic 373.317 magicfor https://cran.r-project.org/web/packages/magicfor/vignettes/magicfor.html 373.318 magrittr 373.319 manipulate 373.320 manipulateWidget 373.321 mapproj 373.322 maps 373.323 maptools 373.324 markdown 373.325 MASS 373.326 Matrix 373.327 matrixcalc 373.328 MatrixModels 373.329 matrixStats 373.330 maxstat 373.331 MBESS 373.332 mc2d 373.333 mclust 373.334 memisc 373.335 memoise 373.336 meta 373.337 metafor 373.338 methods 373.339 mgcv 373.340 mi 373.341 mice http://www.stefvanbuuren.nl/mi/FIMD.html Flexible Imputation of Missing Data https://stefvanbuuren.name/fimd/ 373.342 microbenchmark 373.343 mime 373.344 miniUI 373.345 minpack.lm 373.346 minqa 373.347 misc3d 373.348 mitml 373.349 mixlm 373.350 mixOmics 373.351 mlbench 373.352 mnormt 373.353 modelr 373.354 modeltools 373.355 mosaic https://github.com/ProjectMOSAIC/mosaic/blob/master/vignettes/mosaic-resources.Rmd http://mosaic-web.org/ 373.356 mosaicCore 373.357 mosaicData 373.358 multcomp 373.359 multcompView 373.360 multicool 373.361 MuMIn 373.362 munsell 373.363 mvnormtest 373.364 mvtnorm 373.365 network 373.366 networkD3 373.367 neurobase 373.368 neuroim 373.369 nFactors 373.370 nleqslv 373.371 nlme 373.372 nloptr 373.373 NLP 373.374 nnet 373.375 nortest 373.376 nparLD 373.377 numbers 373.378 numDeriv 373.379 nycflights13 373.380 OceanView 373.381 officer 373.382 OpenMx 373.383 openssl 373.384 openxlsx 373.385 OptimClassifier 373.386 ordinal 373.387 orloca 373.388 orloca.es 373.389 oro.dicom 373.390 oro.nifti 373.391 packagefinder 373.392 packrat 373.393 pacman 373.394 pan 373.395 pander 373.396 papeR 373.397 parallel 373.398 party 373.399 pbapply 373.400 pbdZMQ 373.401 pbivnorm 373.402 pbkrtest 373.403 pcaPP 373.404 permute 373.405 phia 373.406 pillar 373.407 pkgbuild 373.408 pkgconfig 373.409 pkgload 373.410 PKI 373.411 plogr 373.412 plot3D 373.413 plot3Drgl 373.414 plotly 373.415 pls 373.416 plyr 373.417 PMCMR 373.418 png 373.419 popEpi 373.420 ppcor 373.421 prabclus 373.422 pracma 373.423 praise 373.424 prediction 373.425 prettydoc 373.426 prettyR 373.427 prettyunits 373.428 pROC 373.429 processx 373.430 prodlim 373.431 progress 373.432 promises 373.433 pspearman 373.434 psych 373.435 psycho 373.436 pubh 373.437 purrr 373.438 purrrlyr 373.439 pwr 373.440 qgraph 373.441 quadprog 373.442 quantmod 373.443 quantreg 373.444 questionr 373.445 qvcalc 373.446 R.cache 373.447 R.matlab 373.448 R.methodsS3 373.449 R.oo 373.450 R.utils 373.451 R2HTML 373.452 R6 373.453 rainbow 373.454 rainfreq 373.455 randomcoloR 373.456 randtests 373.457 ranger 373.458 RApiDatetime 373.459 rappdirs 373.460 rARPACK 373.461 raster 373.462 rattle 373.463 rCharts 373.464 rcmdcheck 373.465 Rcmdr 373.466 RcmdrMisc 373.467 RcmdrPlugin.aRnova 373.468 RcmdrPlugin.BCA 373.469 RcmdrPlugin.BiclustGUI 373.470 RcmdrPlugin.coin 373.471 RcmdrPlugin.depthTools 373.472 RcmdrPlugin.DoE 373.473 RcmdrPlugin.doex 373.474 RcmdrPlugin.EACSPIR 373.475 RcmdrPlugin.EBM 373.476 RcmdrPlugin.EcoVirtual 373.477 RcmdrPlugin.epack 373.478 RcmdrPlugin.Export 373.479 RcmdrPlugin.EZR 373.480 RcmdrPlugin.FactoMineR 373.481 RcmdrPlugin.FuzzyClust 373.482 RcmdrPlugin.GWRM 373.483 RcmdrPlugin.HH 373.484 RcmdrPlugin.IPSUR 373.485 RcmdrPlugin.KMggplot2 373.486 RcmdrPlugin.lfstat 373.487 RcmdrPlugin.MA 373.488 RcmdrPlugin.mosaic 373.489 RcmdrPlugin.MPAStats 373.490 RcmdrPlugin.NMBU 373.491 RcmdrPlugin.OptimClassifier 373.492 RcmdrPlugin.orloca 373.493 RcmdrPlugin.PcaRobust 373.494 RcmdrPlugin.plotByGroup 373.495 RcmdrPlugin.pointG 373.496 RcmdrPlugin.qual 373.497 RcmdrPlugin.RiskDemo 373.498 RcmdrPlugin.RMTCJags 373.499 RcmdrPlugin.ROC 373.500 RcmdrPlugin.sampling 373.501 RcmdrPlugin.SCDA 373.502 RcmdrPlugin.SLC 373.503 RcmdrPlugin.SM 373.504 RcmdrPlugin.sos 373.505 RcmdrPlugin.steepness 373.506 RcmdrPlugin.survival 373.507 RcmdrPlugin.sutteForecastR 373.508 RcmdrPlugin.TeachingDemos 373.509 RcmdrPlugin.temis 373.510 RcmdrPlugin.UCA 373.511 RColorBrewer 373.512 Rcpp 373.513 RcppArmadillo 373.514 RcppEigen 373.515 RCurl 373.516 readODS 373.517 readr 373.518 readstata13 373.519 readxl 373.520 RefManageR 373.521 relimp 373.522 rematch 373.523 rematch2 373.524 remotes 373.525 repr 373.526 reprex 373.527 reshape 373.528 reshape2 373.529 ResourceSelection 373.530 rex 373.531 rgexf 373.532 rgl 373.533 RGtk2 373.534 rhandsontable 373.535 RISmed 373.536 rio 373.537 rjags 373.538 rJava 373.539 rjson 373.540 RJSONIO 373.541 rlang 373.542 rmarkdown 373.543 rmatio 373.544 rmdformats 373.545 rmeta 373.546 Rmpfr 373.547 RMySQL 373.548 RNifti 373.549 robets 373.550 robust 373.551 robustbase 373.552 rockchalk 373.553 ROCR 373.554 Rook 373.555 roomba 373.556 roxygen2 373.557 rpart 373.558 rpart.plot 373.559 rpf 373.560 RPostgreSQL 373.561 rprojroot 373.562 rrcov 373.563 rsconnect 373.564 rsm 373.565 RSpectra 373.566 RSQLite 373.567 rstan 373.568 rstanarm 373.569 rstantools 373.570 rstudioapi 373.571 RStudioConsoleRender 373.572 rsvd 373.573 Rtsne 373.574 rtweet 373.575 runjags 373.576 RVAideMemoire 373.577 rversions 373.578 rvest 373.579 rvg https://github.com/davidgohel/rvg 373.580 s4vd 373.581 sampling 373.582 sandwich 373.583 scales 373.584 scatr 373.585 scatterplot3d 373.586 scholar 373.587 SCMA 373.588 SCRT 373.589 SCVA 373.590 sde 373.591 SDMTools 373.592 selectr 373.593 sem 373.594 SemiCompRisks 373.595 semPlot 373.596 semTools 373.597 sendmailR 373.598 servr 373.599 sessioninfo 373.600 sf 373.601 sfsmisc 373.602 shape 373.603 shiny 373.604 shinyFiles 373.605 shinyjs 373.606 shinystan 373.607 shinythemes 373.608 sjlabelled 373.609 sjmisc 373.610 sjstats 373.611 skimr 373.612 slam 373.613 SLC 373.614 Sleuth2 373.615 smcure 373.616 sna 373.617 snakecase 373.618 som 373.619 sos 373.620 sourcetools 373.621 sp 373.622 sparklyr 373.623 SparseM 373.624 spatial 373.625 spData 373.626 splines 373.627 splitstackshape 373.628 SQUAREM 373.629 ssanv 373.630 ssgraph 373.631 stabledist 373.632 StanHeaders 373.633 stapler 373.634 stargazer 373.635 statisticalModeling 373.636 statnet.common 373.637 stats 373.638 stats4 373.639 steepness 373.640 stencila 373.641 stringdist 373.642 stringi 373.643 stringr 373.644 strucchange 373.645 styler 373.646 superbiclust 373.647 SuppDists 373.648 survey 373.649 survival 373.650 survminer 373.651 survMisc 373.652 sutteForecastR 373.653 svglite 373.654 tableone https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html 373.655 tables 373.656 tabplot 373.657 tangram https://github.com/spgarbet/tangram https://cran.r-project.org/web/packages/tangram/index.html https://cran.r-project.org/web/packages/tangram/vignettes/summary-example.html Global Style for Rmd Example \\```{r, results='asis'} cat(custom_css(\"lancet.css\")) ``` .figbody thead { background: #aaffff !important; } .figbody tbody .odd { background: #aaffff !important; } https://cran.r-project.org/web/packages/tangram/vignettes/fda-example.html https://cran.r-project.org/web/packages/tangram/vignettes/example.html https://cran.r-project.org/web/packages/tangram/vignettes/single-style.html 373.658 tcltk 373.659 tcltk2 373.660 TeachingDemos 373.661 testit 373.662 testthat 373.663 TH.data 373.664 threejs 373.665 tibble 373.666 tidybayes Bayesian analysis + tidy data + geoms http://mjskay.github.io/tidybayes/ 373.667 tidygraph 373.668 tidyr 373.669 tidyselect 373.670 tidyverse 373.671 timeDate 373.672 timeSeries 373.673 tinytex 373.674 tkrplot 373.675 tm 373.676 TMB 373.677 tools 373.678 tree 373.679 triebeard 373.680 trimcluster 373.681 tseries 373.682 TTR 373.683 tufterhandout 373.684 tutorial 373.685 tweenr 373.686 ucminf 373.687 units 373.688 updateR 373.689 urca 373.690 urltools 373.691 uroot 373.692 userfriendlyscience 373.693 usethis 373.694 utf8 373.695 utils 373.696 uuid 373.697 V8 373.698 vcd 373.699 vcdExtra 373.700 vegan 373.701 VGAM 373.702 ViewPipeSteps https://github.com/daranzolin/ViewPipeSteps 373.703 viridis 373.704 viridisLite 373.705 visdat 373.706 visNetwork 373.707 visreg 373.708 wbstats 373.709 webshot 373.710 whisker 373.711 WhiteStripe 373.712 withr 373.713 wordcloud 373.714 workflowr 373.715 writexl 373.716 WRS2 373.717 xfun 373.718 XLConnect 373.719 XLConnectJars 373.720 xlsx 373.721 xlsxjars 373.722 XML 373.723 xml2 373.724 xplain 373.725 xray 373.726 xtable 373.727 xts 373.728 yaImpute 373.729 yaml 373.730 zip 373.731 zoo 373.732 Effsize a package for efficient effect size computation https://github.com/mtorchiano/effsize 373.733 keyring https://www.infoworld.com/video/91987/r-tip-keep-passwords-and-tokens-secure-with-the-keyring-package 373.734 testthat R tip: Test your code with testthat https://www.infoworld.com/video/87735/r-tip-test-your-code-with-testthat 373.735 cronR Schedule R scripts on a Mac https://www.infoworld.com/video/90629/r-tip-schedule-r-scripts-on-a-mac https://www.r-bloggers.com/creating-custom-sankey-diagrams-using-r/ https://plot.ly/r/sankey-diagram/ https://cran.r-project.org/web/packages/riverplot/riverplot.pdf "],["classification-and-regression-training.html", "Chapter 374 Classification And REgression Training 374.1 Calculate Sensitivity, Specificity And Predictive Values", " Chapter 374 Classification And REgression Training http://topepo.github.io/caret/index.html 374.1 Calculate Sensitivity, Specificity And Predictive Values https://www.rdocumentation.org/packages/caret/versions/3.51/topics/sensitivity sensitivity(data, reference, positive = levels(reference)[1]) specificity(data, reference, negative = levels(reference)[2]) posPredValue(data, reference, positive = levels(reference)[1]) negPredValue(data, reference, negative = levels(reference)[2]) Some notes on my first shiny app https://ggvy.cl/post/some-notes-on-my-first-shiny-app/ "],["shiny-online-documentation.html", "Chapter 375 Shiny Online Documentation", " Chapter 375 Shiny Online Documentation https://shiny.rstudio.com "],["mastering-shiny.html", "Chapter 376 Mastering Shiny 376.1 summarytool’s Core Functions 376.2 1 - freq() : Frequency Tables 376.3 2 - ctable() : Cross-Tabulations 376.4 3 - descr() : Descriptive Univariate Stats 376.5 4 - dfSummary() : Data Frame Summaries 376.6 The print() and view() Functions 376.7 Using by() to Show Results By Groups 376.8 Using lapply() to Show Several freq() tables at once 376.9 Using summarytools in Rmarkdown documents 376.10 Writing Output to Files 376.11 Global options 376.12 Overriding formatting attributes 376.13 Order of Priority for Options / Parameters 376.14 Customizing looks with CSS 376.15 Working with shiny apps 376.16 Getting Most Properties of an Object With what.is() 376.17 Limitations 376.18 Stay Up-to-date", " Chapter 376 Mastering Shiny https://mastering-shiny.org/ http://blog.schochastics.net/post/an-rstudio-addin-for-network-analysis-and-visualization/ summarytools is an R package providing tools to neatly and quickly summarize data. It can also make R a little easier to learn and use. Four functions are at the core of the package: freq() : frequency tables with proportions, cumulative proportions and missing data information. ctable() : cross-tabulations between two factors or any discrete data, with total, rows or columns proportions, as well as marginal totals. descr() : descriptive (univariate) statistics for numerical data. dfSummary() : Extensive data frame summaries that facilitate data cleaning and firsthand evaluation. An emphasis has been put on both what and how results are presented, so that the package can serve both as a data exploration and reporting tool, which can be used either on its own for minimal reports, or along with larger sets of tools such as RStudio’s for rmarkdown, and knitr. Building on the strengths of pander and htmltools, the outputs produced by summarytools can be: Displayed in plain text in the R console (default behaviour) Used in Rmardown documents and knitted along with other text and R output Written to html files that fire up in RStudio’s Viewer pane or in your system’s default browser Written to plain text files / Rmarkdown text files 376.0.1 Latest Improvements Version 0.8.3 brings several improvements to summarytools, notably: Introduction of global settings (customizable defaults) Options to make content fit more naturally in shiny apps or Rmarkdown documents A better handling of “split-group” statistics with by() A more thorough documentation 376.1 summarytool’s Core Functions 376.2 1 - freq() : Frequency Tables The freq() function generates a table of frequencies with counts and proportions. Since this page use markdown rendering, we’ll set style = 'rmarkdown' to take advantage of it. If we do not worry about missing data, we can set {r # eport.nas = FALSE: We could simplify further and omit the Totals row by setting totals = FALSE. To get familiar with the output styles, try different values for style= and see how results look in the console. 376.3 2 - ctable() : Cross-Tabulations We’ll now use a sample data frame called tobacco, which is included in the package. We want to cross-tabulate the two categorical variables smoker and diseased. By default, ctable() gives row proportions, but we’ll include the full syntax anyway. Since markdown has not support (yet) for multi-line headings, we’ll show an image of the resulting html table. Notice that instead of ctable(tobacco$smoker, tobacco$diseased, ...), we used the with() function, making the syntax less redundant. It is possible to display column, total, or no proportions at all. We can also omit the marginal totals to have a simple “2 x 2” table. 376.4 3 - descr() : Descriptive Univariate Stats The descr() function generates common central tendency statistics and measures of dispersion for numerical data. It can handle single vectors as well as data frames, in which case it just ignores non-numerical columns (and displays a message to that effect). 376.4.1 Transposing and selecting only the stats you need If your eyes/brain prefer seeing things the other way around, just use transpose = TRUE. Here, we also select only the statistics we wish to see, and specify headings = TRUE to avoid reprinting the same information as above. 376.5 4 - dfSummary() : Data Frame Summaries dfSummary() collects information about all variables in a data frame and displays it in a singe, legible table. To generate a summary report and have it displayed in RStudio’s Viewer pane (or in your default Web Browser if working with another interface), we simply do like this: view(dfSummary(iris)) It is also possible to use dfSummary() in Rmarkdown documents. In this next example, note that due to rmarkdown compatibility issues, histograms are not shown. We’re working on this. Further down, we’ll see how tu use html rendering to go around this problem. 376.6 The print() and view() Functions summarytools has a generic print method, print.summarytools(). By default, its method argument is set to 'pander'. One of the ways in which view() is useful is that we can use it to easily display html outputs in RStudio’s Viewer. In this case, the view() function simply acts as a wrapper around the generic print() function, specifying the method = 'viewer' for us. When used outside RStudio, the method falls back on 'browser' and the report is fired up in the system’s default browser. 376.7 Using by() to Show Results By Groups With freq() and descr(), you can use R’s base function by() to show statistics split by a ventilation / categorical variable. R’s by() function returns a list containing as many summarytools objects as there are categories in our ventilation variable. To propertly display the content present in that list, we use the view() function. Using print(), while technically possible, will not give as much satisfactory results. 376.7.0.1 Example Using the iris data frame, we will display descriptive statistics broken down by Species. To see an html version of these results, we’d simply do this (results not shown): view(iris_stats_by_species) 376.7.1 Special Case - Using descr() With by() For A Single Variable Instead of showing several tables having only one column each, the view() function will assemble the results into a single table: The transposed version looks like this: 376.8 Using lapply() to Show Several freq() tables at once As is the case for by(), the view() function is essential for making results nice and tidy. tobacco_subset &lt;- tobacco[, c(&quot;gender&quot;, &quot;age.gr&quot;, &quot;smoker&quot;)] freq_tables &lt;- lapply(tobacco_subset, freq) view(freq_tables, footnote = NA, file = &quot;freq-tables.html&quot;) 376.9 Using summarytools in Rmarkdown documents As we have seen, summarytools can generate both text (including rmarkdown) and html results. Both can be used in Rmarkdown, according to your preferences. There is a vignette dedicated to this, which gives several examples, but if you’re in a hurry, here are a few tips to get started: Always set the knitr chunk option {r # esults = 'asis'. You can do this on a chunk-by-chunk basis, but here is how to do it globally: knitr::opts_chunk$set(echo = TRUE, results = &#39;asis&#39;) Refer to this page for more on knitr’s options. To get better results when using html (with method = 'render'), set up your .Rmd document so it includes summarytool’s css. 376.9.0.1 Example # --- # title: &quot;RMarkdown using summarytools&quot; # output: # html_document: # css: C:/R/win-library/3.4/summarytools/includes/stylesheets/summarytools.css # --- For more details on using summarytools in Rmarkdown documents, please refer to the corresponding vignette. 376.10 Writing Output to Files The console will always tell you the location of the temporary html file that is created in the process. However, you can specify the name and location of that file explicitly if you need to reuse it later on: view(iris_stats_by_species, file = &quot;~/iris_stats_by_species.html&quot;) Based on the file extension you provide (.html vs others), summarytools will use the appropriate method; there is no need to specify the method argument. 376.10.1 Appending output files There is also an append = logical argument for adding content to existing reports, both text/Rmarkdown and html. This is useful if you want to quickly include several statistical tables in a single file. It is fast alternative to creating an .Rmd document if you don’t need the extra content that the latter allows. 376.11 Global options Version 0.8.3 introduced the following set of global options: {r # ound.digits = 2 plain.ascii = TRUE headings = FALSE (if using in a markdown document or a shiny app, setting this to TRUE might be preferable footnote = 'default' (set to empty string or NA to omit footnote) display.labels = TRUE freq.totals = TRUE freq.display.nas = TRUE ctable.totals = TRUE ctable.prop = 'r' (display row proportions by default) descr.stats = 'all' descr.transpose = FALSE bootstrap.css = TRUE (if using in a markdown document or a shiny app, setting this to FALSE might be preferable custom.css = NA escape.pipe = FALSE 376.11.0.1 Examples st_options() # display all global options&#39; values st_options(&quot;round.digits&quot;) # display only one option st_options(&quot;headings&quot;, TRUE) # change an option&#39;s value st_options(&quot;footnote&quot;, NA) # Turn off the footnote on all outputs. # This option was used prior to generating the present document. 376.12 Overriding formatting attributes When a summarytools object is stored, its formatting attributes are stored with it. However, you can override most of them when using the print() and view() functions. 376.12.0.1 Example Note that the omitted attributes are stil part of the age_stats object. 376.13 Order of Priority for Options / Parameters Options over-ridden explicitly with print() or view() have precendence options specified as explicit arguments to freq() / ctable() / descr() / dfSummary() come second Global options, which can be set with st_options, come third 376.14 Customizing looks with CSS Version 0.8 of summarytools uses RStudio’s htmltools package and version 4 of Bootstrap’s cascading stylesheets. It is possible to include your own css if you wish to customize the look of the output tables. See the documentation for the package’s print.summarytools() function for details, but here is a quick example to give you the gist of it. 376.14.0.1 Example Say you need to make the font size really small, smaller than by using the st-small class as seen in a previous example. For this, you would create a CSS file - let’s call it “custom.css” - containing a class such as the following: .table-condensed { font-size: 8px; } Then, to apply it to a summarytools object and display it in your browser: view(dfSummary(tobacco), custom.css = &quot;path/to/custom.css&quot;, table.classes = &quot;table-condensed&quot;) 376.15 Working with shiny apps To include summarytools functions into shiny apps, it is recommended that you: set bootstrap.css = FASE to avoid interacting with the app’s layout adjust the size of the graphs in dfSummary() set headings to TRUE 376.15.0.1 Example {r # print(dfSummary(somedata, graph.magnif = 0.8), method = 'render', headings = TRUE, bootstrap.css = FALSE) 376.16 Getting Most Properties of an Object With what.is() When developing, we often use a number of functions to obtain an object’s properties. what.is() proposes to lump together the results of most of these functions (class(), typeof(), attributes() and others). what.is(iris) Checking object against known &#39;is...&#39; functions (59) $properties property value 1 class data.frame 2 typeof list 3 mode list 4 storage.mode list 5 dim 150 x 5 6 length 5 7 is.object TRUE 8 object.type S3 9 object.size 7256 Bytes $attributes.lengths names class row.names 5 1 150 $extensive.is [1] &quot;is.data.frame&quot; &quot;is.list&quot; &quot;is.object&quot; &quot;is.recursive&quot; [5] &quot;is.unsorted&quot; 376.17 Limitations The text histograms in dfSummary are not yet supported in {r # markdown. Better use the ‘render’ method. It is not possible to control the heading levels of individual items. You can however choose to headings altogether. 376.18 Stay Up-to-date Check out the project’s page - from there you can see the latest updates and also submit feature requests. To install the version of summarytools that is on CRAN, but that might have benefited from quick fixes: {r # install.packages('devtools') library(devtools) install_github('dcomtois/summarytools') To install the package in its development version, use {r # install_github('dcomtois/summarytools', ref='dev-current') "],["final-notes.html", "Chapter 377 Final notes 377.1 Important Note 377.2 Using method = ‘render’", " Chapter 377 Final notes The package comes with no guarantees. It is a work in progress and feedback / feature requests are welcome. Just send me an email (dominic.comtois (at) gmail.com), or open an Issue on GitHub if you find a bug. This document uses theme {r # markdown::html_vignette. Below are examples using recommended styles for Rmarkdown rendering. Available styles in summarytools are the same as pander’s: simple (default) rmarkdown grid multiline For freq(), descr() (and ctable(), although with caveats), rmarkdown style is recommended. For dfSummary(), grid is recommended. 377.1 Important Note knitr option {r # esults = 'asis' must be specified to get good results. This can be done globally via opts_chunk$set(results='asis'), or in the individual chunks. The following summarytools global options have been set: 377.2 Using method = ‘render’ To generate tables using summarytool’s own html rendering, the .Rmd document’s configuration part (yaml) must point to the package’s summarytools.css file. This can be achieved in several ways; the current vignette uses this configuration: output: rmarkdown::html_vignette: css: - !expr system.file(&quot;rmarkdown/templates/html_vignette/resources/vignette.css&quot;, package = &quot;rmarkdown&quot;) - !expr system.file(&quot;includes/stylesheets/summarytools.css&quot;, package = &quot;summarytools&quot;) An alternative is to point to the directory on your system containing summarytools.css: --- title: &quot;RMarkdown using summarytools&quot; output: html_document: css: C:/R/win-library/3.4/summarytools/includes/stylesheets/summarytools.css --- Starting with freq(), we’ll review the recommended methods and styles to get going with summarytools in Rmarkdown documents. Jump to… ctable() descr() dfSummary() "],["freq.html", "Chapter 378 freq() 378.1 Rmarkdown Style 378.2 HTML Rendering", " Chapter 378 freq() freq() is best used with `style = ‘rmarkdown’; html rendering is also possible. 378.1 Rmarkdown Style 378.2 HTML Rendering If you find the table too large, you can use table.classes = 'st-small' - an example is provided further below. Back to top "],["ctable.html", "Chapter 379 ctable() 379.1 Rmarkdown Style 379.2 HTML Rendering", " Chapter 379 ctable() 379.1 Rmarkdown Style Tables with heading spanning over 2 rows are not fully supported in markdown (yet), but the result is getting close to acceptable. 379.2 HTML Rendering For best results, use this method. Back to top "],["descr3.html", "Chapter 380 descr() 3 380.1 Rmarkdown Style 380.2 HTML Rendering", " Chapter 380 descr() 3 descr() is also best used with style = 'rmarkdown', and HTML rendering is also supported. 380.1 Rmarkdown Style 380.2 HTML Rendering We’ll use table.classes = ‘st-small’ to show how it affects the table’s size (compare to the freq() table rendered earlier). Back to top "],["dfsummary.html", "Chapter 381 dfSummary() 381.1 Grid Style 381.2 HTML Rendering", " Chapter 381 dfSummary() 381.1 Grid Style This gives good results, although the histograms are not shown. This has to do with an unresolved issue, but we’re working hard to figure out a solution. Don’t forget to specify plain.ascii = FALSE, or you won’t get good results. dfSummary(tobacco, style = &quot;grid&quot;, plain.ascii = FALSE) Table 381.1: NoVariableStats / ValuesFreqs (% of Valid)Graphtext.graphValidMissing 1gender\\[factor]1\\. F\\2\\. M\\489 (50.0%)\\\\489 (50.0%)&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAFgAAAA3CAQAAAAiPkUwAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAAAiklEQVRo3u3YMQ6AIAxG4dZ4R+/gffQOnFJXMLKQAP3Je1sX8g1dqD+m1TYbADhaez7cQRf69ArY7Jht+ykVk9xKAAYMGDBgwIBDBRgwYMCLgT9/utT2ysA8/yh78zN9y41yKyEHLnb4CnpIMQ4pAwMMGDBgwIABhwowYMCAFwNrH1IUklsJwL17AbI4C1zud1IRAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwJsJ/TwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMFefx/MAAAA9dEVYdGljYzpjb3B5cmlnaHQAQ29weXJpZ2h0IDIwMDcgQXBwbGUgSW5jLiwgYWxsIHJpZ2h0cyByZXNlcnZlZC6eZtwpAAAAI3RFWHRpY2M6ZGVzY3JpcHRpb24AR2VuZXJpYyBSR0IgUHJvZmlsZRqnOI4AAAAASUVORK5CYII=\"&gt;IIIIIIIIII \\ IIIIIIIIII978\\(97.8%)22\\(2.2%) 2age\\[numeric]Mean (sd) : 49.6 (18.3)\\min &lt; med &lt; max:\\18 &lt; 50 &lt; 80\\IQR (CV) : 32 (0.4)63 distinct values&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuCAQAAABxABKuAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAABqElEQVR42u3cXU7CQBhAUWvco3vQ9eAeXKW+Vi2Bw48zJfe8SSKBy7T92hSWr6eI59EvYG8KhgqGXtZ/LKNfzV0cNnfT7/Bm10/wcv6/7dfrn0c+L36ufwh2OHIgls94Hv+ywl43Hrv8Mx6rnT4qGCoYKhgqGNrpHHYYds3g4mDXz8/X2R5V7j/AXLHCbjk/z+Houl0tgzOCjVv+97T9rk6v0LNW2CNN6te+p46SqGCoYKhgqGDoxpP+Y44gazcO9ogDyE8DzyW3VuP8l60HBtvnqVU7fTTZ5Z3R10BOmyzY/AeNNklUMFQwVDA02U5/20wnXLsINtOI2yaJCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoZ+3Cow0z0Ms/p1b8X8dwCO1iaJCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoYKhgqGCoaW9bdlPvrqzKa31Y+HLzUybZKoYKhg6BvI0CkKx+5FawAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMCbCf08AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjAtMTItMTJUMjA6MTU6MTMrMDA6MDBXn8fzAAAAPXRFWHRpY2M6Y29weXJpZ2h0AENvcHlyaWdodCAyMDA3IEFwcGxlIEluYy4sIGFsbCByaWdodHMgcmVzZXJ2ZWQunmbcKQAAACN0RVh0aWNjOmRlc2NyaXB0aW9uAEdlbmVyaWMgUkdCIFByb2ZpbGUapziOAAAAAElFTkSuQmCC\"&gt;\\. \\ \\ \\ \\ . \\ \\ \\ \\ . . . :\\: : : : : . : : : :\\: : : : : : : : : :\\: : : : : : : : : :\\: : : : : : : : : :975\\(97.5%)25\\(2.5%) 3age.gr\\[factor]1\\. 18-34\\2\\. 35-50\\3\\. 51-70\\4\\. 71 +\\258 (26.5%)\\\\241 (24.7%)\\\\317 (32.5%)\\\\159 (16.3%)&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAD0AAABmCAQAAADSIlFWAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAAAu0lEQVRo3u3Yyw2AIBBFUTH0aBHUoz1YpW4HjAGUzyRzZ6cknsXD5IG7llmzTpON0l4+HI2DDy59IwEfL20N4TOzbjNraGhoaGhoaP10UpBypablOFnU3OfPlI7UyHrZG/bwkE2vUw8v2a42s4aGhoaGhobWT9PDB49NutsR4GXEdup4Ff+c+P+xmTU0NDQ0NDS0fpojwODRknV9D89fuBfStT3836a0mTU0NDQ0NDS0flpLDx87NrOeSN85XBgUiroJAwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMCbCf08AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjAtMTItMTJUMjA6MTU6MTMrMDA6MDBXn8fzAAAAPXRFWHRpY2M6Y29weXJpZ2h0AENvcHlyaWdodCAyMDA3IEFwcGxlIEluYy4sIGFsbCByaWdodHMgcmVzZXJ2ZWQunmbcKQAAACN0RVh0aWNjOmRlc2NyaXB0aW9uAEdlbmVyaWMgUkdCIFByb2ZpbGUapziOAAAAAElFTkSuQmCC\"&gt;IIIII \\ IIII \\ IIIIII \\ III975\\(97.5%)25\\(2.5%) 4BMI\\[numeric]Mean (sd) : 25.7 (4.5)\\min &lt; med &lt; max:\\8.8 &lt; 25.6 &lt; 39.4\\IQR (CV) : 5.7 (0.2)974 distinct values&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuCAQAAABxABKuAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAABtklEQVR42u3cy63CMBQAUYLokR6gHuiBKmHDwtiIaPKxfc2cXTZP0YhLEju86XkQcWx9AtEYDDIYdEoPptZnk7gVX67XZqeXnspp8V/Z3fnj6NH6dN4cSchgkMEgg0EGgwwGGQwyGGQwyGCQwSCDQR0/fOf6WL8IFOycHbdZv3AkoU4+YbcwezGdBOtl4OY5kpDBIINBBoMMBhkMMhhkMMhgkMEgg0EGgwwGGQwyGGQwyGCQwSCDQQaDDAYZDOpmm22JfDezxqsDoYO1+OmDIwkZDDIYZDCoyZd+nHd1So2uklHe1Sk5kpDBIINBoe/0czXesx4qWI1LiSMJGQwyGGQwyGCQwSCDQQaDDAYZDDIYZDDIYJDBIINBBoMMBhkMqrJEHXnjNldpTb/P/8m6hCMJDbVrVNp+423wYNtvvDmSkMEgg0EGgwwGGQwyGGQwyGDQDnf6I61NlHZ5NIr7Uvk8RxIyGDT4akVp7Y9S/y7Y2rVfRxIyGGQwyGCQwaDVV8noD0J0X2mD24rYD0Ll2X/5CCQJ/+4+bN7vD8BHsOjjVcOUNrob7KtLMpKTjRhvKyCDQQaDXtw9LRTdb6Y+AAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwJsJ/TwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMFefx/MAAAA9dEVYdGljYzpjb3B5cmlnaHQAQ29weXJpZ2h0IDIwMDcgQXBwbGUgSW5jLiwgYWxsIHJpZ2h0cyByZXNlcnZlZC6eZtwpAAAAI3RFWHRpY2M6ZGVzY3JpcHRpb24AR2VuZXJpYyBSR0IgUHJvZmlsZRqnOI4AAAAASUVORK5CYII=\"&gt;\\\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ :\\\\ \\ \\ \\ \\ \\ \\ \\ : : :\\\\ \\ \\ \\ \\ \\ \\ \\ : : :\\\\ \\ \\ \\ \\ \\ : : : : :\\\\ \\ \\ \\ . : : : : : .974\\(97.4%)26\\(2.6%) 5smoker\\[factor]1\\. Yes\\2\\. No\\298 (29.8%)\\\\702 (70.2%)&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAHYAAAA3CAQAAABzqnZTAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAAAoElEQVRo3u3ZQQ5AQAxAUSPu6BDOwx2ckm3HVkbl9/+dWPCSjkW1a6rTnP0CYsW+b4kXx7ADvLUsYCQt/a11yAPPLOmjUmMslppYamKpiaUmlppYamKpiaUmltpjB/WXbdGYWty+pa0ABxZ9pca4FLY7szvxL1c4m58syfPqP7ilxlgsNbHUxFITS00sNbHUxFITS00stbpLcnqlxlgstRvzMQxcS8hrcgAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMCbCf08AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjAtMTItMTJUMjA6MTU6MTMrMDA6MDBXn8fzAAAAPXRFWHRpY2M6Y29weXJpZ2h0AENvcHlyaWdodCAyMDA3IEFwcGxlIEluYy4sIGFsbCByaWdodHMgcmVzZXJ2ZWQunmbcKQAAACN0RVh0aWNjOmRlc2NyaXB0aW9uAEdlbmVyaWMgUkdCIFByb2ZpbGUapziOAAAAAElFTkSuQmCC\"&gt;IIIII \\ IIIIIIIIIIIIII1000\\(100.0%)0\\(0.0%) 6cigs.per.day\\[numeric]Mean (sd) : 6.8 (11.9)\\min &lt; med &lt; max:\\0 &lt; 0 &lt; 40\\IQR (CV) : 11 (1.8)37 distinct values&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJgAAABuCAQAAABxABKuAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAABaElEQVR42u3dy22DQBRAUYjo0T0k9Tg9uEpnS7JhjgMmVu7ZWRZouMNn+eb7FPF29gJeTcFQwdCy/vE59EL7mM9e9LOtsyzf/7psHnw7e/Un65FEBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDBUMFQwVDy+9P8dN1YCTe6w7EOyDY9ki8vzMQb2Rzp2labe8hwZ51KVv36cg5dN7hA8EGd+XwS7kNnGX/e/2BYHssYp85lmc8+n0lUcFQwdC8fm+ODRX+f95XX+O5RqZHEhUMFQx9AeUgHMrg0as9AAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwJsJ/TwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMFefx/MAAAA9dEVYdGljYzpjb3B5cmlnaHQAQ29weXJpZ2h0IDIwMDcgQXBwbGUgSW5jLiwgYWxsIHJpZ2h0cyByZXNlcnZlZC6eZtwpAAAAI3RFWHRpY2M6ZGVzY3JpcHRpb24AR2VuZXJpYyBSR0IgUHJvZmlsZRqnOI4AAAAASUVORK5CYII=\"&gt;\\:\\:\\:\\:\\: \\ \\ . . . . . .965\\(96.5%)35\\(3.5%) 7diseased\\[factor]1\\. Yes\\2\\. No\\224 (22.4%)\\\\776 (77.6%)&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAIEAAAA3CAQAAACBOuGzAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAAAq0lEQVRo3u3ZQQqEMAwF0FS84xxizuPcYU6p21RciBZK6fs7EcQ8SBZJ2WP2LL1/oH8QIIhY88OvwWD4lt4l3UkudK1ffV5++t+7tgfRCAgQIECAAAECBAgQIECAAAECBAgQXOS0Oxxx9/c2Je9Sh1j+NkmuWiMgOM2CbZ4ba+r5xqeUMVIPfY2AAAECBAgQIECAAAECBAgQIECAAMFFnFLqU8qc0QgIEETEARxmDFzppUJdAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwJsJ/TwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMFefx/MAAAA9dEVYdGljYzpjb3B5cmlnaHQAQ29weXJpZ2h0IDIwMDcgQXBwbGUgSW5jLiwgYWxsIHJpZ2h0cyByZXNlcnZlZC6eZtwpAAAAI3RFWHRpY2M6ZGVzY3JpcHRpb24AR2VuZXJpYyBSR0IgUHJvZmlsZRqnOI4AAAAASUVORK5CYII=\"&gt;IIII \\ IIIIIIIIIIIIIII1000\\(100.0%)0\\(0.0%) 8disease\\[character]1\\. Hypertension\\2\\. Cancer\\3\\. Cholesterol\\4\\. Heart\\5\\. Pulmonary\\6\\. Musculoskeletal\\7\\. Diabetes\\8\\. Hearing\\9\\. Digestive\\10\\. Hypotension\\[ 3 others ]\\36 (16.2%)\\\\34 (15.3%)\\\\21 ( 9.5%)\\\\20 ( 9.0%)\\\\20 ( 9.0%)\\\\19 ( 8.6%)\\\\14 ( 6.3%)\\\\14 ( 6.3%)\\\\12 ( 5.4%)\\\\11 ( 5.0%)\\\\21 ( 9.5%)&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAACUAAAELCAQAAAD0Rod6AAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAABC0lEQVR42u3bQW7CQAxA0Zmqd+wd4DztHTgl3Ua0ydiIKJ7wvGORJ8WW8lf0e3vVfLxMKkp9Ln/8pBd36StUa18p6LbXC6JQKNQbUg8f5NtzSmuttb4sQ08/vnx6gl19Jzt47atUroOPJ6q5KxQKhZqF0sH4JDp47Qlqq4Pjg9TcFQqFQs1C6WB8wh0cVTDcwcg5au4KhUKhdqXE6xBKB1EoFKoIpYPxES8UCoU6H6WD8Rl2cNy/f6m/HcycoeauUCgUahZKB+OjgygUCnU+SgfjM+hgvIKDDuaOUHNXKBQKNQulg/HZ7GCmgpsdzJ6g5q5QKBRqV0q8DqH86Q+FQqGKUHt1sMwL1qR+AeANQIR95RuZAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwJsJ/TwAAACV0RVh0ZGF0ZTptb2RpZnkAMjAyMC0xMi0xMlQyMDoxNToxMyswMDowMFefx/MAAAA9dEVYdGljYzpjb3B5cmlnaHQAQ29weXJpZ2h0IDIwMDcgQXBwbGUgSW5jLiwgYWxsIHJpZ2h0cyByZXNlcnZlZC6eZtwpAAAAI3RFWHRpY2M6ZGVzY3JpcHRpb24AR2VuZXJpYyBSR0IgUHJvZmlsZRqnOI4AAAAASUVORK5CYII=\"&gt;III \\ III \\ I \\ I \\ I \\ I \\ I \\ I \\ I \\ \\ I222\\(22.2%)778\\(77.8%) 9samp.wgts\\[numeric]Mean (sd) : 1 (0.1)\\min &lt; med &lt; max:\\0.9 &lt; 1 &lt; 1.1\\IQR (CV) : 0.2 (0.1)0.86!: 267 (26.7%)\\1.04!: 249 (24.9%)\\1.05!: 324 (32.4%)\\1.06!: 160 (16.0%)\\! rounded&lt;img style=\"border:none;background-color:transparent;padding:0\" src=\"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAD0AAABmCAQAAADSIlFWAAAAAmJLR0QA/4ePzL8AAAAHdElNRQfkDAwUDw0sIcpTAAAAvElEQVRo3u3Yyw2AIBBFUcfQo0VYj/ZglbodTBREPpPMfTtiwlk8TAbknEZlHiY7pYNe7NWLXyVeayDEn5aq8PH61WfX0NDQ0NDQ0Pbp24B0lO1SFNGDmhRvkxut0fW0VZzD12R7jebwnOPqs2toaGhoaGho+zRzeOf4pJtdAR6ijlPTp/h74v/HZ9fQ0NDQ0NDQ9mmuAJ1jpevvc3j6wT2T/jqH/zuUPruGhoaGhoaGtk9bmcP7xmfXA+kLNzIYFPix1vAAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjAtMTItMTJUMjA6MTU6MTMrMDA6MDAmwn9PAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIwLTEyLTEyVDIwOjE1OjEzKzAwOjAwV5/H8wAAAD10RVh0aWNjOmNvcHlyaWdodABDb3B5cmlnaHQgMjAwNyBBcHBsZSBJbmMuLCBhbGwgcmlnaHRzIHJlc2VydmVkLp5m3CkAAAAjdEVYdGljYzpkZXNjcmlwdGlvbgBHZW5lcmljIFJHQiBQcm9maWxlGqc4jgAAAABJRU5ErkJggg==\"&gt;IIIII \\ IIII \\ IIIIII \\ III \\ \\1000\\(100.0%)0\\(0.0%) 381.2 HTML Rendering Although the results are not as neat as they are when simply generating an html report from the R interpreter – the transparency of the graphs is lost in translation –, this is the best method still. Back to top background-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg) ??? Image credit: Wikimedia Commons class: inverse, center, middle "],["get-started-1.html", "Chapter 382 Get Started", " Chapter 382 Get Started "],["hello-world-1.html", "Chapter 383 Hello World", " Chapter 383 Hello World Install the xaringan package from Github: devtools::install_github(&quot;yihui/xaringan&quot;) – You are recommended to use the RStudio IDE, but you do not have to. Create a new R Markdown document from the menu File -&gt; New File -&gt; R Markdown -&gt; From Template -&gt; Ninja Presentation;1 – Click the Knit button to compile it; – or use the RStudio Addin2 “Infinite Moon Reader” to live preview the slides (every time you update and save the Rmd document, the slides will be automatically reloaded in RStudio Viewer. .footnote[ [1] 中文用户请看这份教程 [2] See #2 if you do not see the template or addin in RStudio. ] "],["hello-ninja-1.html", "Chapter 384 Hello Ninja", " Chapter 384 Hello Ninja As a presentation ninja, you certainly should not be satisfied by the “Hello World” example. You need to understand more about two things: The remark.js library; The xaringan package; Basically xaringan injected the chakra of R Markdown (minus Pandoc) into remark.js. The slides are rendered by remark.js in the web browser, and the Markdown source needed by remark.js is generated from R Markdown (knitr). "],["remark-js-1.html", "Chapter 385 remark.js", " Chapter 385 remark.js You can see an introduction of remark.js from its homepage. You should read the remark.js Wiki at least once to know how to create a new slide (Markdown syntax* and slide properties); format a slide (e.g. text alignment); configure the slideshow; and use the presentation (keyboard shortcuts). It is important to be familiar with remark.js before you can understand the options in xaringan. .footnote[[*] It is different with Pandoc’s Markdown! It is limited but should be enough for presentation purposes. Come on… You do not need a slide for the Table of Contents! Well, the Markdown support in remark.js may be improved in the future.] class: inverse, middle, center "],["using-xaringan-1.html", "Chapter 386 Using xaringan", " Chapter 386 Using xaringan "],["xaringan-1.html", "Chapter 387 xaringan", " Chapter 387 xaringan Provides an R Markdown output format xaringan::moon_reader as a wrapper for remark.js, and you can use it in the YAML metadata, e.g. --- title: &quot;A Cool Presentation&quot; output: xaringan::moon_reader: yolo: true nature: autoplay: 30000 --- See the help page ?xaringan::moon_reader for all possible options that you can use. "],["remark-js-vs-xaringan-1.html", "Chapter 388 remark.js vs xaringan", " Chapter 388 remark.js vs xaringan Some differences between using remark.js (left) and using xaringan (right): .pull-left[ 1. Start with a boilerplate HTML file; Plain Markdown; Write JavaScript to autoplay slides; Manually configure MathJax; Highlight code with *; Edit Markdown source and refresh browser to see updated slides; ] .pull-right[ 1. Start with an R Markdown document; R Markdown (can embed R/other code chunks); Provide an option autoplay; MathJax just works;* Highlight code with {{}}; The RStudio addin “Infinite Moon Reader” automatically refreshes slides on changes; ] .footnote[[*] Not really. See next page.] "],["math-expressions-1.html", "Chapter 389 Math Expressions", " Chapter 389 Math Expressions You can write LaTeX math expressions inside a pair of dollar signs, e.g. $+$ renders \\(\\alpha+\\beta\\). You can use the display style with double dollar signs: $$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$ \\[\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\\] Limitations: The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character; There should not be spaces after the opening $ or before the closing $. Math does not work on the title slide (see #61 for a workaround). "],["r-code-1.html", "Chapter 390 R Code", " Chapter 390 R Code # a boring regression fit = lm(dist ~ 1 + speed, data = cars) coef(summary(fit)) # Estimate Std. Error t value Pr(&gt;|t|) # (Intercept) -17.579095 6.7584402 -2.601058 1.231882e-02 # speed 3.932409 0.4155128 9.463990 1.489836e-12 dojutsu = c(&quot;地爆天星&quot;, &quot;天照&quot;, &quot;加具土命&quot;, &quot;神威&quot;, &quot;須佐能乎&quot;, &quot;無限月読&quot;) grep(&quot;天&quot;, dojutsu, value = TRUE) # [1] &quot;地爆天星&quot; &quot;天照&quot; "],["r-plots-1.html", "Chapter 391 R Plots", " Chapter 391 R Plots par(mar = c(4, 4, 1, 0.1)) plot(cars, pch = 19, col = &quot;darkgray&quot;, las = 1) abline(fit, lwd = 2) "],["tables-3.html", "Chapter 392 Tables", " Chapter 392 Tables If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g., "],["html-widgets-1.html", "Chapter 393 HTML Widgets", " Chapter 393 HTML Widgets I have not thoroughly tested HTML widgets against xaringan. Some may work well, and some may not. It is a little tricky. Similarly, the Shiny mode ({r # untime: shiny) does not work. I might get these issues fixed in the future, but these are not of high priority to me. I never turn my presentation into a Shiny app. When I need to demonstrate more complicated examples, I just launch them separately. It is convenient to share slides with other people when they are plain HTML/JS applications. See the next page for two HTML widgets. library(leaflet) leaflet() %&gt;% addTiles() %&gt;% setView(-93.65, 42.0285, zoom = 17) DT::datatable( head(iris, 10), fillContainer = FALSE, options = list(pageLength = 8) ) "],["some-tips-8.html", "Chapter 394 Some Tips", " Chapter 394 Some Tips When you use the “Infinite Moon Reader” addin in RStudio, your R session will be blocked by default. You can click the red button on the right of the console to stop serving the slides, or use the daemonized mode so that it does not block your R session. To do the latter, you can set the option {r # options(servr.daemon = TRUE) in your current R session, or in ~/.Rprofile so that it is applied to all future R sessions. I do the latter by myself. To know more about the web server, see the servr package. – Do not forget to try the yolo option of xaringan::moon_reader. output: xaringan::moon_reader: yolo: true "],["some-tips-9.html", "Chapter 395 Some Tips", " Chapter 395 Some Tips Slides can be automatically played if you set the autoplay option under nature, e.g. go to the next slide every 30 seconds in a lightning talk: output: xaringan::moon_reader: nature: autoplay: 30000 – A countdown timer can be added to every page of the slides using the countdown option under nature, e.g. if you want to spend one minute on every page when you give the talk, you can set: output: xaringan::moon_reader: nature: countdown: 60000 Then you will see a timer counting down from 01:00, to 00:59, 00:58, … When the time is out, the timer will continue but the time turns red. "],["some-tips-10.html", "Chapter 396 Some Tips", " Chapter 396 Some Tips The title slide is created automatically by xaringan, but it is just another remark.js slide added before your other slides. The title slide is set to class: center, middle, inverse, title-slide by default. You can change the classes applied to the title slide with the titleSlideClass option of nature (title-slide is always applied). output: xaringan::moon_reader: nature: titleSlideClass: [top, left, inverse] – If you’d like to create your own title slide, disable xaringan’s title slide with the seal = FALSE option of moon_reader. output: xaringan::moon_reader: seal: false "],["some-tips-11.html", "Chapter 397 Some Tips", " Chapter 397 Some Tips There are several ways to build incremental slides. See this presentation for examples. The option highlightLines: true of nature will highlight code lines that start with *, or are wrapped in {{ }}, or have trailing comments #&lt;&lt;; output: xaringan::moon_reader: nature: highlightLines: true See examples on the next page. "],["some-tips-12.html", "Chapter 398 Some Tips", " Chapter 398 Some Tips .pull-left[ An example using a leading *: ```{r # if (TRUE) { ** message(&quot;Very important!&quot;) } ``` Output: {r # if (TRUE) { * message(\"Very important!\") } This is invalid R code, so it is a plain fenced code block that is not executed. ] .pull-right[ An example using {{}}: `{r # &#39;&#39;````{r tidy=FALSE} if (TRUE) { *{{ message(&quot;Very important!&quot;) }} } ``` Output: if (TRUE) { {{ message(&quot;Very important!&quot;) }} } It is valid R code so you can run it. Note that {{}} can wrap an R expression of multiple lines. ] "],["some-tips-13.html", "Chapter 399 Some Tips", " Chapter 399 Some Tips An example of using the trailing comment #&lt;&lt; to highlight lines: `{r # &#39;&#39;````{r tidy=FALSE} library(ggplot2) ggplot(mtcars) + aes(mpg, disp) + geom_point() + #&lt;&lt; geom_smooth() #&lt;&lt; ``` Output: library(ggplot2) ggplot(mtcars) + aes(mpg, disp) + geom_point() + #&lt;&lt; geom_smooth() #&lt;&lt; "],["some-tips-14.html", "Chapter 400 Some Tips", " Chapter 400 Some Tips When you enable line-highlighting, you can also use the chunk option highlight.output to highlight specific lines of the text output from a code chunk. For example, highlight.output = TRUE means highlighting all lines, and highlight.output = c(1, 3) means highlighting the first and third line. `{r # &#39;&#39;````{r, highlight.output=c(1, 3)} head(iris) ``` head(iris) Table 400.1: Sepal.LengthSepal.WidthPetal.LengthPetal.WidthSpecies 5.13.51.40.2setosa 4.93&nbsp;&nbsp;1.40.2setosa 4.73.21.30.2setosa 4.63.11.50.2setosa 5&nbsp;&nbsp;3.61.40.2setosa 5.43.91.70.4setosa Question: what does highlight.output = c(TRUE, FALSE) mean? (Hint: think about R’s recycling of vectors) "],["some-tips-15.html", "Chapter 401 Some Tips", " Chapter 401 Some Tips To make slides work offline, you need to download a copy of remark.js in advance, because xaringan uses the online version by default (see the help page ?xaringan::moon_reader). You can use xaringan::summon_remark() to download the latest or a specified version of remark.js. By default, it is downloaded to libs/remark-latest.min.js. Then change the chakra option in YAML to point to this file, e.g. output: xaringan::moon_reader: chakra: libs/remark-latest.min.js If you used Google fonts in slides (the default theme uses Yanone Kaffeesatz, Droid Serif, and Source Code Pro), they won’t work offline unless you download or install them locally. The Heroku app google-webfonts-helper can help you download fonts and generate the necessary CSS. "],["macros-1.html", "Chapter 402 Macros", " Chapter 402 Macros remark.js allows users to define custom macros (JS functions) that can be applied to Markdown text using the syntax ![:macroName arg1, arg2, ...] or ![:macroName arg1, arg2, ...](this). For example, before remark.js initializes the slides, you can define a macro named scale: remark.macros.scale = function (percentage) { var url = this; return &#39;&lt;img src=&quot;&#39; + url + &#39;&quot; style=&quot;width: &#39; + percentage + &#39;&quot; /&gt;&#39;; }; Then the Markdown text ![:scale 50%](image.jpg) will be translated to &lt;img src=&quot;image.jpg&quot; style=&quot;width: 50%&quot; /&gt; "],["macros-continued-1.html", "Chapter 403 Macros (continued)", " Chapter 403 Macros (continued) To insert macros in xaringan slides, you can use the option beforeInit under the option nature, e.g., output: xaringan::moon_reader: nature: beforeInit: &quot;macros.js&quot; You save your remark.js macros in the file macros.js. The beforeInit option can be used to insert arbitrary JS code before {r # emark.create(). Inserting macros is just one of its possible applications. "],["css-2.html", "Chapter 404 CSS", " Chapter 404 CSS Among all options in xaringan::moon_reader, the most challenging but perhaps also the most rewarding one is css, because it allows you to customize the appearance of your slides using any CSS rules or hacks you know. You can see the default CSS file here. You can completely replace it with your own CSS files, or define new rules to override the default. See the help page ?xaringan::moon_reader for more information. "],["css-3.html", "Chapter 405 CSS", " Chapter 405 CSS For example, suppose you want to change the font for code from the default “Source Code Pro” to “Ubuntu Mono”. You can create a CSS file named, say, ubuntu-mono.css: @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic); .remark-code, .remark-inline-code { font-family: &#39;Ubuntu Mono&#39;; } Then set the css option in the YAML metadata: output: xaringan::moon_reader: css: [&quot;default&quot;, &quot;ubuntu-mono.css&quot;] Here I assume ubuntu-mono.css is under the same directory as your Rmd. See yihui/xaringan#83 for an example of using the Fira Code font, which supports ligatures in program code. "],["themes-2.html", "Chapter 406 Themes", " Chapter 406 Themes Don’t want to learn CSS? Okay, you can use some user-contributed themes. A theme typically consists of two CSS files foo.css and foo-fonts.css, where foo is the theme name. Below are some existing themes: "],["themes-3.html", "Chapter 407 Themes", " Chapter 407 Themes To use a theme, you can specify the css option as an array of CSS filenames (without the .css extensions), e.g., output: xaringan::moon_reader: css: [default, metropolis, metropolis-fonts] If you want to contribute a theme to xaringan, please read this blog post. background-image: url(https://upload.wikimedia.org/wikipedia/commons/b/be/Sharingan_triple.svg) background-size: 100px background-position: 90% 8% "],["sharingan-1.html", "Chapter 408 Sharingan", " Chapter 408 Sharingan The R package name xaringan was derived1 from Sharingan, a dōjutsu in the Japanese anime Naruto with two abilities: the “Eye of Insight” the “Eye of Hypnotism” I think a presentation is basically a way to communicate insights to the audience, and a great presentation may even “hypnotize” the audience.2,3 .footnote[ [1] In Chinese, the pronounciation of X is Sh /ʃ/ (as in shrimp). Now you should have a better idea of how to pronounce my last name Xie. [2] By comparison, bad presentations only put the audience to sleep. [3] Personally I find that setting background images for slides is a killer feature of remark.js. It is an effective way to bring visual impact into your presentations. ] "],["naruto-terminology-1.html", "Chapter 409 Naruto terminology", " Chapter 409 Naruto terminology The xaringan package borrowed a few terms from Naruto, such as Sharingan (写輪眼; the package name) The moon reader (月読; an attractive R Markdown output format) Chakra (查克拉; the path to the remark.js library, which is the power to drive the presentation) Nature transformation (性質変化; transform the chakra by setting different options) The infinite moon reader (無限月読; start a local web server to continuously serve your slides) The summoning technique (download remark.js from the web) You can click the links to know more about them if you want. The jutsu “Moon Reader” may seem a little evil, but that does not mean your slides are evil. class: center "],["hand-seals-1.html", "Chapter 410 Hand seals (印)", " Chapter 410 Hand seals (印) Press h or ? to see the possible ninjutsu you can use in remark.js. class: center, middle "],["thanks-1.html", "Chapter 411 Thanks!", " Chapter 411 Thanks! Slides created via the R package xaringan. The chakra comes from remark.js, knitr, and R Markdown. http://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html This tutorial provides an introduction to survival analysis, and to conducting a survival analysis in R. This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center R-Presenters series on August 30, 2018. # load(here::here(&#39;data&#39;, &#39;survival_data_example.RData&#39;)) "],["introduction-3.html", "Chapter 412 Introduction 412.1 What is survival data? 412.2 Examples from other fields 412.3 Aliases for survival analysis 412.4 Questions of interest", " Chapter 412 Introduction 412.1 What is survival data? Time-to-event data that consists of a distinct start time and end time. Examples from cancer: Time from surgery to death Time from start of treatment to progression Time from response to recurrence 412.2 Examples from other fields Time-to-event data is common in many fields including, but not limited to: Time from HIV infection to development of AIDS Time to heart attack Time to onset of substance abuse Time to initiation of sexual activity Time to machine malfunction 412.3 Aliases for survival analysis Because survival analysis is common in many other fields, it also goes by other names: Reliability analysis Duration analysis Event history analysis Time-to-event analysis 412.4 Questions of interest The two most common questions I encounter related to survival analysis are: What is the probability of survival to a certain point in time? What is the average survival time? "],["censoring.html", "Chapter 413 Censoring 413.1 What is censoring? 413.2 Censored survival data 413.3 We can incorporate censored data using survival analysis techniques 413.4 Danger of ignoring censoring 413.5 Components of survival data", " Chapter 413 Censoring 413.1 What is censoring? In survival analysis it is common for the exact event time to be unknown, or unobserved, which is called censoring. A subject may be censored due to: Loss to follow-up Withdrawal from study No event by end of fixed study period Specifically these are examples of right censoring. Other common types of censoring include: Left Interval 413.2 Censored survival data When the exact event time is unknown then some patients are censored, and survival analysis methods are required. In this example, how would we compute the proportion who are event-free at 10 years? Subjects 2, 3, 5, 6, 8, 9, and 10 were all event-free at 10 years. Subjects 4 and 7 had the event before 10 years. Subject 1 was censored before 10 years, so we don’t know whether they had the event or not by 10 years. How do we incorporate this subject into our estimate? 413.3 We can incorporate censored data using survival analysis techniques Toy example of a Kaplan-Meier curve for this simple data (details to follow): Horizontal lines represent survival duration for the interval An interval is terminated by an event The height of vertical lines show the change in cumulative probability Censored observations, indicated by tick marks, reduces the cumulative survival between intervals 413.4 Danger of ignoring censoring Case study: musicians and mortality Conclusion: Musical genre is associated with early death among musicians. Problem: this graph does not account for the right-censored nature of the data. 413.5 Components of survival data For subject \\(i\\): Event time \\(T_i\\) Censoring time \\(C_i\\) Event indicator \\(\\delta_i\\): 1 if event observed (i.e. \\(T_i \\leq C_i\\)) 0 if censored (i.e. \\(T_i &gt; C_i\\)) Observed time \\(Y_i = \\min(T_i, C_i)\\) "],["data-example.html", "Chapter 414 Data example 414.1 Research question of interest 414.2 Data structure", " Chapter 414 Data example 414.1 Research question of interest Investigating the “obesity paradox” in kidney cancer patients. Increased BMI associated with risk of kidney cancer Is increased BMI also associated with worse prognosis among kidney cancer patients? 414.2 Data structure {r # nrow(df) kidney cancer patients Outcome: overall survival Predictor: BMI Variables: “os_yrs”: the observed time \\(Y_i = min(T_i, C_i)\\) “os”: the event indicator \\(\\delta_i\\) “bmi_cat”: 1 = Normal BMI &lt; 25, 2 = Overweight BMI 25-30, 3 = Obese BMI &gt; 30 "],["preparing-data-for-analysis.html", "Chapter 415 Preparing data for analysis 415.1 Dates 415.2 Formatting dates - base R 415.3 Formatting dates - lubridate 415.4 Event indicator 415.5 Calculating survival times - base R 415.6 Calculating survival times - lubridate", " Chapter 415 Preparing data for analysis 415.1 Dates Data will often come with start and end dates rather than pre-calculated survival times. Our data example includes the following variables: “proc_date”: Date of surgery “last_status_date”: Date of death or last follow-up “last_status”: Character variable denoting whether the patient is alive, and the cause of death if dead The first step is to make sure these are formatted as dates in R. 415.2 Formatting dates - base R First let’s look at the current format of our surgery date: We see this is a character variable in a certain format, but we need it to be formatted as a Date. And after formatting we see that surgery date has Date format now: Note that in base R the format must include the separator as well as the symbol. e.g. if your date is in format m/d/Y then you would need format = \"%m/%d/%Y\" See a full list of date format symbols at https://www.statmethods.net/input/dates.html 415.3 Formatting dates - lubridate We can also use the lubridate package to format dates. Again we look at our original surgery date variable: And now use the lubridate::dmy function to format this into a Date: And again we see that R now recognizes surgery date as a Date format: The help page for ?ymd will show all format options. Note that unlike the base R option, the separators do not need to be specified 415.4 Event indicator Most functions used in survival analysis will also require a binary indicator of event that is: 0 for no event 1 for event Currently our data example contains a character variable indicating whehter the patient is alive, and if not indicating the cause of death, so we must create a binary indicator. 415.5 Calculating survival times - base R Now that we have our dates formatted, we need to calculate the difference between start and end time in some units, usually months or years. A base R solution to calculate the number of years from surgery to death: Here we use difftime to calculate the number of days between our two dates and convert it to a numeric value using as.numeric. We then convert to years by dividing by 365.25, the average number of days in a year. Sidenote: the &gt;0 nature of survival times is another reason why standard regression techniques such as linear regression would not be an appropriate way to analyze time-to-event data 415.6 Calculating survival times - lubridate We can also use the lubridate package to calculate the number of years from surgery to death: {r difftime_ex2, message = FALSE, warning = FALSE} library(lubridate) df &lt;- df %&gt;% mutate(os_yrs_opt2 = as.duration(proc_date %--% last_status_date) / dyears(1)) {r eval=FALSE, include=FALSE, echo=TRUE} summary(df$os_yrs_opt2) Here the operator %--% is used to designate a time interval, which is then converted to the number of elapsed seconds using as.duration and finally converted to years by dividing by dyears(1), which gives the number of seconds in a year. If you look closely you will see the result differs slightly from the previous result due to rounding differences, but nothing that would impact our results Note: we need to load the lubridate package using a call to library in order to be able to access the special operators (similar to situation with pipes) "],["analyzing-survival-data.html", "Chapter 416 Analyzing survival data 416.1 Questions of interest 416.2 Creating survival objects 416.3 Estimating survival curves with the Kaplan-Meier method 416.4 Kaplan-Meier plot - base R 416.5 Kaplan-Meier plot - ggsurvplot 416.6 Estimating \\(x\\)-year survival 416.7 \\(x\\)-year survival and the survival curve 416.8 \\(x\\)-year survival is often estimated incorrectly 416.9 Estimating median survival time 416.10 Median survival time and the survival curve 416.11 Median survival is often estimated incorrectly", " Chapter 416 Analyzing survival data 416.1 Questions of interest Recall the questions of interest: What is the probability of surviving to a certain point in time? What is the average survival time? 416.2 Creating survival objects The Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs. The Surv function from the survival package creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a + if the subject was censored. Let’s look at the first 10 observations: 416.3 Estimating survival curves with the Kaplan-Meier method The survival::survfit function creates survival curves based on a formula. Let’s generate the overall survival curve for the entire cohort, assign it to object f1, and look at the names of that object: Some key components of this survfit object that will be used to create survival curves include: time, which contains the start and endpoints of each time interval surv, which contains the survival probability corresponding to each time 416.4 Kaplan-Meier plot - base R Now we plot the survfit object in base R to get the Kaplan-Meier plot: The default plot in base R shows the step function (solid line) with associated confidence intervals (dotted lines). Note that the tick marks for censored patients are not shown by default, but could be added using mark.time = TRUE 416.5 Kaplan-Meier plot - ggsurvplot Alternatively, the ggsurvplot function from the survminer package is built on ggplot2, and can be used to create Kaplan-Meier plots: {r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE} survminer::ggsurvplot( fit = survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;) The default plot using survminer::ggsurvplot shows the step function (solid line) with associated confidence bands (shaded area). The tick marks for censored patients are shown by default, somewhat obscuring the line itself in this example, and could be supressed using censor = FALSE 416.6 Estimating \\(x\\)-year survival One quantity often of interest in a survival analysis is the probability of surviving a certain number (\\(x\\)) of years. For example, to estimate the probability of survivng to 5 years, use summary with the times argument: We find that the 5-year probability of survival in this study is {r # round(summary(f1, times = 5)$surv * 100)%. The associated lower and upper bounds of the 95% confidence interval are also displayed. 416.7 \\(x\\)-year survival and the survival curve The 5-year survival probability is the point on the y-axis that corresponds to 5 years on the x-axis for the survival curve. {r eval=FALSE, message=FALSE, include=FALSE} survplot1 &lt;- survminer::ggsurvplot(survival::survfit( survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, break.x.by = 5, palette = ezfun::msk_palette(&quot;main&quot;)) + geom_segment(x = 5, xend = 5, y = -1, yend = 0.808, col = 2, lwd = 2) + geom_segment(x = 5, xend = -0.7, y = 0.808, yend = 0.808, arrow = arrow(length = unit(0.3, &quot;inches&quot;)), col = 2, lwd = 2) survplot1$plot &lt;- survplot1$plot + annotate(&quot;text&quot;, x = 0.2, y = 0.7, label = &quot;81%&quot;, size = 6, col = 2) survplot1 416.8 \\(x\\)-year survival is often estimated incorrectly What happens if you use a “naive” estimate? {r # table(df$os[df$os_yrs &lt;= 5])[2] of the {r # nrow(df) patients died by 5 years so: \\[\\Big(1 - \\frac{297}{2119}\\Big) \\times 100 = 86\\%\\] You get an incorrect estimate of the 5-year probability of survival when you ignore the fact that {r # table(df$os[df$os_yrs &lt;= 5])[1] patients were censored before 5 years. Recall the correct estimate of the 5-year probability of survival was {r # round(summary(f1, times = 5)$surv * 100)%. 416.9 Estimating median survival time Another quantity often of interest in a survival analysis is the average survival time, which we quantify using the median (survival times are not expected to be normally distributed so the mean is not an appropriate summary). We can obtain this directly from our survfit object: {r eval=FALSE, include=FALSE, echo=TRUE} survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df) We see the median survival time is {r # round(summary(f1)$table[\"median\"], 1) years. The lower and upper bounds of the 95% confidence interval are also displayed. 416.10 Median survival time and the survival curve Median survival is the time corresponding to a survival probability of 0.5: {r eval=FALSE, message=FALSE, include=FALSE} survplot2 &lt;- survminer::ggsurvplot(survival::survfit( survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, break.x.by = 5, palette = ezfun::msk_palette(&quot;main&quot;)) + geom_segment(x = -1, xend = 12.6794, y = 0.5, yend = 0.5, col = 2, lwd = 2) + geom_segment(x = 12.6794, xend = 12.6794, y = 0.5, yend = -0.02, arrow = arrow(length = unit(0.3, &quot;inches&quot;)), col = 2, lwd = 2) survplot2$plot &lt;- survplot2$plot + annotate(&quot;text&quot;, x = 9.5, y = 0.02, label = &quot;12.7 years&quot;, size = 6, col = 2) survplot2 416.11 Median survival is often estimated incorrectly What happens if you use a “naive” estimate? Summarize the median survival time among the {r # table(df$os)[2] patients who died: You get an incorrect estimate of median survival time of {r # round(median(df$os_yrs[df$os == 1]), 1) years when you ignore the fact that censored patients also contribute follow-up time. Recall the correct estimate of median survival time is {r # round(summary(f1)$table[\"median\"], 1) years. "],["comparing-survival-times-between-groups.html", "Chapter 417 Comparing survival times between groups 417.1 Questions of interest with respect to between-group differences 417.2 Kaplan-Meier plot by group 417.3 \\(x\\)-year survival probability by group 417.4 Log-rank test for between-group significance test", " Chapter 417 Comparing survival times between groups 417.1 Questions of interest with respect to between-group differences Is there a difference in survival probability between groups? From our example: does the probability of survival differ according to BMI among kidney cancer patients? 417.2 Kaplan-Meier plot by group We can add a covariate to the right-hand side of the survival::survfit object to obtain a stratified Kaplan-Meier plot. Let’s also look at some other customization we can do with survminer::ggsurvplot. {r fig.height = 6} survminer::ggsurvplot( fit = survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, legend.title = &quot;BMI&quot;, legend.labs = c(&quot;Normal&quot;, &quot;Overweight&quot;, &quot;Obese&quot;), break.x.by = 5, palette = ezfun::msk_palette(&quot;contrast&quot;), censor = FALSE, risk.table = TRUE, risk.table.y.text = FALSE) By looking at the curves, we can see that normal BMI patients have the lowest overall survival probability, followed by overweight BMI patients and obese BMI patients. The risk table below the plot shows us the number of patients at risk at certain time points, which can give an idea of how much information is being used to calculate the estimates at each time 417.3 \\(x\\)-year survival probability by group As before, we can get an estimate of, for example, 5-year survival by using summary with the times argument in our survival::survfit object: To summarize: 417.4 Log-rank test for between-group significance test We can conduct between-group significance tests using a log-rank test. The log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups. There are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question. We get the log-rank p-value using the survival::survdiff function: And we see that the p-value is &lt;.001, indicating a significant difference in overall survival according to BMI. "],["regression-1.html", "Chapter 418 Regression 418.1 The Cox regression model 418.2 Cox regression example using a single covariate 418.3 Hazard ratios 418.4 Summary", " Chapter 418 Regression 418.1 The Cox regression model We may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables. The Cox regression model is a semi-parametric model that can be used to fit univariable and multivariable regression models that have survival outcomes. Some key assumptions of the model: non-informative censoring proportional hazards Note: parametric regression models for survival outcomes are also available, but I won’t cover them in detail here. 418.2 Cox regression example using a single covariate We can fit regression models for survival data using the survival::coxph function, which takes a survival::Surv object on the left hand side and has standard syntax for regression formulas in R on the right hand side. survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), data = df) We can see a tidy version of the output using the tidy function from the broom package: 418.3 Hazard ratios The quantity of interest from a Cox regression model is a hazard ratio (HR). If you have a regression parameter \\(\\beta\\) (from column estimate in our survival::coxph) then HR = \\(\\exp(\\beta)\\). For example, from our example we obtain the regression parameter \\(\\beta_1=-0.4441733\\) for obese vs normal BMI, so we have HR = \\(\\exp(\\beta_1)=0.64\\). A HR &lt; 1 indicates reduced hazard of death whereas a HR &gt; 1 indicates an increased hazard of death. So we would say that obese BMI kidney cancer patients have 0.64 times reduced hazard of death as compared to normal BMI kidney cancer patients. 418.4 Summary Time-to-event data is common Survival analysis techniques are required to account for censored data The survival package provides tools for survival analysis, including the Surv and survfit functions The survminer package allows for customization of Kaplan-Meier plots based on ggplot2 Between-group comparisons can be made with the log-rank test using survival::survdiff Multiavariable Cox regression analysis can be accomplished using survival::coxph This tutorial provides an introduction to survival analysis, and to conducting a survival analysis in R. This tutorial was originally presented at the Memorial Sloan Kettering Cancer Center R-Presenters series on August 30, 2018. # load(here::here(&#39;data&#39;, &#39;survival_data_example.RData&#39;)) "],["introduction-4.html", "Chapter 419 Introduction 419.1 What is survival data? 419.2 Examples from other fields 419.3 Aliases for survival analysis 419.4 Questions of interest", " Chapter 419 Introduction 419.1 What is survival data? Time-to-event data that consists of a distinct start time and end time. Examples from cancer: Time from surgery to death Time from start of treatment to progression Time from response to recurrence 419.2 Examples from other fields Time-to-event data is common in many fields including, but not limited to: Time from HIV infection to development of AIDS Time to heart attack Time to onset of substance abuse Time to initiation of sexual activity Time to machine malfunction 419.3 Aliases for survival analysis Because survival analysis is common in many other fields, it also goes by other names: Reliability analysis Duration analysis Event history analysis Time-to-event analysis 419.4 Questions of interest The two most common questions I encounter related to survival analysis are: What is the probability of survival to a certain point in time? What is the average survival time? "],["censoring-1.html", "Chapter 420 Censoring 420.1 What is censoring? 420.2 Censored survival data 420.3 We can incorporate censored data using survival analysis techniques 420.4 Danger of ignoring censoring 420.5 Components of survival data", " Chapter 420 Censoring 420.1 What is censoring? In survival analysis it is common for the exact event time to be unknown, or unobserved, which is called censoring. A subject may be censored due to: Loss to follow-up Withdrawal from study No event by end of fixed study period Specifically these are examples of right censoring. Other common types of censoring include: Left Interval 420.2 Censored survival data When the exact event time is unknown then some patients are censored, and survival analysis methods are required. In this example, how would we compute the proportion who are event-free at 10 years? Subjects 2, 3, 5, 6, 8, 9, and 10 were all event-free at 10 years. Subjects 4 and 7 had the event before 10 years. Subject 1 was censored before 10 years, so we don’t know whether they had the event or not by 10 years. How do we incorporate this subject into our estimate? 420.3 We can incorporate censored data using survival analysis techniques Toy example of a Kaplan-Meier curve for this simple data (details to follow): Horizontal lines represent survival duration for the interval An interval is terminated by an event The height of vertical lines show the change in cumulative probability Censored observations, indicated by tick marks, reduces the cumulative survival between intervals 420.4 Danger of ignoring censoring Case study: musicians and mortality Conclusion: Musical genre is associated with early death among musicians. Problem: this graph does not account for the right-censored nature of the data. 420.5 Components of survival data For subject \\(i\\): Event time \\(T_i\\) Censoring time \\(C_i\\) Event indicator \\(\\delta_i\\): 1 if event observed (i.e. \\(T_i \\leq C_i\\)) 0 if censored (i.e. \\(T_i &gt; C_i\\)) Observed time \\(Y_i = \\min(T_i, C_i)\\) "],["data-example-1.html", "Chapter 421 Data example 421.1 Research question of interest 421.2 Data structure", " Chapter 421 Data example 421.1 Research question of interest Investigating the “obesity paradox” in kidney cancer patients. Increased BMI associated with risk of kidney cancer Is increased BMI also associated with worse prognosis among kidney cancer patients? 421.2 Data structure {r # nrow(df) kidney cancer patients Outcome: overall survival Predictor: BMI Variables: “os_yrs”: the observed time \\(Y_i = min(T_i, C_i)\\) “os”: the event indicator \\(\\delta_i\\) “bmi_cat”: 1 = Normal BMI &lt; 25, 2 = Overweight BMI 25-30, 3 = Obese BMI &gt; 30 "],["preparing-data-for-analysis-1.html", "Chapter 422 Preparing data for analysis 422.1 Dates 422.2 Formatting dates - base R 422.3 Formatting dates - lubridate 422.4 Event indicator 422.5 Calculating survival times - base R 422.6 Calculating survival times - lubridate", " Chapter 422 Preparing data for analysis 422.1 Dates Data will often come with start and end dates rather than pre-calculated survival times. Our data example includes the following variables: “proc_date”: Date of surgery “last_status_date”: Date of death or last follow-up “last_status”: Character variable denoting whether the patient is alive, and the cause of death if dead The first step is to make sure these are formatted as dates in R. 422.2 Formatting dates - base R First let’s look at the current format of our surgery date: We see this is a character variable in a certain format, but we need it to be formatted as a Date. And after formatting we see that surgery date has Date format now: Note that in base R the format must include the separator as well as the symbol. e.g. if your date is in format m/d/Y then you would need format = \"%m/%d/%Y\" See a full list of date format symbols at https://www.statmethods.net/input/dates.html 422.3 Formatting dates - lubridate We can also use the lubridate package to format dates. Again we look at our original surgery date variable: And now use the lubridate::dmy function to format this into a Date: {r format_date2 2} df &lt;- df %&gt;% mutate(proc_date_format2 = lubridate::dmy(proc_date)) And again we see that R now recognizes surgery date as a Date format: The help page for ?ymd will show all format options. Note that unlike the base R option, the separators do not need to be specified 422.4 Event indicator Most functions used in survival analysis will also require a binary indicator of event that is: 0 for no event 1 for event Currently our data example contains a character variable indicating whehter the patient is alive, and if not indicating the cause of death, so we must create a binary indicator. 422.5 Calculating survival times - base R Now that we have our dates formatted, we need to calculate the difference between start and end time in some units, usually months or years. A base R solution to calculate the number of years from surgery to death: {r difftime_ex1 2} df &lt;- df %&gt;% mutate(os_yrs_opt1 = as.numeric(difftime(last_status_date, proc_date, units = &quot;days&quot;)) / 365.25) Here we use difftime to calculate the number of days between our two dates and convert it to a numeric value using as.numeric. We then convert to years by dividing by 365.25, the average number of days in a year. Sidenote: the &gt;0 nature of survival times is another reason why standard regression techniques such as linear regression would not be an appropriate way to analyze time-to-event data 422.6 Calculating survival times - lubridate We can also use the lubridate package to calculate the number of years from surgery to death: {r difftime_ex2 2, message = FALSE, warning = FALSE} library(lubridate) df &lt;- df %&gt;% mutate(os_yrs_opt2 = as.duration(proc_date %--% last_status_date) / dyears(1)) Here the operator %--% is used to designate a time interval, which is then converted to the number of elapsed seconds using as.duration and finally converted to years by dividing by dyears(1), which gives the number of seconds in a year. If you look closely you will see the result differs slightly from the previous result due to rounding differences, but nothing that would impact our results Note: we need to load the lubridate package using a call to library in order to be able to access the special operators (similar to situation with pipes) "],["analyzing-survival-data-1.html", "Chapter 423 Analyzing survival data 423.1 Questions of interest 423.2 Creating survival objects 423.3 Estimating survival curves with the Kaplan-Meier method 423.4 Kaplan-Meier plot - base R 423.5 Kaplan-Meier plot - ggsurvplot 423.6 Estimating \\(x\\)-year survival 423.7 \\(x\\)-year survival and the survival curve 423.8 \\(x\\)-year survival is often estimated incorrectly 423.9 Estimating median survival time 423.10 Median survival time and the survival curve 423.11 Median survival is often estimated incorrectly", " Chapter 423 Analyzing survival data 423.1 Questions of interest Recall the questions of interest: What is the probability of surviving to a certain point in time? What is the average survival time? 423.2 Creating survival objects The Kaplan-Meier method is the most common way to estimate survival times and probabilities. It is a non-parametric approach that results in a step function, where there is a step down each time an event occurs. The Surv function from the survival package creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a + if the subject was censored. Let’s look at the first 10 observations: 423.3 Estimating survival curves with the Kaplan-Meier method The survival::survfit function creates survival curves based on a formula. Let’s generate the overall survival curve for the entire cohort, assign it to object f1, and look at the names of that object: Some key components of this survfit object that will be used to create survival curves include: time, which contains the start and endpoints of each time interval surv, which contains the survival probability corresponding to each time 423.4 Kaplan-Meier plot - base R Now we plot the survfit object in base R to get the Kaplan-Meier plot: The default plot in base R shows the step function (solid line) with associated confidence intervals (dotted lines). Note that the tick marks for censored patients are not shown by default, but could be added using mark.time = TRUE 423.5 Kaplan-Meier plot - ggsurvplot Alternatively, the ggsurvplot function from the survminer package is built on ggplot2, and can be used to create Kaplan-Meier plots: {r, message = FALSE, warning = FALSE} survminer::ggsurvplot( fit = survival::survfit(survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;) The default plot using survminer::ggsurvplot shows the step function (solid line) with associated confidence bands (shaded area). The tick marks for censored patients are shown by default, somewhat obscuring the line itself in this example, and could be supressed using censor = FALSE 423.6 Estimating \\(x\\)-year survival One quantity often of interest in a survival analysis is the probability of surviving a certain number (\\(x\\)) of years. For example, to estimate the probability of survivng to 5 years, use summary with the times argument: We find that the 5-year probability of survival in this study is {r # round(summary(f1, times = 5)$surv * 100)%. The associated lower and upper bounds of the 95% confidence interval are also displayed. 423.7 \\(x\\)-year survival and the survival curve The 5-year survival probability is the point on the y-axis that corresponds to 5 years on the x-axis for the survival curve. {r, message = FALSE, echo = TRUE} survplot1 &lt;- survminer::ggsurvplot(survival::survfit( survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, break.x.by = 5, palette = ezfun::msk_palette(&quot;main&quot;)) + geom_segment(x = 5, xend = 5, y = -1, yend = 0.808, col = 2, lwd = 2) + geom_segment(x = 5, xend = -0.7, y = 0.808, yend = 0.808, arrow = arrow(length = unit(0.3, &quot;inches&quot;)), col = 2, lwd = 2) survplot1$plot &lt;- survplot1$plot + annotate(&quot;text&quot;, x = 0.2, y = 0.7, label = &quot;81%&quot;, size = 6, col = 2) survplot1 423.8 \\(x\\)-year survival is often estimated incorrectly What happens if you use a “naive” estimate? {r # table(df$os[df$os_yrs &lt;= 5])[2] of the {r # nrow(df) patients died by 5 years so: \\[\\Big(1 - \\frac{297}{2119}\\Big) \\times 100 = 86\\%\\] You get an incorrect estimate of the 5-year probability of survival when you ignore the fact that {r # table(df$os[df$os_yrs &lt;= 5])[1] patients were censored before 5 years. Recall the correct estimate of the 5-year probability of survival was {r # round(summary(f1, times = 5)$surv * 100)%. 423.9 Estimating median survival time Another quantity often of interest in a survival analysis is the average survival time, which we quantify using the median (survival times are not expected to be normally distributed so the mean is not an appropriate summary). We can obtain this directly from our survfit object: We see the median survival time is {r # round(summary(f1)$table[\"median\"], 1) years. The lower and upper bounds of the 95% confidence interval are also displayed. 423.10 Median survival time and the survival curve Median survival is the time corresponding to a survival probability of 0.5: {r, message = FALSE, echo = TRUE} survplot2 &lt;- survminer::ggsurvplot(survival::survfit( survival::Surv(os_yrs, os) ~ 1, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, break.x.by = 5, palette = ezfun::msk_palette(&quot;main&quot;)) + geom_segment(x = -1, xend = 12.6794, y = 0.5, yend = 0.5, col = 2, lwd = 2) + geom_segment(x = 12.6794, xend = 12.6794, y = 0.5, yend = -0.02, arrow = arrow(length = unit(0.3, &quot;inches&quot;)), col = 2, lwd = 2) survplot2$plot &lt;- survplot2$plot + annotate(&quot;text&quot;, x = 9.5, y = 0.02, label = &quot;12.7 years&quot;, size = 6, col = 2) survplot2 423.11 Median survival is often estimated incorrectly What happens if you use a “naive” estimate? Summarize the median survival time among the {r # table(df$os)[2] patients who died: You get an incorrect estimate of median survival time of {r # round(median(df$os_yrs[df$os == 1]), 1) years when you ignore the fact that censored patients also contribute follow-up time. Recall the correct estimate of median survival time is {r # round(summary(f1)$table[\"median\"], 1) years. "],["comparing-survival-times-between-groups-1.html", "Chapter 424 Comparing survival times between groups 424.1 Questions of interest with respect to between-group differences 424.2 Kaplan-Meier plot by group 424.3 \\(x\\)-year survival probability by group 424.4 Log-rank test for between-group significance test", " Chapter 424 Comparing survival times between groups 424.1 Questions of interest with respect to between-group differences Is there a difference in survival probability between groups? From our example: does the probability of survival differ according to BMI among kidney cancer patients? 424.2 Kaplan-Meier plot by group We can add a covariate to the right-hand side of the survival::survfit object to obtain a stratified Kaplan-Meier plot. Let’s also look at some other customization we can do with survminer::ggsurvplot. {r fig.height = 6} survminer::ggsurvplot( fit = survival::survfit(survival::Surv(os_yrs, os) ~ bmi_cat, data = df), xlab = &quot;Years&quot;, ylab = &quot;Overall survival probability&quot;, legend.title = &quot;BMI&quot;, legend.labs = c(&quot;Normal&quot;, &quot;Overweight&quot;, &quot;Obese&quot;), break.x.by = 5, palette = ezfun::msk_palette(&quot;contrast&quot;), censor = FALSE, risk.table = TRUE, risk.table.y.text = FALSE) By looking at the curves, we can see that normal BMI patients have the lowest overall survival probability, followed by overweight BMI patients and obese BMI patients. The risk table below the plot shows us the number of patients at risk at certain time points, which can give an idea of how much information is being used to calculate the estimates at each time 424.3 \\(x\\)-year survival probability by group As before, we can get an estimate of, for example, 5-year survival by using summary with the times argument in our survival::survfit object: To summarize: 424.4 Log-rank test for between-group significance test We can conduct between-group significance tests using a log-rank test. The log-rank test equally weights observations over the entire follow-up time and is the most common way to compare survival times between groups. There are versions that more heavily weight the early or late follow-up that could be more appropriate depending on the research question. We get the log-rank p-value using the survival::survdiff function: And we see that the p-value is &lt;.001, indicating a significant difference in overall survival according to BMI. "],["regression-2.html", "Chapter 425 Regression 425.1 The Cox regression model 425.2 Cox regression example using a single covariate 425.3 Hazard ratios 425.4 Summary 425.5 Survival Analysis in R", " Chapter 425 Regression 425.1 The Cox regression model We may want to quantify an effect size for a single variable, or include more than one variable into a regression model to account for the effects of multiple variables. The Cox regression model is a semi-parametric model that can be used to fit univariable and multivariable regression models that have survival outcomes. Some key assumptions of the model: non-informative censoring proportional hazards Note: parametric regression models for survival outcomes are also available, but I won’t cover them in detail here. 425.2 Cox regression example using a single covariate We can fit regression models for survival data using the survival::coxph function, which takes a survival::Surv object on the left hand side and has standard syntax for regression formulas in R on the right hand side. {r eval = FALSE} survival::coxph(survival::Surv(os_yrs, os) ~ factor(bmi_cat), data = df) We can see a tidy version of the output using the tidy function from the broom package: 425.3 Hazard ratios The quantity of interest from a Cox regression model is a hazard ratio (HR). If you have a regression parameter \\(\\beta\\) (from column estimate in our survival::coxph) then HR = \\(\\exp(\\beta)\\). For example, from our example we obtain the regression parameter \\(\\beta_1=-0.4441733\\) for obese vs normal BMI, so we have HR = \\(\\exp(\\beta_1)=0.64\\). A HR &lt; 1 indicates reduced hazard of death whereas a HR &gt; 1 indicates an increased hazard of death. So we would say that obese BMI kidney cancer patients have 0.64 times reduced hazard of death as compared to normal BMI kidney cancer patients. 425.4 Summary Time-to-event data is common Survival analysis techniques are required to account for censored data The survival package provides tools for survival analysis, including the Surv and survfit functions The survminer package allows for customization of Kaplan-Meier plots based on ggplot2 Between-group comparisons can be made with the log-rank test using survival::survdiff Multiavariable Cox regression analysis can be accomplished using survival::coxph 425.5 Survival Analysis in R https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/ 425.5.1 Censored Data 425.5.2 Kaplan Meier 425.5.3 Life Table 425.5.4 KM Graph Overall 425.5.5 KM per treatment group 425.5.6 KM Graph per treatment group "],["survminer-2.html", "Chapter 426 survminer", " Chapter 426 survminer http://www.sthda.com/english/rpkgs/survminer/#uber-platinum-customized-survival-curves "],["openintro-statistics.html", "Chapter 427 OpenIntro Statistics", " Chapter 427 OpenIntro Statistics https://www.openintro.org/stat/surv.php https://www.openintro.org/download.php?file=survival_analysis_in_R&amp;referrer=/stat/surv.php https://www.openintro.org/download.php?file=survival_analysis_in_R_code&amp;referrer=/stat/surv.php https://www.openintro.org/download.php?file=survival_analysis_in_R_code_df-cp&amp;referrer=/stat/surv.php "],["survsup.html", "Chapter 428 survsup", " Chapter 428 survsup Plotting survival curves with the survsup package https://cran.r-project.org/web/packages/survsup/vignettes/survsup_intro.html http://github.com/dlindholm/survsup/ https://cran.r-project.org/package=gridExtra "],["survivalanalysis.html", "Chapter 429 survivalAnalysis 429.1 Univariate Survival Analysis", " Chapter 429 survivalAnalysis 429.1 Univariate Survival Analysis https://cran.r-project.org/web/packages/survivalAnalysis/vignettes/univariate.html "],["breast-cancer-wisconsin.html", "Chapter 430 breast cancer wisconsin", " Chapter 430 breast cancer wisconsin "],["lung-cancer.html", "Chapter 431 Lung Cancer", " Chapter 431 Lung Cancer "],["configuring-a-remote-for-a-fork.html", "Chapter 432 Configuring a remote for a fork 432.1 Open Terminal. 432.2 List the current configured remote repository for your fork. 432.3 Specify a new remote upstream repository that will be synced with the fork. 432.4 Verify the new upstream repository you’ve specified for your fork.", " Chapter 432 Configuring a remote for a fork https://help.github.com/articles/configuring-a-remote-for-a-fork/ 432.1 Open Terminal. 432.2 List the current configured remote repository for your fork. {bash} git remote -v origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) 432.3 Specify a new remote upstream repository that will be synced with the fork. {bash} git remote add upstream https://github.com/BIOP/IPA4LSx.git git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git git remote add upstream https://github.com/BIOP/IPA4LSx.git 432.4 Verify the new upstream repository you’ve specified for your fork. {bash} git remote -v origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch) upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push) "],["syncing-a-fork.html", "Chapter 433 Syncing a fork 433.1 Open Terminal. 433.2 Change the current working directory to your local project. 433.3 Fetch the branches and their respective commits from the upstream repository. Commits to master will be stored in a local branch, upstream/master. 433.4 Check out your fork’s local master branch. 433.5 Merge the changes from upstream/master into your local master branch. This brings your fork’s master branch into sync with the upstream repository, without losing your local changes. 433.6 If your local branch didn’t have any unique commits, Git will instead perform a “fast-forward”: 433.7 Tables 433.8 tttable", " Chapter 433 Syncing a fork https://help.github.com/articles/syncing-a-fork/ 433.1 Open Terminal. 433.2 Change the current working directory to your local project. 433.3 Fetch the branches and their respective commits from the upstream repository. Commits to master will be stored in a local branch, upstream/master. {bash} git fetch upstream git fetch upstream remote: Counting objects: 75, done. remote: Compressing objects: 100% (53/53), done. remote: Total 62 (delta 27), reused 44 (delta 9) Unpacking objects: 100% (62/62), done. From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY * [new branch] master -&gt; upstream/master 433.4 Check out your fork’s local master branch. {bash} git checkout master git checkout master Switched to branch &#39;master&#39; 433.5 Merge the changes from upstream/master into your local master branch. This brings your fork’s master branch into sync with the upstream repository, without losing your local changes. {bash} git merge upstream/master git merge upstream/master Updating a422352..5fdff0f Fast-forward README | 9 ------- README.md | 7 ++++++ 2 files changed, 7 insertions(+), 9 deletions(-) delete mode 100644 README create mode 100644 README.md 433.6 If your local branch didn’t have any unique commits, Git will instead perform a “fast-forward”: {bash} git merge upstream/master git merge upstream/master Updating 34e91da..16c56ad Fast-forward README.md | 5 +++-- 1 file changed, 3 insertions(+), 2 deletions(-) Tip: Syncing your fork only updates your local copy of the repository. To update your fork on GitHub, you must push your changes. finalfit http://www.datasurg.net/2018/07/12/finalfit-now-includes-bootstrap-simulation-for-model-prediction/ https://kbroman.org/knitr_knutshell/pages/figs_tables.html 433.7 Tables 433.8 tttable https://github.com/leeper/tttable 433.8.1 - renderers 433.8.1.1 - xtable https://rdrr.io/cran/xtable/man/xtable.html 433.8.1.2 - flextable https://davidgohel.github.io/flextable/index.html https://cran.r-project.org/web/packages/flextable/vignettes/overview.html Make Beautiful Tables with the Formattable Package https://www.displayr.com/formattable/?utm_medium=Feed&amp;utm_source=Syndication 433.8.1.3 - knitr::kable() 433.8.1.4 - formatttable 433.8.1.5 - knitLatex 433.8.1.6 - htmlTable 433.8.1.7 - psytabs 433.8.1.8 - SortableHTMLTables 433.8.1.9 - tablaxlsx 433.8.1.10 - table1xls 433.8.1.11 - tableHTML 433.8.1.12 - TableMonster 433.8.1.13 - texreg 433.8.1.14 - ztable 433.8.1.15 - apaStyle 433.8.1.16 - apaTables 433.8.1.17 - apsrtable 433.8.1.18 - DT https://www.infoworld.com/video/91607/r-tip-quick-interactive-tables https://rstudio.github.io/DT/ https://datatables.net/ 433.8.1.19 - gtsummary https://github.com/vincentarelbundock/gtsummary 433.8.2 - higher-level functionality 433.8.2.1 - finalfit https://github.com/ewenharrison/finalfit http://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/ 433.8.2.2 - janitor 433.8.2.3 - huxtable https://hughjonesd.github.io/huxtable/design-principles.html 433.8.2.4 - tables 433.8.2.5 - stargazer 433.8.2.6 - pixiedust pixiedust: Tables so Beautifully Fine-Tuned You Will Believe It’s Magic https://cran.r-project.org/web/packages/pixiedust/vignettes/pixiedust.html https://cran.r-project.org/web/packages/pixiedust/vignettes/advancedMagic.html 433.8.2.7 - reporttools 433.8.2.8 - rtable 433.8.2.9 - summarytools 433.8.2.10 - tab 433.8.2.11 - tableone 433.8.2.12 - carpenter https://cran.r-project.org/web/packages/carpenter/vignettes/carpenter.html 433.8.2.13 - dtables 433.8.2.14 - etable 433.8.2.15 - tangram tangram (grammar of tables) https://github.com/spgarbet/tangram http://htmlpreview.github.io/?https://github.com/spgarbet/tg/blob/master/vignettes/example.html https://github.com/spgarbet/tangram/issues/36 433.8.3 - pivots 433.8.3.1 - rpivotttable 433.8.4 - other 433.8.4.1 - gtable 433.8.4.2 - sjtlm https://strengejacke.github.io/sjPlot/articles/sjtlm.html 433.8.4.3 - arsenal to compare data frames: https://cran.r-project.org/web/packages/arsenal/vignettes/compare.html 433.8.4.3.1 - arsenal::paired summary statistics for a set of variables paired across two time points: https://cran.r-project.org/web/packages/arsenal/vignettes/paired.html 433.8.4.3.2 - arsenal::freqlist https://cran.r-project.org/web/packages/arsenal/vignettes/freqlist.html summary(noby, title = “Basic freqlist output”) summary(freqlist(~ arm + sex + mdquality.s, data = mockstudy, addNA = TRUE)) summary(freqlist(~arm + sex + addNA(mdquality.s), data = mockstudy)) summary(freqlist(~arm + sex + includeNA(mdquality.s, “Missing”), data = mockstudy)) withnames &lt;- freqlist(tab.ex, labelTranslations = c(&quot;Treatment Arm&quot;, &quot;Gender&quot;, &quot;LASA QOL&quot;), digits = 0) summary(withnames) 433.8.4.3.3 - arsenal::tableby https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html 433.8.4.3.4 - arsenal::modelsum https://cran.r-project.org/web/packages/arsenal/vignettes/modelsum.html 433.8.4.4 - desctable https://cran.r-project.org/web/packages/desctable/vignettes/desctable.html "],["gt.html", "Chapter 434 GT", " Chapter 434 GT https://github.com/rstudio/gt "],["sparklines.html", "Chapter 435 sparklines", " Chapter 435 sparklines R tip: Sparklines in HTML tables https://www.infoworld.com/video/91867/r-tip-sparklines-in-html-tables https://ai.google/education/ https://github.com/tensorflow/workshops https://experiments.withgoogle.com/collection/ai https://developers.google.com/machine-learning/crash-course/ https://ai.google/education/responsible-ai-practices https://research.google.com/seedbank/ https://codelabs.developers.google.com/codelabs/end-to-end-ml/index.html#0 https://regexr.com/ https://regex101.com/ "],["read-text-files-with-readtext.html", "Chapter 436 Read text files with readtext()", " Chapter 436 Read text files with readtext() https://cran.r-project.org/web/packages/readtext/vignettes/readtext_vignette.html "],["qdapregex.html", "Chapter 437 qdapRegex", " Chapter 437 qdapRegex https://github.com/trinker/qdapRegex http://trinker.github.io/qdapRegex_dev/index.html "],["stringr-2.html", "Chapter 438 stringr", " Chapter 438 stringr https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html stringr::str_view() "],["regexplain.html", "Chapter 439 RegExplain", " Chapter 439 RegExplain https://www.garrickadenbuie.com/project/regexplain/ "],["a-tidy-text-analysis-of-my-google-search-history.html", "Chapter 440 A Tidy Text Analysis of My Google Search History", " Chapter 440 A Tidy Text Analysis of My Google Search History https://www.r-bloggers.com/a-tidy-text-analysis-of-my-google-search-history/ "],["text-mining-with-r-a-tidy-approach.html", "Chapter 441 Text Mining with R A Tidy Approach", " Chapter 441 Text Mining with R A Tidy Approach https://www.tidytextmining.com/ "],["pride-and-prejudice.html", "Chapter 442 Pride and Prejudice", " Chapter 442 Pride and Prejudice https://juliasilge.com/blog/tidy-text-classification/ https://juliasilge.com/blog/if-i-loved-nlp-less/ "],["cleannlp.html", "Chapter 443 cleanNLP", " Chapter 443 cleanNLP https://statsmaths.github.io/cleanNLP/ "],["text-analysis-of-holy-books.html", "Chapter 444 Text analysis of holy books 444.1 quRan 444.2 sacred 444.3 scriptuRs", " Chapter 444 Text analysis of holy books 444.1 quRan https://github.com/andrewheiss/quRan https://github.com/andrewheiss/quRan/blob/master/data-raw/clean_data.R 444.1.1 Tidy text, parts of speech, and unique words in the Qur’an https://www.andrewheiss.com/blog/2018/12/28/tidytext-pos-arabic/ 444.2 sacred http://sacred.john-coene.com/ https://github.com/JohnCoene/sacred 444.3 scriptuRs https://github.com/andrewheiss/scriptuRs 444.3.1 Tidy text, parts of speech, and unique words in the Bible https://www.andrewheiss.com/blog/2018/12/26/tidytext-pos-john/ "],["word-associations-from-the-small-world-of-words.html", "Chapter 445 WORD ASSOCIATIONS FROM THE SMALL WORLD OF WORDS", " Chapter 445 WORD ASSOCIATIONS FROM THE SMALL WORLD OF WORDS https://juliasilge.com/blog/word-associations/ "],["section-1.html", "Chapter 446 ", " Chapter 446 slug: the-lesser-known-stars-of-the-tidyverse tags: - tidyverse - R - Code categories: [] output: html_notebook I copied this code just to learn myself. See original links below: "],["webinar-tidyverse-exploratory-analysis-emily-robinson-1.html", "Chapter 447 Webinar: Tidyverse Exploratory Analysis (Emily Robinson) 447.1 Reading in the data 447.2 Initial examination", " Chapter 447 Webinar: Tidyverse Exploratory Analysis (Emily Robinson) https://hookedondata.org/the-lesser-known-stars-of-the-tidyverse/ https://www.rstudio.com/resources/videos/the-lesser-known-stars-of-the-tidyverse/ https://github.com/robinsones/robinsones_blog/blob/master/content/post/multipleChoiceResponses.csv https://github.com/robinsones/robinsones_blog/blob/master/content/post/2018-11-16-the-lesser-known-stars-of-the-tidyverse.Rmd 447.1 Reading in the data {r eval=FALSE, include=FALSE, echo=TRUE} knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE, error = TRUE) library(tidyverse) library(magrittr) theme_set(theme_bw()) {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses_base &lt;- read.csv(&quot;data/multipleChoiceResponses.csv&quot;) {r eval=FALSE, include=FALSE, echo=TRUE} # for one column sum(is.na(multiple_choice_responses_base$Country)) {r eval=FALSE, include=FALSE, echo=TRUE} # for five columns multiple_choice_responses_base %&gt;% summarise_at(1:5, ~sum(is.na(.))) multiple_choice_responses_base %&gt;% summarise_at(vars(GenderSelect:StudentStatus), ~sum(is.na(.))) multiple_choice_responses_base %&gt;% summarise_at(vars(GenderSelect, Age), ~sum(is.na(.))) {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses_base %&gt;% count(StudentStatus) Yep. We see here we have a lot of \"\" entries instead of NAs. We can correct this with na_if from dplyr, which takes as an argument what we want to turn into NAs. We can also use %&lt;&gt;%, which is a reassignment pipe. While this is nice to save some typing, it can make it confusing when reading a script, so use with caution. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses_base %&lt;&gt;% na_if(&quot;&quot;) ## is the same as: multiple_choice_responses_base &lt;- multiple_choice_responses_base %&gt;% na_if(&quot;&quot;) Now let’s count the NAs again. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses_base %&gt;% summarise_at(1:5, ~sum(is.na(.))) And it’s fixed! How could we have avoided this all in the first place? By using {r # eadr::read_csv instead of {r # ead.csv. If you’re not familiar with ::, it’s for explicitly setting what package you’re getting the function on the right from. This is helpful in three ways: There can be name conflicts, where two packages have functions with the same name. Using :: ensures you’re getting the function you want. if you only want to use one function from a package, you can use :: to skip the library call. As long as you’ve installed the package, you don’t need to have loaded it to get the function. For teaching purposes, it’s nice to remind people where the function is coming from. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses &lt;- readr::read_csv(&quot;multipleChoiceResponses.csv&quot;) It’s definitely faster, but it seems we have some errors. Let’s inspect them. {r eval=FALSE, include=FALSE, echo=TRUE} problems(multiple_choice_responses) We see each row and column where a problem occurs. What’s happening is that {r # ead_csv uses the first 1000 rows of a column to guess its type. But in some cases, it’s guessing the column is an integer, because the first 1000 rows are whole numbers, when actually it should be double, as some entries have decimal points. We can fix this by changing the number of rows {r # ead_csv uses to guess the column type (with the guess_max argument) to the number of rows in the data set. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses &lt;- readr::read_csv(&quot;multipleChoiceResponses.csv&quot;, guess_max = nrow(multiple_choice_responses)) Error-free! 447.2 Initial examination Let’s see what we can glean from the column names themselves. I’ll only look at the first 20 since there are so many. {r eval=FALSE, include=FALSE, echo=TRUE} colnames(multiple_choice_responses) %&gt;% head(20) We can see that there were categories of questions, like “LearningPlatform,” with each platform having its own column. Now let’s take a look at our numeric columns with skimr. Skimr is a package from rOpenSci that allows you to quickly view summaries of your data. We can use select_if to select only columns where a certain condition, in this case whether it’s a numeric column, is true. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses %&gt;% select_if(is.numeric) %&gt;% skimr::skim() I love the histograms. We can quickly see from them that people self teach a lot and spend a good amount of time building models and gathering data, compared to visualizing data or working in production. Let’s see how many distinct answers we have for each question. We can use n_distinct(), a shorter and faster version of length(unique()). We’ll use summarise_all, which is the same as summarise_at except that you don’t select a group of columns and so it applies to every one in the dataset. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses %&gt;% summarise_all(n_distinct) %&gt;% select(1:10) This data would be more helpful if it was tidy and had two columns, question and num_distinct_answers. We can use tidyr::gather to change our data from “wide” to “long” format and then arrange it so we can see the columns with the most distinct answers first. If you’ve used (or are still using!) reshape2, check out tidyr; reshape2 is retired and is only updated with changes necessary for it to remain on CRAN. While not exactly equivalent, tidyr::spread replaces {r # eshape2::dcast, tidyr::separate {r # eshape2::colsplit, and tidyr::gather {r # eshape2::melt. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses %&gt;% summarise_all(n_distinct) %&gt;% tidyr::gather(question, num_distinct_answers) %&gt;% arrange(desc(num_distinct_answers)) Let’s take a look at the question with the most distinct answers, WorkMethodsSelect. {r eval=FALSE, include=FALSE, echo=TRUE} multiple_choice_responses %&gt;% count(WorkMethodsSelect, sort = TRUE) We can see this is a multiple select question, where if a person selected multiple answers they’re listed as one entry, separated by commas. Let’s tidy it up. First, let’s get rid of the NAs. We can use !is.na(WorkMethodsSelect), short for is.na(WorkMethodsSelect) == FALSE, to filter out NAs. We then use str_split, from stringr, to divide the entries up. str_split(WorkMethodsSelect, \",\") says “Take this string and split it into a list by dividing it where there are ,s.” {r eval=FALSE, include=FALSE, echo=TRUE} nested_workmethods &lt;- multiple_choice_responses %&gt;% select(WorkMethodsSelect) %&gt;% filter(!is.na(WorkMethodsSelect)) %&gt;% mutate(work_method = str_split(WorkMethodsSelect, &quot;,&quot;)) nested_workmethods %&gt;% select(work_method) Now we have a list column, with each entry in the list being one work method. We can unnest this so we can get back a tidy dataframe. {r eval=FALSE, include=FALSE, echo=TRUE} unnested_workmethods &lt;- nested_workmethods %&gt;% tidyr::unnest(work_method) %&gt;% select(work_method) unnested_workmethods Great! As a last step, let’s count this data so we can find which are the most common work methods people use. {r eval=FALSE, include=FALSE, echo=TRUE} unnested_workmethods %&gt;% count(work_method, sort = TRUE) We see the classic methods of data visualization, logistic regression, and cross-validation lead the pack. 447.2.1 Graphing Frequency of Different Work Challenges Now let’s move on to understanding what challenges people face at work. This was one of those categories where there were multiple questions asked, all having names starting with WorkChallengeFrequency and ending with the challenge (e.g “DirtyData”). We can find the relevant columns by using the dplyr select helper contains. We then use gather to tidy the data for analysis, filter for only the non-NAs, and remove the WorkChallengeFrequency from each question using stringr::str_remove. {r eval=FALSE, include=FALSE, echo=TRUE} WorkChallenges &lt;- multiple_choice_responses %&gt;% select(contains(&quot;WorkChallengeFrequency&quot;)) %&gt;% gather(question, response) %&gt;% filter(!is.na(response)) %&gt;% mutate(question = stringr::str_remove(question, &quot;WorkChallengeFrequency&quot;)) WorkChallenges Let’s make a facet bar plot, one for each question with the frequency of responses.To make the x-axis tick labels readable, we’ll change them to be vertical instead of horizontal. {r WorkChallenges_graph1, fig.width = 9, fig.height = 6} ggplot(WorkChallenges, aes(x = response)) + geom_bar() + facet_wrap(~question) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) This graph has two main problems. First, there are too many histograms for it to be really useful. But second, the order of the x-axis is wrong. We want it to go from least often to most, but instead {r # arely is in the middle. We can manually reorder the level of this variable using forcats::fct_relevel. {r WorkChallenges_graph2, fig.width = 9, fig.height = 6} WorkChallenges %&gt;% mutate(response = fct_relevel(response, &quot;Rarely&quot;, &quot;Sometimes&quot;, &quot;Often&quot;, &quot;Most of the time&quot;)) %&gt;% ggplot(aes(x = response)) + geom_bar() + facet_wrap(~question) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) Now we’ve got the x-axis in the order we want it. Let’s try dichotomizing the variable by grouping “most of the time” and “often” together as the person considering something a challenge. We can use if_else and %in%. %in% is equivalent to {r # esponse == \"Most of the time\" | response == \"Often\" and can save you a lot of typing if you have a bunch of variables to match. Grouping by the question, we can use summarise to reduce the dataset to one row per question, adding the variable perc_problem for the percentage of responses that thought something was a challenge often or most of the time. This way, we can make one graph with data for all the questions and easily compare them. {r eval=FALSE, include=FALSE, echo=TRUE} perc_problem_work_challenge &lt;- WorkChallenges %&gt;% mutate(response = if_else(response %in% c(&quot;Most of the time&quot;, &quot;Often&quot;), 1, 0)) %&gt;% group_by(question) %&gt;% summarise(perc_problem = mean(response)) {r perc_problem_work_challenge_graph, fig.width = 8, fig.height = 5} ggplot(perc_problem_work_challenge, aes(x = question, y = perc_problem)) + geom_point() + coord_flip() This is better, but it’s hard to read because the points are scattered all over the place. Although you can spot the highest one, you then have to track it back to the correct variable. And it’s also hard to tell the order of the ones in the middle. We can use forcats:fct_reorder to change the x-axis to be ordered by another variable, in this case the y-axis. While we’re at it, we can use scale_y_continuous andscales::percent to update our axis to display in percent and labs to change our axis labels. {r perc_problem_work_challenge_graph2, fig.width = 8, fig.height = 5} ggplot(perc_problem_work_challenge, aes(x = perc_problem, y = fct_reorder(question, perc_problem))) + geom_point() + scale_x_continuous(labels = scales::percent) + labs(y = &quot;Work Challenge&quot;, x = &quot;Percentage of people encountering challenge frequently&quot;) Much better! You can now easily tell which work challenges are encountered most frequently. 447.2.2 Conclusion I’m a big advocate of using and teaching the tidyverse for data analysis and visualization in R (it runs in the family). In addition to doing these talks, I’ve released a DataCamp course on Categorical Data in the Tidyverse. I walk through some of the functions in this course and more from forcats. It’s part of the new Tidyverse Fundamentals skill track, which is suitable for people are new to R or those looking to switch to the tidyverse. Check it out and let us know what you think. Some other good resources for learning the tidyverse are Hadley Wickham and Garrett Grolemund’s free R for Data Science book and RStudio’s cheat sheets. If you have questions, I recommend using the tidyverse section of RStudio community and/or the #rstats hashtag on Twitter. If you do, make sure you include a reproducible example (see best practices here) with the reprex package! "],["tidyxl.html", "Chapter 448 tidyxl", " Chapter 448 tidyxl https://github.com/nacnudus/tidyxl "],["tidycells.html", "Chapter 449 tidycells", " Chapter 449 tidycells "],["introduction-5.html", "Chapter 450 Introduction", " Chapter 450 Introduction The Tufte handout style is a style that Edward Tufte uses in his books and handouts. Tufte’s style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography. This style has been implemented in LaTeX and HTML/CSS2, respectively. We have ported both implementations into the tufte package. If you want LaTeX/PDF output, you may use the tufte_handout format for handouts, and tufte_book for books. For HTML output, use tufte_html. These formats can be either specified in the YAML metadata at the beginning of an R Markdown document (see an example below), or passed to the {r # markdown::render() function. See Allaire et al. (2020) for more information about rmarkdown. --- title: &quot;An Example Using the Tufte Style&quot; author: &quot;John Smith&quot; output: tufte::tufte_handout: default tufte::tufte_html: default --- There are two goals of this package: To produce both PDF and HTML output with similar styles from the same R Markdown document; To provide simple syntax to write elements of the Tufte style such as side notes and margin figures, e.g. when you want a margin figure, all you need to do is the chunk option fig.margin = TRUE, and we will take care of the details for you, so you never need to think about \\begin{marginfigure} \\end{marginfigure} or &lt;span class=\"marginfigure\"&gt; &lt;/span&gt;; the LaTeX and HTML code under the hood may be complicated, but you never need to learn or write such code. If you have any feature requests or find bugs in tufte, please do not hesitate to file them to https://github.com/rstudio/tufte/issues. For general questions, you may ask them on StackOverflow: http://stackoverflow.com/tags/rmarkdown. References "],["headings.html", "Chapter 451 Headings", " Chapter 451 Headings This style provides first and second-level headings (that is, # and ##), demonstrated in the next section. You may get unexpected output if you try to use ### and smaller headings. {r # newthought('In his later books')3, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and sets the first few words of the sentence in small caps. To accomplish this using this style, call the newthought() function in tufte in an inline R expression `{r # ` as demonstrated at the beginning of this paragraph.4 Beautiful Evidence↩︎ Note you should not assume tufte has been attached to your R session. You should either library(tufte) in your R Markdown document before you call newthought(), or use tufte::newthought().↩︎ "],["figures.html", "Chapter 452 Figures 452.1 Margin Figures 452.2 Arbitrary Margin Content 452.3 Full Width Figures 452.4 Main Column Figures", " Chapter 452 Figures 452.1 Margin Figures Images and graphics play an integral role in Tufte’s work. To place figures in the margin you can use the knitr chunk option fig.margin = TRUE. For example: library(ggplot2) mtcars2 &lt;- mtcars mtcars2$am &lt;- factor(mtcars$am, labels = c(&quot;automatic&quot;, &quot;manual&quot;)) ggplot(mtcars2, aes(hp, mpg, color = am)) + geom_point() + geom_smooth() + theme(legend.position = &quot;bottom&quot;) Figure 452.1: MPG vs horsepower, colored by transmission. Note the use of the fig.cap chunk option to provide a figure caption. You can adjust the proportions of figures using the fig.width and fig.height chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin. 452.2 Arbitrary Margin Content In fact, you can include anything in the margin using the knitr engine named marginfigure. Unlike R code chunks ```{r eval=FALSE, include=FALSE, echo=TRUE}, you write a chunk starting with ```{marginfigure} instead, then put the content in the chunk. See an example on the right about the first fundamental theorem of calculus. We know from _the first fundamental theorem of calculus_ that for $x$ in $[a, b]$: $$\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).$$ For the sake of portability between LaTeX and HTML, you should keep the margin content as simple as possible (syntax-wise) in the marginefigure blocks. You may use simple Markdown syntax like **bold** and _italic_ text, but please refrain from using footnotes, citations, or block-level elements (e.g. blockquotes and lists) there. Note: if you set echo = TRUE in your global chunk options, you will have to add echo = TRUE to the chunk to display a margin figure, for example ```{marginfigure, echo = TRUE}. 452.3 Full Width Figures You can arrange for figures to span across the entire page by using the chunk option fig.fullwidth = TRUE. ggplot(diamonds, aes(carat, price)) + geom_smooth() + facet_grid(~cut) Figure 452.2: A full width figure. Other chunk options related to figures can still be used, such as fig.width, fig.cap, out.width, and so on. For full width figures, usually fig.width is large and fig.height is small. In the above example, the plot size is \\(10 \\times 2\\). 452.4 Main Column Figures Besides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output. ggplot(diamonds, aes(cut, price)) + geom_boxplot() Figure 452.3: A figure in the main column. "],["sidenotes.html", "Chapter 453 Sidenotes", " Chapter 453 Sidenotes One of the most prominent and distinctive features of this style is the extensive use of sidenotes. There is a wide margin to provide ample room for sidenotes and small figures. Any use of a footnote will automatically be converted to a sidenote.5 If you’d like to place ancillary information in the margin without the sidenote mark (the superscript number), you can use the margin_note() function from tufte in an inline R expression. {r # margin_note(\"This is a margin note. Notice that there is no number preceding the note.\") This function does not process the text with Pandoc, so Markdown syntax will not work here. If you need to write anything in Markdown syntax, please use the marginfigure block described previously. This is a sidenote that was entered using a footnote.↩︎ "],["references.html", "Chapter 454 References", " Chapter 454 References References can be displayed as margin notes for HTML output. For example, we can cite R here (R Core Team 2020). To enable this feature, you must set link-citations: yes in the YAML metadata, and the version of pandoc-citeproc should be at least 0.7.2. You can always install your own version of Pandoc from http://pandoc.org/installing.html if the version is not sufficient. To check the version of pandoc-citeproc in your system, you may run this in R: If your version of pandoc-citeproc is too low, or you did not set link-citations: yes in YAML, references in the HTML output will be placed at the end of the output document. References "],["tables-6.html", "Chapter 455 Tables", " Chapter 455 Tables You can use the kable() function from the knitr package to format tables that integrate well with the rest of the Tufte handout style. The table captions are placed in the margin like figures in the HTML output. "],["block-quotes.html", "Chapter 456 Block Quotes", " Chapter 456 Block Quotes We know from the Markdown syntax that paragraphs that start with &gt; are converted to block quotes. If you want to add a right-aligned footer for the quote, you may use the function quote_footer() from tufte in an inline R expression. Here is an example: “If it weren’t for my lawyer, I’d still be in prison. It went a lot faster with two people digging.” {r # tufte::quote_footer('--- Joe Martin') Without using quote_footer(), it looks like this (the second line is just a normal paragraph): “Great people talk about ideas, average people talk about things, and small people talk about wine.” — Fran Lebowitz "],["responsiveness.html", "Chapter 457 Responsiveness", " Chapter 457 Responsiveness The HTML page is responsive in the sense that when the page width is smaller than 760px, sidenotes and margin notes will be hidden by default. For sidenotes, you can click their numbers (the superscripts) to toggle their visibility. For margin notes, you may click the circled plus signs to toggle visibility. "],["more-examples.html", "Chapter 458 More Examples", " Chapter 458 More Examples The rest of this document consists of a few test cases to make sure everything still works well in slightly more complicated scenarios. First we generate two plots in one figure environment with the chunk option fig.show = 'hold': p &lt;- ggplot(mtcars2, aes(hp, mpg, color = am)) + geom_point() p p + geom_smooth() Figure 458.1: Two plots in one figure environment. Then two plots in separate figure environments (the code is identical to the previous code chunk, but the chunk option is the default fig.show = 'asis' now): p &lt;- ggplot(mtcars2, aes(hp, mpg, color = am)) + geom_point() p Figure 458.2: Two plots in separate figure environments (the first plot). p + geom_smooth() Figure 458.3: Two plots in separate figure environments (the second plot). You may have noticed that the two figures have different captions, and that is because we used a character vector of length 2 for the chunk option fig.cap (something like fig.cap = c('first plot', 'second plot')). Next we show multiple plots in margin figures. Similarly, two plots in the same figure environment in the margin: p p + geom_smooth(method = &quot;lm&quot;) Figure 458.4: Two plots in one figure environment in the margin. Then two plots from the same code chunk placed in different figure environments: knitr::kable(head(iris, 15)) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa p Figure 458.5: Two plots in separate figure environments in the margin (the first plot). knitr::kable(head(iris, 12)) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa p + geom_smooth(method = &quot;lm&quot;) Figure 458.6: Two plots in separate figure environments in the margin (the second plot). knitr::kable(head(iris, 5)) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa We blended some tables in the above code chunk only as placeholders to make sure there is enough vertical space among the margin figures, otherwise they will be stacked tightly together. For a practical document, you should not insert too many margin figures consecutively and make the margin crowded. You do not have to assign captions to figures. We show three figures with no captions below in the margin, in the main column, and in full width, respectively. # a boxplot of weight vs transmission; this figure will be placed in the margin ggplot(mtcars2, aes(am, wt)) + geom_boxplot() + coord_flip() # a figure in the main column p &lt;- ggplot(mtcars, aes(wt, hp)) + geom_point() p # a fullwidth figure p + geom_smooth(method = &quot;lm&quot;) + facet_grid(~gear) "],["some-notes-on-tufte-css.html", "Chapter 459 Some Notes on Tufte CSS", " Chapter 459 Some Notes on Tufte CSS There are a few other things in Tufte CSS that we have not mentioned so far. If you prefer {r # sans_serif('sans-serif fonts'), use the function sans_serif() in tufte. For epigraphs, you may use a pair of underscores to make the paragraph italic in a block quote, e.g. I can win an argument on any topic, against any opponent. People know this, and steer clear of me at parties. Often, as a sign of their great respect, they don’t even invite me. {r # quote_footer('--- Dave Barry') We hope you will enjoy the simplicity of R Markdown and this R package, and we sincerely thank the authors of the Tufte-CSS and Tufte-LaTeX projects for developing the beautiful CSS and LaTeX classes. Our tufte package would not have been possible without their heavy lifting. You can turn on/off some features of the Tufte style in HTML output. The default features enabled are: output: tufte::tufte_html: tufte_features: [&quot;fonts&quot;, &quot;background&quot;, &quot;italics&quot;] If you do not want the page background to be lightyellow, you can remove background from tufte_features. You can also customize the style of the HTML page via a CSS file. For example, if you do not want the subtitle to be italic, you can define h3.subtitle em { font-style: normal; } in, say, a CSS file my_style.css (under the same directory of your Rmd document), and apply it to your HTML output via the css option, e.g., output: tufte::tufte_html: tufte_features: [&quot;fonts&quot;, &quot;background&quot;] css: &quot;my_style.css&quot; There is also a variant of the Tufte style in HTML/CSS named “Envisoned CSS”. This style can be used by specifying the argument tufte_variant = 'envisioned' in tufte_html()6, e.g. output: tufte::tufte_html: tufte_variant: &quot;envisioned&quot; To see the R Markdown source of this example document, you may follow this link to Github, use the wizard in RStudio IDE (File -&gt; New File -&gt; R Markdown -&gt; From Template), or open the Rmd file in the package: This document is also available in Chinese, and its envisioned style can be found here. Exploratory Data Analysis &amp; Data Preparation with ‘funModeling’ https://blog.datascienceheroes.com/exploratory-data-analysis-data-preparation-with-funmodeling/ Content for “Wrangling data in the Tidyverse” - a tutorial given at useR! 2018 https://github.com/drsimonj/tidyverse_tutorial-useR2018 Teaching R to New Users - From tapply to the Tidyverse https://simplystatistics.org/2018/07/12/use-r-keynote-2018/ jstor An R Package for Analysing Scientific Articles https://speakerdeck.com/tklebel/jstor-an-r-package-for-analysing-scientific-articles?slide=25 workshop in survival analysis using R https://github.com/dave-harrington/survival_workshop https://github.com/dave-harrington/eventtimedata Teaching R to New Users - From tapply to the Tidyverse https://simplystatistics.org/2018/07/12/use-r-keynote-2018/ Data Driven Decision Making (D3M) http://www.vishalsingh.org/teaching/#content Tidymodeling Titanic Tragedy https://cdn.rawgit.com/ClaytonJY/tidymodels-talk/145e6574/slides.html#1 Disease risk modelling and visualization using R https://paula-moraga.github.io/teaching/ Creating a Geodemographic Classification Using K-means Clustering in R https://data.cdrc.ac.uk/tutorial/creating-a-geodemographic-classification-using-k-means-clustering-in-r Advanced R http://adv-r.had.co.nz/ How to use R for matching samples (propensity score) https://datascienceplus.com/how-to-use-r-for-matching-samples-propensity-score/ https://rtweet.info/ {r include=FALSE, eval=FALSE, echo = TRUE} library(tidyverse) library(rtweet) The actual Envisioned CSS was not used in the tufte package. We only changed the fonts, background color, and text color based on the default Tufte style.↩︎ "],["get-data.html", "Chapter 460 get data", " Chapter 460 get data {r include=FALSE, eval=FALSE, echo = TRUE} gipath &lt;- rtweet::search_tweets(q = &quot;#gipath&quot;, n = 18000, include_rts = FALSE, # retryonratelimit = TRUE ) # gipath %&gt;% # select(user_id,status_id, contains(&quot;url&quot;)) %&gt;% # filter(!is.na(ext_media_url)) %&gt;% # View() "],["filter-tweet.html", "Chapter 461 filter tweet", " Chapter 461 filter tweet {r filter tweet} for (i in 1:dim(gipath)[1]) { nam &lt;- paste0(&quot;gitweetid&quot;, i) assign(nam, gipath$status_id[i]) nam2 &lt;- paste0(&quot;gitweet&quot;, i) assign(nam2, gipath[gipath$status_id==gitweetid1, ]) } "],["tweet-owner.html", "Chapter 462 tweet owner", " Chapter 462 tweet owner {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$screen_name "],["tweet-time.html", "Chapter 463 tweet time", " Chapter 463 tweet time {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$created_at "],["tweet-text.html", "Chapter 464 tweet text", " Chapter 464 tweet text {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$text "],["tweet-media.html", "Chapter 465 tweet media", " Chapter 465 tweet media {r tweet media} unlist(gitweet2$ext_media_url) {r tweet media length} length(unlist(gitweet2$ext_media_url)) {r eval=FALSE, include=FALSE, echo=TRUE} "],["download-image-read-image.html", "Chapter 466 download image, read image", " Chapter 466 download image, read image {r download image read image, error=FALSE, comment=FALSE} for (i in 1:length(unlist(gitweet2$ext_media_url))) { urls &lt;- unlist(gitweet2$ext_media_url)[i] dest &lt;- paste0(&quot;twfigure/jpeg&quot;,i,&quot;.jpg&quot;, collapse = &quot;&quot;) download.file(url = urls, destfile = dest, mode = &#39;wb&#39;) } images &lt;- capture.output( cat( for (i in 1:length(unlist(gitweet2$ext_media_url))) { cat( paste0(&quot;![](twfigure/jpeg&quot;, i, &quot;.jpg){width=30%}&quot;, collapse = &quot;&quot; ), &quot;\\n&quot; ) } , sep = &quot;\\n&quot;) ) "],["auto-output.html", "Chapter 467 Auto Output", " Chapter 467 Auto Output Tweet by: {r # gitweet2$screen_name Tweet Time: {r # gitweet2$created_at {r # gitweet2$text {r # unlist(gitweet2$hashtags) {r # unlist(gitweet2$symbols) {r # unlist(gitweet2$urls_expanded_url) {r # images {r eval=FALSE, include=FALSE, echo=TRUE} tweetbody1 &lt;- &quot;gitweet1$screen_name; gitweet1$created_at; gitweet1$text; unlist(gitweet1$hashtags); unlist(gitweet1$symbols); unlist(gitweet1$urls_expanded_url)&quot; evaluate::replay(evaluate::evaluate(tweetbody1)) {r eval=FALSE, include=FALSE, echo=TRUE} library(evaluate) s &lt;- paste(capture.output(replay(evaluate::evaluate(tweetbody1))), collapse=&quot;\\n&quot;) cat(s) {r eval=FALSE, include=FALSE, echo=TRUE} dont_print_source = function(x){ if (class(x)!=&quot;source&quot;){ cat(x) } } L &lt;- evaluate::evaluate(tweetbody1) # library(R.utils) # s3 &lt;- paste(captureOutput( # for(i in 1:length(L)) dont_print_source(L[[i]]) # ), collapse=&quot;\\n&quot;) s3 &lt;- gsub(&quot;\\\\[1]|\\&quot;&quot;, &quot;&quot;, paste(capture.output( for(i in 1:length(L)) dont_print_source(L[[i]]) ), collapse=&quot;\\n&quot;)) {r # s3 https://community.rstudio.com/t/how-to-use-an-object-rather-than-a-file-as-source-for-knitting-resolved/3057/6 {r eval=FALSE, include=FALSE, echo=TRUE} tweetAutoOutput &lt;- function(x) { } Tweet by: {r # gitweet2$screen_name Tweet Time: {r # gitweet2$created_at {r # gitweet2$text {r # unlist(gitweet2$hashtags) {r # unlist(gitweet2$symbols) {r # unlist(gitweet2$urls_expanded_url) {r # images "],["olders.html", "Chapter 468 olders", " Chapter 468 olders rtweet::get_collections(“serdarbalci”) {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1 &lt;- gipath %&gt;% filter(user_id == 3011337389) {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$user_id {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$status_id {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$created_at {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$screen_name {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$ext_media_url {r eval=FALSE, include=FALSE, echo=TRUE} length(gitweet1$ext_media_url) {r eval=FALSE, include=FALSE, echo=TRUE} imageurl1 &lt;- gitweet1$ext_media_url[[1]][1] {r eval=FALSE, include=FALSE, echo=TRUE} imageurl1 {r eval=FALSE, include=FALSE, echo=TRUE} imageurl2 &lt;- gitweet1$ext_media_url[[1]][2] {r eval=FALSE, include=FALSE, echo=TRUE} imageurl2 {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$text {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$source {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$display_text_width {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$reply_to_status_id {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$reply_to_status_id {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$reply_to_user_id {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$reply_to_screen_name {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$is_quote {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$is_retweet {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$favorite_count {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$retweet_count {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$hashtags {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$symbols {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$urls_url {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$urls_t.co {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$urls_expanded_url {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$media_url {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$media_t.co {r eval=FALSE, include=FALSE, echo=TRUE} gitweet1$media_expanded_url dene1 dene2 image 0 image 1 image 2 image 3 https://github.com/gadenbuie/tweetrmd "],["tweetrmd.html", "Chapter 469 tweetrmd 469.1 Installation 469.2 Embed a Tweet 469.3 Take a screenshot of a tweet 469.4 Customize tweet appearance", " Chapter 469 tweetrmd Easily embed Tweets anywhere R Markdown turns plain text into HTML. 469.1 Installation You can install the released version of tweetrmd from GitHub: # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;gadenbuie/tweetrmd&quot;) 469.2 Embed a Tweet {r eval=FALSE, include=FALSE, echo=TRUE} library(tweetrmd) tweet_embed(&quot;https://twitter.com/alexpghayes/status/1211748406730706944&quot;) Or if you would rather use the screen name and status id. {r eval=FALSE, include=FALSE, echo=TRUE} tweet_embed(tweet_url(&quot;alexpghayes&quot;, &quot;1211748406730706944&quot;)) 469.3 Take a screenshot of a tweet Screenshots are automatically embedded in R Markdown documents, or you can save the screenshot as a .png or .pdf file. Uses the rstudio/webshot2 package. {r screenshot, out.width=&quot;400px&quot;} tweet_screenshot(tweet_url(&quot;alexpghayes&quot;, &quot;1211748406730706944&quot;)) 469.4 Customize tweet appearance Twitter’s oembed API provides a number of options, all of which are made available for customization in tweet_embed() and tweet_screenshot(). {r screenshot-customized, out.width=&quot;300px&quot;} tweet_screenshot( tweet_url(&quot;alexpghayes&quot;, &quot;1211748406730706944&quot;), maxwidth = 300, hide_media = TRUE, theme = &quot;dark&quot; ) Note: When using tweet_embed(), you may need to add the following line to your YAML header for strict markdown output formats. yaml always_allow_html: true 469.4.1 API connection http://rtweet.info/ https://apps.twitter.com/ 469.4.2 Search Tweets 469.4.3 Stream Tweets 469.4.4 Twitter connections and user information 469.4.5 Twitter Trends 469.4.6 Post tweet via R 469.4.7 Follow via R 469.4.8 Election Analysis on Twitter 469.4.9 Graphing Tweets http://graphtweets.john-coene.com/index.html "],["a-shiny-app-with-rtweet.html", "Chapter 470 A Shiny App with rtweet", " Chapter 470 A Shiny App with rtweet https://aj17.shinyapps.io/twitteranalytics/ "],["conference-tweets.html", "Chapter 471 Conference tweets", " Chapter 471 Conference tweets https://twitter.com/APo_ORV/status/1016412207867973632 https://twitter.com/grrrck/status/959137137118646272 https://gadenbuie.shinyapps.io/rsconf_tweets/ https://github.com/gadenbuie/rsconf_tweets https://behindbars.shinyapps.io/user2018/ https://github.com/oliviergimenez/isec2018_tweet_analysis "],["twitter-article-mentions-and-citations.html", "Chapter 472 Twitter Article Mentions and Citations", " Chapter 472 Twitter Article Mentions and Citations https://github.com/dsquintana/ajp "],["twitterreport.html", "Chapter 473 twitterreport", " Chapter 473 twitterreport https://github.com/gvegayon/twitterreport "],["streamr.html", "Chapter 474 streamR", " Chapter 474 streamR https://cran.r-project.org/web/packages/streamR/ Retweet count for specific tweet https://stackoverflow.com/questions/10427147/retweet-count-for-specific-tweet "],["statquotes.html", "Chapter 475 statquotes", " Chapter 475 statquotes "],["rtweet-workshop.html", "Chapter 476 rtweet-workshop", " Chapter 476 rtweet-workshop https://github.com/mkearney/rtweet-workshop https://rtweet-workshop.mikewk.com/ "],["making-a-twitter-dashboard-with-r.html", "Chapter 477 Making a twitter dashboard with R", " Chapter 477 Making a twitter dashboard with R https://jsta.rbind.io/blog/making-a-twitter-dashboard-with-r/ https://jsta.rbind.io/tweets http://rtweet.info/articles/auth.html Visualization of Biomedical Data https://www.annualreviews.org/doi/10.1146/annurev-biodatasci-080917-013424 Regional population structures at a glance https://ikashnitsky.github.io/2018/the-lancet-paper/ Global Migration, animated with R http://blog.revolutionanalytics.com/2018/06/global-migration-animated-with-r.html Creating a Geodemographic Classification Using K-means Clustering in R https://data.cdrc.ac.uk/tutorial/creating-a-geodemographic-classification-using-k-means-clustering-in-r Tidy Eval Meets ggplot2 http://www.onceupondata.com/2018/07/06/ggplot-tidyeval/ http://serialmentor.com/dataviz/ You Can Design a Good Chart with R https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e Data to Viz https://www.data-to-viz.com/ ggpubr ggpubr: ‘ggplot2’ Based Publication Ready Plots http://www.sthda.com/english/rpkgs/ggpubr/ R Graph Gallery https://www.r-graph-gallery.com/ The Data Visualisation Catalogue https://datavizcatalogue.com/ Dataviz Project http://datavizproject.com/ Python Graph Gallery https://python-graph-gallery.com/ Financial Times Visual Vocabulary https://github.com/ft-interactive/chart-doctor/tree/master/visual-vocabulary Xenographics Weird but (sometimes) useful charts https://xeno.graphics/ https://vis.design/ Show Me Shiny Gallery of R Web Apps https://www.showmeshiny.com/ Where Work Pays: Occupations &amp; Earnings across the United States http://www.hamiltonproject.org/charts/where_work_pays_interactive You Can Design a Good Chart with R But do R users invest in design? https://towardsdatascience.com/you-can-design-a-good-chart-with-r-5d00ed7dd18e Machine Learning Results in R: one plot to rule them all! https://datascienceplus.com/machine-learning-results-one-plot-to-rule-them-all/ data visualisation applications, tools and libraries http://www.visualisingdata.com/resources/ The ultimate online collection toolbox: Combining RSelenium and Rvest - Part 1 https://www.youtube.com/watch?v=OxbvFiYxEzI https://gist.github.com/HanjoStudy/aeb331b7a277be9639f3cfb3bf875ba2 https://hanjostudy.github.io/Presentations/UseR2018/RSelenium/rselenium.html#1 https://hanjostudy.github.io/Presentations/UseR2018/Rvest/rvest.html#1 Automated Text Feature Engineering using textfeatures in R https://www.r-bloggers.com/automated-text-feature-engineering-using-textfeatures-in-r/ "],["selectorgadget.html", "Chapter 478 Selectorgadget", " Chapter 478 Selectorgadget https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html "],["polite.html", "Chapter 479 polite", " Chapter 479 polite https://github.com/dmi3kno/polite "],["introduction-to-data-science.html", "Chapter 480 Introduction to Data Science", " Chapter 480 Introduction to Data Science https://rafalab.github.io/dsbook/ "],["rstudio-education.html", "Chapter 481 RStudio Education", " Chapter 481 RStudio Education https://education.rstudio.com/ "],["statistics-in-action-with-r.html", "Chapter 482 Statistics in Action with R", " Chapter 482 Statistics in Action with R http://sia.webpopix.org/index.html "],["swirlstats.html", "Chapter 483 swirlstats", " Chapter 483 swirlstats https://swirlstats.com/ "],["data-skills-for-reproducible-science.html", "Chapter 484 Data Skills for Reproducible Science", " Chapter 484 Data Skills for Reproducible Science https://gupsych.github.io/data_skills/index.html "],["rstats-ed.html", "Chapter 485 rstats-ed", " Chapter 485 rstats-ed https://github.com/rstudio-education/rstats-ed "],["new-online-courses-psu.html", "Chapter 486 new online courses psu", " Chapter 486 new online courses psu https://newonlinecourses.science.psu.edu/statprogram/ "],["think-stats.html", "Chapter 487 Think Stats", " Chapter 487 Think Stats https://greenteapress.com/wp/think-stats-2e/ "],["statsthinking21.html", "Chapter 488 statsthinking21", " Chapter 488 statsthinking21 http://statsthinking21.org/index.html "],["rstudio-8.html", "Chapter 489 RStudio", " Chapter 489 RStudio https://www.rstudio.com/online-learning/ "],["r-statistics.html", "Chapter 490 r-statistics", " Chapter 490 r-statistics http://r-statistics.co/R-Tutorial.html "],["advanced-data-science.html", "Chapter 491 Advanced Data Science", " Chapter 491 Advanced Data Science https://jhu-advdatasci.github.io/2018/ "],["how-do-i.html", "Chapter 492 How Do I? …", " Chapter 492 How Do I? … https://smach.github.io/R4JournalismBook/HowDoI.html "],["data-management-and-manipulation-using-r.html", "Chapter 493 Data management and manipulation using R", " Chapter 493 Data management and manipulation using R https://ozanj.github.io/rclass/resources/ "],["teaching-reproducible-data-analysis-in-r.html", "Chapter 494 Teaching Reproducible Data Analysis in R", " Chapter 494 Teaching Reproducible Data Analysis in R https://gupsych.github.io/trdair_workshop/ "],["academic-websites.html", "Chapter 495 Academic Websites", " Chapter 495 Academic Websites https://gupsych.github.io/acadweb/ "],["data-skills-for-reproducible-science-1.html", "Chapter 496 Data Skills for Reproducible Science", " Chapter 496 Data Skills for Reproducible Science https://gupsych.github.io/data_skills/ "],["methodology-metascience.html", "Chapter 497 Methodology &amp; Metascience", " Chapter 497 Methodology &amp; Metascience https://gupsych.github.io/mms/ "],["causal-inference-book.html", "Chapter 498 Causal Inference Book", " Chapter 498 Causal Inference Book https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/ "],["introtor.html", "Chapter 499 IntroToR", " Chapter 499 IntroToR https://github.com/sbalci/IntroToR.git "],["youtube-collections.html", "Chapter 500 YouTube Collections", " Chapter 500 YouTube Collections Jamovi https://www.youtube.com/playlist?list=PLkk92zzyru5OAtc_ItUubaSSq6S_TGfRn Do More with R https://www.youtube.com/playlist?list=PL7D2RMSmRO9JOvPC1gbA8Mc3azvSfm8Vv https://www.youtube.com/playlist?list=PLYaGSokOr0MPz1tgwTW4JKcelhdJyUIrb Neat proofs/perspectives https://www.youtube.com/playlist?list=PLZHQObOWTQDPSKntUcMArGheySM4gL7wS Learning medical statistics with python and Jupyter notebooks https://www.youtube.com/playlist?list=PLsu0TcgLDUiIueDMfTX3322AZhdGb0_zm Data Visualization and R https://www.youtube.com/playlist?list=PLCj1LhGni3hPGy6Kj1AFxHYkKklxenO9D "],["what-they-forgot-to-teach-you-about-r.html", "Chapter 501 What They Forgot to Teach You About R", " Chapter 501 What They Forgot to Teach You About R https://whattheyforgot.org/ "],["keeping-up-to-date-with-r-news.html", "Chapter 502 Keeping up to date with R news", " Chapter 502 Keeping up to date with R news https://masalmon.eu/2019/01/25/uptodate/ "],["advanced-r-markdown-workshop.html", "Chapter 503 Advanced R Markdown Workshop", " Chapter 503 Advanced R Markdown Workshop https://arm.rbind.io/days/day1/learnr/ "],["cran-task-views.html", "Chapter 504 CRAN Task Views", " Chapter 504 CRAN Task Views https://cran.r-project.org/web/views/ "],["wikibook-r-programming.html", "Chapter 505 WikiBook R Programming", " Chapter 505 WikiBook R Programming https://en.wikibooks.org/wiki/R_Programming "],["happy-git-and-github-for-the-user-1.html", "Chapter 506 Happy Git and GitHub for the useR", " Chapter 506 Happy Git and GitHub for the useR https://happygitwithr.com https://r-bootcamp.netlify.com/ "],["how-i-use-r.html", "Chapter 507 How I Use R", " Chapter 507 How I Use R https://howiuser.com "]]
